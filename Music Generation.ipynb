{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Case-Study: Music Generation Using LSTM</u>\n",
    "This case study will deal with generating midi music using LSTM <br/>\n",
    "Reference: https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5 <br/>\n",
    "In this case study we will generate music using abc notation. ABC notation are a series of characters. By training the char-RNN we can generate new meaningful abc notation and convert it into midi format. Using following site we can convert, play and download the generated midi music https://abcjs.net/abcjs-editor.html <br/>\n",
    "<u>Data-Source</u>: I have collected data using following two sources:\n",
    "\n",
    "1. http://abc.sourceforge.net/NMD/\n",
    "2. http://trillian.mit.edu/~jc/music/book/oneills/1850/X/ <br/>\n",
    "I merged the abc notations of all the tunes into one text file which will act as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "LOG_DIR = './logs'\n",
    "MODEL_DIR = './model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(epoch, model):\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "    model.save_weights(os.path.join(MODEL_DIR, 'weights.{}.h5'.format(epoch)))\n",
    "\n",
    "def load_weights(epoch, model):\n",
    "    model.load_weights(os.path.join(MODEL_DIR, 'weights.{}.h5'.format(epoch)))\n",
    "\n",
    "def build_model(batch_size, seq_len, vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 512, batch_input_shape=(batch_size, seq_len)))\n",
    "    for i in range(3):\n",
    "        model.add(LSTM(256, return_sequences=True, stateful=True))\n",
    "        model.add(Dropout(0.2))\n",
    "    model.add(TimeDistributed(Dense(vocab_size))) \n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batches(T, vocab_size):\n",
    "    length = T.shape[0]; #129,665\n",
    "    batch_chars = int(length / BATCH_SIZE); # 8,104\n",
    "\n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, SEQ_LENGTH): # (0, 8040, 64)\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH)) # 16X64\n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, vocab_size)) # 16X64X86\n",
    "        for batch_idx in range(0, BATCH_SIZE): # (0,16)\n",
    "            for i in range(0, SEQ_LENGTH): #(0,64)\n",
    "                X[batch_idx, i] = T[batch_chars * batch_idx + start + i] # \n",
    "                Y[batch_idx, i, T[batch_chars * batch_idx + start + i + 1]] = 1\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLogger(object):\n",
    "    def __init__(self, file):\n",
    "        self.file = os.path.join(LOG_DIR, file)\n",
    "        self.epochs = 0\n",
    "        with open(self.file, 'w') as f:\n",
    "            f.write('epoch,loss,acc\\n')\n",
    "\n",
    "    def add_entry(self, loss, acc):\n",
    "        self.epochs += 1\n",
    "        s = '{},{},{}\\n'.format(self.epochs, loss, acc)\n",
    "        with open(self.file, 'a') as f:\n",
    "            f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(text, epochs, save_freq):\n",
    "\n",
    "    # character to index and vice-versa mappings\n",
    "    char_to_idx = { ch: i for (i, ch) in enumerate(sorted(list(set(text)))) }\n",
    "    print(\"Number of unique characters: \" + str(len(char_to_idx))) #86\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, 'char_to_idx.json'), 'w') as f:\n",
    "        json.dump(char_to_idx, f)\n",
    "\n",
    "    idx_to_char = { i: ch for (ch, i) in char_to_idx.items() }\n",
    "    vocab_size = len(char_to_idx)\n",
    "\n",
    "    #model_architecture\n",
    "    model = build_model(BATCH_SIZE, SEQ_LENGTH, vocab_size)\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    #Train data generation\n",
    "    T = np.asarray([char_to_idx[c] for c in text], dtype=np.int32) #convert complete text into numerical indices\n",
    "\n",
    "    print(\"Length of text:\" + str(T.size)) #129,665\n",
    "\n",
    "    steps_per_epoch = (len(text) / BATCH_SIZE - 1) / SEQ_LENGTH  \n",
    "\n",
    "    log = TrainLogger('training_log.csv')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('\\nEpoch {}/{}'.format(epoch + 1, epochs))\n",
    "        \n",
    "        losses, accs = [], []\n",
    "\n",
    "        for i, (X, Y) in enumerate(read_batches(T, vocab_size)):\n",
    "            \n",
    "            #print(X);\n",
    "            loss, acc = model.train_on_batch(X, Y)\n",
    "            print('Batch {}: loss = {}, acc = {}'.format(i + 1, loss, acc))\n",
    "            losses.append(loss)\n",
    "            accs.append(acc)\n",
    "\n",
    "        log.add_entry(np.average(losses), np.average(accs))\n",
    "\n",
    "        if (epoch + 1) % save_freq == 0:\n",
    "            save_weights(epoch + 1, model)\n",
    "            print('Saved checkpoint to', 'weights.{}.h5'.format(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 86\n",
      "WARNING:tensorflow:From C:\\Users\\prateeksood\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\prateeksood\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (16, 64, 512)             44032     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (16, 64, 256)             787456    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (16, 64, 86)              22102     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (16, 64, 86)              0         \n",
      "=================================================================\n",
      "Total params: 1,904,214\n",
      "Trainable params: 1,904,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Length of text:129665\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\prateeksood\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\prateeksood\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Batch 1: loss = 4.454503059387207, acc = 0.0078125\n",
      "Batch 2: loss = 4.441534519195557, acc = 0.1484375\n",
      "Batch 3: loss = 4.417881965637207, acc = 0.1142578125\n",
      "Batch 4: loss = 4.336363792419434, acc = 0.1455078125\n",
      "Batch 5: loss = 4.054615020751953, acc = 0.1611328125\n",
      "Batch 6: loss = 3.792966365814209, acc = 0.142578125\n",
      "Batch 7: loss = 3.727830648422241, acc = 0.138671875\n",
      "Batch 8: loss = 3.6554133892059326, acc = 0.1044921875\n",
      "Batch 9: loss = 3.699862003326416, acc = 0.0791015625\n",
      "Batch 10: loss = 3.6141953468322754, acc = 0.0791015625\n",
      "Batch 11: loss = 3.4861953258514404, acc = 0.08984375\n",
      "Batch 12: loss = 3.482163906097412, acc = 0.13671875\n",
      "Batch 13: loss = 3.5340304374694824, acc = 0.142578125\n",
      "Batch 14: loss = 3.477492332458496, acc = 0.1533203125\n",
      "Batch 15: loss = 3.548708915710449, acc = 0.1455078125\n",
      "Batch 16: loss = 3.437950611114502, acc = 0.1552734375\n",
      "Batch 17: loss = 3.348702907562256, acc = 0.1708984375\n",
      "Batch 18: loss = 3.2896742820739746, acc = 0.1669921875\n",
      "Batch 19: loss = 3.4997644424438477, acc = 0.1455078125\n",
      "Batch 20: loss = 3.4706029891967773, acc = 0.1259765625\n",
      "Batch 21: loss = 3.4823594093322754, acc = 0.1240234375\n",
      "Batch 22: loss = 3.44356632232666, acc = 0.1298828125\n",
      "Batch 23: loss = 3.2362968921661377, acc = 0.173828125\n",
      "Batch 24: loss = 3.3875184059143066, acc = 0.162109375\n",
      "Batch 25: loss = 3.373823642730713, acc = 0.1591796875\n",
      "Batch 26: loss = 3.382546901702881, acc = 0.1494140625\n",
      "Batch 27: loss = 3.1324191093444824, acc = 0.19140625\n",
      "Batch 28: loss = 3.2605719566345215, acc = 0.1708984375\n",
      "Batch 29: loss = 3.376251697540283, acc = 0.1455078125\n",
      "Batch 30: loss = 3.317241668701172, acc = 0.14453125\n",
      "Batch 31: loss = 3.2217307090759277, acc = 0.16015625\n",
      "Batch 32: loss = 3.3244292736053467, acc = 0.1416015625\n",
      "Batch 33: loss = 3.2526769638061523, acc = 0.162109375\n",
      "Batch 34: loss = 3.250303268432617, acc = 0.1494140625\n",
      "Batch 35: loss = 3.189824104309082, acc = 0.1650390625\n",
      "Batch 36: loss = 3.3604700565338135, acc = 0.142578125\n",
      "Batch 37: loss = 3.29506254196167, acc = 0.125\n",
      "Batch 38: loss = 3.2566747665405273, acc = 0.1376953125\n",
      "Batch 39: loss = 3.2482802867889404, acc = 0.1455078125\n",
      "Batch 40: loss = 3.2345399856567383, acc = 0.1552734375\n",
      "Batch 41: loss = 3.2318642139434814, acc = 0.1513671875\n",
      "Batch 42: loss = 3.0984721183776855, acc = 0.1806640625\n",
      "Batch 43: loss = 3.1332075595855713, acc = 0.1728515625\n",
      "Batch 44: loss = 3.2547597885131836, acc = 0.166015625\n",
      "Batch 45: loss = 3.2621703147888184, acc = 0.1591796875\n",
      "Batch 46: loss = 3.1732194423675537, acc = 0.169921875\n",
      "Batch 47: loss = 3.195558547973633, acc = 0.16015625\n",
      "Batch 48: loss = 3.127603054046631, acc = 0.1796875\n",
      "Batch 49: loss = 3.269400119781494, acc = 0.14453125\n",
      "Batch 50: loss = 3.1637821197509766, acc = 0.1669921875\n",
      "Batch 51: loss = 3.1614034175872803, acc = 0.16015625\n",
      "Batch 52: loss = 3.12201189994812, acc = 0.1669921875\n",
      "Batch 53: loss = 3.1851840019226074, acc = 0.146484375\n",
      "Batch 54: loss = 3.2653884887695312, acc = 0.14453125\n",
      "Batch 55: loss = 3.28115177154541, acc = 0.150390625\n",
      "Batch 56: loss = 3.146787643432617, acc = 0.1474609375\n",
      "Batch 57: loss = 3.1322450637817383, acc = 0.1728515625\n",
      "Batch 58: loss = 3.20979642868042, acc = 0.14453125\n",
      "Batch 59: loss = 3.2610793113708496, acc = 0.142578125\n",
      "Batch 60: loss = 3.1587185859680176, acc = 0.154296875\n",
      "Batch 61: loss = 3.1902694702148438, acc = 0.158203125\n",
      "Batch 62: loss = 3.079381227493286, acc = 0.1806640625\n",
      "Batch 63: loss = 3.222827434539795, acc = 0.1552734375\n",
      "Batch 64: loss = 3.18686580657959, acc = 0.154296875\n",
      "Batch 65: loss = 3.073155164718628, acc = 0.1708984375\n",
      "Batch 66: loss = 3.0979766845703125, acc = 0.166015625\n",
      "Batch 67: loss = 3.1670031547546387, acc = 0.154296875\n",
      "Batch 68: loss = 3.173853635787964, acc = 0.150390625\n",
      "Batch 69: loss = 3.0962142944335938, acc = 0.16796875\n",
      "Batch 70: loss = 3.013038158416748, acc = 0.185546875\n",
      "Batch 71: loss = 3.130220890045166, acc = 0.1787109375\n",
      "Batch 72: loss = 3.1543822288513184, acc = 0.177734375\n",
      "Batch 73: loss = 3.057253122329712, acc = 0.19140625\n",
      "Batch 74: loss = 2.9778859615325928, acc = 0.197265625\n",
      "Batch 75: loss = 2.9623656272888184, acc = 0.1875\n",
      "Batch 76: loss = 3.0315675735473633, acc = 0.201171875\n",
      "Batch 77: loss = 2.969334363937378, acc = 0.20703125\n",
      "Batch 78: loss = 2.927837610244751, acc = 0.2021484375\n",
      "Batch 79: loss = 2.95853328704834, acc = 0.2158203125\n",
      "Batch 80: loss = 2.817995548248291, acc = 0.2158203125\n",
      "Batch 81: loss = 3.0413899421691895, acc = 0.1953125\n",
      "Batch 82: loss = 3.102046251296997, acc = 0.1875\n",
      "Batch 83: loss = 2.9526429176330566, acc = 0.2080078125\n",
      "Batch 84: loss = 2.942518949508667, acc = 0.21484375\n",
      "Batch 85: loss = 2.806856632232666, acc = 0.234375\n",
      "Batch 86: loss = 2.9767117500305176, acc = 0.2021484375\n",
      "Batch 87: loss = 3.117368221282959, acc = 0.1875\n",
      "Batch 88: loss = 2.952313184738159, acc = 0.2275390625\n",
      "Batch 89: loss = 3.005091428756714, acc = 0.1845703125\n",
      "Batch 90: loss = 3.0511698722839355, acc = 0.2138671875\n",
      "Batch 91: loss = 2.9128005504608154, acc = 0.2099609375\n",
      "Batch 92: loss = 2.924478054046631, acc = 0.2138671875\n",
      "Batch 93: loss = 2.960451602935791, acc = 0.19921875\n",
      "Batch 94: loss = 2.857905387878418, acc = 0.228515625\n",
      "Batch 95: loss = 2.8459739685058594, acc = 0.2216796875\n",
      "Batch 96: loss = 2.802832841873169, acc = 0.2314453125\n",
      "Batch 97: loss = 2.96382999420166, acc = 0.177734375\n",
      "Batch 98: loss = 2.9436986446380615, acc = 0.1953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 99: loss = 2.756934642791748, acc = 0.2353515625\n",
      "Batch 100: loss = 2.726947784423828, acc = 0.263671875\n",
      "Batch 101: loss = 2.920135498046875, acc = 0.2177734375\n",
      "Batch 102: loss = 2.9779295921325684, acc = 0.2001953125\n",
      "Batch 103: loss = 2.8829305171966553, acc = 0.208984375\n",
      "Batch 104: loss = 2.7745485305786133, acc = 0.234375\n",
      "Batch 105: loss = 2.702662467956543, acc = 0.23828125\n",
      "Batch 106: loss = 2.7654964923858643, acc = 0.234375\n",
      "Batch 107: loss = 2.806772232055664, acc = 0.2294921875\n",
      "Batch 108: loss = 2.701447010040283, acc = 0.2548828125\n",
      "Batch 109: loss = 2.624694347381592, acc = 0.24609375\n",
      "Batch 110: loss = 2.764573097229004, acc = 0.23046875\n",
      "Batch 111: loss = 2.769519805908203, acc = 0.2646484375\n",
      "Batch 112: loss = 2.746000051498413, acc = 0.2578125\n",
      "Batch 113: loss = 2.721895694732666, acc = 0.24609375\n",
      "Batch 114: loss = 2.8626604080200195, acc = 0.2216796875\n",
      "Batch 115: loss = 2.802711248397827, acc = 0.2451171875\n",
      "Batch 116: loss = 2.766936779022217, acc = 0.244140625\n",
      "Batch 117: loss = 2.889815092086792, acc = 0.2255859375\n",
      "Batch 118: loss = 2.7386412620544434, acc = 0.2451171875\n",
      "Batch 119: loss = 2.651453971862793, acc = 0.2734375\n",
      "Batch 120: loss = 2.7275166511535645, acc = 0.259765625\n",
      "Batch 121: loss = 2.63338041305542, acc = 0.271484375\n",
      "Batch 122: loss = 2.7765283584594727, acc = 0.2265625\n",
      "Batch 123: loss = 2.7044496536254883, acc = 0.2490234375\n",
      "Batch 124: loss = 2.5993876457214355, acc = 0.2841796875\n",
      "Batch 125: loss = 2.570192337036133, acc = 0.2890625\n",
      "Batch 126: loss = 2.740506649017334, acc = 0.255859375\n",
      "\n",
      "Epoch 2/100\n",
      "Batch 1: loss = 2.933310031890869, acc = 0.255859375\n",
      "Batch 2: loss = 2.508197546005249, acc = 0.3134765625\n",
      "Batch 3: loss = 2.728242874145508, acc = 0.2490234375\n",
      "Batch 4: loss = 2.5509989261627197, acc = 0.2958984375\n",
      "Batch 5: loss = 2.576895236968994, acc = 0.3046875\n",
      "Batch 6: loss = 2.662065029144287, acc = 0.265625\n",
      "Batch 7: loss = 2.6845405101776123, acc = 0.255859375\n",
      "Batch 8: loss = 2.5229601860046387, acc = 0.2880859375\n",
      "Batch 9: loss = 2.6079835891723633, acc = 0.271484375\n",
      "Batch 10: loss = 2.4285969734191895, acc = 0.3037109375\n",
      "Batch 11: loss = 2.4772510528564453, acc = 0.3203125\n",
      "Batch 12: loss = 2.5251920223236084, acc = 0.330078125\n",
      "Batch 13: loss = 2.529672622680664, acc = 0.2939453125\n",
      "Batch 14: loss = 2.4188828468322754, acc = 0.3212890625\n",
      "Batch 15: loss = 2.535099506378174, acc = 0.3046875\n",
      "Batch 16: loss = 2.4575188159942627, acc = 0.3095703125\n",
      "Batch 17: loss = 2.4535844326019287, acc = 0.3154296875\n",
      "Batch 18: loss = 2.4422824382781982, acc = 0.314453125\n",
      "Batch 19: loss = 2.5167741775512695, acc = 0.2998046875\n",
      "Batch 20: loss = 2.436342239379883, acc = 0.322265625\n",
      "Batch 21: loss = 2.523261547088623, acc = 0.3125\n",
      "Batch 22: loss = 2.441556930541992, acc = 0.2998046875\n",
      "Batch 23: loss = 2.267686128616333, acc = 0.369140625\n",
      "Batch 24: loss = 2.4210076332092285, acc = 0.326171875\n",
      "Batch 25: loss = 2.357278347015381, acc = 0.3203125\n",
      "Batch 26: loss = 2.337602138519287, acc = 0.3427734375\n",
      "Batch 27: loss = 2.23048996925354, acc = 0.3583984375\n",
      "Batch 28: loss = 2.2261452674865723, acc = 0.37109375\n",
      "Batch 29: loss = 2.320119857788086, acc = 0.35546875\n",
      "Batch 30: loss = 2.3195247650146484, acc = 0.3779296875\n",
      "Batch 31: loss = 2.3468775749206543, acc = 0.361328125\n",
      "Batch 32: loss = 2.4724578857421875, acc = 0.318359375\n",
      "Batch 33: loss = 2.360668182373047, acc = 0.345703125\n",
      "Batch 34: loss = 2.2962143421173096, acc = 0.3408203125\n",
      "Batch 35: loss = 2.2647547721862793, acc = 0.373046875\n",
      "Batch 36: loss = 2.456726312637329, acc = 0.3349609375\n",
      "Batch 37: loss = 2.433284282684326, acc = 0.3212890625\n",
      "Batch 38: loss = 2.3539743423461914, acc = 0.3388671875\n",
      "Batch 39: loss = 2.2568910121917725, acc = 0.3662109375\n",
      "Batch 40: loss = 2.2050979137420654, acc = 0.3759765625\n",
      "Batch 41: loss = 2.2077698707580566, acc = 0.36328125\n",
      "Batch 42: loss = 2.07836651802063, acc = 0.40625\n",
      "Batch 43: loss = 2.1103920936584473, acc = 0.3974609375\n",
      "Batch 44: loss = 2.2795639038085938, acc = 0.341796875\n",
      "Batch 45: loss = 2.201262950897217, acc = 0.3662109375\n",
      "Batch 46: loss = 2.1305599212646484, acc = 0.3779296875\n",
      "Batch 47: loss = 2.156315326690674, acc = 0.375\n",
      "Batch 48: loss = 2.039071559906006, acc = 0.3720703125\n",
      "Batch 49: loss = 2.2385196685791016, acc = 0.3564453125\n",
      "Batch 50: loss = 2.1013078689575195, acc = 0.3876953125\n",
      "Batch 51: loss = 2.1365084648132324, acc = 0.3798828125\n",
      "Batch 52: loss = 2.148700714111328, acc = 0.390625\n",
      "Batch 53: loss = 2.2454938888549805, acc = 0.3515625\n",
      "Batch 54: loss = 2.2739524841308594, acc = 0.3388671875\n",
      "Batch 55: loss = 2.327214002609253, acc = 0.322265625\n",
      "Batch 56: loss = 2.0753211975097656, acc = 0.3740234375\n",
      "Batch 57: loss = 2.0824594497680664, acc = 0.3837890625\n",
      "Batch 58: loss = 2.1692051887512207, acc = 0.361328125\n",
      "Batch 59: loss = 2.2013468742370605, acc = 0.3525390625\n",
      "Batch 60: loss = 2.0876522064208984, acc = 0.4013671875\n",
      "Batch 61: loss = 2.2968692779541016, acc = 0.359375\n",
      "Batch 62: loss = 2.135754346847534, acc = 0.3681640625\n",
      "Batch 63: loss = 2.297604560852051, acc = 0.33984375\n",
      "Batch 64: loss = 2.088679313659668, acc = 0.39453125\n",
      "Batch 65: loss = 2.0248475074768066, acc = 0.421875\n",
      "Batch 66: loss = 2.062277317047119, acc = 0.41796875\n",
      "Batch 67: loss = 2.1533663272857666, acc = 0.388671875\n",
      "Batch 68: loss = 2.100597381591797, acc = 0.4111328125\n",
      "Batch 69: loss = 2.0100603103637695, acc = 0.40234375\n",
      "Batch 70: loss = 2.0863077640533447, acc = 0.4169921875\n",
      "Batch 71: loss = 2.0667552947998047, acc = 0.40625\n",
      "Batch 72: loss = 2.110131025314331, acc = 0.3935546875\n",
      "Batch 73: loss = 2.048692464828491, acc = 0.4150390625\n",
      "Batch 74: loss = 1.9540247917175293, acc = 0.435546875\n",
      "Batch 75: loss = 1.9833534955978394, acc = 0.4169921875\n",
      "Batch 76: loss = 2.0423874855041504, acc = 0.412109375\n",
      "Batch 77: loss = 1.9344911575317383, acc = 0.4306640625\n",
      "Batch 78: loss = 1.892246961593628, acc = 0.443359375\n",
      "Batch 79: loss = 1.854920506477356, acc = 0.458984375\n",
      "Batch 80: loss = 1.7346253395080566, acc = 0.453125\n",
      "Batch 81: loss = 1.9529163837432861, acc = 0.421875\n",
      "Batch 82: loss = 2.0111989974975586, acc = 0.4375\n",
      "Batch 83: loss = 1.9285328388214111, acc = 0.42578125\n",
      "Batch 84: loss = 1.8820135593414307, acc = 0.4658203125\n",
      "Batch 85: loss = 1.7928433418273926, acc = 0.4482421875\n",
      "Batch 86: loss = 2.0724411010742188, acc = 0.4013671875\n",
      "Batch 87: loss = 2.1325061321258545, acc = 0.4072265625\n",
      "Batch 88: loss = 2.089052438735962, acc = 0.4169921875\n",
      "Batch 89: loss = 2.1735892295837402, acc = 0.3701171875\n",
      "Batch 90: loss = 2.19057559967041, acc = 0.421875\n",
      "Batch 91: loss = 1.9531176090240479, acc = 0.4375\n",
      "Batch 92: loss = 1.9307221174240112, acc = 0.41796875\n",
      "Batch 93: loss = 1.935037612915039, acc = 0.435546875\n",
      "Batch 94: loss = 1.885148048400879, acc = 0.4462890625\n",
      "Batch 95: loss = 1.856809377670288, acc = 0.4365234375\n",
      "Batch 96: loss = 1.9143600463867188, acc = 0.43359375\n",
      "Batch 97: loss = 2.068535327911377, acc = 0.369140625\n",
      "Batch 98: loss = 2.0118255615234375, acc = 0.43359375\n",
      "Batch 99: loss = 1.8768246173858643, acc = 0.4462890625\n",
      "Batch 100: loss = 1.8027803897857666, acc = 0.4501953125\n",
      "Batch 101: loss = 2.107447624206543, acc = 0.390625\n",
      "Batch 102: loss = 2.1652655601501465, acc = 0.3759765625\n",
      "Batch 103: loss = 2.0425500869750977, acc = 0.400390625\n",
      "Batch 104: loss = 1.941725254058838, acc = 0.4326171875\n",
      "Batch 105: loss = 1.8840553760528564, acc = 0.4384765625\n",
      "Batch 106: loss = 1.989612340927124, acc = 0.41015625\n",
      "Batch 107: loss = 1.9212815761566162, acc = 0.42578125\n",
      "Batch 108: loss = 1.8669712543487549, acc = 0.43359375\n",
      "Batch 109: loss = 1.818812370300293, acc = 0.455078125\n",
      "Batch 110: loss = 1.9459964036941528, acc = 0.435546875\n",
      "Batch 111: loss = 2.071324348449707, acc = 0.4306640625\n",
      "Batch 112: loss = 1.9892067909240723, acc = 0.4306640625\n",
      "Batch 113: loss = 1.8885536193847656, acc = 0.4345703125\n",
      "Batch 114: loss = 2.012024164199829, acc = 0.431640625\n",
      "Batch 115: loss = 2.026549816131592, acc = 0.427734375\n",
      "Batch 116: loss = 1.9702519178390503, acc = 0.4306640625\n",
      "Batch 117: loss = 2.0305237770080566, acc = 0.4345703125\n",
      "Batch 118: loss = 1.8922512531280518, acc = 0.435546875\n",
      "Batch 119: loss = 1.8796839714050293, acc = 0.4296875\n",
      "Batch 120: loss = 1.9727897644042969, acc = 0.423828125\n",
      "Batch 121: loss = 1.83181893825531, acc = 0.447265625\n",
      "Batch 122: loss = 2.025282144546509, acc = 0.3955078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 123: loss = 1.943406581878662, acc = 0.4248046875\n",
      "Batch 124: loss = 1.9015250205993652, acc = 0.43359375\n",
      "Batch 125: loss = 1.8292503356933594, acc = 0.4599609375\n",
      "Batch 126: loss = 2.02077579498291, acc = 0.40625\n",
      "\n",
      "Epoch 3/100\n",
      "Batch 1: loss = 2.4512686729431152, acc = 0.361328125\n",
      "Batch 2: loss = 1.8895479440689087, acc = 0.4423828125\n",
      "Batch 3: loss = 2.062023162841797, acc = 0.4208984375\n",
      "Batch 4: loss = 1.849985957145691, acc = 0.45703125\n",
      "Batch 5: loss = 1.981330156326294, acc = 0.416015625\n",
      "Batch 6: loss = 2.057020664215088, acc = 0.4228515625\n",
      "Batch 7: loss = 2.091796875, acc = 0.416015625\n",
      "Batch 8: loss = 1.8745825290679932, acc = 0.462890625\n",
      "Batch 9: loss = 1.9244987964630127, acc = 0.462890625\n",
      "Batch 10: loss = 1.7572044134140015, acc = 0.4951171875\n",
      "Batch 11: loss = 1.8536360263824463, acc = 0.46484375\n",
      "Batch 12: loss = 2.021289825439453, acc = 0.4462890625\n",
      "Batch 13: loss = 1.9408237934112549, acc = 0.4423828125\n",
      "Batch 14: loss = 1.8511977195739746, acc = 0.4521484375\n",
      "Batch 15: loss = 1.9107320308685303, acc = 0.4501953125\n",
      "Batch 16: loss = 1.9672579765319824, acc = 0.4384765625\n",
      "Batch 17: loss = 1.9071049690246582, acc = 0.455078125\n",
      "Batch 18: loss = 1.9951062202453613, acc = 0.4169921875\n",
      "Batch 19: loss = 2.0288991928100586, acc = 0.419921875\n",
      "Batch 20: loss = 1.857970952987671, acc = 0.4541015625\n",
      "Batch 21: loss = 2.0281929969787598, acc = 0.412109375\n",
      "Batch 22: loss = 1.8751659393310547, acc = 0.44921875\n",
      "Batch 23: loss = 1.8317019939422607, acc = 0.4716796875\n",
      "Batch 24: loss = 1.9069383144378662, acc = 0.435546875\n",
      "Batch 25: loss = 1.8212451934814453, acc = 0.47265625\n",
      "Batch 26: loss = 1.7936177253723145, acc = 0.474609375\n",
      "Batch 27: loss = 1.7716503143310547, acc = 0.47265625\n",
      "Batch 28: loss = 1.7392524480819702, acc = 0.470703125\n",
      "Batch 29: loss = 1.761765480041504, acc = 0.48046875\n",
      "Batch 30: loss = 1.8202462196350098, acc = 0.4736328125\n",
      "Batch 31: loss = 1.9378618001937866, acc = 0.4638671875\n",
      "Batch 32: loss = 2.0908894538879395, acc = 0.4052734375\n",
      "Batch 33: loss = 1.9198191165924072, acc = 0.451171875\n",
      "Batch 34: loss = 1.8074760437011719, acc = 0.46875\n",
      "Batch 35: loss = 1.836061954498291, acc = 0.4521484375\n",
      "Batch 36: loss = 1.9974761009216309, acc = 0.4296875\n",
      "Batch 37: loss = 1.964719295501709, acc = 0.4443359375\n",
      "Batch 38: loss = 1.886353850364685, acc = 0.455078125\n",
      "Batch 39: loss = 1.8534345626831055, acc = 0.4609375\n",
      "Batch 40: loss = 1.7916903495788574, acc = 0.455078125\n",
      "Batch 41: loss = 1.72430419921875, acc = 0.49609375\n",
      "Batch 42: loss = 1.6725939512252808, acc = 0.5\n",
      "Batch 43: loss = 1.7364026308059692, acc = 0.470703125\n",
      "Batch 44: loss = 1.811130404472351, acc = 0.455078125\n",
      "Batch 45: loss = 1.690719485282898, acc = 0.5\n",
      "Batch 46: loss = 1.7573754787445068, acc = 0.4892578125\n",
      "Batch 47: loss = 1.7898359298706055, acc = 0.4658203125\n",
      "Batch 48: loss = 1.6814594268798828, acc = 0.4794921875\n",
      "Batch 49: loss = 1.763366460800171, acc = 0.4814453125\n",
      "Batch 50: loss = 1.6706392765045166, acc = 0.501953125\n",
      "Batch 51: loss = 1.7659984827041626, acc = 0.4765625\n",
      "Batch 52: loss = 1.801222324371338, acc = 0.46875\n",
      "Batch 53: loss = 1.8476136922836304, acc = 0.453125\n",
      "Batch 54: loss = 1.830053448677063, acc = 0.4765625\n",
      "Batch 55: loss = 1.881541132926941, acc = 0.4677734375\n",
      "Batch 56: loss = 1.704101324081421, acc = 0.478515625\n",
      "Batch 57: loss = 1.8002941608428955, acc = 0.4580078125\n",
      "Batch 58: loss = 1.772812843322754, acc = 0.4814453125\n",
      "Batch 59: loss = 1.6814508438110352, acc = 0.525390625\n",
      "Batch 60: loss = 1.7326644659042358, acc = 0.4951171875\n",
      "Batch 61: loss = 1.9476828575134277, acc = 0.4560546875\n",
      "Batch 62: loss = 1.91483473777771, acc = 0.404296875\n",
      "Batch 63: loss = 1.9538395404815674, acc = 0.4580078125\n",
      "Batch 64: loss = 1.6174616813659668, acc = 0.548828125\n",
      "Batch 65: loss = 1.7042406797409058, acc = 0.505859375\n",
      "Batch 66: loss = 1.7077140808105469, acc = 0.5126953125\n",
      "Batch 67: loss = 1.7607570886611938, acc = 0.5068359375\n",
      "Batch 68: loss = 1.7250852584838867, acc = 0.51171875\n",
      "Batch 69: loss = 1.6495802402496338, acc = 0.5185546875\n",
      "Batch 70: loss = 1.8193247318267822, acc = 0.466796875\n",
      "Batch 71: loss = 1.7031102180480957, acc = 0.4970703125\n",
      "Batch 72: loss = 1.7034633159637451, acc = 0.5048828125\n",
      "Batch 73: loss = 1.6999914646148682, acc = 0.5048828125\n",
      "Batch 74: loss = 1.684255599975586, acc = 0.4833984375\n",
      "Batch 75: loss = 1.7495338916778564, acc = 0.4580078125\n",
      "Batch 76: loss = 1.7854254245758057, acc = 0.474609375\n",
      "Batch 77: loss = 1.6136150360107422, acc = 0.5439453125\n",
      "Batch 78: loss = 1.5516198873519897, acc = 0.55859375\n",
      "Batch 79: loss = 1.5155705213546753, acc = 0.5546875\n",
      "Batch 80: loss = 1.523963451385498, acc = 0.5087890625\n",
      "Batch 81: loss = 1.5951734781265259, acc = 0.5478515625\n",
      "Batch 82: loss = 1.6251646280288696, acc = 0.5419921875\n",
      "Batch 83: loss = 1.6191743612289429, acc = 0.5380859375\n",
      "Batch 84: loss = 1.6083858013153076, acc = 0.537109375\n",
      "Batch 85: loss = 1.6139572858810425, acc = 0.5126953125\n",
      "Batch 86: loss = 1.7192132472991943, acc = 0.501953125\n",
      "Batch 87: loss = 1.6602082252502441, acc = 0.5498046875\n",
      "Batch 88: loss = 1.842383861541748, acc = 0.4775390625\n",
      "Batch 89: loss = 1.8586469888687134, acc = 0.4873046875\n",
      "Batch 90: loss = 1.9078357219696045, acc = 0.482421875\n",
      "Batch 91: loss = 1.7710089683532715, acc = 0.4755859375\n",
      "Batch 92: loss = 1.5882978439331055, acc = 0.533203125\n",
      "Batch 93: loss = 1.5929243564605713, acc = 0.5380859375\n",
      "Batch 94: loss = 1.6356191635131836, acc = 0.52734375\n",
      "Batch 95: loss = 1.6285862922668457, acc = 0.50390625\n",
      "Batch 96: loss = 1.6218143701553345, acc = 0.5185546875\n",
      "Batch 97: loss = 1.6603288650512695, acc = 0.5341796875\n",
      "Batch 98: loss = 1.664562702178955, acc = 0.53125\n",
      "Batch 99: loss = 1.6473278999328613, acc = 0.5048828125\n",
      "Batch 100: loss = 1.5722864866256714, acc = 0.5166015625\n",
      "Batch 101: loss = 1.7522081136703491, acc = 0.49609375\n",
      "Batch 102: loss = 1.8455950021743774, acc = 0.458984375\n",
      "Batch 103: loss = 1.76859712600708, acc = 0.4853515625\n",
      "Batch 104: loss = 1.6541967391967773, acc = 0.5185546875\n",
      "Batch 105: loss = 1.7027615308761597, acc = 0.498046875\n",
      "Batch 106: loss = 1.735095500946045, acc = 0.5087890625\n",
      "Batch 107: loss = 1.6584882736206055, acc = 0.51953125\n",
      "Batch 108: loss = 1.6364330053329468, acc = 0.529296875\n",
      "Batch 109: loss = 1.623576045036316, acc = 0.509765625\n",
      "Batch 110: loss = 1.646409511566162, acc = 0.5322265625\n",
      "Batch 111: loss = 1.7838518619537354, acc = 0.4775390625\n",
      "Batch 112: loss = 1.6728054285049438, acc = 0.525390625\n",
      "Batch 113: loss = 1.6271347999572754, acc = 0.5166015625\n",
      "Batch 114: loss = 1.7329071760177612, acc = 0.5205078125\n",
      "Batch 115: loss = 1.7676196098327637, acc = 0.494140625\n",
      "Batch 116: loss = 1.7289354801177979, acc = 0.494140625\n",
      "Batch 117: loss = 1.6886450052261353, acc = 0.5302734375\n",
      "Batch 118: loss = 1.6356676816940308, acc = 0.5166015625\n",
      "Batch 119: loss = 1.7049299478530884, acc = 0.484375\n",
      "Batch 120: loss = 1.768627405166626, acc = 0.4765625\n",
      "Batch 121: loss = 1.5839042663574219, acc = 0.521484375\n",
      "Batch 122: loss = 1.6659014225006104, acc = 0.5087890625\n",
      "Batch 123: loss = 1.648682951927185, acc = 0.5126953125\n",
      "Batch 124: loss = 1.6701669692993164, acc = 0.482421875\n",
      "Batch 125: loss = 1.648606300354004, acc = 0.50390625\n",
      "Batch 126: loss = 1.7959307432174683, acc = 0.4853515625\n",
      "\n",
      "Epoch 4/100\n",
      "Batch 1: loss = 2.20571231842041, acc = 0.42578125\n",
      "Batch 2: loss = 1.7093279361724854, acc = 0.4921875\n",
      "Batch 3: loss = 1.7885279655456543, acc = 0.482421875\n",
      "Batch 4: loss = 1.6100139617919922, acc = 0.5244140625\n",
      "Batch 5: loss = 1.7953987121582031, acc = 0.4599609375\n",
      "Batch 6: loss = 1.8638193607330322, acc = 0.47265625\n",
      "Batch 7: loss = 1.838202953338623, acc = 0.4716796875\n",
      "Batch 8: loss = 1.6487147808074951, acc = 0.529296875\n",
      "Batch 9: loss = 1.696397304534912, acc = 0.494140625\n",
      "Batch 10: loss = 1.5375621318817139, acc = 0.564453125\n",
      "Batch 11: loss = 1.6660473346710205, acc = 0.513671875\n",
      "Batch 12: loss = 1.848300576210022, acc = 0.47265625\n",
      "Batch 13: loss = 1.7227956056594849, acc = 0.494140625\n",
      "Batch 14: loss = 1.611351490020752, acc = 0.51171875\n",
      "Batch 15: loss = 1.7031173706054688, acc = 0.5087890625\n",
      "Batch 16: loss = 1.7881317138671875, acc = 0.4755859375\n",
      "Batch 17: loss = 1.7386279106140137, acc = 0.5068359375\n",
      "Batch 18: loss = 1.7736214399337769, acc = 0.48046875\n",
      "Batch 19: loss = 1.7991464138031006, acc = 0.482421875\n",
      "Batch 20: loss = 1.6460506916046143, acc = 0.5224609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 21: loss = 1.810774803161621, acc = 0.4716796875\n",
      "Batch 22: loss = 1.6678733825683594, acc = 0.5078125\n",
      "Batch 23: loss = 1.680580496788025, acc = 0.4912109375\n",
      "Batch 24: loss = 1.7372902631759644, acc = 0.5\n",
      "Batch 25: loss = 1.619311809539795, acc = 0.5234375\n",
      "Batch 26: loss = 1.6386699676513672, acc = 0.5185546875\n",
      "Batch 27: loss = 1.6378629207611084, acc = 0.5087890625\n",
      "Batch 28: loss = 1.5826284885406494, acc = 0.525390625\n",
      "Batch 29: loss = 1.5662949085235596, acc = 0.5517578125\n",
      "Batch 30: loss = 1.625789999961853, acc = 0.5283203125\n",
      "Batch 31: loss = 1.7198413610458374, acc = 0.49609375\n",
      "Batch 32: loss = 1.9067401885986328, acc = 0.4482421875\n",
      "Batch 33: loss = 1.7377053499221802, acc = 0.5009765625\n",
      "Batch 34: loss = 1.6736335754394531, acc = 0.4970703125\n",
      "Batch 35: loss = 1.675252914428711, acc = 0.4990234375\n",
      "Batch 36: loss = 1.7875125408172607, acc = 0.4873046875\n",
      "Batch 37: loss = 1.7324655055999756, acc = 0.525390625\n",
      "Batch 38: loss = 1.709017276763916, acc = 0.4921875\n",
      "Batch 39: loss = 1.681267499923706, acc = 0.501953125\n",
      "Batch 40: loss = 1.617583155632019, acc = 0.515625\n",
      "Batch 41: loss = 1.549745798110962, acc = 0.5537109375\n",
      "Batch 42: loss = 1.5212453603744507, acc = 0.537109375\n",
      "Batch 43: loss = 1.6171948909759521, acc = 0.505859375\n",
      "Batch 44: loss = 1.6400583982467651, acc = 0.517578125\n",
      "Batch 45: loss = 1.496847152709961, acc = 0.55078125\n",
      "Batch 46: loss = 1.581310510635376, acc = 0.517578125\n",
      "Batch 47: loss = 1.6057387590408325, acc = 0.5224609375\n",
      "Batch 48: loss = 1.5304374694824219, acc = 0.51953125\n",
      "Batch 49: loss = 1.540764570236206, acc = 0.55078125\n",
      "Batch 50: loss = 1.5379788875579834, acc = 0.546875\n",
      "Batch 51: loss = 1.6104068756103516, acc = 0.5029296875\n",
      "Batch 52: loss = 1.6724045276641846, acc = 0.4990234375\n",
      "Batch 53: loss = 1.6845715045928955, acc = 0.4990234375\n",
      "Batch 54: loss = 1.6113457679748535, acc = 0.544921875\n",
      "Batch 55: loss = 1.6718323230743408, acc = 0.5283203125\n",
      "Batch 56: loss = 1.5374937057495117, acc = 0.525390625\n",
      "Batch 57: loss = 1.6718902587890625, acc = 0.4873046875\n",
      "Batch 58: loss = 1.6069837808609009, acc = 0.5283203125\n",
      "Batch 59: loss = 1.431823968887329, acc = 0.5771484375\n",
      "Batch 60: loss = 1.562467098236084, acc = 0.5244140625\n",
      "Batch 61: loss = 1.732155442237854, acc = 0.5224609375\n",
      "Batch 62: loss = 1.800958514213562, acc = 0.455078125\n",
      "Batch 63: loss = 1.7781420946121216, acc = 0.494140625\n",
      "Batch 64: loss = 1.4406960010528564, acc = 0.5869140625\n",
      "Batch 65: loss = 1.5702157020568848, acc = 0.5380859375\n",
      "Batch 66: loss = 1.573528528213501, acc = 0.5439453125\n",
      "Batch 67: loss = 1.56223726272583, acc = 0.5712890625\n",
      "Batch 68: loss = 1.569425106048584, acc = 0.5576171875\n",
      "Batch 69: loss = 1.503840446472168, acc = 0.541015625\n",
      "Batch 70: loss = 1.691101312637329, acc = 0.4990234375\n",
      "Batch 71: loss = 1.5242252349853516, acc = 0.5283203125\n",
      "Batch 72: loss = 1.5164676904678345, acc = 0.5458984375\n",
      "Batch 73: loss = 1.5905863046646118, acc = 0.515625\n",
      "Batch 74: loss = 1.539374828338623, acc = 0.525390625\n",
      "Batch 75: loss = 1.6251637935638428, acc = 0.498046875\n",
      "Batch 76: loss = 1.6440696716308594, acc = 0.5078125\n",
      "Batch 77: loss = 1.4633280038833618, acc = 0.5751953125\n",
      "Batch 78: loss = 1.439138650894165, acc = 0.5673828125\n",
      "Batch 79: loss = 1.3627166748046875, acc = 0.578125\n",
      "Batch 80: loss = 1.4228880405426025, acc = 0.546875\n",
      "Batch 81: loss = 1.4573904275894165, acc = 0.580078125\n",
      "Batch 82: loss = 1.4365026950836182, acc = 0.5771484375\n",
      "Batch 83: loss = 1.4932564496994019, acc = 0.564453125\n",
      "Batch 84: loss = 1.4734126329421997, acc = 0.556640625\n",
      "Batch 85: loss = 1.5311174392700195, acc = 0.5302734375\n",
      "Batch 86: loss = 1.560413122177124, acc = 0.5498046875\n",
      "Batch 87: loss = 1.4971555471420288, acc = 0.5810546875\n",
      "Batch 88: loss = 1.748927354812622, acc = 0.4931640625\n",
      "Batch 89: loss = 1.7077229022979736, acc = 0.5390625\n",
      "Batch 90: loss = 1.7743500471115112, acc = 0.509765625\n",
      "Batch 91: loss = 1.6712267398834229, acc = 0.501953125\n",
      "Batch 92: loss = 1.4628304243087769, acc = 0.5703125\n",
      "Batch 93: loss = 1.4327683448791504, acc = 0.5810546875\n",
      "Batch 94: loss = 1.4783459901809692, acc = 0.5673828125\n",
      "Batch 95: loss = 1.5106806755065918, acc = 0.53125\n",
      "Batch 96: loss = 1.5137593746185303, acc = 0.5302734375\n",
      "Batch 97: loss = 1.5138325691223145, acc = 0.5556640625\n",
      "Batch 98: loss = 1.5310282707214355, acc = 0.5498046875\n",
      "Batch 99: loss = 1.5266425609588623, acc = 0.5390625\n",
      "Batch 100: loss = 1.4836803674697876, acc = 0.5517578125\n",
      "Batch 101: loss = 1.6221654415130615, acc = 0.5263671875\n",
      "Batch 102: loss = 1.689469814300537, acc = 0.5087890625\n",
      "Batch 103: loss = 1.6132423877716064, acc = 0.5185546875\n",
      "Batch 104: loss = 1.5009288787841797, acc = 0.556640625\n",
      "Batch 105: loss = 1.5639201402664185, acc = 0.5224609375\n",
      "Batch 106: loss = 1.6127570867538452, acc = 0.5341796875\n",
      "Batch 107: loss = 1.5366404056549072, acc = 0.54296875\n",
      "Batch 108: loss = 1.5411956310272217, acc = 0.54296875\n",
      "Batch 109: loss = 1.510359525680542, acc = 0.533203125\n",
      "Batch 110: loss = 1.4865893125534058, acc = 0.564453125\n",
      "Batch 111: loss = 1.6640762090682983, acc = 0.4970703125\n",
      "Batch 112: loss = 1.5535504817962646, acc = 0.5458984375\n",
      "Batch 113: loss = 1.50503408908844, acc = 0.5380859375\n",
      "Batch 114: loss = 1.5775188207626343, acc = 0.5517578125\n",
      "Batch 115: loss = 1.643670916557312, acc = 0.5185546875\n",
      "Batch 116: loss = 1.5892527103424072, acc = 0.5205078125\n",
      "Batch 117: loss = 1.5333000421524048, acc = 0.5478515625\n",
      "Batch 118: loss = 1.4946600198745728, acc = 0.5419921875\n",
      "Batch 119: loss = 1.5779540538787842, acc = 0.5048828125\n",
      "Batch 120: loss = 1.6566674709320068, acc = 0.4853515625\n",
      "Batch 121: loss = 1.4784104824066162, acc = 0.5498046875\n",
      "Batch 122: loss = 1.5271356105804443, acc = 0.54296875\n",
      "Batch 123: loss = 1.520200490951538, acc = 0.5478515625\n",
      "Batch 124: loss = 1.5583438873291016, acc = 0.5166015625\n",
      "Batch 125: loss = 1.5399794578552246, acc = 0.53125\n",
      "Batch 126: loss = 1.6690788269042969, acc = 0.5205078125\n",
      "\n",
      "Epoch 5/100\n",
      "Batch 1: loss = 2.0909273624420166, acc = 0.4521484375\n",
      "Batch 2: loss = 1.6125379800796509, acc = 0.5078125\n",
      "Batch 3: loss = 1.64522123336792, acc = 0.5166015625\n",
      "Batch 4: loss = 1.5211584568023682, acc = 0.53125\n",
      "Batch 5: loss = 1.689335584640503, acc = 0.4990234375\n",
      "Batch 6: loss = 1.7260656356811523, acc = 0.4931640625\n",
      "Batch 7: loss = 1.7091162204742432, acc = 0.50390625\n",
      "Batch 8: loss = 1.5315022468566895, acc = 0.5546875\n",
      "Batch 9: loss = 1.5624711513519287, acc = 0.5322265625\n",
      "Batch 10: loss = 1.4094295501708984, acc = 0.5751953125\n",
      "Batch 11: loss = 1.5984444618225098, acc = 0.529296875\n",
      "Batch 12: loss = 1.7339866161346436, acc = 0.4853515625\n",
      "Batch 13: loss = 1.5819722414016724, acc = 0.5283203125\n",
      "Batch 14: loss = 1.485790729522705, acc = 0.546875\n",
      "Batch 15: loss = 1.5780290365219116, acc = 0.552734375\n",
      "Batch 16: loss = 1.6422849893569946, acc = 0.501953125\n",
      "Batch 17: loss = 1.5968661308288574, acc = 0.5380859375\n",
      "Batch 18: loss = 1.6691961288452148, acc = 0.4990234375\n",
      "Batch 19: loss = 1.666892647743225, acc = 0.5087890625\n",
      "Batch 20: loss = 1.4976415634155273, acc = 0.5556640625\n",
      "Batch 21: loss = 1.6838370561599731, acc = 0.4990234375\n",
      "Batch 22: loss = 1.521193265914917, acc = 0.5322265625\n",
      "Batch 23: loss = 1.5449905395507812, acc = 0.5400390625\n",
      "Batch 24: loss = 1.597880482673645, acc = 0.51171875\n",
      "Batch 25: loss = 1.4682271480560303, acc = 0.5537109375\n",
      "Batch 26: loss = 1.478469967842102, acc = 0.5546875\n",
      "Batch 27: loss = 1.5267012119293213, acc = 0.529296875\n",
      "Batch 28: loss = 1.5169260501861572, acc = 0.5244140625\n",
      "Batch 29: loss = 1.4588128328323364, acc = 0.572265625\n",
      "Batch 30: loss = 1.4803836345672607, acc = 0.5595703125\n",
      "Batch 31: loss = 1.6320419311523438, acc = 0.5068359375\n",
      "Batch 32: loss = 1.7734558582305908, acc = 0.47265625\n",
      "Batch 33: loss = 1.5733909606933594, acc = 0.5244140625\n",
      "Batch 34: loss = 1.559008002281189, acc = 0.5263671875\n",
      "Batch 35: loss = 1.5666253566741943, acc = 0.5166015625\n",
      "Batch 36: loss = 1.676478385925293, acc = 0.494140625\n",
      "Batch 37: loss = 1.628195881843567, acc = 0.529296875\n",
      "Batch 38: loss = 1.6024169921875, acc = 0.5146484375\n",
      "Batch 39: loss = 1.562798261642456, acc = 0.51953125\n",
      "Batch 40: loss = 1.5194172859191895, acc = 0.5390625\n",
      "Batch 41: loss = 1.4270294904708862, acc = 0.57421875\n",
      "Batch 42: loss = 1.4105174541473389, acc = 0.55078125\n",
      "Batch 43: loss = 1.4977481365203857, acc = 0.5302734375\n",
      "Batch 44: loss = 1.509751796722412, acc = 0.5458984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 45: loss = 1.3689513206481934, acc = 0.578125\n",
      "Batch 46: loss = 1.4801874160766602, acc = 0.5400390625\n",
      "Batch 47: loss = 1.4758317470550537, acc = 0.54296875\n",
      "Batch 48: loss = 1.4119012355804443, acc = 0.5498046875\n",
      "Batch 49: loss = 1.398828148841858, acc = 0.58984375\n",
      "Batch 50: loss = 1.3892765045166016, acc = 0.5830078125\n",
      "Batch 51: loss = 1.4830079078674316, acc = 0.53125\n",
      "Batch 52: loss = 1.5573521852493286, acc = 0.5244140625\n",
      "Batch 53: loss = 1.5584700107574463, acc = 0.5283203125\n",
      "Batch 54: loss = 1.4746285676956177, acc = 0.576171875\n",
      "Batch 55: loss = 1.5073997974395752, acc = 0.5556640625\n",
      "Batch 56: loss = 1.4241011142730713, acc = 0.55859375\n",
      "Batch 57: loss = 1.565049171447754, acc = 0.48828125\n",
      "Batch 58: loss = 1.4944665431976318, acc = 0.5439453125\n",
      "Batch 59: loss = 1.2775862216949463, acc = 0.61328125\n",
      "Batch 60: loss = 1.4470069408416748, acc = 0.5322265625\n",
      "Batch 61: loss = 1.5663197040557861, acc = 0.5244140625\n",
      "Batch 62: loss = 1.6650689840316772, acc = 0.4677734375\n",
      "Batch 63: loss = 1.6528146266937256, acc = 0.49609375\n",
      "Batch 64: loss = 1.2888031005859375, acc = 0.6015625\n",
      "Batch 65: loss = 1.4586131572723389, acc = 0.544921875\n",
      "Batch 66: loss = 1.4679474830627441, acc = 0.5517578125\n",
      "Batch 67: loss = 1.432860255241394, acc = 0.587890625\n",
      "Batch 68: loss = 1.4695532321929932, acc = 0.564453125\n",
      "Batch 69: loss = 1.3966057300567627, acc = 0.5732421875\n",
      "Batch 70: loss = 1.5519073009490967, acc = 0.529296875\n",
      "Batch 71: loss = 1.413194179534912, acc = 0.5732421875\n",
      "Batch 72: loss = 1.3979244232177734, acc = 0.5654296875\n",
      "Batch 73: loss = 1.486070156097412, acc = 0.537109375\n",
      "Batch 74: loss = 1.4475712776184082, acc = 0.53125\n",
      "Batch 75: loss = 1.5154178142547607, acc = 0.5244140625\n",
      "Batch 76: loss = 1.5317351818084717, acc = 0.529296875\n",
      "Batch 77: loss = 1.3323032855987549, acc = 0.5927734375\n",
      "Batch 78: loss = 1.3300012350082397, acc = 0.591796875\n",
      "Batch 79: loss = 1.2451046705245972, acc = 0.6181640625\n",
      "Batch 80: loss = 1.3478813171386719, acc = 0.5498046875\n",
      "Batch 81: loss = 1.3381415605545044, acc = 0.5888671875\n",
      "Batch 82: loss = 1.3027172088623047, acc = 0.6064453125\n",
      "Batch 83: loss = 1.3699663877487183, acc = 0.58203125\n",
      "Batch 84: loss = 1.3640632629394531, acc = 0.5859375\n",
      "Batch 85: loss = 1.4496839046478271, acc = 0.552734375\n",
      "Batch 86: loss = 1.442549467086792, acc = 0.576171875\n",
      "Batch 87: loss = 1.3720340728759766, acc = 0.599609375\n",
      "Batch 88: loss = 1.5941869020462036, acc = 0.5107421875\n",
      "Batch 89: loss = 1.5213124752044678, acc = 0.5595703125\n",
      "Batch 90: loss = 1.6216821670532227, acc = 0.5146484375\n",
      "Batch 91: loss = 1.5148206949234009, acc = 0.5302734375\n",
      "Batch 92: loss = 1.3360471725463867, acc = 0.583984375\n",
      "Batch 93: loss = 1.298424482345581, acc = 0.609375\n",
      "Batch 94: loss = 1.3739489316940308, acc = 0.5888671875\n",
      "Batch 95: loss = 1.420800805091858, acc = 0.5322265625\n",
      "Batch 96: loss = 1.4218032360076904, acc = 0.546875\n",
      "Batch 97: loss = 1.4240286350250244, acc = 0.55859375\n",
      "Batch 98: loss = 1.4071877002716064, acc = 0.57421875\n",
      "Batch 99: loss = 1.4212472438812256, acc = 0.548828125\n",
      "Batch 100: loss = 1.371110439300537, acc = 0.5546875\n",
      "Batch 101: loss = 1.4766418933868408, acc = 0.5458984375\n",
      "Batch 102: loss = 1.5654723644256592, acc = 0.509765625\n",
      "Batch 103: loss = 1.5071966648101807, acc = 0.5322265625\n",
      "Batch 104: loss = 1.3687670230865479, acc = 0.572265625\n",
      "Batch 105: loss = 1.4358903169631958, acc = 0.5615234375\n",
      "Batch 106: loss = 1.4939674139022827, acc = 0.548828125\n",
      "Batch 107: loss = 1.4056601524353027, acc = 0.552734375\n",
      "Batch 108: loss = 1.4124504327774048, acc = 0.556640625\n",
      "Batch 109: loss = 1.38765287399292, acc = 0.548828125\n",
      "Batch 110: loss = 1.342658281326294, acc = 0.59375\n",
      "Batch 111: loss = 1.5686242580413818, acc = 0.5126953125\n",
      "Batch 112: loss = 1.379746913909912, acc = 0.56640625\n",
      "Batch 113: loss = 1.391893744468689, acc = 0.568359375\n",
      "Batch 114: loss = 1.4662666320800781, acc = 0.5693359375\n",
      "Batch 115: loss = 1.5301791429519653, acc = 0.533203125\n",
      "Batch 116: loss = 1.5238068103790283, acc = 0.5234375\n",
      "Batch 117: loss = 1.3987250328063965, acc = 0.5849609375\n",
      "Batch 118: loss = 1.4051004648208618, acc = 0.5419921875\n",
      "Batch 119: loss = 1.4773268699645996, acc = 0.5146484375\n",
      "Batch 120: loss = 1.5182902812957764, acc = 0.5263671875\n",
      "Batch 121: loss = 1.3365898132324219, acc = 0.5654296875\n",
      "Batch 122: loss = 1.3704487085342407, acc = 0.5673828125\n",
      "Batch 123: loss = 1.3771214485168457, acc = 0.5693359375\n",
      "Batch 124: loss = 1.430915117263794, acc = 0.5244140625\n",
      "Batch 125: loss = 1.4098362922668457, acc = 0.5517578125\n",
      "Batch 126: loss = 1.550747275352478, acc = 0.529296875\n",
      "\n",
      "Epoch 6/100\n",
      "Batch 1: loss = 1.946423053741455, acc = 0.482421875\n",
      "Batch 2: loss = 1.5119481086730957, acc = 0.517578125\n",
      "Batch 3: loss = 1.5202231407165527, acc = 0.5341796875\n",
      "Batch 4: loss = 1.40469229221344, acc = 0.5595703125\n",
      "Batch 5: loss = 1.6082875728607178, acc = 0.509765625\n",
      "Batch 6: loss = 1.600846529006958, acc = 0.51953125\n",
      "Batch 7: loss = 1.576786756515503, acc = 0.529296875\n",
      "Batch 8: loss = 1.4111815690994263, acc = 0.56640625\n",
      "Batch 9: loss = 1.415852665901184, acc = 0.54296875\n",
      "Batch 10: loss = 1.2888987064361572, acc = 0.59375\n",
      "Batch 11: loss = 1.4816606044769287, acc = 0.5537109375\n",
      "Batch 12: loss = 1.5972211360931396, acc = 0.5107421875\n",
      "Batch 13: loss = 1.466577410697937, acc = 0.5390625\n",
      "Batch 14: loss = 1.369276523590088, acc = 0.5693359375\n",
      "Batch 15: loss = 1.4104007482528687, acc = 0.578125\n",
      "Batch 16: loss = 1.5396558046340942, acc = 0.5087890625\n",
      "Batch 17: loss = 1.4827682971954346, acc = 0.5498046875\n",
      "Batch 18: loss = 1.5539023876190186, acc = 0.5283203125\n",
      "Batch 19: loss = 1.549095869064331, acc = 0.53125\n",
      "Batch 20: loss = 1.3644516468048096, acc = 0.5654296875\n",
      "Batch 21: loss = 1.5637621879577637, acc = 0.5205078125\n",
      "Batch 22: loss = 1.3707332611083984, acc = 0.5654296875\n",
      "Batch 23: loss = 1.4201091527938843, acc = 0.5361328125\n",
      "Batch 24: loss = 1.4815741777420044, acc = 0.5380859375\n",
      "Batch 25: loss = 1.3346426486968994, acc = 0.583984375\n",
      "Batch 26: loss = 1.3834278583526611, acc = 0.5869140625\n",
      "Batch 27: loss = 1.4378407001495361, acc = 0.546875\n",
      "Batch 28: loss = 1.4294683933258057, acc = 0.5498046875\n",
      "Batch 29: loss = 1.3521827459335327, acc = 0.6025390625\n",
      "Batch 30: loss = 1.3549751043319702, acc = 0.5810546875\n",
      "Batch 31: loss = 1.5034046173095703, acc = 0.5498046875\n",
      "Batch 32: loss = 1.670220136642456, acc = 0.4990234375\n",
      "Batch 33: loss = 1.4650826454162598, acc = 0.5439453125\n",
      "Batch 34: loss = 1.460233211517334, acc = 0.5361328125\n",
      "Batch 35: loss = 1.4363456964492798, acc = 0.552734375\n",
      "Batch 36: loss = 1.529883623123169, acc = 0.52734375\n",
      "Batch 37: loss = 1.5189409255981445, acc = 0.546875\n",
      "Batch 38: loss = 1.5126827955245972, acc = 0.5322265625\n",
      "Batch 39: loss = 1.4577652215957642, acc = 0.5517578125\n",
      "Batch 40: loss = 1.4269657135009766, acc = 0.541015625\n",
      "Batch 41: loss = 1.3301070928573608, acc = 0.572265625\n",
      "Batch 42: loss = 1.3402738571166992, acc = 0.5732421875\n",
      "Batch 43: loss = 1.442549228668213, acc = 0.5234375\n",
      "Batch 44: loss = 1.389172911643982, acc = 0.564453125\n",
      "Batch 45: loss = 1.2640089988708496, acc = 0.599609375\n",
      "Batch 46: loss = 1.399643898010254, acc = 0.5546875\n",
      "Batch 47: loss = 1.3602008819580078, acc = 0.572265625\n",
      "Batch 48: loss = 1.3450641632080078, acc = 0.5595703125\n",
      "Batch 49: loss = 1.2630964517593384, acc = 0.6162109375\n",
      "Batch 50: loss = 1.3017293214797974, acc = 0.59375\n",
      "Batch 51: loss = 1.3721442222595215, acc = 0.55078125\n",
      "Batch 52: loss = 1.4940681457519531, acc = 0.53515625\n",
      "Batch 53: loss = 1.465514063835144, acc = 0.515625\n",
      "Batch 54: loss = 1.3969181776046753, acc = 0.5849609375\n",
      "Batch 55: loss = 1.3750104904174805, acc = 0.5673828125\n",
      "Batch 56: loss = 1.3420788049697876, acc = 0.548828125\n",
      "Batch 57: loss = 1.4514451026916504, acc = 0.49609375\n",
      "Batch 58: loss = 1.4705954790115356, acc = 0.525390625\n",
      "Batch 59: loss = 1.2111029624938965, acc = 0.6005859375\n",
      "Batch 60: loss = 1.3659507036209106, acc = 0.548828125\n",
      "Batch 61: loss = 1.4643906354904175, acc = 0.5517578125\n",
      "Batch 62: loss = 1.5677685737609863, acc = 0.4951171875\n",
      "Batch 63: loss = 1.599457025527954, acc = 0.4990234375\n",
      "Batch 64: loss = 1.2471222877502441, acc = 0.5986328125\n",
      "Batch 65: loss = 1.408408522605896, acc = 0.546875\n",
      "Batch 66: loss = 1.3690781593322754, acc = 0.5576171875\n",
      "Batch 67: loss = 1.347124457359314, acc = 0.6103515625\n",
      "Batch 68: loss = 1.388404369354248, acc = 0.5947265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 69: loss = 1.3191311359405518, acc = 0.5908203125\n",
      "Batch 70: loss = 1.4747881889343262, acc = 0.525390625\n",
      "Batch 71: loss = 1.3218501806259155, acc = 0.5810546875\n",
      "Batch 72: loss = 1.310623049736023, acc = 0.5751953125\n",
      "Batch 73: loss = 1.408919334411621, acc = 0.5498046875\n",
      "Batch 74: loss = 1.3851948976516724, acc = 0.5380859375\n",
      "Batch 75: loss = 1.4479775428771973, acc = 0.5390625\n",
      "Batch 76: loss = 1.4602266550064087, acc = 0.5498046875\n",
      "Batch 77: loss = 1.260224461555481, acc = 0.603515625\n",
      "Batch 78: loss = 1.262890338897705, acc = 0.5888671875\n",
      "Batch 79: loss = 1.151736855506897, acc = 0.6337890625\n",
      "Batch 80: loss = 1.2338188886642456, acc = 0.576171875\n",
      "Batch 81: loss = 1.2487831115722656, acc = 0.611328125\n",
      "Batch 82: loss = 1.2131165266036987, acc = 0.6298828125\n",
      "Batch 83: loss = 1.3121975660324097, acc = 0.5830078125\n",
      "Batch 84: loss = 1.2921202182769775, acc = 0.58984375\n",
      "Batch 85: loss = 1.3938190937042236, acc = 0.5595703125\n",
      "Batch 86: loss = 1.3516637086868286, acc = 0.5751953125\n",
      "Batch 87: loss = 1.3030850887298584, acc = 0.60546875\n",
      "Batch 88: loss = 1.4845576286315918, acc = 0.5283203125\n",
      "Batch 89: loss = 1.429041862487793, acc = 0.5654296875\n",
      "Batch 90: loss = 1.5170074701309204, acc = 0.5478515625\n",
      "Batch 91: loss = 1.4378941059112549, acc = 0.5361328125\n",
      "Batch 92: loss = 1.2744765281677246, acc = 0.5947265625\n",
      "Batch 93: loss = 1.2007989883422852, acc = 0.6328125\n",
      "Batch 94: loss = 1.239311695098877, acc = 0.6083984375\n",
      "Batch 95: loss = 1.322264313697815, acc = 0.5576171875\n",
      "Batch 96: loss = 1.3568499088287354, acc = 0.5615234375\n",
      "Batch 97: loss = 1.3528457880020142, acc = 0.5771484375\n",
      "Batch 98: loss = 1.3437864780426025, acc = 0.59375\n",
      "Batch 99: loss = 1.3471095561981201, acc = 0.5615234375\n",
      "Batch 100: loss = 1.2918380498886108, acc = 0.57421875\n",
      "Batch 101: loss = 1.3878073692321777, acc = 0.5703125\n",
      "Batch 102: loss = 1.4380141496658325, acc = 0.5546875\n",
      "Batch 103: loss = 1.4170823097229004, acc = 0.55078125\n",
      "Batch 104: loss = 1.290597915649414, acc = 0.591796875\n",
      "Batch 105: loss = 1.360654354095459, acc = 0.572265625\n",
      "Batch 106: loss = 1.4180843830108643, acc = 0.5615234375\n",
      "Batch 107: loss = 1.3357048034667969, acc = 0.568359375\n",
      "Batch 108: loss = 1.3521859645843506, acc = 0.580078125\n",
      "Batch 109: loss = 1.324326753616333, acc = 0.5576171875\n",
      "Batch 110: loss = 1.2673813104629517, acc = 0.5986328125\n",
      "Batch 111: loss = 1.458114504814148, acc = 0.5283203125\n",
      "Batch 112: loss = 1.28341805934906, acc = 0.5830078125\n",
      "Batch 113: loss = 1.3268978595733643, acc = 0.5673828125\n",
      "Batch 114: loss = 1.3913594484329224, acc = 0.5830078125\n",
      "Batch 115: loss = 1.4607429504394531, acc = 0.525390625\n",
      "Batch 116: loss = 1.4501423835754395, acc = 0.556640625\n",
      "Batch 117: loss = 1.3353263139724731, acc = 0.5908203125\n",
      "Batch 118: loss = 1.3105077743530273, acc = 0.5703125\n",
      "Batch 119: loss = 1.395890712738037, acc = 0.541015625\n",
      "Batch 120: loss = 1.4459824562072754, acc = 0.529296875\n",
      "Batch 121: loss = 1.2693829536437988, acc = 0.5849609375\n",
      "Batch 122: loss = 1.297978162765503, acc = 0.5927734375\n",
      "Batch 123: loss = 1.3125033378601074, acc = 0.5859375\n",
      "Batch 124: loss = 1.3738359212875366, acc = 0.5341796875\n",
      "Batch 125: loss = 1.3646368980407715, acc = 0.5615234375\n",
      "Batch 126: loss = 1.4808025360107422, acc = 0.556640625\n",
      "\n",
      "Epoch 7/100\n",
      "Batch 1: loss = 1.81514573097229, acc = 0.4892578125\n",
      "Batch 2: loss = 1.4467136859893799, acc = 0.5283203125\n",
      "Batch 3: loss = 1.4362437725067139, acc = 0.541015625\n",
      "Batch 4: loss = 1.3490129709243774, acc = 0.5673828125\n",
      "Batch 5: loss = 1.5135622024536133, acc = 0.5283203125\n",
      "Batch 6: loss = 1.5272722244262695, acc = 0.5263671875\n",
      "Batch 7: loss = 1.51755952835083, acc = 0.5244140625\n",
      "Batch 8: loss = 1.3482822179794312, acc = 0.5810546875\n",
      "Batch 9: loss = 1.3285263776779175, acc = 0.5634765625\n",
      "Batch 10: loss = 1.220341444015503, acc = 0.6162109375\n",
      "Batch 11: loss = 1.4295374155044556, acc = 0.5546875\n",
      "Batch 12: loss = 1.494591236114502, acc = 0.5390625\n",
      "Batch 13: loss = 1.3592156171798706, acc = 0.5673828125\n",
      "Batch 14: loss = 1.3055986166000366, acc = 0.5966796875\n",
      "Batch 15: loss = 1.3506156206130981, acc = 0.5771484375\n",
      "Batch 16: loss = 1.4885952472686768, acc = 0.529296875\n",
      "Batch 17: loss = 1.3990224599838257, acc = 0.5537109375\n",
      "Batch 18: loss = 1.441657543182373, acc = 0.533203125\n",
      "Batch 19: loss = 1.4253714084625244, acc = 0.5478515625\n",
      "Batch 20: loss = 1.2883156538009644, acc = 0.5859375\n",
      "Batch 21: loss = 1.4923492670059204, acc = 0.5341796875\n",
      "Batch 22: loss = 1.2883288860321045, acc = 0.5810546875\n",
      "Batch 23: loss = 1.3506855964660645, acc = 0.5576171875\n",
      "Batch 24: loss = 1.3897573947906494, acc = 0.5576171875\n",
      "Batch 25: loss = 1.2712550163269043, acc = 0.59765625\n",
      "Batch 26: loss = 1.3177635669708252, acc = 0.5791015625\n",
      "Batch 27: loss = 1.3766480684280396, acc = 0.5673828125\n",
      "Batch 28: loss = 1.375741720199585, acc = 0.5546875\n",
      "Batch 29: loss = 1.3061563968658447, acc = 0.6025390625\n",
      "Batch 30: loss = 1.3135466575622559, acc = 0.58984375\n",
      "Batch 31: loss = 1.4332985877990723, acc = 0.5615234375\n",
      "Batch 32: loss = 1.5884391069412231, acc = 0.5078125\n",
      "Batch 33: loss = 1.3775718212127686, acc = 0.5732421875\n",
      "Batch 34: loss = 1.384732961654663, acc = 0.5498046875\n",
      "Batch 35: loss = 1.3844211101531982, acc = 0.5625\n",
      "Batch 36: loss = 1.4306938648223877, acc = 0.564453125\n",
      "Batch 37: loss = 1.4211394786834717, acc = 0.57421875\n",
      "Batch 38: loss = 1.4460045099258423, acc = 0.5712890625\n",
      "Batch 39: loss = 1.3735260963439941, acc = 0.560546875\n",
      "Batch 40: loss = 1.3277912139892578, acc = 0.5771484375\n",
      "Batch 41: loss = 1.2674015760421753, acc = 0.5927734375\n",
      "Batch 42: loss = 1.2800164222717285, acc = 0.5888671875\n",
      "Batch 43: loss = 1.3702173233032227, acc = 0.54296875\n",
      "Batch 44: loss = 1.3404741287231445, acc = 0.564453125\n",
      "Batch 45: loss = 1.2160413265228271, acc = 0.6171875\n",
      "Batch 46: loss = 1.324493646621704, acc = 0.5732421875\n",
      "Batch 47: loss = 1.2844831943511963, acc = 0.578125\n",
      "Batch 48: loss = 1.2472271919250488, acc = 0.5751953125\n",
      "Batch 49: loss = 1.1859846115112305, acc = 0.638671875\n",
      "Batch 50: loss = 1.2341856956481934, acc = 0.595703125\n",
      "Batch 51: loss = 1.2783195972442627, acc = 0.568359375\n",
      "Batch 52: loss = 1.3971160650253296, acc = 0.544921875\n",
      "Batch 53: loss = 1.3778070211410522, acc = 0.55078125\n",
      "Batch 54: loss = 1.314308524131775, acc = 0.5927734375\n",
      "Batch 55: loss = 1.3223371505737305, acc = 0.5830078125\n",
      "Batch 56: loss = 1.2689478397369385, acc = 0.5771484375\n",
      "Batch 57: loss = 1.3820059299468994, acc = 0.5283203125\n",
      "Batch 58: loss = 1.332417607307434, acc = 0.578125\n",
      "Batch 59: loss = 1.1019079685211182, acc = 0.6533203125\n",
      "Batch 60: loss = 1.2862486839294434, acc = 0.5625\n",
      "Batch 61: loss = 1.378307580947876, acc = 0.57421875\n",
      "Batch 62: loss = 1.511488676071167, acc = 0.4951171875\n",
      "Batch 63: loss = 1.4721686840057373, acc = 0.5498046875\n",
      "Batch 64: loss = 1.0902025699615479, acc = 0.6552734375\n",
      "Batch 65: loss = 1.3023149967193604, acc = 0.576171875\n",
      "Batch 66: loss = 1.2852693796157837, acc = 0.58203125\n",
      "Batch 67: loss = 1.2607234716415405, acc = 0.6220703125\n",
      "Batch 68: loss = 1.315166711807251, acc = 0.59375\n",
      "Batch 69: loss = 1.2548894882202148, acc = 0.595703125\n",
      "Batch 70: loss = 1.3958485126495361, acc = 0.552734375\n",
      "Batch 71: loss = 1.2341363430023193, acc = 0.603515625\n",
      "Batch 72: loss = 1.2191822528839111, acc = 0.5947265625\n",
      "Batch 73: loss = 1.3406319618225098, acc = 0.5654296875\n",
      "Batch 74: loss = 1.3126323223114014, acc = 0.5615234375\n",
      "Batch 75: loss = 1.4031879901885986, acc = 0.5400390625\n",
      "Batch 76: loss = 1.3928205966949463, acc = 0.560546875\n",
      "Batch 77: loss = 1.1963260173797607, acc = 0.615234375\n",
      "Batch 78: loss = 1.2080035209655762, acc = 0.5966796875\n",
      "Batch 79: loss = 1.0898654460906982, acc = 0.646484375\n",
      "Batch 80: loss = 1.200761318206787, acc = 0.58203125\n",
      "Batch 81: loss = 1.1842331886291504, acc = 0.6201171875\n",
      "Batch 82: loss = 1.1438908576965332, acc = 0.6337890625\n",
      "Batch 83: loss = 1.2582032680511475, acc = 0.59765625\n",
      "Batch 84: loss = 1.2357923984527588, acc = 0.5947265625\n",
      "Batch 85: loss = 1.3327590227127075, acc = 0.578125\n",
      "Batch 86: loss = 1.279319405555725, acc = 0.595703125\n",
      "Batch 87: loss = 1.255296230316162, acc = 0.6103515625\n",
      "Batch 88: loss = 1.433750033378601, acc = 0.55078125\n",
      "Batch 89: loss = 1.3472309112548828, acc = 0.5732421875\n",
      "Batch 90: loss = 1.4539653062820435, acc = 0.5595703125\n",
      "Batch 91: loss = 1.3791694641113281, acc = 0.5595703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 92: loss = 1.2007473707199097, acc = 0.625\n",
      "Batch 93: loss = 1.1530823707580566, acc = 0.630859375\n",
      "Batch 94: loss = 1.1935372352600098, acc = 0.625\n",
      "Batch 95: loss = 1.2750332355499268, acc = 0.564453125\n",
      "Batch 96: loss = 1.2829152345657349, acc = 0.58984375\n",
      "Batch 97: loss = 1.295170545578003, acc = 0.583984375\n",
      "Batch 98: loss = 1.2788063287734985, acc = 0.603515625\n",
      "Batch 99: loss = 1.2912087440490723, acc = 0.5771484375\n",
      "Batch 100: loss = 1.2614247798919678, acc = 0.587890625\n",
      "Batch 101: loss = 1.34464693069458, acc = 0.5712890625\n",
      "Batch 102: loss = 1.3942146301269531, acc = 0.5595703125\n",
      "Batch 103: loss = 1.3348605632781982, acc = 0.5673828125\n",
      "Batch 104: loss = 1.2364833354949951, acc = 0.5986328125\n",
      "Batch 105: loss = 1.279084324836731, acc = 0.5908203125\n",
      "Batch 106: loss = 1.3733912706375122, acc = 0.5673828125\n",
      "Batch 107: loss = 1.2726585865020752, acc = 0.5859375\n",
      "Batch 108: loss = 1.2787854671478271, acc = 0.5869140625\n",
      "Batch 109: loss = 1.2597368955612183, acc = 0.57421875\n",
      "Batch 110: loss = 1.2198134660720825, acc = 0.6083984375\n",
      "Batch 111: loss = 1.395921230316162, acc = 0.56640625\n",
      "Batch 112: loss = 1.2536317110061646, acc = 0.5927734375\n",
      "Batch 113: loss = 1.270105004310608, acc = 0.5927734375\n",
      "Batch 114: loss = 1.3404922485351562, acc = 0.6025390625\n",
      "Batch 115: loss = 1.3870794773101807, acc = 0.56640625\n",
      "Batch 116: loss = 1.3853000402450562, acc = 0.5703125\n",
      "Batch 117: loss = 1.2768967151641846, acc = 0.595703125\n",
      "Batch 118: loss = 1.2489676475524902, acc = 0.5751953125\n",
      "Batch 119: loss = 1.350710391998291, acc = 0.541015625\n",
      "Batch 120: loss = 1.4071831703186035, acc = 0.548828125\n",
      "Batch 121: loss = 1.2146097421646118, acc = 0.607421875\n",
      "Batch 122: loss = 1.246899127960205, acc = 0.615234375\n",
      "Batch 123: loss = 1.2861311435699463, acc = 0.5927734375\n",
      "Batch 124: loss = 1.3277558088302612, acc = 0.5625\n",
      "Batch 125: loss = 1.306220293045044, acc = 0.57421875\n",
      "Batch 126: loss = 1.4177727699279785, acc = 0.5859375\n",
      "\n",
      "Epoch 8/100\n",
      "Batch 1: loss = 1.7168511152267456, acc = 0.5126953125\n",
      "Batch 2: loss = 1.414370059967041, acc = 0.5556640625\n",
      "Batch 3: loss = 1.3435428142547607, acc = 0.583984375\n",
      "Batch 4: loss = 1.3129534721374512, acc = 0.5830078125\n",
      "Batch 5: loss = 1.4794273376464844, acc = 0.5390625\n",
      "Batch 6: loss = 1.4762444496154785, acc = 0.5390625\n",
      "Batch 7: loss = 1.4690710306167603, acc = 0.5341796875\n",
      "Batch 8: loss = 1.2744613885879517, acc = 0.5869140625\n",
      "Batch 9: loss = 1.2732515335083008, acc = 0.587890625\n",
      "Batch 10: loss = 1.1825132369995117, acc = 0.6083984375\n",
      "Batch 11: loss = 1.3599001169204712, acc = 0.5634765625\n",
      "Batch 12: loss = 1.4358294010162354, acc = 0.53125\n",
      "Batch 13: loss = 1.3468586206436157, acc = 0.5595703125\n",
      "Batch 14: loss = 1.2300560474395752, acc = 0.6064453125\n",
      "Batch 15: loss = 1.2868214845657349, acc = 0.5869140625\n",
      "Batch 16: loss = 1.4223122596740723, acc = 0.5439453125\n",
      "Batch 17: loss = 1.3429210186004639, acc = 0.57421875\n",
      "Batch 18: loss = 1.422696590423584, acc = 0.53515625\n",
      "Batch 19: loss = 1.373984694480896, acc = 0.560546875\n",
      "Batch 20: loss = 1.2282602787017822, acc = 0.59375\n",
      "Batch 21: loss = 1.44795560836792, acc = 0.5439453125\n",
      "Batch 22: loss = 1.2189269065856934, acc = 0.5966796875\n",
      "Batch 23: loss = 1.2985374927520752, acc = 0.57421875\n",
      "Batch 24: loss = 1.3303340673446655, acc = 0.5595703125\n",
      "Batch 25: loss = 1.1955419778823853, acc = 0.6044921875\n",
      "Batch 26: loss = 1.2456769943237305, acc = 0.6162109375\n",
      "Batch 27: loss = 1.352640151977539, acc = 0.564453125\n",
      "Batch 28: loss = 1.310664176940918, acc = 0.580078125\n",
      "Batch 29: loss = 1.2596030235290527, acc = 0.619140625\n",
      "Batch 30: loss = 1.2146062850952148, acc = 0.6142578125\n",
      "Batch 31: loss = 1.3716368675231934, acc = 0.583984375\n",
      "Batch 32: loss = 1.511639952659607, acc = 0.5224609375\n",
      "Batch 33: loss = 1.3251311779022217, acc = 0.58203125\n",
      "Batch 34: loss = 1.3243904113769531, acc = 0.564453125\n",
      "Batch 35: loss = 1.332897663116455, acc = 0.578125\n",
      "Batch 36: loss = 1.3766868114471436, acc = 0.5576171875\n",
      "Batch 37: loss = 1.3438622951507568, acc = 0.587890625\n",
      "Batch 38: loss = 1.3974345922470093, acc = 0.572265625\n",
      "Batch 39: loss = 1.32686185836792, acc = 0.5546875\n",
      "Batch 40: loss = 1.2989397048950195, acc = 0.568359375\n",
      "Batch 41: loss = 1.2326840162277222, acc = 0.6025390625\n",
      "Batch 42: loss = 1.256866216659546, acc = 0.583984375\n",
      "Batch 43: loss = 1.3187804222106934, acc = 0.5546875\n",
      "Batch 44: loss = 1.2704815864562988, acc = 0.5869140625\n",
      "Batch 45: loss = 1.1537094116210938, acc = 0.630859375\n",
      "Batch 46: loss = 1.2823325395584106, acc = 0.5966796875\n",
      "Batch 47: loss = 1.2400143146514893, acc = 0.5947265625\n",
      "Batch 48: loss = 1.180905818939209, acc = 0.6015625\n",
      "Batch 49: loss = 1.127185344696045, acc = 0.64453125\n",
      "Batch 50: loss = 1.1824902296066284, acc = 0.625\n",
      "Batch 51: loss = 1.230896234512329, acc = 0.5927734375\n",
      "Batch 52: loss = 1.345017910003662, acc = 0.5625\n",
      "Batch 53: loss = 1.3374935388565063, acc = 0.5595703125\n",
      "Batch 54: loss = 1.2181975841522217, acc = 0.623046875\n",
      "Batch 55: loss = 1.2393717765808105, acc = 0.6064453125\n",
      "Batch 56: loss = 1.2255141735076904, acc = 0.583984375\n",
      "Batch 57: loss = 1.3419194221496582, acc = 0.552734375\n",
      "Batch 58: loss = 1.3032176494598389, acc = 0.583984375\n",
      "Batch 59: loss = 1.0588361024856567, acc = 0.6630859375\n",
      "Batch 60: loss = 1.2468695640563965, acc = 0.5732421875\n",
      "Batch 61: loss = 1.3061168193817139, acc = 0.6044921875\n",
      "Batch 62: loss = 1.438014030456543, acc = 0.5205078125\n",
      "Batch 63: loss = 1.432281732559204, acc = 0.544921875\n",
      "Batch 64: loss = 1.0513590574264526, acc = 0.66015625\n",
      "Batch 65: loss = 1.269231915473938, acc = 0.59375\n",
      "Batch 66: loss = 1.2338244915008545, acc = 0.599609375\n",
      "Batch 67: loss = 1.2068586349487305, acc = 0.626953125\n",
      "Batch 68: loss = 1.276799201965332, acc = 0.6044921875\n",
      "Batch 69: loss = 1.2205801010131836, acc = 0.6083984375\n",
      "Batch 70: loss = 1.3174725770950317, acc = 0.572265625\n",
      "Batch 71: loss = 1.1896579265594482, acc = 0.6171875\n",
      "Batch 72: loss = 1.1706295013427734, acc = 0.6240234375\n",
      "Batch 73: loss = 1.283893346786499, acc = 0.578125\n",
      "Batch 74: loss = 1.2727597951889038, acc = 0.5615234375\n",
      "Batch 75: loss = 1.3480494022369385, acc = 0.5458984375\n",
      "Batch 76: loss = 1.3340098857879639, acc = 0.56640625\n",
      "Batch 77: loss = 1.155174970626831, acc = 0.6240234375\n",
      "Batch 78: loss = 1.1763761043548584, acc = 0.6142578125\n",
      "Batch 79: loss = 1.0431139469146729, acc = 0.6640625\n",
      "Batch 80: loss = 1.127159833908081, acc = 0.6005859375\n",
      "Batch 81: loss = 1.131363868713379, acc = 0.6259765625\n",
      "Batch 82: loss = 1.085142731666565, acc = 0.662109375\n",
      "Batch 83: loss = 1.2191574573516846, acc = 0.595703125\n",
      "Batch 84: loss = 1.1897311210632324, acc = 0.6083984375\n",
      "Batch 85: loss = 1.3109302520751953, acc = 0.568359375\n",
      "Batch 86: loss = 1.258915662765503, acc = 0.5927734375\n",
      "Batch 87: loss = 1.1770267486572266, acc = 0.6220703125\n",
      "Batch 88: loss = 1.3602617979049683, acc = 0.5654296875\n",
      "Batch 89: loss = 1.2856228351593018, acc = 0.5966796875\n",
      "Batch 90: loss = 1.3721222877502441, acc = 0.58203125\n",
      "Batch 91: loss = 1.3270974159240723, acc = 0.57421875\n",
      "Batch 92: loss = 1.1451096534729004, acc = 0.6298828125\n",
      "Batch 93: loss = 1.1016002893447876, acc = 0.6416015625\n",
      "Batch 94: loss = 1.1523773670196533, acc = 0.6259765625\n",
      "Batch 95: loss = 1.2337374687194824, acc = 0.576171875\n",
      "Batch 96: loss = 1.242246389389038, acc = 0.5869140625\n",
      "Batch 97: loss = 1.2502646446228027, acc = 0.59375\n",
      "Batch 98: loss = 1.2505197525024414, acc = 0.6123046875\n",
      "Batch 99: loss = 1.2411506175994873, acc = 0.5947265625\n",
      "Batch 100: loss = 1.2166187763214111, acc = 0.591796875\n",
      "Batch 101: loss = 1.2764862775802612, acc = 0.5927734375\n",
      "Batch 102: loss = 1.3456958532333374, acc = 0.5703125\n",
      "Batch 103: loss = 1.275315284729004, acc = 0.5888671875\n",
      "Batch 104: loss = 1.1960086822509766, acc = 0.61328125\n",
      "Batch 105: loss = 1.2488709688186646, acc = 0.6025390625\n",
      "Batch 106: loss = 1.3296210765838623, acc = 0.5927734375\n",
      "Batch 107: loss = 1.216334342956543, acc = 0.6064453125\n",
      "Batch 108: loss = 1.2334922552108765, acc = 0.607421875\n",
      "Batch 109: loss = 1.201932430267334, acc = 0.60546875\n",
      "Batch 110: loss = 1.165060043334961, acc = 0.6328125\n",
      "Batch 111: loss = 1.3403050899505615, acc = 0.564453125\n",
      "Batch 112: loss = 1.1749944686889648, acc = 0.6123046875\n",
      "Batch 113: loss = 1.2237977981567383, acc = 0.5966796875\n",
      "Batch 114: loss = 1.2991366386413574, acc = 0.619140625\n",
      "Batch 115: loss = 1.3342406749725342, acc = 0.58203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 116: loss = 1.3560192584991455, acc = 0.568359375\n",
      "Batch 117: loss = 1.2016639709472656, acc = 0.619140625\n",
      "Batch 118: loss = 1.181517481803894, acc = 0.5966796875\n",
      "Batch 119: loss = 1.289259910583496, acc = 0.5546875\n",
      "Batch 120: loss = 1.350553035736084, acc = 0.5556640625\n",
      "Batch 121: loss = 1.1965422630310059, acc = 0.60546875\n",
      "Batch 122: loss = 1.1858781576156616, acc = 0.62890625\n",
      "Batch 123: loss = 1.2251574993133545, acc = 0.603515625\n",
      "Batch 124: loss = 1.28956139087677, acc = 0.556640625\n",
      "Batch 125: loss = 1.268887996673584, acc = 0.580078125\n",
      "Batch 126: loss = 1.3821738958358765, acc = 0.5732421875\n",
      "\n",
      "Epoch 9/100\n",
      "Batch 1: loss = 1.6302099227905273, acc = 0.546875\n",
      "Batch 2: loss = 1.3506977558135986, acc = 0.56640625\n",
      "Batch 3: loss = 1.3133761882781982, acc = 0.5927734375\n",
      "Batch 4: loss = 1.248171329498291, acc = 0.595703125\n",
      "Batch 5: loss = 1.4255727529525757, acc = 0.55078125\n",
      "Batch 6: loss = 1.4268726110458374, acc = 0.552734375\n",
      "Batch 7: loss = 1.4036496877670288, acc = 0.556640625\n",
      "Batch 8: loss = 1.2511353492736816, acc = 0.5986328125\n",
      "Batch 9: loss = 1.2444586753845215, acc = 0.59375\n",
      "Batch 10: loss = 1.1297252178192139, acc = 0.642578125\n",
      "Batch 11: loss = 1.321203589439392, acc = 0.5693359375\n",
      "Batch 12: loss = 1.3804041147232056, acc = 0.556640625\n",
      "Batch 13: loss = 1.2773284912109375, acc = 0.5634765625\n",
      "Batch 14: loss = 1.2032365798950195, acc = 0.603515625\n",
      "Batch 15: loss = 1.2250374555587769, acc = 0.6064453125\n",
      "Batch 16: loss = 1.3466486930847168, acc = 0.560546875\n",
      "Batch 17: loss = 1.2854340076446533, acc = 0.603515625\n",
      "Batch 18: loss = 1.3916923999786377, acc = 0.5458984375\n",
      "Batch 19: loss = 1.309335470199585, acc = 0.59375\n",
      "Batch 20: loss = 1.1832512617111206, acc = 0.6162109375\n",
      "Batch 21: loss = 1.376220941543579, acc = 0.5654296875\n",
      "Batch 22: loss = 1.167249321937561, acc = 0.6162109375\n",
      "Batch 23: loss = 1.2312532663345337, acc = 0.5908203125\n",
      "Batch 24: loss = 1.2734063863754272, acc = 0.5791015625\n",
      "Batch 25: loss = 1.173532485961914, acc = 0.62109375\n",
      "Batch 26: loss = 1.1879534721374512, acc = 0.6181640625\n",
      "Batch 27: loss = 1.296888828277588, acc = 0.58203125\n",
      "Batch 28: loss = 1.286170244216919, acc = 0.5888671875\n",
      "Batch 29: loss = 1.222458839416504, acc = 0.6181640625\n",
      "Batch 30: loss = 1.1971158981323242, acc = 0.6162109375\n",
      "Batch 31: loss = 1.3195469379425049, acc = 0.59375\n",
      "Batch 32: loss = 1.4702671766281128, acc = 0.5458984375\n",
      "Batch 33: loss = 1.2747036218643188, acc = 0.60546875\n",
      "Batch 34: loss = 1.272953748703003, acc = 0.5869140625\n",
      "Batch 35: loss = 1.3047080039978027, acc = 0.5712890625\n",
      "Batch 36: loss = 1.32594895362854, acc = 0.6005859375\n",
      "Batch 37: loss = 1.3071281909942627, acc = 0.5986328125\n",
      "Batch 38: loss = 1.3230522871017456, acc = 0.60546875\n",
      "Batch 39: loss = 1.276824951171875, acc = 0.5654296875\n",
      "Batch 40: loss = 1.2368748188018799, acc = 0.5947265625\n",
      "Batch 41: loss = 1.1827518939971924, acc = 0.615234375\n",
      "Batch 42: loss = 1.192161202430725, acc = 0.6044921875\n",
      "Batch 43: loss = 1.2813133001327515, acc = 0.5732421875\n",
      "Batch 44: loss = 1.2178165912628174, acc = 0.611328125\n",
      "Batch 45: loss = 1.1285252571105957, acc = 0.63671875\n",
      "Batch 46: loss = 1.2243529558181763, acc = 0.607421875\n",
      "Batch 47: loss = 1.1845099925994873, acc = 0.6240234375\n",
      "Batch 48: loss = 1.1385082006454468, acc = 0.625\n",
      "Batch 49: loss = 1.09234619140625, acc = 0.6591796875\n",
      "Batch 50: loss = 1.1510450839996338, acc = 0.6376953125\n",
      "Batch 51: loss = 1.1929662227630615, acc = 0.59375\n",
      "Batch 52: loss = 1.2754628658294678, acc = 0.57421875\n",
      "Batch 53: loss = 1.3038675785064697, acc = 0.5703125\n",
      "Batch 54: loss = 1.2211309671401978, acc = 0.6201171875\n",
      "Batch 55: loss = 1.1847347021102905, acc = 0.6064453125\n",
      "Batch 56: loss = 1.2007372379302979, acc = 0.603515625\n",
      "Batch 57: loss = 1.2858374118804932, acc = 0.5576171875\n",
      "Batch 58: loss = 1.2513397932052612, acc = 0.6083984375\n",
      "Batch 59: loss = 1.0314223766326904, acc = 0.677734375\n",
      "Batch 60: loss = 1.198388695716858, acc = 0.6015625\n",
      "Batch 61: loss = 1.282250165939331, acc = 0.5927734375\n",
      "Batch 62: loss = 1.400914192199707, acc = 0.5244140625\n",
      "Batch 63: loss = 1.3721990585327148, acc = 0.556640625\n",
      "Batch 64: loss = 1.0018129348754883, acc = 0.677734375\n",
      "Batch 65: loss = 1.233283519744873, acc = 0.5986328125\n",
      "Batch 66: loss = 1.2095035314559937, acc = 0.61328125\n",
      "Batch 67: loss = 1.1481164693832397, acc = 0.630859375\n",
      "Batch 68: loss = 1.2430427074432373, acc = 0.599609375\n",
      "Batch 69: loss = 1.1721638441085815, acc = 0.623046875\n",
      "Batch 70: loss = 1.2782857418060303, acc = 0.5830078125\n",
      "Batch 71: loss = 1.1623241901397705, acc = 0.61328125\n",
      "Batch 72: loss = 1.1201902627944946, acc = 0.634765625\n",
      "Batch 73: loss = 1.2519934177398682, acc = 0.6025390625\n",
      "Batch 74: loss = 1.243630051612854, acc = 0.576171875\n",
      "Batch 75: loss = 1.341487169265747, acc = 0.5517578125\n",
      "Batch 76: loss = 1.3058902025222778, acc = 0.578125\n",
      "Batch 77: loss = 1.1215391159057617, acc = 0.630859375\n",
      "Batch 78: loss = 1.1336607933044434, acc = 0.6279296875\n",
      "Batch 79: loss = 0.9996477365493774, acc = 0.6767578125\n",
      "Batch 80: loss = 1.0841093063354492, acc = 0.6181640625\n",
      "Batch 81: loss = 1.1074624061584473, acc = 0.6376953125\n",
      "Batch 82: loss = 1.0604335069656372, acc = 0.66015625\n",
      "Batch 83: loss = 1.1891052722930908, acc = 0.62109375\n",
      "Batch 84: loss = 1.1625372171401978, acc = 0.62109375\n",
      "Batch 85: loss = 1.2582216262817383, acc = 0.583984375\n",
      "Batch 86: loss = 1.189948558807373, acc = 0.6103515625\n",
      "Batch 87: loss = 1.1312581300735474, acc = 0.62890625\n",
      "Batch 88: loss = 1.319594144821167, acc = 0.572265625\n",
      "Batch 89: loss = 1.2393748760223389, acc = 0.5966796875\n",
      "Batch 90: loss = 1.3150005340576172, acc = 0.5908203125\n",
      "Batch 91: loss = 1.2768315076828003, acc = 0.6005859375\n",
      "Batch 92: loss = 1.1117925643920898, acc = 0.63671875\n",
      "Batch 93: loss = 1.0616761445999146, acc = 0.6396484375\n",
      "Batch 94: loss = 1.1354509592056274, acc = 0.6357421875\n",
      "Batch 95: loss = 1.1837451457977295, acc = 0.5888671875\n",
      "Batch 96: loss = 1.2031155824661255, acc = 0.599609375\n",
      "Batch 97: loss = 1.2215638160705566, acc = 0.595703125\n",
      "Batch 98: loss = 1.229026436805725, acc = 0.62109375\n",
      "Batch 99: loss = 1.2185873985290527, acc = 0.607421875\n",
      "Batch 100: loss = 1.1796491146087646, acc = 0.623046875\n",
      "Batch 101: loss = 1.2206000089645386, acc = 0.6044921875\n",
      "Batch 102: loss = 1.3143832683563232, acc = 0.5703125\n",
      "Batch 103: loss = 1.2263977527618408, acc = 0.6025390625\n",
      "Batch 104: loss = 1.1590291261672974, acc = 0.6171875\n",
      "Batch 105: loss = 1.2101426124572754, acc = 0.6162109375\n",
      "Batch 106: loss = 1.2786370515823364, acc = 0.6025390625\n",
      "Batch 107: loss = 1.1998145580291748, acc = 0.60546875\n",
      "Batch 108: loss = 1.2020363807678223, acc = 0.607421875\n",
      "Batch 109: loss = 1.16708505153656, acc = 0.6083984375\n",
      "Batch 110: loss = 1.1326541900634766, acc = 0.6357421875\n",
      "Batch 111: loss = 1.3046090602874756, acc = 0.5791015625\n",
      "Batch 112: loss = 1.1374521255493164, acc = 0.6279296875\n",
      "Batch 113: loss = 1.1996335983276367, acc = 0.6025390625\n",
      "Batch 114: loss = 1.2805789709091187, acc = 0.619140625\n",
      "Batch 115: loss = 1.3071494102478027, acc = 0.5751953125\n",
      "Batch 116: loss = 1.3171484470367432, acc = 0.5869140625\n",
      "Batch 117: loss = 1.179361343383789, acc = 0.6162109375\n",
      "Batch 118: loss = 1.1507302522659302, acc = 0.6064453125\n",
      "Batch 119: loss = 1.2345194816589355, acc = 0.5888671875\n",
      "Batch 120: loss = 1.2835696935653687, acc = 0.578125\n",
      "Batch 121: loss = 1.1371307373046875, acc = 0.6259765625\n",
      "Batch 122: loss = 1.1554009914398193, acc = 0.6259765625\n",
      "Batch 123: loss = 1.1933964490890503, acc = 0.611328125\n",
      "Batch 124: loss = 1.2443687915802002, acc = 0.568359375\n",
      "Batch 125: loss = 1.2363488674163818, acc = 0.6005859375\n",
      "Batch 126: loss = 1.3474541902542114, acc = 0.5732421875\n",
      "\n",
      "Epoch 10/100\n",
      "Batch 1: loss = 1.5959036350250244, acc = 0.560546875\n",
      "Batch 2: loss = 1.3236562013626099, acc = 0.576171875\n",
      "Batch 3: loss = 1.2651883363723755, acc = 0.6162109375\n",
      "Batch 4: loss = 1.2463117837905884, acc = 0.6025390625\n",
      "Batch 5: loss = 1.3688856363296509, acc = 0.560546875\n",
      "Batch 6: loss = 1.370844841003418, acc = 0.568359375\n",
      "Batch 7: loss = 1.3616453409194946, acc = 0.5673828125\n",
      "Batch 8: loss = 1.2189090251922607, acc = 0.607421875\n",
      "Batch 9: loss = 1.2113597393035889, acc = 0.6015625\n",
      "Batch 10: loss = 1.101636290550232, acc = 0.6474609375\n",
      "Batch 11: loss = 1.2697741985321045, acc = 0.5791015625\n",
      "Batch 12: loss = 1.345686912536621, acc = 0.556640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13: loss = 1.2295842170715332, acc = 0.5751953125\n",
      "Batch 14: loss = 1.184929370880127, acc = 0.59765625\n",
      "Batch 15: loss = 1.2012829780578613, acc = 0.6142578125\n",
      "Batch 16: loss = 1.3285439014434814, acc = 0.568359375\n",
      "Batch 17: loss = 1.252878189086914, acc = 0.59375\n",
      "Batch 18: loss = 1.315256118774414, acc = 0.57421875\n",
      "Batch 19: loss = 1.2412902116775513, acc = 0.6025390625\n",
      "Batch 20: loss = 1.1558797359466553, acc = 0.6142578125\n",
      "Batch 21: loss = 1.3268625736236572, acc = 0.580078125\n",
      "Batch 22: loss = 1.1284438371658325, acc = 0.62890625\n",
      "Batch 23: loss = 1.20247220993042, acc = 0.6103515625\n",
      "Batch 24: loss = 1.2307331562042236, acc = 0.5947265625\n",
      "Batch 25: loss = 1.1177741289138794, acc = 0.6279296875\n",
      "Batch 26: loss = 1.1189301013946533, acc = 0.6455078125\n",
      "Batch 27: loss = 1.2528095245361328, acc = 0.59765625\n",
      "Batch 28: loss = 1.2283928394317627, acc = 0.6064453125\n",
      "Batch 29: loss = 1.1780790090560913, acc = 0.638671875\n",
      "Batch 30: loss = 1.1285545825958252, acc = 0.642578125\n",
      "Batch 31: loss = 1.2885706424713135, acc = 0.583984375\n",
      "Batch 32: loss = 1.4429863691329956, acc = 0.5400390625\n",
      "Batch 33: loss = 1.2112400531768799, acc = 0.607421875\n",
      "Batch 34: loss = 1.2353729009628296, acc = 0.6005859375\n",
      "Batch 35: loss = 1.241361141204834, acc = 0.5869140625\n",
      "Batch 36: loss = 1.264757513999939, acc = 0.6005859375\n",
      "Batch 37: loss = 1.26631498336792, acc = 0.6142578125\n",
      "Batch 38: loss = 1.2715331315994263, acc = 0.61328125\n",
      "Batch 39: loss = 1.2355843782424927, acc = 0.58984375\n",
      "Batch 40: loss = 1.2079780101776123, acc = 0.611328125\n",
      "Batch 41: loss = 1.131707787513733, acc = 0.6376953125\n",
      "Batch 42: loss = 1.160072922706604, acc = 0.6181640625\n",
      "Batch 43: loss = 1.2421718835830688, acc = 0.58984375\n",
      "Batch 44: loss = 1.1596382856369019, acc = 0.6376953125\n",
      "Batch 45: loss = 1.0711066722869873, acc = 0.642578125\n",
      "Batch 46: loss = 1.1795318126678467, acc = 0.6328125\n",
      "Batch 47: loss = 1.1539310216903687, acc = 0.6201171875\n",
      "Batch 48: loss = 1.092973232269287, acc = 0.6337890625\n",
      "Batch 49: loss = 1.0610624551773071, acc = 0.6533203125\n",
      "Batch 50: loss = 1.0965189933776855, acc = 0.654296875\n",
      "Batch 51: loss = 1.128981113433838, acc = 0.6142578125\n",
      "Batch 52: loss = 1.2465314865112305, acc = 0.6015625\n",
      "Batch 53: loss = 1.23343825340271, acc = 0.5947265625\n",
      "Batch 54: loss = 1.172226905822754, acc = 0.6240234375\n",
      "Batch 55: loss = 1.152334451675415, acc = 0.62109375\n",
      "Batch 56: loss = 1.1575100421905518, acc = 0.607421875\n",
      "Batch 57: loss = 1.236083745956421, acc = 0.5625\n",
      "Batch 58: loss = 1.212534785270691, acc = 0.61328125\n",
      "Batch 59: loss = 0.985493540763855, acc = 0.67578125\n",
      "Batch 60: loss = 1.168442964553833, acc = 0.619140625\n",
      "Batch 61: loss = 1.233338475227356, acc = 0.6142578125\n",
      "Batch 62: loss = 1.3668957948684692, acc = 0.52734375\n",
      "Batch 63: loss = 1.3420311212539673, acc = 0.5703125\n",
      "Batch 64: loss = 0.9884881973266602, acc = 0.6796875\n",
      "Batch 65: loss = 1.2065829038619995, acc = 0.6220703125\n",
      "Batch 66: loss = 1.1788662672042847, acc = 0.6220703125\n",
      "Batch 67: loss = 1.1079373359680176, acc = 0.6416015625\n",
      "Batch 68: loss = 1.1810493469238281, acc = 0.625\n",
      "Batch 69: loss = 1.136149287223816, acc = 0.6328125\n",
      "Batch 70: loss = 1.231626033782959, acc = 0.60546875\n",
      "Batch 71: loss = 1.1289448738098145, acc = 0.6240234375\n",
      "Batch 72: loss = 1.0932506322860718, acc = 0.634765625\n",
      "Batch 73: loss = 1.2188153266906738, acc = 0.6064453125\n",
      "Batch 74: loss = 1.199502944946289, acc = 0.587890625\n",
      "Batch 75: loss = 1.290623426437378, acc = 0.55859375\n",
      "Batch 76: loss = 1.2665328979492188, acc = 0.5966796875\n",
      "Batch 77: loss = 1.0828497409820557, acc = 0.646484375\n",
      "Batch 78: loss = 1.1172281503677368, acc = 0.638671875\n",
      "Batch 79: loss = 0.9437405467033386, acc = 0.6796875\n",
      "Batch 80: loss = 1.0439882278442383, acc = 0.6337890625\n",
      "Batch 81: loss = 1.0593595504760742, acc = 0.6484375\n",
      "Batch 82: loss = 1.0129523277282715, acc = 0.671875\n",
      "Batch 83: loss = 1.144927978515625, acc = 0.625\n",
      "Batch 84: loss = 1.1348989009857178, acc = 0.62109375\n",
      "Batch 85: loss = 1.2207677364349365, acc = 0.6083984375\n",
      "Batch 86: loss = 1.1505475044250488, acc = 0.6298828125\n",
      "Batch 87: loss = 1.0944253206253052, acc = 0.6474609375\n",
      "Batch 88: loss = 1.2791149616241455, acc = 0.5947265625\n",
      "Batch 89: loss = 1.1952118873596191, acc = 0.6142578125\n",
      "Batch 90: loss = 1.266953706741333, acc = 0.6162109375\n",
      "Batch 91: loss = 1.2596993446350098, acc = 0.6005859375\n",
      "Batch 92: loss = 1.1051561832427979, acc = 0.640625\n",
      "Batch 93: loss = 1.0142576694488525, acc = 0.6650390625\n",
      "Batch 94: loss = 1.0728235244750977, acc = 0.6611328125\n",
      "Batch 95: loss = 1.1327013969421387, acc = 0.60546875\n",
      "Batch 96: loss = 1.1494886875152588, acc = 0.6298828125\n",
      "Batch 97: loss = 1.17842698097229, acc = 0.6181640625\n",
      "Batch 98: loss = 1.1811977624893188, acc = 0.6396484375\n",
      "Batch 99: loss = 1.1781847476959229, acc = 0.6103515625\n",
      "Batch 100: loss = 1.1270713806152344, acc = 0.634765625\n",
      "Batch 101: loss = 1.1661641597747803, acc = 0.62109375\n",
      "Batch 102: loss = 1.255174994468689, acc = 0.595703125\n",
      "Batch 103: loss = 1.1623077392578125, acc = 0.6220703125\n",
      "Batch 104: loss = 1.110276699066162, acc = 0.6376953125\n",
      "Batch 105: loss = 1.1424545049667358, acc = 0.64453125\n",
      "Batch 106: loss = 1.2421406507492065, acc = 0.6083984375\n",
      "Batch 107: loss = 1.1408309936523438, acc = 0.6298828125\n",
      "Batch 108: loss = 1.1596579551696777, acc = 0.6259765625\n",
      "Batch 109: loss = 1.129058837890625, acc = 0.6279296875\n",
      "Batch 110: loss = 1.1071332693099976, acc = 0.65625\n",
      "Batch 111: loss = 1.2547073364257812, acc = 0.591796875\n",
      "Batch 112: loss = 1.1069374084472656, acc = 0.6318359375\n",
      "Batch 113: loss = 1.162524938583374, acc = 0.626953125\n",
      "Batch 114: loss = 1.2115356922149658, acc = 0.6337890625\n",
      "Batch 115: loss = 1.2535245418548584, acc = 0.5966796875\n",
      "Batch 116: loss = 1.2773200273513794, acc = 0.6064453125\n",
      "Batch 117: loss = 1.1329708099365234, acc = 0.6328125\n",
      "Batch 118: loss = 1.1039025783538818, acc = 0.6279296875\n",
      "Batch 119: loss = 1.2076494693756104, acc = 0.6015625\n",
      "Batch 120: loss = 1.2355117797851562, acc = 0.587890625\n",
      "Batch 121: loss = 1.1097922325134277, acc = 0.6318359375\n",
      "Batch 122: loss = 1.1028087139129639, acc = 0.6416015625\n",
      "Batch 123: loss = 1.1422573328018188, acc = 0.6162109375\n",
      "Batch 124: loss = 1.2037007808685303, acc = 0.5869140625\n",
      "Batch 125: loss = 1.1954894065856934, acc = 0.5986328125\n",
      "Batch 126: loss = 1.295052170753479, acc = 0.6123046875\n",
      "Saved checkpoint to weights.10.h5\n",
      "\n",
      "Epoch 11/100\n",
      "Batch 1: loss = 1.530796766281128, acc = 0.5576171875\n",
      "Batch 2: loss = 1.2856602668762207, acc = 0.5791015625\n",
      "Batch 3: loss = 1.2257039546966553, acc = 0.6240234375\n",
      "Batch 4: loss = 1.20917546749115, acc = 0.6005859375\n",
      "Batch 5: loss = 1.3375447988510132, acc = 0.5673828125\n",
      "Batch 6: loss = 1.339009404182434, acc = 0.5615234375\n",
      "Batch 7: loss = 1.3238658905029297, acc = 0.5869140625\n",
      "Batch 8: loss = 1.1762439012527466, acc = 0.6201171875\n",
      "Batch 9: loss = 1.1838343143463135, acc = 0.6005859375\n",
      "Batch 10: loss = 1.0740137100219727, acc = 0.6708984375\n",
      "Batch 11: loss = 1.2398731708526611, acc = 0.6005859375\n",
      "Batch 12: loss = 1.2903156280517578, acc = 0.587890625\n",
      "Batch 13: loss = 1.1743282079696655, acc = 0.6005859375\n",
      "Batch 14: loss = 1.137826919555664, acc = 0.6181640625\n",
      "Batch 15: loss = 1.1259381771087646, acc = 0.6279296875\n",
      "Batch 16: loss = 1.2652345895767212, acc = 0.5947265625\n",
      "Batch 17: loss = 1.2046353816986084, acc = 0.625\n",
      "Batch 18: loss = 1.2633700370788574, acc = 0.5771484375\n",
      "Batch 19: loss = 1.215680480003357, acc = 0.5947265625\n",
      "Batch 20: loss = 1.1290408372879028, acc = 0.62109375\n",
      "Batch 21: loss = 1.292039394378662, acc = 0.5849609375\n",
      "Batch 22: loss = 1.097180724143982, acc = 0.6318359375\n",
      "Batch 23: loss = 1.1422367095947266, acc = 0.6328125\n",
      "Batch 24: loss = 1.1585745811462402, acc = 0.62109375\n",
      "Batch 25: loss = 1.0652616024017334, acc = 0.654296875\n",
      "Batch 26: loss = 1.0784752368927002, acc = 0.6611328125\n",
      "Batch 27: loss = 1.225297451019287, acc = 0.611328125\n",
      "Batch 28: loss = 1.1948519945144653, acc = 0.609375\n",
      "Batch 29: loss = 1.1361562013626099, acc = 0.6513671875\n",
      "Batch 30: loss = 1.0940427780151367, acc = 0.6552734375\n",
      "Batch 31: loss = 1.2398033142089844, acc = 0.6083984375\n",
      "Batch 32: loss = 1.3929580450057983, acc = 0.5517578125\n",
      "Batch 33: loss = 1.1650993824005127, acc = 0.625\n",
      "Batch 34: loss = 1.1999585628509521, acc = 0.6103515625\n",
      "Batch 35: loss = 1.1991939544677734, acc = 0.6162109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 36: loss = 1.2217414379119873, acc = 0.619140625\n",
      "Batch 37: loss = 1.2214219570159912, acc = 0.6376953125\n",
      "Batch 38: loss = 1.237048625946045, acc = 0.62109375\n",
      "Batch 39: loss = 1.2091764211654663, acc = 0.6083984375\n",
      "Batch 40: loss = 1.1696569919586182, acc = 0.6103515625\n",
      "Batch 41: loss = 1.1012780666351318, acc = 0.6455078125\n",
      "Batch 42: loss = 1.123471975326538, acc = 0.6259765625\n",
      "Batch 43: loss = 1.1955022811889648, acc = 0.58984375\n",
      "Batch 44: loss = 1.1333229541778564, acc = 0.634765625\n",
      "Batch 45: loss = 1.0286099910736084, acc = 0.64453125\n",
      "Batch 46: loss = 1.1356287002563477, acc = 0.6298828125\n",
      "Batch 47: loss = 1.0904475450515747, acc = 0.6455078125\n",
      "Batch 48: loss = 1.065772533416748, acc = 0.642578125\n",
      "Batch 49: loss = 1.02667236328125, acc = 0.6640625\n",
      "Batch 50: loss = 1.0642178058624268, acc = 0.6669921875\n",
      "Batch 51: loss = 1.095870852470398, acc = 0.6337890625\n",
      "Batch 52: loss = 1.2034728527069092, acc = 0.5986328125\n",
      "Batch 53: loss = 1.1903395652770996, acc = 0.607421875\n",
      "Batch 54: loss = 1.1280401945114136, acc = 0.646484375\n",
      "Batch 55: loss = 1.1049797534942627, acc = 0.654296875\n",
      "Batch 56: loss = 1.1256051063537598, acc = 0.615234375\n",
      "Batch 57: loss = 1.191556453704834, acc = 0.5966796875\n",
      "Batch 58: loss = 1.1798533201217651, acc = 0.6171875\n",
      "Batch 59: loss = 0.9559692144393921, acc = 0.7060546875\n",
      "Batch 60: loss = 1.1161718368530273, acc = 0.6328125\n",
      "Batch 61: loss = 1.1904245615005493, acc = 0.61328125\n",
      "Batch 62: loss = 1.3450027704238892, acc = 0.5322265625\n",
      "Batch 63: loss = 1.2891430854797363, acc = 0.59765625\n",
      "Batch 64: loss = 0.9604953527450562, acc = 0.6865234375\n",
      "Batch 65: loss = 1.144514560699463, acc = 0.6455078125\n",
      "Batch 66: loss = 1.1213271617889404, acc = 0.640625\n",
      "Batch 67: loss = 1.0740032196044922, acc = 0.6611328125\n",
      "Batch 68: loss = 1.1372319459915161, acc = 0.630859375\n",
      "Batch 69: loss = 1.0851316452026367, acc = 0.6474609375\n",
      "Batch 70: loss = 1.1935217380523682, acc = 0.61328125\n",
      "Batch 71: loss = 1.0761494636535645, acc = 0.66015625\n",
      "Batch 72: loss = 1.0534793138504028, acc = 0.662109375\n",
      "Batch 73: loss = 1.1843239068984985, acc = 0.6240234375\n",
      "Batch 74: loss = 1.161494255065918, acc = 0.6142578125\n",
      "Batch 75: loss = 1.2314207553863525, acc = 0.591796875\n",
      "Batch 76: loss = 1.2273013591766357, acc = 0.603515625\n",
      "Batch 77: loss = 1.0529590845108032, acc = 0.642578125\n",
      "Batch 78: loss = 1.0325820446014404, acc = 0.6728515625\n",
      "Batch 79: loss = 0.9337514638900757, acc = 0.693359375\n",
      "Batch 80: loss = 1.0042545795440674, acc = 0.6513671875\n",
      "Batch 81: loss = 1.0207611322402954, acc = 0.6650390625\n",
      "Batch 82: loss = 0.9836119413375854, acc = 0.6806640625\n",
      "Batch 83: loss = 1.107386827468872, acc = 0.626953125\n",
      "Batch 84: loss = 1.1093497276306152, acc = 0.64453125\n",
      "Batch 85: loss = 1.1606285572052002, acc = 0.6142578125\n",
      "Batch 86: loss = 1.1216329336166382, acc = 0.6376953125\n",
      "Batch 87: loss = 1.0613012313842773, acc = 0.6533203125\n",
      "Batch 88: loss = 1.2472515106201172, acc = 0.6044921875\n",
      "Batch 89: loss = 1.144577980041504, acc = 0.6142578125\n",
      "Batch 90: loss = 1.2223248481750488, acc = 0.62109375\n",
      "Batch 91: loss = 1.2208534479141235, acc = 0.6015625\n",
      "Batch 92: loss = 1.0693964958190918, acc = 0.654296875\n",
      "Batch 93: loss = 0.9826421737670898, acc = 0.68359375\n",
      "Batch 94: loss = 1.0517040491104126, acc = 0.65625\n",
      "Batch 95: loss = 1.0979130268096924, acc = 0.615234375\n",
      "Batch 96: loss = 1.135619878768921, acc = 0.62890625\n",
      "Batch 97: loss = 1.1296679973602295, acc = 0.638671875\n",
      "Batch 98: loss = 1.1562241315841675, acc = 0.6474609375\n",
      "Batch 99: loss = 1.1318376064300537, acc = 0.6240234375\n",
      "Batch 100: loss = 1.076918125152588, acc = 0.6396484375\n",
      "Batch 101: loss = 1.1349704265594482, acc = 0.6298828125\n",
      "Batch 102: loss = 1.1955193281173706, acc = 0.6123046875\n",
      "Batch 103: loss = 1.1290652751922607, acc = 0.630859375\n",
      "Batch 104: loss = 1.0763177871704102, acc = 0.6357421875\n",
      "Batch 105: loss = 1.107796549797058, acc = 0.6416015625\n",
      "Batch 106: loss = 1.2033202648162842, acc = 0.634765625\n",
      "Batch 107: loss = 1.1047383546829224, acc = 0.6552734375\n",
      "Batch 108: loss = 1.119720458984375, acc = 0.6240234375\n",
      "Batch 109: loss = 1.0897016525268555, acc = 0.6376953125\n",
      "Batch 110: loss = 1.0835541486740112, acc = 0.6533203125\n",
      "Batch 111: loss = 1.2154489755630493, acc = 0.6025390625\n",
      "Batch 112: loss = 1.0522236824035645, acc = 0.642578125\n",
      "Batch 113: loss = 1.122542142868042, acc = 0.63671875\n",
      "Batch 114: loss = 1.1839605569839478, acc = 0.63671875\n",
      "Batch 115: loss = 1.1937661170959473, acc = 0.6279296875\n",
      "Batch 116: loss = 1.2517622709274292, acc = 0.609375\n",
      "Batch 117: loss = 1.075953722000122, acc = 0.646484375\n",
      "Batch 118: loss = 1.0376429557800293, acc = 0.64453125\n",
      "Batch 119: loss = 1.164959192276001, acc = 0.6044921875\n",
      "Batch 120: loss = 1.182711124420166, acc = 0.6103515625\n",
      "Batch 121: loss = 1.069665551185608, acc = 0.66015625\n",
      "Batch 122: loss = 1.067917823791504, acc = 0.64453125\n",
      "Batch 123: loss = 1.1159684658050537, acc = 0.6279296875\n",
      "Batch 124: loss = 1.1677387952804565, acc = 0.5908203125\n",
      "Batch 125: loss = 1.153351068496704, acc = 0.6005859375\n",
      "Batch 126: loss = 1.2575702667236328, acc = 0.6103515625\n",
      "\n",
      "Epoch 12/100\n",
      "Batch 1: loss = 1.4891109466552734, acc = 0.5732421875\n",
      "Batch 2: loss = 1.2667288780212402, acc = 0.5986328125\n",
      "Batch 3: loss = 1.1789121627807617, acc = 0.63671875\n",
      "Batch 4: loss = 1.1686580181121826, acc = 0.6181640625\n",
      "Batch 5: loss = 1.2978243827819824, acc = 0.583984375\n",
      "Batch 6: loss = 1.3146815299987793, acc = 0.5830078125\n",
      "Batch 7: loss = 1.2553215026855469, acc = 0.59765625\n",
      "Batch 8: loss = 1.1403846740722656, acc = 0.6318359375\n",
      "Batch 9: loss = 1.131036639213562, acc = 0.6220703125\n",
      "Batch 10: loss = 1.0221145153045654, acc = 0.666015625\n",
      "Batch 11: loss = 1.187577247619629, acc = 0.625\n",
      "Batch 12: loss = 1.228203296661377, acc = 0.60546875\n",
      "Batch 13: loss = 1.1370501518249512, acc = 0.6005859375\n",
      "Batch 14: loss = 1.1170120239257812, acc = 0.6455078125\n",
      "Batch 15: loss = 1.1001276969909668, acc = 0.658203125\n",
      "Batch 16: loss = 1.2344269752502441, acc = 0.6025390625\n",
      "Batch 17: loss = 1.1660115718841553, acc = 0.615234375\n",
      "Batch 18: loss = 1.2167375087738037, acc = 0.60546875\n",
      "Batch 19: loss = 1.1735248565673828, acc = 0.6376953125\n",
      "Batch 20: loss = 1.0690157413482666, acc = 0.638671875\n",
      "Batch 21: loss = 1.2638205289840698, acc = 0.6025390625\n",
      "Batch 22: loss = 1.0650341510772705, acc = 0.6552734375\n",
      "Batch 23: loss = 1.1062674522399902, acc = 0.640625\n",
      "Batch 24: loss = 1.1032695770263672, acc = 0.630859375\n",
      "Batch 25: loss = 1.0552462339401245, acc = 0.6484375\n",
      "Batch 26: loss = 1.0468332767486572, acc = 0.662109375\n",
      "Batch 27: loss = 1.1524803638458252, acc = 0.6259765625\n",
      "Batch 28: loss = 1.128066062927246, acc = 0.630859375\n",
      "Batch 29: loss = 1.0954903364181519, acc = 0.669921875\n",
      "Batch 30: loss = 1.0382366180419922, acc = 0.669921875\n",
      "Batch 31: loss = 1.2123315334320068, acc = 0.6181640625\n",
      "Batch 32: loss = 1.3540713787078857, acc = 0.5625\n",
      "Batch 33: loss = 1.1294410228729248, acc = 0.6240234375\n",
      "Batch 34: loss = 1.163273811340332, acc = 0.611328125\n",
      "Batch 35: loss = 1.1696467399597168, acc = 0.6240234375\n",
      "Batch 36: loss = 1.1686019897460938, acc = 0.638671875\n",
      "Batch 37: loss = 1.1619664430618286, acc = 0.650390625\n",
      "Batch 38: loss = 1.1874144077301025, acc = 0.626953125\n",
      "Batch 39: loss = 1.1464688777923584, acc = 0.6328125\n",
      "Batch 40: loss = 1.1319470405578613, acc = 0.6162109375\n",
      "Batch 41: loss = 1.0505664348602295, acc = 0.6552734375\n",
      "Batch 42: loss = 1.0722594261169434, acc = 0.6337890625\n",
      "Batch 43: loss = 1.1598175764083862, acc = 0.6083984375\n",
      "Batch 44: loss = 1.0788447856903076, acc = 0.654296875\n",
      "Batch 45: loss = 0.9883328676223755, acc = 0.669921875\n",
      "Batch 46: loss = 1.0890772342681885, acc = 0.6484375\n",
      "Batch 47: loss = 1.0641297101974487, acc = 0.64453125\n",
      "Batch 48: loss = 1.015639066696167, acc = 0.6611328125\n",
      "Batch 49: loss = 0.9680624604225159, acc = 0.68359375\n",
      "Batch 50: loss = 1.035066843032837, acc = 0.68359375\n",
      "Batch 51: loss = 1.0261765718460083, acc = 0.6435546875\n",
      "Batch 52: loss = 1.14741849899292, acc = 0.6220703125\n",
      "Batch 53: loss = 1.1526601314544678, acc = 0.6123046875\n",
      "Batch 54: loss = 1.0814414024353027, acc = 0.6572265625\n",
      "Batch 55: loss = 1.0641863346099854, acc = 0.650390625\n",
      "Batch 56: loss = 1.0832724571228027, acc = 0.630859375\n",
      "Batch 57: loss = 1.1588141918182373, acc = 0.591796875\n",
      "Batch 58: loss = 1.1443840265274048, acc = 0.6279296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 59: loss = 0.9130498766899109, acc = 0.7099609375\n",
      "Batch 60: loss = 1.0616358518600464, acc = 0.6357421875\n",
      "Batch 61: loss = 1.1489965915679932, acc = 0.646484375\n",
      "Batch 62: loss = 1.3066048622131348, acc = 0.55859375\n",
      "Batch 63: loss = 1.2584879398345947, acc = 0.6015625\n",
      "Batch 64: loss = 0.9291914105415344, acc = 0.7001953125\n",
      "Batch 65: loss = 1.1148021221160889, acc = 0.64453125\n",
      "Batch 66: loss = 1.0981974601745605, acc = 0.6533203125\n",
      "Batch 67: loss = 1.0097508430480957, acc = 0.669921875\n",
      "Batch 68: loss = 1.0985846519470215, acc = 0.65234375\n",
      "Batch 69: loss = 1.0475109815597534, acc = 0.6591796875\n",
      "Batch 70: loss = 1.152604103088379, acc = 0.6376953125\n",
      "Batch 71: loss = 1.0500069856643677, acc = 0.654296875\n",
      "Batch 72: loss = 1.0147117376327515, acc = 0.67578125\n",
      "Batch 73: loss = 1.1351141929626465, acc = 0.6328125\n",
      "Batch 74: loss = 1.1048451662063599, acc = 0.6357421875\n",
      "Batch 75: loss = 1.201348066329956, acc = 0.59765625\n",
      "Batch 76: loss = 1.1536868810653687, acc = 0.6279296875\n",
      "Batch 77: loss = 1.0127036571502686, acc = 0.6708984375\n",
      "Batch 78: loss = 1.0321788787841797, acc = 0.6689453125\n",
      "Batch 79: loss = 0.8773915767669678, acc = 0.7197265625\n",
      "Batch 80: loss = 0.9501993656158447, acc = 0.6591796875\n",
      "Batch 81: loss = 0.9993417263031006, acc = 0.6669921875\n",
      "Batch 82: loss = 0.9534352421760559, acc = 0.68359375\n",
      "Batch 83: loss = 1.0625813007354736, acc = 0.6552734375\n",
      "Batch 84: loss = 1.0557951927185059, acc = 0.6630859375\n",
      "Batch 85: loss = 1.1314347982406616, acc = 0.6171875\n",
      "Batch 86: loss = 1.0805227756500244, acc = 0.6494140625\n",
      "Batch 87: loss = 1.0384867191314697, acc = 0.6494140625\n",
      "Batch 88: loss = 1.2033904790878296, acc = 0.619140625\n",
      "Batch 89: loss = 1.1218427419662476, acc = 0.638671875\n",
      "Batch 90: loss = 1.1856374740600586, acc = 0.6328125\n",
      "Batch 91: loss = 1.1614649295806885, acc = 0.6416015625\n",
      "Batch 92: loss = 1.0300904512405396, acc = 0.66796875\n",
      "Batch 93: loss = 0.9665656089782715, acc = 0.693359375\n",
      "Batch 94: loss = 1.0283572673797607, acc = 0.673828125\n",
      "Batch 95: loss = 1.0584003925323486, acc = 0.638671875\n",
      "Batch 96: loss = 1.094390869140625, acc = 0.6484375\n",
      "Batch 97: loss = 1.071582555770874, acc = 0.662109375\n",
      "Batch 98: loss = 1.1081311702728271, acc = 0.65234375\n",
      "Batch 99: loss = 1.079355001449585, acc = 0.642578125\n",
      "Batch 100: loss = 1.053591012954712, acc = 0.6416015625\n",
      "Batch 101: loss = 1.0763546228408813, acc = 0.654296875\n",
      "Batch 102: loss = 1.155756950378418, acc = 0.6416015625\n",
      "Batch 103: loss = 1.103227138519287, acc = 0.6474609375\n",
      "Batch 104: loss = 1.0625075101852417, acc = 0.650390625\n",
      "Batch 105: loss = 1.0538941621780396, acc = 0.6552734375\n",
      "Batch 106: loss = 1.1854331493377686, acc = 0.609375\n",
      "Batch 107: loss = 1.069943904876709, acc = 0.650390625\n",
      "Batch 108: loss = 1.074688196182251, acc = 0.654296875\n",
      "Batch 109: loss = 1.054438591003418, acc = 0.6337890625\n",
      "Batch 110: loss = 1.0242359638214111, acc = 0.669921875\n",
      "Batch 111: loss = 1.1707518100738525, acc = 0.623046875\n",
      "Batch 112: loss = 1.0287667512893677, acc = 0.6591796875\n",
      "Batch 113: loss = 1.0851976871490479, acc = 0.6435546875\n",
      "Batch 114: loss = 1.1394298076629639, acc = 0.6640625\n",
      "Batch 115: loss = 1.14752197265625, acc = 0.6318359375\n",
      "Batch 116: loss = 1.2357125282287598, acc = 0.6298828125\n",
      "Batch 117: loss = 1.0531057119369507, acc = 0.65625\n",
      "Batch 118: loss = 0.9932036399841309, acc = 0.6640625\n",
      "Batch 119: loss = 1.1081268787384033, acc = 0.63671875\n",
      "Batch 120: loss = 1.145958662033081, acc = 0.62890625\n",
      "Batch 121: loss = 1.0306150913238525, acc = 0.6630859375\n",
      "Batch 122: loss = 1.0359482765197754, acc = 0.65625\n",
      "Batch 123: loss = 1.0753302574157715, acc = 0.6455078125\n",
      "Batch 124: loss = 1.1172903776168823, acc = 0.6259765625\n",
      "Batch 125: loss = 1.1191942691802979, acc = 0.623046875\n",
      "Batch 126: loss = 1.2156867980957031, acc = 0.6240234375\n",
      "\n",
      "Epoch 13/100\n",
      "Batch 1: loss = 1.4192360639572144, acc = 0.5791015625\n",
      "Batch 2: loss = 1.238099217414856, acc = 0.6123046875\n",
      "Batch 3: loss = 1.153621792793274, acc = 0.6416015625\n",
      "Batch 4: loss = 1.1453278064727783, acc = 0.6220703125\n",
      "Batch 5: loss = 1.2579984664916992, acc = 0.58984375\n",
      "Batch 6: loss = 1.2256863117218018, acc = 0.599609375\n",
      "Batch 7: loss = 1.2204358577728271, acc = 0.6142578125\n",
      "Batch 8: loss = 1.1103646755218506, acc = 0.640625\n",
      "Batch 9: loss = 1.0734827518463135, acc = 0.650390625\n",
      "Batch 10: loss = 0.9762129783630371, acc = 0.6689453125\n",
      "Batch 11: loss = 1.165926218032837, acc = 0.6201171875\n",
      "Batch 12: loss = 1.1905598640441895, acc = 0.6083984375\n",
      "Batch 13: loss = 1.111652135848999, acc = 0.6259765625\n",
      "Batch 14: loss = 1.083083152770996, acc = 0.642578125\n",
      "Batch 15: loss = 1.0531322956085205, acc = 0.6630859375\n",
      "Batch 16: loss = 1.1959528923034668, acc = 0.599609375\n",
      "Batch 17: loss = 1.1145415306091309, acc = 0.6572265625\n",
      "Batch 18: loss = 1.178944706916809, acc = 0.62109375\n",
      "Batch 19: loss = 1.091935634613037, acc = 0.6591796875\n",
      "Batch 20: loss = 1.027475357055664, acc = 0.66015625\n",
      "Batch 21: loss = 1.229053020477295, acc = 0.6025390625\n",
      "Batch 22: loss = 1.0360897779464722, acc = 0.662109375\n",
      "Batch 23: loss = 1.0473744869232178, acc = 0.6455078125\n",
      "Batch 24: loss = 1.0784536600112915, acc = 0.630859375\n",
      "Batch 25: loss = 0.9974176287651062, acc = 0.6689453125\n",
      "Batch 26: loss = 1.0065546035766602, acc = 0.677734375\n",
      "Batch 27: loss = 1.1497251987457275, acc = 0.6279296875\n",
      "Batch 28: loss = 1.0967177152633667, acc = 0.6328125\n",
      "Batch 29: loss = 1.0706757307052612, acc = 0.673828125\n",
      "Batch 30: loss = 0.9978705048561096, acc = 0.6728515625\n",
      "Batch 31: loss = 1.1725010871887207, acc = 0.6181640625\n",
      "Batch 32: loss = 1.3021050691604614, acc = 0.572265625\n",
      "Batch 33: loss = 1.0987391471862793, acc = 0.6474609375\n",
      "Batch 34: loss = 1.1140822172164917, acc = 0.6337890625\n",
      "Batch 35: loss = 1.1181612014770508, acc = 0.646484375\n",
      "Batch 36: loss = 1.121492862701416, acc = 0.6474609375\n",
      "Batch 37: loss = 1.1242084503173828, acc = 0.65234375\n",
      "Batch 38: loss = 1.1370723247528076, acc = 0.6376953125\n",
      "Batch 39: loss = 1.1010122299194336, acc = 0.640625\n",
      "Batch 40: loss = 1.0808348655700684, acc = 0.6484375\n",
      "Batch 41: loss = 1.0090136528015137, acc = 0.669921875\n",
      "Batch 42: loss = 1.046065330505371, acc = 0.6591796875\n",
      "Batch 43: loss = 1.1003875732421875, acc = 0.6328125\n",
      "Batch 44: loss = 1.033386468887329, acc = 0.6533203125\n",
      "Batch 45: loss = 0.9468364715576172, acc = 0.6865234375\n",
      "Batch 46: loss = 1.0611132383346558, acc = 0.6513671875\n",
      "Batch 47: loss = 1.0247068405151367, acc = 0.6650390625\n",
      "Batch 48: loss = 0.9844579696655273, acc = 0.6611328125\n",
      "Batch 49: loss = 0.9671615958213806, acc = 0.6982421875\n",
      "Batch 50: loss = 1.0049575567245483, acc = 0.681640625\n",
      "Batch 51: loss = 1.0051316022872925, acc = 0.6669921875\n",
      "Batch 52: loss = 1.123605728149414, acc = 0.6259765625\n",
      "Batch 53: loss = 1.1211802959442139, acc = 0.6171875\n",
      "Batch 54: loss = 1.0491846799850464, acc = 0.6728515625\n",
      "Batch 55: loss = 1.020674705505371, acc = 0.6611328125\n",
      "Batch 56: loss = 1.0583606958389282, acc = 0.6455078125\n",
      "Batch 57: loss = 1.1189205646514893, acc = 0.6201171875\n",
      "Batch 58: loss = 1.102994441986084, acc = 0.6494140625\n",
      "Batch 59: loss = 0.8819257020950317, acc = 0.716796875\n",
      "Batch 60: loss = 1.0417602062225342, acc = 0.671875\n",
      "Batch 61: loss = 1.1111152172088623, acc = 0.6572265625\n",
      "Batch 62: loss = 1.2739641666412354, acc = 0.5634765625\n",
      "Batch 63: loss = 1.232114315032959, acc = 0.6240234375\n",
      "Batch 64: loss = 0.9132785201072693, acc = 0.7119140625\n",
      "Batch 65: loss = 1.0737378597259521, acc = 0.6474609375\n",
      "Batch 66: loss = 1.0452537536621094, acc = 0.6455078125\n",
      "Batch 67: loss = 0.9673599004745483, acc = 0.677734375\n",
      "Batch 68: loss = 1.0735810995101929, acc = 0.65234375\n",
      "Batch 69: loss = 1.0224312543869019, acc = 0.6767578125\n",
      "Batch 70: loss = 1.1216394901275635, acc = 0.6337890625\n",
      "Batch 71: loss = 1.0103678703308105, acc = 0.6689453125\n",
      "Batch 72: loss = 0.9786388874053955, acc = 0.6865234375\n",
      "Batch 73: loss = 1.106999397277832, acc = 0.6298828125\n",
      "Batch 74: loss = 1.0795636177062988, acc = 0.646484375\n",
      "Batch 75: loss = 1.1711533069610596, acc = 0.6181640625\n",
      "Batch 76: loss = 1.0991082191467285, acc = 0.6416015625\n",
      "Batch 77: loss = 0.9649550318717957, acc = 0.66796875\n",
      "Batch 78: loss = 1.0001611709594727, acc = 0.6689453125\n",
      "Batch 79: loss = 0.855004072189331, acc = 0.7080078125\n",
      "Batch 80: loss = 0.9342001676559448, acc = 0.6708984375\n",
      "Batch 81: loss = 0.9615082740783691, acc = 0.6748046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 82: loss = 0.9104523658752441, acc = 0.7080078125\n",
      "Batch 83: loss = 1.0372049808502197, acc = 0.6630859375\n",
      "Batch 84: loss = 1.0226259231567383, acc = 0.6611328125\n",
      "Batch 85: loss = 1.1018240451812744, acc = 0.6318359375\n",
      "Batch 86: loss = 1.0497201681137085, acc = 0.646484375\n",
      "Batch 87: loss = 1.0178472995758057, acc = 0.658203125\n",
      "Batch 88: loss = 1.1711294651031494, acc = 0.625\n",
      "Batch 89: loss = 1.0822343826293945, acc = 0.6484375\n",
      "Batch 90: loss = 1.1357383728027344, acc = 0.6396484375\n",
      "Batch 91: loss = 1.1299536228179932, acc = 0.6484375\n",
      "Batch 92: loss = 1.0254837274551392, acc = 0.6708984375\n",
      "Batch 93: loss = 0.9199303388595581, acc = 0.7138671875\n",
      "Batch 94: loss = 0.9805803298950195, acc = 0.6923828125\n",
      "Batch 95: loss = 1.0136401653289795, acc = 0.6484375\n",
      "Batch 96: loss = 1.0402555465698242, acc = 0.6689453125\n",
      "Batch 97: loss = 1.044458031654358, acc = 0.6591796875\n",
      "Batch 98: loss = 1.0626219511032104, acc = 0.6650390625\n",
      "Batch 99: loss = 1.0539042949676514, acc = 0.6513671875\n",
      "Batch 100: loss = 1.023759126663208, acc = 0.658203125\n",
      "Batch 101: loss = 1.036850094795227, acc = 0.669921875\n",
      "Batch 102: loss = 1.1356102228164673, acc = 0.6416015625\n",
      "Batch 103: loss = 1.0743496417999268, acc = 0.658203125\n",
      "Batch 104: loss = 0.9855499863624573, acc = 0.6767578125\n",
      "Batch 105: loss = 1.0163969993591309, acc = 0.66796875\n",
      "Batch 106: loss = 1.1220759153366089, acc = 0.6474609375\n",
      "Batch 107: loss = 1.0552890300750732, acc = 0.66796875\n",
      "Batch 108: loss = 1.0392169952392578, acc = 0.6552734375\n",
      "Batch 109: loss = 1.042130947113037, acc = 0.6474609375\n",
      "Batch 110: loss = 0.9928860664367676, acc = 0.68359375\n",
      "Batch 111: loss = 1.13228440284729, acc = 0.6435546875\n",
      "Batch 112: loss = 1.0019763708114624, acc = 0.6650390625\n",
      "Batch 113: loss = 1.0707027912139893, acc = 0.6591796875\n",
      "Batch 114: loss = 1.0913364887237549, acc = 0.6748046875\n",
      "Batch 115: loss = 1.1275207996368408, acc = 0.6337890625\n",
      "Batch 116: loss = 1.1719800233840942, acc = 0.6474609375\n",
      "Batch 117: loss = 1.0338637828826904, acc = 0.658203125\n",
      "Batch 118: loss = 0.9718717336654663, acc = 0.671875\n",
      "Batch 119: loss = 1.0736494064331055, acc = 0.6484375\n",
      "Batch 120: loss = 1.099268913269043, acc = 0.6455078125\n",
      "Batch 121: loss = 1.0094177722930908, acc = 0.66796875\n",
      "Batch 122: loss = 1.0240464210510254, acc = 0.6640625\n",
      "Batch 123: loss = 1.0484411716461182, acc = 0.6611328125\n",
      "Batch 124: loss = 1.0837819576263428, acc = 0.6318359375\n",
      "Batch 125: loss = 1.1087405681610107, acc = 0.638671875\n",
      "Batch 126: loss = 1.1836388111114502, acc = 0.634765625\n",
      "\n",
      "Epoch 14/100\n",
      "Batch 1: loss = 1.3812522888183594, acc = 0.6005859375\n",
      "Batch 2: loss = 1.1841696500778198, acc = 0.62109375\n",
      "Batch 3: loss = 1.1213972568511963, acc = 0.638671875\n",
      "Batch 4: loss = 1.091275930404663, acc = 0.642578125\n",
      "Batch 5: loss = 1.2112786769866943, acc = 0.619140625\n",
      "Batch 6: loss = 1.2216005325317383, acc = 0.6162109375\n",
      "Batch 7: loss = 1.2150864601135254, acc = 0.59765625\n",
      "Batch 8: loss = 1.0487940311431885, acc = 0.6630859375\n",
      "Batch 9: loss = 1.0411992073059082, acc = 0.6513671875\n",
      "Batch 10: loss = 0.9665124416351318, acc = 0.6923828125\n",
      "Batch 11: loss = 1.1085231304168701, acc = 0.63671875\n",
      "Batch 12: loss = 1.1351280212402344, acc = 0.6240234375\n",
      "Batch 13: loss = 1.0618455410003662, acc = 0.640625\n",
      "Batch 14: loss = 1.0360956192016602, acc = 0.6650390625\n",
      "Batch 15: loss = 1.0230166912078857, acc = 0.6826171875\n",
      "Batch 16: loss = 1.127432107925415, acc = 0.6435546875\n",
      "Batch 17: loss = 1.0913407802581787, acc = 0.65234375\n",
      "Batch 18: loss = 1.139296293258667, acc = 0.6240234375\n",
      "Batch 19: loss = 1.0776264667510986, acc = 0.67578125\n",
      "Batch 20: loss = 1.0269322395324707, acc = 0.67578125\n",
      "Batch 21: loss = 1.1983400583267212, acc = 0.623046875\n",
      "Batch 22: loss = 1.0118293762207031, acc = 0.68359375\n",
      "Batch 23: loss = 1.028444766998291, acc = 0.658203125\n",
      "Batch 24: loss = 1.0596845149993896, acc = 0.6533203125\n",
      "Batch 25: loss = 0.9837163090705872, acc = 0.66015625\n",
      "Batch 26: loss = 0.9844620227813721, acc = 0.6728515625\n",
      "Batch 27: loss = 1.1173323392868042, acc = 0.66015625\n",
      "Batch 28: loss = 1.0517346858978271, acc = 0.6640625\n",
      "Batch 29: loss = 1.0383330583572388, acc = 0.681640625\n",
      "Batch 30: loss = 0.9652493000030518, acc = 0.6865234375\n",
      "Batch 31: loss = 1.1377227306365967, acc = 0.6279296875\n",
      "Batch 32: loss = 1.2368088960647583, acc = 0.58984375\n",
      "Batch 33: loss = 1.0513958930969238, acc = 0.6494140625\n",
      "Batch 34: loss = 1.0907727479934692, acc = 0.6279296875\n",
      "Batch 35: loss = 1.0812933444976807, acc = 0.6591796875\n",
      "Batch 36: loss = 1.0897345542907715, acc = 0.6474609375\n",
      "Batch 37: loss = 1.1062731742858887, acc = 0.6611328125\n",
      "Batch 38: loss = 1.1059260368347168, acc = 0.6591796875\n",
      "Batch 39: loss = 1.0962249040603638, acc = 0.6455078125\n",
      "Batch 40: loss = 1.0490537881851196, acc = 0.6494140625\n",
      "Batch 41: loss = 0.9828789234161377, acc = 0.677734375\n",
      "Batch 42: loss = 1.0127782821655273, acc = 0.6611328125\n",
      "Batch 43: loss = 1.0613789558410645, acc = 0.6455078125\n",
      "Batch 44: loss = 1.020646333694458, acc = 0.6787109375\n",
      "Batch 45: loss = 0.9409875869750977, acc = 0.697265625\n",
      "Batch 46: loss = 1.020247459411621, acc = 0.6767578125\n",
      "Batch 47: loss = 0.9843769073486328, acc = 0.673828125\n",
      "Batch 48: loss = 0.9674232602119446, acc = 0.6640625\n",
      "Batch 49: loss = 0.9066816568374634, acc = 0.6982421875\n",
      "Batch 50: loss = 0.9789597392082214, acc = 0.7001953125\n",
      "Batch 51: loss = 0.9717479944229126, acc = 0.673828125\n",
      "Batch 52: loss = 1.0895063877105713, acc = 0.630859375\n",
      "Batch 53: loss = 1.0878604650497437, acc = 0.6376953125\n",
      "Batch 54: loss = 0.9848352074623108, acc = 0.68359375\n",
      "Batch 55: loss = 0.9760928153991699, acc = 0.68359375\n",
      "Batch 56: loss = 1.0232493877410889, acc = 0.6591796875\n",
      "Batch 57: loss = 1.102975845336914, acc = 0.62890625\n",
      "Batch 58: loss = 1.0895801782608032, acc = 0.6357421875\n",
      "Batch 59: loss = 0.8684662580490112, acc = 0.7236328125\n",
      "Batch 60: loss = 1.0251621007919312, acc = 0.6728515625\n",
      "Batch 61: loss = 1.0715820789337158, acc = 0.6630859375\n",
      "Batch 62: loss = 1.2316670417785645, acc = 0.583984375\n",
      "Batch 63: loss = 1.1800739765167236, acc = 0.6142578125\n",
      "Batch 64: loss = 0.8783799409866333, acc = 0.7099609375\n",
      "Batch 65: loss = 1.072995901107788, acc = 0.658203125\n",
      "Batch 66: loss = 1.0256316661834717, acc = 0.6630859375\n",
      "Batch 67: loss = 0.9729509353637695, acc = 0.681640625\n",
      "Batch 68: loss = 1.0439196825027466, acc = 0.666015625\n",
      "Batch 69: loss = 0.9778756499290466, acc = 0.685546875\n",
      "Batch 70: loss = 1.1198052167892456, acc = 0.634765625\n",
      "Batch 71: loss = 0.9947032928466797, acc = 0.6728515625\n",
      "Batch 72: loss = 0.9635376930236816, acc = 0.685546875\n",
      "Batch 73: loss = 1.088810682296753, acc = 0.63671875\n",
      "Batch 74: loss = 1.062082052230835, acc = 0.6474609375\n",
      "Batch 75: loss = 1.145390272140503, acc = 0.6259765625\n",
      "Batch 76: loss = 1.0808943510055542, acc = 0.6484375\n",
      "Batch 77: loss = 0.9396007061004639, acc = 0.68359375\n",
      "Batch 78: loss = 0.9423572421073914, acc = 0.6875\n",
      "Batch 79: loss = 0.853652834892273, acc = 0.7099609375\n",
      "Batch 80: loss = 0.9054527878761292, acc = 0.6845703125\n",
      "Batch 81: loss = 0.964363694190979, acc = 0.6796875\n",
      "Batch 82: loss = 0.8767723441123962, acc = 0.7177734375\n",
      "Batch 83: loss = 1.0036355257034302, acc = 0.673828125\n",
      "Batch 84: loss = 1.0119808912277222, acc = 0.671875\n",
      "Batch 85: loss = 1.0719714164733887, acc = 0.66015625\n",
      "Batch 86: loss = 1.0252983570098877, acc = 0.673828125\n",
      "Batch 87: loss = 0.9813203811645508, acc = 0.677734375\n",
      "Batch 88: loss = 1.1391456127166748, acc = 0.625\n",
      "Batch 89: loss = 1.047980785369873, acc = 0.662109375\n",
      "Batch 90: loss = 1.1336296796798706, acc = 0.65234375\n",
      "Batch 91: loss = 1.1178888082504272, acc = 0.650390625\n",
      "Batch 92: loss = 1.0060827732086182, acc = 0.6728515625\n",
      "Batch 93: loss = 0.9125996828079224, acc = 0.7080078125\n",
      "Batch 94: loss = 0.968969464302063, acc = 0.6943359375\n",
      "Batch 95: loss = 0.9955297708511353, acc = 0.650390625\n",
      "Batch 96: loss = 1.0508818626403809, acc = 0.65625\n",
      "Batch 97: loss = 1.004227638244629, acc = 0.6875\n",
      "Batch 98: loss = 1.0264039039611816, acc = 0.6708984375\n",
      "Batch 99: loss = 1.0138022899627686, acc = 0.673828125\n",
      "Batch 100: loss = 0.975147545337677, acc = 0.6767578125\n",
      "Batch 101: loss = 0.9986233115196228, acc = 0.6865234375\n",
      "Batch 102: loss = 1.0720958709716797, acc = 0.65625\n",
      "Batch 103: loss = 1.039042353630066, acc = 0.671875\n",
      "Batch 104: loss = 0.9492616653442383, acc = 0.681640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 105: loss = 1.0044211149215698, acc = 0.6689453125\n",
      "Batch 106: loss = 1.0983495712280273, acc = 0.6533203125\n",
      "Batch 107: loss = 1.0440711975097656, acc = 0.6748046875\n",
      "Batch 108: loss = 0.9914249181747437, acc = 0.6533203125\n",
      "Batch 109: loss = 1.000581979751587, acc = 0.671875\n",
      "Batch 110: loss = 0.9405466318130493, acc = 0.6904296875\n",
      "Batch 111: loss = 1.1152681112289429, acc = 0.6474609375\n",
      "Batch 112: loss = 0.9673396348953247, acc = 0.693359375\n",
      "Batch 113: loss = 1.017647624015808, acc = 0.662109375\n",
      "Batch 114: loss = 1.0638277530670166, acc = 0.6650390625\n",
      "Batch 115: loss = 1.0958939790725708, acc = 0.638671875\n",
      "Batch 116: loss = 1.1355434656143188, acc = 0.6572265625\n",
      "Batch 117: loss = 0.9838627576828003, acc = 0.681640625\n",
      "Batch 118: loss = 0.9336643815040588, acc = 0.6875\n",
      "Batch 119: loss = 1.0408313274383545, acc = 0.6728515625\n",
      "Batch 120: loss = 1.0874665975570679, acc = 0.642578125\n",
      "Batch 121: loss = 0.9907849431037903, acc = 0.6708984375\n",
      "Batch 122: loss = 0.9892253279685974, acc = 0.6767578125\n",
      "Batch 123: loss = 1.0224952697753906, acc = 0.669921875\n",
      "Batch 124: loss = 1.0548473596572876, acc = 0.6396484375\n",
      "Batch 125: loss = 1.0733447074890137, acc = 0.662109375\n",
      "Batch 126: loss = 1.169316291809082, acc = 0.642578125\n",
      "\n",
      "Epoch 15/100\n",
      "Batch 1: loss = 1.3566038608551025, acc = 0.5947265625\n",
      "Batch 2: loss = 1.1605732440948486, acc = 0.6240234375\n",
      "Batch 3: loss = 1.0742542743682861, acc = 0.6689453125\n",
      "Batch 4: loss = 1.0615556240081787, acc = 0.65234375\n",
      "Batch 5: loss = 1.1784789562225342, acc = 0.6318359375\n",
      "Batch 6: loss = 1.1739320755004883, acc = 0.60546875\n",
      "Batch 7: loss = 1.1585156917572021, acc = 0.623046875\n",
      "Batch 8: loss = 1.0281405448913574, acc = 0.654296875\n",
      "Batch 9: loss = 0.9863452911376953, acc = 0.66796875\n",
      "Batch 10: loss = 0.9292944669723511, acc = 0.70703125\n",
      "Batch 11: loss = 1.081601619720459, acc = 0.646484375\n",
      "Batch 12: loss = 1.1194767951965332, acc = 0.6318359375\n",
      "Batch 13: loss = 1.0226967334747314, acc = 0.6640625\n",
      "Batch 14: loss = 0.9897527098655701, acc = 0.6767578125\n",
      "Batch 15: loss = 0.9841830134391785, acc = 0.6875\n",
      "Batch 16: loss = 1.1262608766555786, acc = 0.634765625\n",
      "Batch 17: loss = 1.0395898818969727, acc = 0.6708984375\n",
      "Batch 18: loss = 1.0911167860031128, acc = 0.654296875\n",
      "Batch 19: loss = 1.0356112718582153, acc = 0.68359375\n",
      "Batch 20: loss = 0.9960241913795471, acc = 0.6689453125\n",
      "Batch 21: loss = 1.1489784717559814, acc = 0.6240234375\n",
      "Batch 22: loss = 0.970314085483551, acc = 0.6884765625\n",
      "Batch 23: loss = 0.9739116430282593, acc = 0.6669921875\n",
      "Batch 24: loss = 1.014045000076294, acc = 0.6669921875\n",
      "Batch 25: loss = 0.9498599767684937, acc = 0.68359375\n",
      "Batch 26: loss = 0.9704676866531372, acc = 0.6904296875\n",
      "Batch 27: loss = 1.0802215337753296, acc = 0.662109375\n",
      "Batch 28: loss = 1.0335620641708374, acc = 0.6572265625\n",
      "Batch 29: loss = 1.005983829498291, acc = 0.6845703125\n",
      "Batch 30: loss = 0.9566186666488647, acc = 0.6826171875\n",
      "Batch 31: loss = 1.094709873199463, acc = 0.6484375\n",
      "Batch 32: loss = 1.2177079916000366, acc = 0.619140625\n",
      "Batch 33: loss = 1.000913381576538, acc = 0.6650390625\n",
      "Batch 34: loss = 1.0368168354034424, acc = 0.6455078125\n",
      "Batch 35: loss = 1.0617754459381104, acc = 0.673828125\n",
      "Batch 36: loss = 1.046777367591858, acc = 0.6533203125\n",
      "Batch 37: loss = 1.04621422290802, acc = 0.6806640625\n",
      "Batch 38: loss = 1.093966007232666, acc = 0.654296875\n",
      "Batch 39: loss = 1.0633834600448608, acc = 0.6630859375\n",
      "Batch 40: loss = 1.0061964988708496, acc = 0.6689453125\n",
      "Batch 41: loss = 0.9373117685317993, acc = 0.6787109375\n",
      "Batch 42: loss = 0.9644410610198975, acc = 0.67578125\n",
      "Batch 43: loss = 1.0306823253631592, acc = 0.6552734375\n",
      "Batch 44: loss = 0.9676806926727295, acc = 0.6884765625\n",
      "Batch 45: loss = 0.916424036026001, acc = 0.69921875\n",
      "Batch 46: loss = 0.9974631667137146, acc = 0.6728515625\n",
      "Batch 47: loss = 0.9683002233505249, acc = 0.6884765625\n",
      "Batch 48: loss = 0.9295921921730042, acc = 0.6865234375\n",
      "Batch 49: loss = 0.8998422622680664, acc = 0.708984375\n",
      "Batch 50: loss = 0.9477408528327942, acc = 0.69921875\n",
      "Batch 51: loss = 0.9457013607025146, acc = 0.6796875\n",
      "Batch 52: loss = 1.051669716835022, acc = 0.6552734375\n",
      "Batch 53: loss = 1.0549349784851074, acc = 0.6416015625\n",
      "Batch 54: loss = 0.9494370222091675, acc = 0.6982421875\n",
      "Batch 55: loss = 0.9370744228363037, acc = 0.6904296875\n",
      "Batch 56: loss = 1.0078262090682983, acc = 0.6650390625\n",
      "Batch 57: loss = 1.0492584705352783, acc = 0.6494140625\n",
      "Batch 58: loss = 1.0450409650802612, acc = 0.6533203125\n",
      "Batch 59: loss = 0.826445460319519, acc = 0.7353515625\n",
      "Batch 60: loss = 0.9749545454978943, acc = 0.671875\n",
      "Batch 61: loss = 1.0412181615829468, acc = 0.677734375\n",
      "Batch 62: loss = 1.1924031972885132, acc = 0.587890625\n",
      "Batch 63: loss = 1.1535495519638062, acc = 0.6328125\n",
      "Batch 64: loss = 0.8610116839408875, acc = 0.71875\n",
      "Batch 65: loss = 1.0321605205535889, acc = 0.666015625\n",
      "Batch 66: loss = 1.0023820400238037, acc = 0.6748046875\n",
      "Batch 67: loss = 0.9179297089576721, acc = 0.689453125\n",
      "Batch 68: loss = 0.9776227474212646, acc = 0.6865234375\n",
      "Batch 69: loss = 0.9497076869010925, acc = 0.69140625\n",
      "Batch 70: loss = 1.0805107355117798, acc = 0.6474609375\n",
      "Batch 71: loss = 0.9781243801116943, acc = 0.66015625\n",
      "Batch 72: loss = 0.9324533939361572, acc = 0.6943359375\n",
      "Batch 73: loss = 1.0614210367202759, acc = 0.6572265625\n",
      "Batch 74: loss = 1.0281950235366821, acc = 0.6533203125\n",
      "Batch 75: loss = 1.1154747009277344, acc = 0.6337890625\n",
      "Batch 76: loss = 1.0683698654174805, acc = 0.65234375\n",
      "Batch 77: loss = 0.899156391620636, acc = 0.7021484375\n",
      "Batch 78: loss = 0.9270549416542053, acc = 0.685546875\n",
      "Batch 79: loss = 0.8249030113220215, acc = 0.712890625\n",
      "Batch 80: loss = 0.8897324800491333, acc = 0.6708984375\n",
      "Batch 81: loss = 0.9374619126319885, acc = 0.6953125\n",
      "Batch 82: loss = 0.8419403433799744, acc = 0.724609375\n",
      "Batch 83: loss = 0.9791557192802429, acc = 0.6806640625\n",
      "Batch 84: loss = 0.9657086730003357, acc = 0.6826171875\n",
      "Batch 85: loss = 1.0340324640274048, acc = 0.6552734375\n",
      "Batch 86: loss = 0.9946424961090088, acc = 0.6806640625\n",
      "Batch 87: loss = 0.9678070545196533, acc = 0.6875\n",
      "Batch 88: loss = 1.128711223602295, acc = 0.638671875\n",
      "Batch 89: loss = 1.0064797401428223, acc = 0.6689453125\n",
      "Batch 90: loss = 1.084255576133728, acc = 0.66796875\n",
      "Batch 91: loss = 1.0718884468078613, acc = 0.646484375\n",
      "Batch 92: loss = 0.9615596532821655, acc = 0.6865234375\n",
      "Batch 93: loss = 0.8653039932250977, acc = 0.7294921875\n",
      "Batch 94: loss = 0.9197124242782593, acc = 0.6943359375\n",
      "Batch 95: loss = 0.9406245946884155, acc = 0.66796875\n",
      "Batch 96: loss = 1.0136513710021973, acc = 0.677734375\n",
      "Batch 97: loss = 0.9845432639122009, acc = 0.68359375\n",
      "Batch 98: loss = 1.0086724758148193, acc = 0.6796875\n",
      "Batch 99: loss = 1.0096075534820557, acc = 0.6708984375\n",
      "Batch 100: loss = 0.9750894904136658, acc = 0.6767578125\n",
      "Batch 101: loss = 0.998622715473175, acc = 0.6884765625\n",
      "Batch 102: loss = 1.062391757965088, acc = 0.6533203125\n",
      "Batch 103: loss = 1.0141818523406982, acc = 0.6708984375\n",
      "Batch 104: loss = 0.9266554117202759, acc = 0.6943359375\n",
      "Batch 105: loss = 0.965341329574585, acc = 0.6875\n",
      "Batch 106: loss = 1.0325652360916138, acc = 0.6708984375\n",
      "Batch 107: loss = 1.000498652458191, acc = 0.6845703125\n",
      "Batch 108: loss = 0.9777718186378479, acc = 0.669921875\n",
      "Batch 109: loss = 0.9671580195426941, acc = 0.6806640625\n",
      "Batch 110: loss = 0.9171828031539917, acc = 0.6943359375\n",
      "Batch 111: loss = 1.074397325515747, acc = 0.662109375\n",
      "Batch 112: loss = 0.9399241209030151, acc = 0.6845703125\n",
      "Batch 113: loss = 1.0074845552444458, acc = 0.6611328125\n",
      "Batch 114: loss = 1.0428955554962158, acc = 0.689453125\n",
      "Batch 115: loss = 1.0759239196777344, acc = 0.66015625\n",
      "Batch 116: loss = 1.117374300956726, acc = 0.6474609375\n",
      "Batch 117: loss = 0.9698413610458374, acc = 0.681640625\n",
      "Batch 118: loss = 0.9192411303520203, acc = 0.6845703125\n",
      "Batch 119: loss = 1.0016909837722778, acc = 0.671875\n",
      "Batch 120: loss = 1.0510830879211426, acc = 0.6611328125\n",
      "Batch 121: loss = 0.9781002998352051, acc = 0.6767578125\n",
      "Batch 122: loss = 0.9745544791221619, acc = 0.681640625\n",
      "Batch 123: loss = 0.9901092052459717, acc = 0.67578125\n",
      "Batch 124: loss = 1.0116006135940552, acc = 0.6455078125\n",
      "Batch 125: loss = 1.079124927520752, acc = 0.6513671875\n",
      "Batch 126: loss = 1.0787250995635986, acc = 0.6572265625\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: loss = 1.310261607170105, acc = 0.6103515625\n",
      "Batch 2: loss = 1.1255462169647217, acc = 0.6484375\n",
      "Batch 3: loss = 1.048454999923706, acc = 0.6650390625\n",
      "Batch 4: loss = 1.0373716354370117, acc = 0.6728515625\n",
      "Batch 5: loss = 1.1571197509765625, acc = 0.634765625\n",
      "Batch 6: loss = 1.1505582332611084, acc = 0.630859375\n",
      "Batch 7: loss = 1.139296293258667, acc = 0.6416015625\n",
      "Batch 8: loss = 1.0092583894729614, acc = 0.673828125\n",
      "Batch 9: loss = 0.9927281737327576, acc = 0.677734375\n",
      "Batch 10: loss = 0.9075478315353394, acc = 0.7080078125\n",
      "Batch 11: loss = 1.064531683921814, acc = 0.6474609375\n",
      "Batch 12: loss = 1.078298807144165, acc = 0.630859375\n",
      "Batch 13: loss = 1.0173691511154175, acc = 0.66015625\n",
      "Batch 14: loss = 0.9749947786331177, acc = 0.6767578125\n",
      "Batch 15: loss = 0.9783337116241455, acc = 0.6923828125\n",
      "Batch 16: loss = 1.069564938545227, acc = 0.6416015625\n",
      "Batch 17: loss = 1.0140939950942993, acc = 0.6845703125\n",
      "Batch 18: loss = 1.0405280590057373, acc = 0.66015625\n",
      "Batch 19: loss = 0.9838560819625854, acc = 0.6943359375\n",
      "Batch 20: loss = 0.951677680015564, acc = 0.6826171875\n",
      "Batch 21: loss = 1.1220602989196777, acc = 0.6298828125\n",
      "Batch 22: loss = 0.9527454376220703, acc = 0.6865234375\n",
      "Batch 23: loss = 0.9564051628112793, acc = 0.6845703125\n",
      "Batch 24: loss = 0.9827723503112793, acc = 0.6806640625\n",
      "Batch 25: loss = 0.9243977069854736, acc = 0.689453125\n",
      "Batch 26: loss = 0.9138758182525635, acc = 0.6962890625\n",
      "Batch 27: loss = 1.0582510232925415, acc = 0.6650390625\n",
      "Batch 28: loss = 1.019589900970459, acc = 0.65625\n",
      "Batch 29: loss = 0.9947848320007324, acc = 0.6982421875\n",
      "Batch 30: loss = 0.9113168716430664, acc = 0.7021484375\n",
      "Batch 31: loss = 1.0874305963516235, acc = 0.6533203125\n",
      "Batch 32: loss = 1.1644049882888794, acc = 0.611328125\n",
      "Batch 33: loss = 0.9556238651275635, acc = 0.673828125\n",
      "Batch 34: loss = 1.0112271308898926, acc = 0.6533203125\n",
      "Batch 35: loss = 0.9941462874412537, acc = 0.6845703125\n",
      "Batch 36: loss = 1.0129435062408447, acc = 0.6640625\n",
      "Batch 37: loss = 1.0279593467712402, acc = 0.67578125\n",
      "Batch 38: loss = 1.0694842338562012, acc = 0.6748046875\n",
      "Batch 39: loss = 1.0122249126434326, acc = 0.6669921875\n",
      "Batch 40: loss = 0.9767458438873291, acc = 0.66796875\n",
      "Batch 41: loss = 0.910839319229126, acc = 0.703125\n",
      "Batch 42: loss = 0.9397066831588745, acc = 0.6904296875\n",
      "Batch 43: loss = 1.0219082832336426, acc = 0.6494140625\n",
      "Batch 44: loss = 0.9433690309524536, acc = 0.705078125\n",
      "Batch 45: loss = 0.882872462272644, acc = 0.703125\n",
      "Batch 46: loss = 0.9171870946884155, acc = 0.6904296875\n",
      "Batch 47: loss = 0.9144063591957092, acc = 0.7021484375\n",
      "Batch 48: loss = 0.9020782113075256, acc = 0.6865234375\n",
      "Batch 49: loss = 0.8516945242881775, acc = 0.72265625\n",
      "Batch 50: loss = 0.9132259488105774, acc = 0.705078125\n",
      "Batch 51: loss = 0.9053013324737549, acc = 0.6962890625\n",
      "Batch 52: loss = 1.0205532312393188, acc = 0.662109375\n",
      "Batch 53: loss = 0.987554669380188, acc = 0.6767578125\n",
      "Batch 54: loss = 0.917287290096283, acc = 0.6982421875\n",
      "Batch 55: loss = 0.8981249332427979, acc = 0.7109375\n",
      "Batch 56: loss = 0.9678641557693481, acc = 0.6767578125\n",
      "Batch 57: loss = 1.0198334455490112, acc = 0.65625\n",
      "Batch 58: loss = 1.0163350105285645, acc = 0.6650390625\n",
      "Batch 59: loss = 0.8001943826675415, acc = 0.7412109375\n",
      "Batch 60: loss = 0.9477924704551697, acc = 0.6806640625\n",
      "Batch 61: loss = 1.004884123802185, acc = 0.6943359375\n",
      "Batch 62: loss = 1.1628680229187012, acc = 0.599609375\n",
      "Batch 63: loss = 1.119708776473999, acc = 0.6416015625\n",
      "Batch 64: loss = 0.8438172936439514, acc = 0.720703125\n",
      "Batch 65: loss = 0.9928134083747864, acc = 0.67578125\n",
      "Batch 66: loss = 0.9774428606033325, acc = 0.6748046875\n",
      "Batch 67: loss = 0.9064313173294067, acc = 0.6953125\n",
      "Batch 68: loss = 0.9740854501724243, acc = 0.6875\n",
      "Batch 69: loss = 0.9092056155204773, acc = 0.7197265625\n",
      "Batch 70: loss = 1.022562861442566, acc = 0.662109375\n",
      "Batch 71: loss = 0.9591505527496338, acc = 0.6943359375\n",
      "Batch 72: loss = 0.9059996604919434, acc = 0.703125\n",
      "Batch 73: loss = 1.034988522529602, acc = 0.6572265625\n",
      "Batch 74: loss = 1.001556158065796, acc = 0.66796875\n",
      "Batch 75: loss = 1.0621236562728882, acc = 0.6513671875\n",
      "Batch 76: loss = 1.0216641426086426, acc = 0.6630859375\n",
      "Batch 77: loss = 0.9091715812683105, acc = 0.7001953125\n",
      "Batch 78: loss = 0.9118731617927551, acc = 0.6806640625\n",
      "Batch 79: loss = 0.8151834607124329, acc = 0.7119140625\n",
      "Batch 80: loss = 0.8323683738708496, acc = 0.6865234375\n",
      "Batch 81: loss = 0.9094966650009155, acc = 0.6884765625\n",
      "Batch 82: loss = 0.8362703323364258, acc = 0.724609375\n",
      "Batch 83: loss = 0.9470590353012085, acc = 0.6787109375\n",
      "Batch 84: loss = 0.9377805590629578, acc = 0.6953125\n",
      "Batch 85: loss = 1.033876895904541, acc = 0.6611328125\n",
      "Batch 86: loss = 0.9928918480873108, acc = 0.6728515625\n",
      "Batch 87: loss = 0.938371479511261, acc = 0.69140625\n",
      "Batch 88: loss = 1.090796709060669, acc = 0.650390625\n",
      "Batch 89: loss = 0.9915533661842346, acc = 0.68359375\n",
      "Batch 90: loss = 1.0451135635375977, acc = 0.67578125\n",
      "Batch 91: loss = 1.0507795810699463, acc = 0.6513671875\n",
      "Batch 92: loss = 0.9473613500595093, acc = 0.6943359375\n",
      "Batch 93: loss = 0.8392761945724487, acc = 0.7314453125\n",
      "Batch 94: loss = 0.9102649688720703, acc = 0.703125\n",
      "Batch 95: loss = 0.9469943046569824, acc = 0.673828125\n",
      "Batch 96: loss = 0.9816476106643677, acc = 0.6884765625\n",
      "Batch 97: loss = 0.9453302025794983, acc = 0.7021484375\n",
      "Batch 98: loss = 0.984060525894165, acc = 0.6875\n",
      "Batch 99: loss = 0.9806318879127502, acc = 0.68359375\n",
      "Batch 100: loss = 0.9497460722923279, acc = 0.681640625\n",
      "Batch 101: loss = 0.9569231271743774, acc = 0.6943359375\n",
      "Batch 102: loss = 1.048248052597046, acc = 0.6611328125\n",
      "Batch 103: loss = 0.9827191233634949, acc = 0.685546875\n",
      "Batch 104: loss = 0.905644416809082, acc = 0.701171875\n",
      "Batch 105: loss = 0.9401513338088989, acc = 0.689453125\n",
      "Batch 106: loss = 1.014108657836914, acc = 0.67578125\n",
      "Batch 107: loss = 0.9662066698074341, acc = 0.693359375\n",
      "Batch 108: loss = 0.9547789096832275, acc = 0.689453125\n",
      "Batch 109: loss = 0.9275668859481812, acc = 0.6953125\n",
      "Batch 110: loss = 0.8834816217422485, acc = 0.70703125\n",
      "Batch 111: loss = 1.0661183595657349, acc = 0.6533203125\n",
      "Batch 112: loss = 0.9045042991638184, acc = 0.6962890625\n",
      "Batch 113: loss = 0.9733336567878723, acc = 0.6826171875\n",
      "Batch 114: loss = 1.028418779373169, acc = 0.6748046875\n",
      "Batch 115: loss = 1.038421630859375, acc = 0.666015625\n",
      "Batch 116: loss = 1.0888361930847168, acc = 0.66796875\n",
      "Batch 117: loss = 0.9192793965339661, acc = 0.6982421875\n",
      "Batch 118: loss = 0.8645250797271729, acc = 0.71484375\n",
      "Batch 119: loss = 0.9615349769592285, acc = 0.689453125\n",
      "Batch 120: loss = 1.0250515937805176, acc = 0.66796875\n",
      "Batch 121: loss = 0.9333925843238831, acc = 0.6953125\n",
      "Batch 122: loss = 0.9507343173027039, acc = 0.697265625\n",
      "Batch 123: loss = 0.9555714130401611, acc = 0.69921875\n",
      "Batch 124: loss = 0.9851967096328735, acc = 0.666015625\n",
      "Batch 125: loss = 1.0341875553131104, acc = 0.658203125\n",
      "Batch 126: loss = 1.0810436010360718, acc = 0.671875\n",
      "\n",
      "Epoch 17/100\n",
      "Batch 1: loss = 1.2584859132766724, acc = 0.6171875\n",
      "Batch 2: loss = 1.1044743061065674, acc = 0.6416015625\n",
      "Batch 3: loss = 1.0247406959533691, acc = 0.693359375\n",
      "Batch 4: loss = 0.9944872856140137, acc = 0.6787109375\n",
      "Batch 5: loss = 1.1047861576080322, acc = 0.6572265625\n",
      "Batch 6: loss = 1.0979994535446167, acc = 0.6513671875\n",
      "Batch 7: loss = 1.073857307434082, acc = 0.66015625\n",
      "Batch 8: loss = 0.9723795652389526, acc = 0.689453125\n",
      "Batch 9: loss = 0.9380484819412231, acc = 0.6845703125\n",
      "Batch 10: loss = 0.8776355385780334, acc = 0.724609375\n",
      "Batch 11: loss = 1.0070887804031372, acc = 0.66796875\n",
      "Batch 12: loss = 1.0435187816619873, acc = 0.6650390625\n",
      "Batch 13: loss = 0.9803822636604309, acc = 0.6689453125\n",
      "Batch 14: loss = 0.9494199156761169, acc = 0.6904296875\n",
      "Batch 15: loss = 0.9118258953094482, acc = 0.716796875\n",
      "Batch 16: loss = 1.0344130992889404, acc = 0.6640625\n",
      "Batch 17: loss = 0.9859198331832886, acc = 0.6904296875\n",
      "Batch 18: loss = 1.0210072994232178, acc = 0.666015625\n",
      "Batch 19: loss = 0.9478689432144165, acc = 0.720703125\n",
      "Batch 20: loss = 0.9211620092391968, acc = 0.6962890625\n",
      "Batch 21: loss = 1.0944242477416992, acc = 0.642578125\n",
      "Batch 22: loss = 0.9241716861724854, acc = 0.6982421875\n",
      "Batch 23: loss = 0.9221707582473755, acc = 0.6865234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 24: loss = 0.9584094285964966, acc = 0.6845703125\n",
      "Batch 25: loss = 0.876287579536438, acc = 0.720703125\n",
      "Batch 26: loss = 0.9012421369552612, acc = 0.69921875\n",
      "Batch 27: loss = 1.0229849815368652, acc = 0.6796875\n",
      "Batch 28: loss = 0.9667053818702698, acc = 0.6845703125\n",
      "Batch 29: loss = 0.9485311508178711, acc = 0.7099609375\n",
      "Batch 30: loss = 0.8705149292945862, acc = 0.7158203125\n",
      "Batch 31: loss = 1.0476117134094238, acc = 0.666015625\n",
      "Batch 32: loss = 1.1419548988342285, acc = 0.619140625\n",
      "Batch 33: loss = 0.9259100556373596, acc = 0.685546875\n",
      "Batch 34: loss = 1.009889006614685, acc = 0.6611328125\n",
      "Batch 35: loss = 0.9684195518493652, acc = 0.685546875\n",
      "Batch 36: loss = 0.98026442527771, acc = 0.689453125\n",
      "Batch 37: loss = 0.9862686395645142, acc = 0.6767578125\n",
      "Batch 38: loss = 1.0323837995529175, acc = 0.673828125\n",
      "Batch 39: loss = 0.9910421967506409, acc = 0.67578125\n",
      "Batch 40: loss = 0.962029218673706, acc = 0.6826171875\n",
      "Batch 41: loss = 0.8779646158218384, acc = 0.7060546875\n",
      "Batch 42: loss = 0.920843780040741, acc = 0.6962890625\n",
      "Batch 43: loss = 0.9748861193656921, acc = 0.673828125\n",
      "Batch 44: loss = 0.9152379631996155, acc = 0.7197265625\n",
      "Batch 45: loss = 0.8515262603759766, acc = 0.7177734375\n",
      "Batch 46: loss = 0.9297798275947571, acc = 0.703125\n",
      "Batch 47: loss = 0.9192876815795898, acc = 0.6943359375\n",
      "Batch 48: loss = 0.8796110153198242, acc = 0.701171875\n",
      "Batch 49: loss = 0.8448618054389954, acc = 0.7275390625\n",
      "Batch 50: loss = 0.8850482106208801, acc = 0.716796875\n",
      "Batch 51: loss = 0.8913910388946533, acc = 0.701171875\n",
      "Batch 52: loss = 0.9942255020141602, acc = 0.67578125\n",
      "Batch 53: loss = 0.9801413416862488, acc = 0.6826171875\n",
      "Batch 54: loss = 0.900864839553833, acc = 0.705078125\n",
      "Batch 55: loss = 0.8635189533233643, acc = 0.72265625\n",
      "Batch 56: loss = 0.9393730163574219, acc = 0.677734375\n",
      "Batch 57: loss = 1.008471965789795, acc = 0.6591796875\n",
      "Batch 58: loss = 1.0009827613830566, acc = 0.673828125\n",
      "Batch 59: loss = 0.7780240774154663, acc = 0.7529296875\n",
      "Batch 60: loss = 0.9312517642974854, acc = 0.6875\n",
      "Batch 61: loss = 0.9793616533279419, acc = 0.6904296875\n",
      "Batch 62: loss = 1.1379133462905884, acc = 0.6240234375\n",
      "Batch 63: loss = 1.096809983253479, acc = 0.654296875\n",
      "Batch 64: loss = 0.822843074798584, acc = 0.73046875\n",
      "Batch 65: loss = 0.9796770215034485, acc = 0.6826171875\n",
      "Batch 66: loss = 0.9612596035003662, acc = 0.6748046875\n",
      "Batch 67: loss = 0.8629955053329468, acc = 0.701171875\n",
      "Batch 68: loss = 0.9453223347663879, acc = 0.7001953125\n",
      "Batch 69: loss = 0.8870162963867188, acc = 0.7236328125\n",
      "Batch 70: loss = 1.0025721788406372, acc = 0.6748046875\n",
      "Batch 71: loss = 0.9379376769065857, acc = 0.6884765625\n",
      "Batch 72: loss = 0.8748837113380432, acc = 0.7109375\n",
      "Batch 73: loss = 0.9962666034698486, acc = 0.6748046875\n",
      "Batch 74: loss = 0.978269100189209, acc = 0.6796875\n",
      "Batch 75: loss = 1.0455496311187744, acc = 0.65625\n",
      "Batch 76: loss = 0.9751091003417969, acc = 0.6845703125\n",
      "Batch 77: loss = 0.8804111480712891, acc = 0.7060546875\n",
      "Batch 78: loss = 0.891400933265686, acc = 0.7080078125\n",
      "Batch 79: loss = 0.781395673751831, acc = 0.7392578125\n",
      "Batch 80: loss = 0.8199700117111206, acc = 0.7060546875\n",
      "Batch 81: loss = 0.8992827534675598, acc = 0.705078125\n",
      "Batch 82: loss = 0.8073137998580933, acc = 0.7294921875\n",
      "Batch 83: loss = 0.9217411279678345, acc = 0.6904296875\n",
      "Batch 84: loss = 0.9028295874595642, acc = 0.71875\n",
      "Batch 85: loss = 0.9808098673820496, acc = 0.6767578125\n",
      "Batch 86: loss = 0.9667500257492065, acc = 0.6884765625\n",
      "Batch 87: loss = 0.8991678953170776, acc = 0.7001953125\n",
      "Batch 88: loss = 1.0557022094726562, acc = 0.671875\n",
      "Batch 89: loss = 0.9772690534591675, acc = 0.6875\n",
      "Batch 90: loss = 1.0512441396713257, acc = 0.6748046875\n",
      "Batch 91: loss = 1.0078799724578857, acc = 0.6689453125\n",
      "Batch 92: loss = 0.940081000328064, acc = 0.7041015625\n",
      "Batch 93: loss = 0.8128873109817505, acc = 0.74609375\n",
      "Batch 94: loss = 0.8697007894515991, acc = 0.7099609375\n",
      "Batch 95: loss = 0.9064383506774902, acc = 0.6904296875\n",
      "Batch 96: loss = 0.9500424861907959, acc = 0.6904296875\n",
      "Batch 97: loss = 0.9198534488677979, acc = 0.7041015625\n",
      "Batch 98: loss = 0.9388936758041382, acc = 0.6982421875\n",
      "Batch 99: loss = 0.9368247389793396, acc = 0.6923828125\n",
      "Batch 100: loss = 0.9291855096817017, acc = 0.681640625\n",
      "Batch 101: loss = 0.9274758100509644, acc = 0.703125\n",
      "Batch 102: loss = 0.9948205947875977, acc = 0.6748046875\n",
      "Batch 103: loss = 0.9489564299583435, acc = 0.6943359375\n",
      "Batch 104: loss = 0.8950424194335938, acc = 0.7001953125\n",
      "Batch 105: loss = 0.9127528667449951, acc = 0.7041015625\n",
      "Batch 106: loss = 0.9718337655067444, acc = 0.69140625\n",
      "Batch 107: loss = 0.9294730424880981, acc = 0.705078125\n",
      "Batch 108: loss = 0.9183260202407837, acc = 0.689453125\n",
      "Batch 109: loss = 0.909024715423584, acc = 0.6904296875\n",
      "Batch 110: loss = 0.8586187958717346, acc = 0.7177734375\n",
      "Batch 111: loss = 1.01552414894104, acc = 0.671875\n",
      "Batch 112: loss = 0.9176236391067505, acc = 0.708984375\n",
      "Batch 113: loss = 0.9503103494644165, acc = 0.677734375\n",
      "Batch 114: loss = 1.0107526779174805, acc = 0.6904296875\n",
      "Batch 115: loss = 1.012798547744751, acc = 0.6669921875\n",
      "Batch 116: loss = 1.0536096096038818, acc = 0.66796875\n",
      "Batch 117: loss = 0.9258655905723572, acc = 0.6953125\n",
      "Batch 118: loss = 0.8606452941894531, acc = 0.703125\n",
      "Batch 119: loss = 0.9507313370704651, acc = 0.6923828125\n",
      "Batch 120: loss = 1.010741949081421, acc = 0.669921875\n",
      "Batch 121: loss = 0.9231207370758057, acc = 0.701171875\n",
      "Batch 122: loss = 0.904775857925415, acc = 0.7158203125\n",
      "Batch 123: loss = 0.9380477666854858, acc = 0.6982421875\n",
      "Batch 124: loss = 0.9805972576141357, acc = 0.6806640625\n",
      "Batch 125: loss = 1.0103685855865479, acc = 0.6728515625\n",
      "Batch 126: loss = 1.0416574478149414, acc = 0.673828125\n",
      "\n",
      "Epoch 18/100\n",
      "Batch 1: loss = 1.2543721199035645, acc = 0.6337890625\n",
      "Batch 2: loss = 1.1022062301635742, acc = 0.654296875\n",
      "Batch 3: loss = 0.9852312803268433, acc = 0.69140625\n",
      "Batch 4: loss = 0.9846077561378479, acc = 0.6796875\n",
      "Batch 5: loss = 1.0600810050964355, acc = 0.666015625\n",
      "Batch 6: loss = 1.0924856662750244, acc = 0.6318359375\n",
      "Batch 7: loss = 1.0554091930389404, acc = 0.6591796875\n",
      "Batch 8: loss = 0.9523188471794128, acc = 0.6875\n",
      "Batch 9: loss = 0.9125791788101196, acc = 0.69140625\n",
      "Batch 10: loss = 0.8792625665664673, acc = 0.70703125\n",
      "Batch 11: loss = 1.0177593231201172, acc = 0.654296875\n",
      "Batch 12: loss = 1.0051660537719727, acc = 0.6630859375\n",
      "Batch 13: loss = 0.9486653208732605, acc = 0.669921875\n",
      "Batch 14: loss = 0.9406564235687256, acc = 0.6982421875\n",
      "Batch 15: loss = 0.9087936878204346, acc = 0.7138671875\n",
      "Batch 16: loss = 1.0054430961608887, acc = 0.6865234375\n",
      "Batch 17: loss = 0.9506767988204956, acc = 0.7109375\n",
      "Batch 18: loss = 1.0063841342926025, acc = 0.6865234375\n",
      "Batch 19: loss = 0.923880934715271, acc = 0.716796875\n",
      "Batch 20: loss = 0.9174990057945251, acc = 0.69140625\n",
      "Batch 21: loss = 1.0584217309951782, acc = 0.66015625\n",
      "Batch 22: loss = 0.9077572226524353, acc = 0.69921875\n",
      "Batch 23: loss = 0.90900057554245, acc = 0.6962890625\n",
      "Batch 24: loss = 0.9053549766540527, acc = 0.701171875\n",
      "Batch 25: loss = 0.867361307144165, acc = 0.7138671875\n",
      "Batch 26: loss = 0.8811508417129517, acc = 0.6982421875\n",
      "Batch 27: loss = 0.9994796514511108, acc = 0.681640625\n",
      "Batch 28: loss = 0.9292688369750977, acc = 0.7001953125\n",
      "Batch 29: loss = 0.9450679421424866, acc = 0.7158203125\n",
      "Batch 30: loss = 0.8497700691223145, acc = 0.712890625\n",
      "Batch 31: loss = 1.021774172782898, acc = 0.6796875\n",
      "Batch 32: loss = 1.0906355381011963, acc = 0.646484375\n",
      "Batch 33: loss = 0.912003755569458, acc = 0.7080078125\n",
      "Batch 34: loss = 0.9596515893936157, acc = 0.677734375\n",
      "Batch 35: loss = 0.9604644775390625, acc = 0.6884765625\n",
      "Batch 36: loss = 0.9501569867134094, acc = 0.697265625\n",
      "Batch 37: loss = 0.9671846628189087, acc = 0.685546875\n",
      "Batch 38: loss = 0.9844223856925964, acc = 0.6748046875\n",
      "Batch 39: loss = 0.961104154586792, acc = 0.6845703125\n",
      "Batch 40: loss = 0.9416067600250244, acc = 0.69921875\n",
      "Batch 41: loss = 0.8465917110443115, acc = 0.708984375\n",
      "Batch 42: loss = 0.8872581720352173, acc = 0.7001953125\n",
      "Batch 43: loss = 0.9486928582191467, acc = 0.6796875\n",
      "Batch 44: loss = 0.9134529829025269, acc = 0.708984375\n",
      "Batch 45: loss = 0.8482440710067749, acc = 0.7265625\n",
      "Batch 46: loss = 0.9056403636932373, acc = 0.7080078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 47: loss = 0.8870257139205933, acc = 0.708984375\n",
      "Batch 48: loss = 0.8581845760345459, acc = 0.708984375\n",
      "Batch 49: loss = 0.8261432647705078, acc = 0.7373046875\n",
      "Batch 50: loss = 0.8683059811592102, acc = 0.728515625\n",
      "Batch 51: loss = 0.8606845140457153, acc = 0.7158203125\n",
      "Batch 52: loss = 0.9524371027946472, acc = 0.6796875\n",
      "Batch 53: loss = 0.9505113363265991, acc = 0.6953125\n",
      "Batch 54: loss = 0.870775043964386, acc = 0.720703125\n",
      "Batch 55: loss = 0.8402379155158997, acc = 0.7236328125\n",
      "Batch 56: loss = 0.9156972169876099, acc = 0.6962890625\n",
      "Batch 57: loss = 0.967228889465332, acc = 0.6708984375\n",
      "Batch 58: loss = 0.9670732021331787, acc = 0.6884765625\n",
      "Batch 59: loss = 0.7630860805511475, acc = 0.759765625\n",
      "Batch 60: loss = 0.8882919549942017, acc = 0.7138671875\n",
      "Batch 61: loss = 0.928597092628479, acc = 0.6982421875\n",
      "Batch 62: loss = 1.0788941383361816, acc = 0.619140625\n",
      "Batch 63: loss = 1.078000545501709, acc = 0.6435546875\n",
      "Batch 64: loss = 0.8048787117004395, acc = 0.7373046875\n",
      "Batch 65: loss = 0.9700653553009033, acc = 0.6767578125\n",
      "Batch 66: loss = 0.933634877204895, acc = 0.6962890625\n",
      "Batch 67: loss = 0.8584334850311279, acc = 0.71484375\n",
      "Batch 68: loss = 0.926855206489563, acc = 0.6875\n",
      "Batch 69: loss = 0.8758333325386047, acc = 0.72265625\n",
      "Batch 70: loss = 0.9714317917823792, acc = 0.685546875\n",
      "Batch 71: loss = 0.9203606247901917, acc = 0.7109375\n",
      "Batch 72: loss = 0.8473596572875977, acc = 0.7109375\n",
      "Batch 73: loss = 0.9957304000854492, acc = 0.666015625\n",
      "Batch 74: loss = 0.9643579721450806, acc = 0.6806640625\n",
      "Batch 75: loss = 1.0353388786315918, acc = 0.662109375\n",
      "Batch 76: loss = 0.9467820525169373, acc = 0.69140625\n",
      "Batch 77: loss = 0.8392655849456787, acc = 0.724609375\n",
      "Batch 78: loss = 0.8620092272758484, acc = 0.728515625\n",
      "Batch 79: loss = 0.7446873188018799, acc = 0.74609375\n",
      "Batch 80: loss = 0.8026535511016846, acc = 0.71875\n",
      "Batch 81: loss = 0.8564636707305908, acc = 0.708984375\n",
      "Batch 82: loss = 0.8075976371765137, acc = 0.73046875\n",
      "Batch 83: loss = 0.8623032569885254, acc = 0.7060546875\n",
      "Batch 84: loss = 0.8966702222824097, acc = 0.7138671875\n",
      "Batch 85: loss = 0.9797917604446411, acc = 0.677734375\n",
      "Batch 86: loss = 0.9356216788291931, acc = 0.6923828125\n",
      "Batch 87: loss = 0.8839834928512573, acc = 0.7109375\n",
      "Batch 88: loss = 1.0482534170150757, acc = 0.646484375\n",
      "Batch 89: loss = 0.9122865796089172, acc = 0.7021484375\n",
      "Batch 90: loss = 0.9668574929237366, acc = 0.703125\n",
      "Batch 91: loss = 0.9879109263420105, acc = 0.6728515625\n",
      "Batch 92: loss = 0.905587375164032, acc = 0.697265625\n",
      "Batch 93: loss = 0.8247628211975098, acc = 0.740234375\n",
      "Batch 94: loss = 0.8498576879501343, acc = 0.7255859375\n",
      "Batch 95: loss = 0.8809491395950317, acc = 0.703125\n",
      "Batch 96: loss = 0.9272856712341309, acc = 0.7119140625\n",
      "Batch 97: loss = 0.8918856978416443, acc = 0.7099609375\n",
      "Batch 98: loss = 0.9193449020385742, acc = 0.705078125\n",
      "Batch 99: loss = 0.9388248920440674, acc = 0.689453125\n",
      "Batch 100: loss = 0.9047762751579285, acc = 0.7060546875\n",
      "Batch 101: loss = 0.8978720307350159, acc = 0.7138671875\n",
      "Batch 102: loss = 0.9750518202781677, acc = 0.68359375\n",
      "Batch 103: loss = 0.9229099154472351, acc = 0.7001953125\n",
      "Batch 104: loss = 0.8494750261306763, acc = 0.7119140625\n",
      "Batch 105: loss = 0.8783320784568787, acc = 0.7119140625\n",
      "Batch 106: loss = 0.9627498388290405, acc = 0.697265625\n",
      "Batch 107: loss = 0.9129687547683716, acc = 0.7158203125\n",
      "Batch 108: loss = 0.8860545754432678, acc = 0.7041015625\n",
      "Batch 109: loss = 0.8806196451187134, acc = 0.7177734375\n",
      "Batch 110: loss = 0.8353261947631836, acc = 0.7236328125\n",
      "Batch 111: loss = 0.9911242723464966, acc = 0.6796875\n",
      "Batch 112: loss = 0.8599774241447449, acc = 0.71875\n",
      "Batch 113: loss = 0.9235955476760864, acc = 0.6982421875\n",
      "Batch 114: loss = 0.9715301990509033, acc = 0.6962890625\n",
      "Batch 115: loss = 0.9799756407737732, acc = 0.693359375\n",
      "Batch 116: loss = 1.0258007049560547, acc = 0.6806640625\n",
      "Batch 117: loss = 0.8828346133232117, acc = 0.701171875\n",
      "Batch 118: loss = 0.8420572280883789, acc = 0.716796875\n",
      "Batch 119: loss = 0.903502345085144, acc = 0.69921875\n",
      "Batch 120: loss = 0.9722921252250671, acc = 0.6787109375\n",
      "Batch 121: loss = 0.9012781381607056, acc = 0.7021484375\n",
      "Batch 122: loss = 0.8812047839164734, acc = 0.703125\n",
      "Batch 123: loss = 0.9089218378067017, acc = 0.7041015625\n",
      "Batch 124: loss = 0.9407919645309448, acc = 0.6865234375\n",
      "Batch 125: loss = 0.9927364587783813, acc = 0.6806640625\n",
      "Batch 126: loss = 1.021991491317749, acc = 0.697265625\n",
      "\n",
      "Epoch 19/100\n",
      "Batch 1: loss = 1.2117586135864258, acc = 0.640625\n",
      "Batch 2: loss = 1.0494575500488281, acc = 0.6669921875\n",
      "Batch 3: loss = 0.9608057737350464, acc = 0.6982421875\n",
      "Batch 4: loss = 0.9408121109008789, acc = 0.7099609375\n",
      "Batch 5: loss = 1.0363825559616089, acc = 0.6767578125\n",
      "Batch 6: loss = 1.0668072700500488, acc = 0.6494140625\n",
      "Batch 7: loss = 1.0361217260360718, acc = 0.669921875\n",
      "Batch 8: loss = 0.9185094833374023, acc = 0.7021484375\n",
      "Batch 9: loss = 0.8796730041503906, acc = 0.7001953125\n",
      "Batch 10: loss = 0.8494570851325989, acc = 0.7080078125\n",
      "Batch 11: loss = 0.9678757786750793, acc = 0.677734375\n",
      "Batch 12: loss = 1.0043182373046875, acc = 0.66796875\n",
      "Batch 13: loss = 0.9489327669143677, acc = 0.68359375\n",
      "Batch 14: loss = 0.9155533313751221, acc = 0.7099609375\n",
      "Batch 15: loss = 0.8951305150985718, acc = 0.720703125\n",
      "Batch 16: loss = 1.0057281255722046, acc = 0.677734375\n",
      "Batch 17: loss = 0.9202258586883545, acc = 0.7197265625\n",
      "Batch 18: loss = 0.9688307642936707, acc = 0.7021484375\n",
      "Batch 19: loss = 0.9039256572723389, acc = 0.7109375\n",
      "Batch 20: loss = 0.8968527317047119, acc = 0.703125\n",
      "Batch 21: loss = 1.016648769378662, acc = 0.662109375\n",
      "Batch 22: loss = 0.8879368305206299, acc = 0.7041015625\n",
      "Batch 23: loss = 0.8973984122276306, acc = 0.689453125\n",
      "Batch 24: loss = 0.9209756851196289, acc = 0.6865234375\n",
      "Batch 25: loss = 0.8470708131790161, acc = 0.7197265625\n",
      "Batch 26: loss = 0.8296462893486023, acc = 0.7255859375\n",
      "Batch 27: loss = 0.9816220998764038, acc = 0.6787109375\n",
      "Batch 28: loss = 0.9168750643730164, acc = 0.6953125\n",
      "Batch 29: loss = 0.9194257259368896, acc = 0.7158203125\n",
      "Batch 30: loss = 0.8620501160621643, acc = 0.7099609375\n",
      "Batch 31: loss = 0.9958719611167908, acc = 0.677734375\n",
      "Batch 32: loss = 1.093064785003662, acc = 0.634765625\n",
      "Batch 33: loss = 0.8629671335220337, acc = 0.708984375\n",
      "Batch 34: loss = 0.9261723756790161, acc = 0.6943359375\n",
      "Batch 35: loss = 0.9264799356460571, acc = 0.6943359375\n",
      "Batch 36: loss = 0.9165299534797668, acc = 0.705078125\n",
      "Batch 37: loss = 0.9159178137779236, acc = 0.7119140625\n",
      "Batch 38: loss = 0.9845485687255859, acc = 0.6953125\n",
      "Batch 39: loss = 0.9362672567367554, acc = 0.6904296875\n",
      "Batch 40: loss = 0.9187211990356445, acc = 0.7041015625\n",
      "Batch 41: loss = 0.8363137245178223, acc = 0.728515625\n",
      "Batch 42: loss = 0.8380213975906372, acc = 0.720703125\n",
      "Batch 43: loss = 0.9425927400588989, acc = 0.677734375\n",
      "Batch 44: loss = 0.8560918569564819, acc = 0.73046875\n",
      "Batch 45: loss = 0.8047088980674744, acc = 0.75\n",
      "Batch 46: loss = 0.8692324757575989, acc = 0.716796875\n",
      "Batch 47: loss = 0.8774847984313965, acc = 0.7109375\n",
      "Batch 48: loss = 0.8299946188926697, acc = 0.703125\n",
      "Batch 49: loss = 0.7867653369903564, acc = 0.759765625\n",
      "Batch 50: loss = 0.8389642238616943, acc = 0.7431640625\n",
      "Batch 51: loss = 0.8167318105697632, acc = 0.716796875\n",
      "Batch 52: loss = 0.9085934162139893, acc = 0.703125\n",
      "Batch 53: loss = 0.9334753155708313, acc = 0.6953125\n",
      "Batch 54: loss = 0.828606903553009, acc = 0.7275390625\n",
      "Batch 55: loss = 0.8222718834877014, acc = 0.740234375\n",
      "Batch 56: loss = 0.8807083368301392, acc = 0.6982421875\n",
      "Batch 57: loss = 0.94214928150177, acc = 0.681640625\n",
      "Batch 58: loss = 0.9592279195785522, acc = 0.6962890625\n",
      "Batch 59: loss = 0.7458043098449707, acc = 0.76171875\n",
      "Batch 60: loss = 0.8843162059783936, acc = 0.712890625\n",
      "Batch 61: loss = 0.9222337007522583, acc = 0.7158203125\n",
      "Batch 62: loss = 1.0902106761932373, acc = 0.6328125\n",
      "Batch 63: loss = 1.018172025680542, acc = 0.666015625\n",
      "Batch 64: loss = 0.778913140296936, acc = 0.7451171875\n",
      "Batch 65: loss = 0.9562625288963318, acc = 0.6923828125\n",
      "Batch 66: loss = 0.9053764939308167, acc = 0.705078125\n",
      "Batch 67: loss = 0.838786244392395, acc = 0.7265625\n",
      "Batch 68: loss = 0.9201611876487732, acc = 0.705078125\n",
      "Batch 69: loss = 0.8484511375427246, acc = 0.724609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 70: loss = 0.939853847026825, acc = 0.6904296875\n",
      "Batch 71: loss = 0.885177731513977, acc = 0.7099609375\n",
      "Batch 72: loss = 0.829630970954895, acc = 0.728515625\n",
      "Batch 73: loss = 0.954468846321106, acc = 0.6884765625\n",
      "Batch 74: loss = 0.9476149082183838, acc = 0.6884765625\n",
      "Batch 75: loss = 1.0021302700042725, acc = 0.6650390625\n",
      "Batch 76: loss = 0.9331340193748474, acc = 0.6806640625\n",
      "Batch 77: loss = 0.8320567011833191, acc = 0.7197265625\n",
      "Batch 78: loss = 0.8510949611663818, acc = 0.71875\n",
      "Batch 79: loss = 0.7522599697113037, acc = 0.732421875\n",
      "Batch 80: loss = 0.7897945642471313, acc = 0.7158203125\n",
      "Batch 81: loss = 0.8427411913871765, acc = 0.7099609375\n",
      "Batch 82: loss = 0.7815992832183838, acc = 0.7431640625\n",
      "Batch 83: loss = 0.8828114867210388, acc = 0.7109375\n",
      "Batch 84: loss = 0.8622469902038574, acc = 0.7119140625\n",
      "Batch 85: loss = 0.954689621925354, acc = 0.685546875\n",
      "Batch 86: loss = 0.9009274244308472, acc = 0.701171875\n",
      "Batch 87: loss = 0.8579123020172119, acc = 0.71484375\n",
      "Batch 88: loss = 1.0365521907806396, acc = 0.671875\n",
      "Batch 89: loss = 0.9118239879608154, acc = 0.7021484375\n",
      "Batch 90: loss = 0.9551821947097778, acc = 0.6953125\n",
      "Batch 91: loss = 0.9590110182762146, acc = 0.6796875\n",
      "Batch 92: loss = 0.8975256085395813, acc = 0.7119140625\n",
      "Batch 93: loss = 0.7743328213691711, acc = 0.751953125\n",
      "Batch 94: loss = 0.8391171097755432, acc = 0.7421875\n",
      "Batch 95: loss = 0.8328517079353333, acc = 0.7080078125\n",
      "Batch 96: loss = 0.920384407043457, acc = 0.69140625\n",
      "Batch 97: loss = 0.8774805068969727, acc = 0.712890625\n",
      "Batch 98: loss = 0.8984679579734802, acc = 0.71484375\n",
      "Batch 99: loss = 0.8901237845420837, acc = 0.703125\n",
      "Batch 100: loss = 0.8959426879882812, acc = 0.7109375\n",
      "Batch 101: loss = 0.8799849152565002, acc = 0.7099609375\n",
      "Batch 102: loss = 0.9317214488983154, acc = 0.697265625\n",
      "Batch 103: loss = 0.8715401291847229, acc = 0.7138671875\n",
      "Batch 104: loss = 0.8347749710083008, acc = 0.7294921875\n",
      "Batch 105: loss = 0.8580902814865112, acc = 0.7119140625\n",
      "Batch 106: loss = 0.9409322738647461, acc = 0.69140625\n",
      "Batch 107: loss = 0.8928384780883789, acc = 0.7138671875\n",
      "Batch 108: loss = 0.8751647472381592, acc = 0.7158203125\n",
      "Batch 109: loss = 0.8707369565963745, acc = 0.7158203125\n",
      "Batch 110: loss = 0.8113074898719788, acc = 0.740234375\n",
      "Batch 111: loss = 0.9742003679275513, acc = 0.6806640625\n",
      "Batch 112: loss = 0.8532531261444092, acc = 0.71484375\n",
      "Batch 113: loss = 0.9115874767303467, acc = 0.693359375\n",
      "Batch 114: loss = 0.9299612641334534, acc = 0.71875\n",
      "Batch 115: loss = 0.9425158500671387, acc = 0.7041015625\n",
      "Batch 116: loss = 1.0070080757141113, acc = 0.6953125\n",
      "Batch 117: loss = 0.876738429069519, acc = 0.7236328125\n",
      "Batch 118: loss = 0.7921196222305298, acc = 0.7412109375\n",
      "Batch 119: loss = 0.8701987266540527, acc = 0.7099609375\n",
      "Batch 120: loss = 0.9195919036865234, acc = 0.6845703125\n",
      "Batch 121: loss = 0.8703963756561279, acc = 0.7041015625\n",
      "Batch 122: loss = 0.8711118698120117, acc = 0.712890625\n",
      "Batch 123: loss = 0.8931235671043396, acc = 0.7099609375\n",
      "Batch 124: loss = 0.9149026274681091, acc = 0.6875\n",
      "Batch 125: loss = 0.9483531713485718, acc = 0.7001953125\n",
      "Batch 126: loss = 0.9905523657798767, acc = 0.685546875\n",
      "\n",
      "Epoch 20/100\n",
      "Batch 1: loss = 1.172958493232727, acc = 0.646484375\n",
      "Batch 2: loss = 1.0121251344680786, acc = 0.67578125\n",
      "Batch 3: loss = 0.9358518123626709, acc = 0.7041015625\n",
      "Batch 4: loss = 0.9118242263793945, acc = 0.70703125\n",
      "Batch 5: loss = 0.9960438013076782, acc = 0.67578125\n",
      "Batch 6: loss = 1.008272409439087, acc = 0.6787109375\n",
      "Batch 7: loss = 0.9836990833282471, acc = 0.681640625\n",
      "Batch 8: loss = 0.9010131359100342, acc = 0.7080078125\n",
      "Batch 9: loss = 0.8653630018234253, acc = 0.7021484375\n",
      "Batch 10: loss = 0.8228785395622253, acc = 0.73828125\n",
      "Batch 11: loss = 0.9472295045852661, acc = 0.6865234375\n",
      "Batch 12: loss = 0.9683467149734497, acc = 0.6845703125\n",
      "Batch 13: loss = 0.8861558437347412, acc = 0.6875\n",
      "Batch 14: loss = 0.8803822994232178, acc = 0.7119140625\n",
      "Batch 15: loss = 0.8497037887573242, acc = 0.736328125\n",
      "Batch 16: loss = 0.9324808716773987, acc = 0.70703125\n",
      "Batch 17: loss = 0.9138575792312622, acc = 0.7099609375\n",
      "Batch 18: loss = 0.9384185075759888, acc = 0.7001953125\n",
      "Batch 19: loss = 0.8829607367515564, acc = 0.7333984375\n",
      "Batch 20: loss = 0.888918399810791, acc = 0.69921875\n",
      "Batch 21: loss = 0.996508777141571, acc = 0.6650390625\n",
      "Batch 22: loss = 0.8542025089263916, acc = 0.7333984375\n",
      "Batch 23: loss = 0.8519169688224792, acc = 0.7109375\n",
      "Batch 24: loss = 0.8832876682281494, acc = 0.7060546875\n",
      "Batch 25: loss = 0.819502592086792, acc = 0.728515625\n",
      "Batch 26: loss = 0.815280556678772, acc = 0.724609375\n",
      "Batch 27: loss = 0.9688307046890259, acc = 0.6923828125\n",
      "Batch 28: loss = 0.8995720744132996, acc = 0.7119140625\n",
      "Batch 29: loss = 0.883651614189148, acc = 0.7255859375\n",
      "Batch 30: loss = 0.8197319507598877, acc = 0.724609375\n",
      "Batch 31: loss = 0.9554684162139893, acc = 0.6962890625\n",
      "Batch 32: loss = 1.0768423080444336, acc = 0.630859375\n",
      "Batch 33: loss = 0.8539520502090454, acc = 0.7060546875\n",
      "Batch 34: loss = 0.9060126543045044, acc = 0.6943359375\n",
      "Batch 35: loss = 0.8894908428192139, acc = 0.71484375\n",
      "Batch 36: loss = 0.8840648531913757, acc = 0.7060546875\n",
      "Batch 37: loss = 0.8955568075180054, acc = 0.712890625\n",
      "Batch 38: loss = 0.9491780996322632, acc = 0.7109375\n",
      "Batch 39: loss = 0.8923919200897217, acc = 0.7021484375\n",
      "Batch 40: loss = 0.8816697001457214, acc = 0.7060546875\n",
      "Batch 41: loss = 0.7882999181747437, acc = 0.732421875\n",
      "Batch 42: loss = 0.8255605101585388, acc = 0.7294921875\n",
      "Batch 43: loss = 0.8971211314201355, acc = 0.689453125\n",
      "Batch 44: loss = 0.8487986326217651, acc = 0.720703125\n",
      "Batch 45: loss = 0.7803629636764526, acc = 0.748046875\n",
      "Batch 46: loss = 0.8329270482063293, acc = 0.73046875\n",
      "Batch 47: loss = 0.8246243596076965, acc = 0.732421875\n",
      "Batch 48: loss = 0.8135532140731812, acc = 0.7138671875\n",
      "Batch 49: loss = 0.7722218632698059, acc = 0.7548828125\n",
      "Batch 50: loss = 0.8296242952346802, acc = 0.748046875\n",
      "Batch 51: loss = 0.8003648519515991, acc = 0.7451171875\n",
      "Batch 52: loss = 0.8708052039146423, acc = 0.7197265625\n",
      "Batch 53: loss = 0.8861297369003296, acc = 0.7099609375\n",
      "Batch 54: loss = 0.7900671362876892, acc = 0.7421875\n",
      "Batch 55: loss = 0.8109865784645081, acc = 0.734375\n",
      "Batch 56: loss = 0.8784931898117065, acc = 0.7109375\n",
      "Batch 57: loss = 0.9147287011146545, acc = 0.6796875\n",
      "Batch 58: loss = 0.9351470470428467, acc = 0.685546875\n",
      "Batch 59: loss = 0.7319531440734863, acc = 0.775390625\n",
      "Batch 60: loss = 0.8812807202339172, acc = 0.7119140625\n",
      "Batch 61: loss = 0.8925800323486328, acc = 0.7333984375\n",
      "Batch 62: loss = 1.0478830337524414, acc = 0.6337890625\n",
      "Batch 63: loss = 0.9807912111282349, acc = 0.6826171875\n",
      "Batch 64: loss = 0.7681396007537842, acc = 0.740234375\n",
      "Batch 65: loss = 0.9255789518356323, acc = 0.689453125\n",
      "Batch 66: loss = 0.8719762563705444, acc = 0.7001953125\n",
      "Batch 67: loss = 0.7979283332824707, acc = 0.7373046875\n",
      "Batch 68: loss = 0.8622676730155945, acc = 0.71875\n",
      "Batch 69: loss = 0.8294976949691772, acc = 0.7236328125\n",
      "Batch 70: loss = 0.9379565715789795, acc = 0.703125\n",
      "Batch 71: loss = 0.8930179476737976, acc = 0.708984375\n",
      "Batch 72: loss = 0.8004556894302368, acc = 0.7373046875\n",
      "Batch 73: loss = 0.9359591603279114, acc = 0.6923828125\n",
      "Batch 74: loss = 0.9060268402099609, acc = 0.7021484375\n",
      "Batch 75: loss = 0.9821434617042542, acc = 0.666015625\n",
      "Batch 76: loss = 0.8944585919380188, acc = 0.6962890625\n",
      "Batch 77: loss = 0.8027657270431519, acc = 0.7421875\n",
      "Batch 78: loss = 0.8244231939315796, acc = 0.73828125\n",
      "Batch 79: loss = 0.7073613405227661, acc = 0.7578125\n",
      "Batch 80: loss = 0.7708595991134644, acc = 0.7412109375\n",
      "Batch 81: loss = 0.8441644906997681, acc = 0.7177734375\n",
      "Batch 82: loss = 0.7613292932510376, acc = 0.74609375\n",
      "Batch 83: loss = 0.8494168519973755, acc = 0.7255859375\n",
      "Batch 84: loss = 0.8417239189147949, acc = 0.7294921875\n",
      "Batch 85: loss = 0.9168713688850403, acc = 0.7099609375\n",
      "Batch 86: loss = 0.8707230091094971, acc = 0.716796875\n",
      "Batch 87: loss = 0.8301823139190674, acc = 0.7275390625\n",
      "Batch 88: loss = 0.9929689764976501, acc = 0.67578125\n",
      "Batch 89: loss = 0.8786704540252686, acc = 0.7197265625\n",
      "Batch 90: loss = 0.9197989702224731, acc = 0.7138671875\n",
      "Batch 91: loss = 0.9334104657173157, acc = 0.6953125\n",
      "Batch 92: loss = 0.852424144744873, acc = 0.7255859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 93: loss = 0.7474300861358643, acc = 0.75\n",
      "Batch 94: loss = 0.7943583130836487, acc = 0.740234375\n",
      "Batch 95: loss = 0.8146931529045105, acc = 0.71875\n",
      "Batch 96: loss = 0.8830878734588623, acc = 0.7158203125\n",
      "Batch 97: loss = 0.8537102341651917, acc = 0.7314453125\n",
      "Batch 98: loss = 0.8626208901405334, acc = 0.712890625\n",
      "Batch 99: loss = 0.8869858980178833, acc = 0.7119140625\n",
      "Batch 100: loss = 0.8545121550559998, acc = 0.708984375\n",
      "Batch 101: loss = 0.8391971588134766, acc = 0.7109375\n",
      "Batch 102: loss = 0.8988441228866577, acc = 0.7158203125\n",
      "Batch 103: loss = 0.8506883382797241, acc = 0.7265625\n",
      "Batch 104: loss = 0.8061884641647339, acc = 0.740234375\n",
      "Batch 105: loss = 0.8388841152191162, acc = 0.71875\n",
      "Batch 106: loss = 0.903863251209259, acc = 0.6953125\n",
      "Batch 107: loss = 0.8498022556304932, acc = 0.740234375\n",
      "Batch 108: loss = 0.8353806138038635, acc = 0.7353515625\n",
      "Batch 109: loss = 0.8448097705841064, acc = 0.740234375\n",
      "Batch 110: loss = 0.8042178153991699, acc = 0.74609375\n",
      "Batch 111: loss = 0.9497042894363403, acc = 0.689453125\n",
      "Batch 112: loss = 0.8151909112930298, acc = 0.7275390625\n",
      "Batch 113: loss = 0.8722937107086182, acc = 0.7119140625\n",
      "Batch 114: loss = 0.8987894058227539, acc = 0.7119140625\n",
      "Batch 115: loss = 0.9312283992767334, acc = 0.7001953125\n",
      "Batch 116: loss = 0.9682790040969849, acc = 0.7021484375\n",
      "Batch 117: loss = 0.8402560949325562, acc = 0.7138671875\n",
      "Batch 118: loss = 0.7813613414764404, acc = 0.748046875\n",
      "Batch 119: loss = 0.8309100270271301, acc = 0.7431640625\n",
      "Batch 120: loss = 0.8968647718429565, acc = 0.703125\n",
      "Batch 121: loss = 0.8561578989028931, acc = 0.708984375\n",
      "Batch 122: loss = 0.8318434953689575, acc = 0.7236328125\n",
      "Batch 123: loss = 0.8649153113365173, acc = 0.71875\n",
      "Batch 124: loss = 0.9231671094894409, acc = 0.6806640625\n",
      "Batch 125: loss = 0.9456033706665039, acc = 0.6953125\n",
      "Batch 126: loss = 0.9380025267601013, acc = 0.7197265625\n",
      "Saved checkpoint to weights.20.h5\n",
      "\n",
      "Epoch 21/100\n",
      "Batch 1: loss = 1.1390564441680908, acc = 0.671875\n",
      "Batch 2: loss = 1.0162526369094849, acc = 0.6767578125\n",
      "Batch 3: loss = 0.8947381377220154, acc = 0.7314453125\n",
      "Batch 4: loss = 0.8906204700469971, acc = 0.712890625\n",
      "Batch 5: loss = 0.9774880409240723, acc = 0.6923828125\n",
      "Batch 6: loss = 1.0201385021209717, acc = 0.669921875\n",
      "Batch 7: loss = 0.9476637840270996, acc = 0.701171875\n",
      "Batch 8: loss = 0.9171005487442017, acc = 0.708984375\n",
      "Batch 9: loss = 0.8506221175193787, acc = 0.7080078125\n",
      "Batch 10: loss = 0.7913693189620972, acc = 0.7353515625\n",
      "Batch 11: loss = 0.9077513217926025, acc = 0.70703125\n",
      "Batch 12: loss = 0.929655134677887, acc = 0.6923828125\n",
      "Batch 13: loss = 0.8576834201812744, acc = 0.71875\n",
      "Batch 14: loss = 0.852329432964325, acc = 0.732421875\n",
      "Batch 15: loss = 0.837961733341217, acc = 0.7412109375\n",
      "Batch 16: loss = 0.9177058339118958, acc = 0.689453125\n",
      "Batch 17: loss = 0.8789379596710205, acc = 0.7236328125\n",
      "Batch 18: loss = 0.9248709678649902, acc = 0.7177734375\n",
      "Batch 19: loss = 0.8399044275283813, acc = 0.7314453125\n",
      "Batch 20: loss = 0.8710832595825195, acc = 0.7138671875\n",
      "Batch 21: loss = 0.9796315431594849, acc = 0.6748046875\n",
      "Batch 22: loss = 0.8313724398612976, acc = 0.73828125\n",
      "Batch 23: loss = 0.8482010364532471, acc = 0.7001953125\n",
      "Batch 24: loss = 0.8602285981178284, acc = 0.7158203125\n",
      "Batch 25: loss = 0.7894787788391113, acc = 0.7509765625\n",
      "Batch 26: loss = 0.7894117832183838, acc = 0.7451171875\n",
      "Batch 27: loss = 0.9383895397186279, acc = 0.68359375\n",
      "Batch 28: loss = 0.8857083320617676, acc = 0.705078125\n",
      "Batch 29: loss = 0.8771103024482727, acc = 0.728515625\n",
      "Batch 30: loss = 0.7929757237434387, acc = 0.7314453125\n",
      "Batch 31: loss = 0.9603215456008911, acc = 0.6953125\n",
      "Batch 32: loss = 1.0379078388214111, acc = 0.658203125\n",
      "Batch 33: loss = 0.8400764465332031, acc = 0.71875\n",
      "Batch 34: loss = 0.8699853420257568, acc = 0.7197265625\n",
      "Batch 35: loss = 0.878975510597229, acc = 0.708984375\n",
      "Batch 36: loss = 0.8655579090118408, acc = 0.71484375\n",
      "Batch 37: loss = 0.8658854365348816, acc = 0.72265625\n",
      "Batch 38: loss = 0.9301294088363647, acc = 0.7001953125\n",
      "Batch 39: loss = 0.8843572735786438, acc = 0.7021484375\n",
      "Batch 40: loss = 0.8575050830841064, acc = 0.72265625\n",
      "Batch 41: loss = 0.7775949835777283, acc = 0.7431640625\n",
      "Batch 42: loss = 0.7920364141464233, acc = 0.736328125\n",
      "Batch 43: loss = 0.8640815019607544, acc = 0.7138671875\n",
      "Batch 44: loss = 0.8151232004165649, acc = 0.736328125\n",
      "Batch 45: loss = 0.77616947889328, acc = 0.7314453125\n",
      "Batch 46: loss = 0.8081200122833252, acc = 0.7421875\n",
      "Batch 47: loss = 0.8198981285095215, acc = 0.73828125\n",
      "Batch 48: loss = 0.7922037839889526, acc = 0.72265625\n",
      "Batch 49: loss = 0.7662153244018555, acc = 0.755859375\n",
      "Batch 50: loss = 0.8086621761322021, acc = 0.755859375\n",
      "Batch 51: loss = 0.7732508182525635, acc = 0.7431640625\n",
      "Batch 52: loss = 0.8689770102500916, acc = 0.703125\n",
      "Batch 53: loss = 0.894273042678833, acc = 0.7119140625\n",
      "Batch 54: loss = 0.7777822017669678, acc = 0.73828125\n",
      "Batch 55: loss = 0.7677711844444275, acc = 0.7548828125\n",
      "Batch 56: loss = 0.8361488580703735, acc = 0.71484375\n",
      "Batch 57: loss = 0.8976768255233765, acc = 0.6982421875\n",
      "Batch 58: loss = 0.8991417288780212, acc = 0.7138671875\n",
      "Batch 59: loss = 0.6985391974449158, acc = 0.775390625\n",
      "Batch 60: loss = 0.8432420492172241, acc = 0.7333984375\n",
      "Batch 61: loss = 0.8459000587463379, acc = 0.73046875\n",
      "Batch 62: loss = 1.0291513204574585, acc = 0.6474609375\n",
      "Batch 63: loss = 0.9740973711013794, acc = 0.6923828125\n",
      "Batch 64: loss = 0.7544468641281128, acc = 0.751953125\n",
      "Batch 65: loss = 0.8911113142967224, acc = 0.705078125\n",
      "Batch 66: loss = 0.8437464237213135, acc = 0.7138671875\n",
      "Batch 67: loss = 0.7686275243759155, acc = 0.740234375\n",
      "Batch 68: loss = 0.8742070198059082, acc = 0.7138671875\n",
      "Batch 69: loss = 0.8064843416213989, acc = 0.73046875\n",
      "Batch 70: loss = 0.8978698253631592, acc = 0.7041015625\n",
      "Batch 71: loss = 0.8642146587371826, acc = 0.708984375\n",
      "Batch 72: loss = 0.8016518950462341, acc = 0.7333984375\n",
      "Batch 73: loss = 0.9220443964004517, acc = 0.697265625\n",
      "Batch 74: loss = 0.8825711607933044, acc = 0.71875\n",
      "Batch 75: loss = 0.982576847076416, acc = 0.6650390625\n",
      "Batch 76: loss = 0.8644059896469116, acc = 0.708984375\n",
      "Batch 77: loss = 0.799777626991272, acc = 0.732421875\n",
      "Batch 78: loss = 0.8068686723709106, acc = 0.7236328125\n",
      "Batch 79: loss = 0.7341131567955017, acc = 0.7646484375\n",
      "Batch 80: loss = 0.7480000257492065, acc = 0.736328125\n",
      "Batch 81: loss = 0.8037671446800232, acc = 0.73046875\n",
      "Batch 82: loss = 0.7421640753746033, acc = 0.7568359375\n",
      "Batch 83: loss = 0.8134990334510803, acc = 0.71875\n",
      "Batch 84: loss = 0.815479576587677, acc = 0.7431640625\n",
      "Batch 85: loss = 0.8944937586784363, acc = 0.6953125\n",
      "Batch 86: loss = 0.8299518823623657, acc = 0.71484375\n",
      "Batch 87: loss = 0.8043076992034912, acc = 0.74609375\n",
      "Batch 88: loss = 0.977904736995697, acc = 0.6845703125\n",
      "Batch 89: loss = 0.850415825843811, acc = 0.712890625\n",
      "Batch 90: loss = 0.9265501499176025, acc = 0.7041015625\n",
      "Batch 91: loss = 0.8879808187484741, acc = 0.6982421875\n",
      "Batch 92: loss = 0.8518078327178955, acc = 0.72265625\n",
      "Batch 93: loss = 0.718439519405365, acc = 0.755859375\n",
      "Batch 94: loss = 0.7825189828872681, acc = 0.755859375\n",
      "Batch 95: loss = 0.7926658391952515, acc = 0.7255859375\n",
      "Batch 96: loss = 0.8615151643753052, acc = 0.712890625\n",
      "Batch 97: loss = 0.8425069451332092, acc = 0.7275390625\n",
      "Batch 98: loss = 0.8444482684135437, acc = 0.7353515625\n",
      "Batch 99: loss = 0.8412131071090698, acc = 0.7197265625\n",
      "Batch 100: loss = 0.8584895133972168, acc = 0.716796875\n",
      "Batch 101: loss = 0.809511125087738, acc = 0.73046875\n",
      "Batch 102: loss = 0.91389000415802, acc = 0.7041015625\n",
      "Batch 103: loss = 0.8337181806564331, acc = 0.7255859375\n",
      "Batch 104: loss = 0.7749474048614502, acc = 0.7373046875\n",
      "Batch 105: loss = 0.7964391112327576, acc = 0.7294921875\n",
      "Batch 106: loss = 0.8523485660552979, acc = 0.7373046875\n",
      "Batch 107: loss = 0.8011023998260498, acc = 0.7421875\n",
      "Batch 108: loss = 0.8233520984649658, acc = 0.7138671875\n",
      "Batch 109: loss = 0.8017421960830688, acc = 0.7412109375\n",
      "Batch 110: loss = 0.7932312488555908, acc = 0.7392578125\n",
      "Batch 111: loss = 0.8966953754425049, acc = 0.705078125\n",
      "Batch 112: loss = 0.8082014322280884, acc = 0.7294921875\n",
      "Batch 113: loss = 0.8613394498825073, acc = 0.712890625\n",
      "Batch 114: loss = 0.8795746564865112, acc = 0.7373046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 115: loss = 0.8898255825042725, acc = 0.7060546875\n",
      "Batch 116: loss = 0.9313387870788574, acc = 0.70703125\n",
      "Batch 117: loss = 0.8170537948608398, acc = 0.7392578125\n",
      "Batch 118: loss = 0.7465050220489502, acc = 0.751953125\n",
      "Batch 119: loss = 0.8182599544525146, acc = 0.75\n",
      "Batch 120: loss = 0.8689773082733154, acc = 0.7216796875\n",
      "Batch 121: loss = 0.8413199186325073, acc = 0.7138671875\n",
      "Batch 122: loss = 0.8009326457977295, acc = 0.7333984375\n",
      "Batch 123: loss = 0.8500807285308838, acc = 0.72265625\n",
      "Batch 124: loss = 0.8903563022613525, acc = 0.6923828125\n",
      "Batch 125: loss = 0.912860095500946, acc = 0.7099609375\n",
      "Batch 126: loss = 0.9209928512573242, acc = 0.712890625\n",
      "\n",
      "Epoch 22/100\n",
      "Batch 1: loss = 1.0976166725158691, acc = 0.6630859375\n",
      "Batch 2: loss = 0.9851886034011841, acc = 0.6962890625\n",
      "Batch 3: loss = 0.8990446925163269, acc = 0.728515625\n",
      "Batch 4: loss = 0.8639786243438721, acc = 0.736328125\n",
      "Batch 5: loss = 0.9603549242019653, acc = 0.69921875\n",
      "Batch 6: loss = 0.9613258838653564, acc = 0.685546875\n",
      "Batch 7: loss = 0.9167793393135071, acc = 0.71484375\n",
      "Batch 8: loss = 0.8548962473869324, acc = 0.7265625\n",
      "Batch 9: loss = 0.8143660426139832, acc = 0.734375\n",
      "Batch 10: loss = 0.758697509765625, acc = 0.7509765625\n",
      "Batch 11: loss = 0.894934892654419, acc = 0.6787109375\n",
      "Batch 12: loss = 0.8724027872085571, acc = 0.71875\n",
      "Batch 13: loss = 0.8493411540985107, acc = 0.716796875\n",
      "Batch 14: loss = 0.808138370513916, acc = 0.744140625\n",
      "Batch 15: loss = 0.8079913258552551, acc = 0.7421875\n",
      "Batch 16: loss = 0.882958173751831, acc = 0.7080078125\n",
      "Batch 17: loss = 0.8570964336395264, acc = 0.7294921875\n",
      "Batch 18: loss = 0.8909464478492737, acc = 0.71484375\n",
      "Batch 19: loss = 0.862725019454956, acc = 0.72265625\n",
      "Batch 20: loss = 0.8418048620223999, acc = 0.7255859375\n",
      "Batch 21: loss = 0.9625333547592163, acc = 0.6826171875\n",
      "Batch 22: loss = 0.8226519227027893, acc = 0.7294921875\n",
      "Batch 23: loss = 0.8237007856369019, acc = 0.7138671875\n",
      "Batch 24: loss = 0.7991112470626831, acc = 0.736328125\n",
      "Batch 25: loss = 0.7853437066078186, acc = 0.755859375\n",
      "Batch 26: loss = 0.7891465425491333, acc = 0.7314453125\n",
      "Batch 27: loss = 0.9220997095108032, acc = 0.7001953125\n",
      "Batch 28: loss = 0.8716726303100586, acc = 0.7314453125\n",
      "Batch 29: loss = 0.8557115793228149, acc = 0.73046875\n",
      "Batch 30: loss = 0.7768274545669556, acc = 0.7421875\n",
      "Batch 31: loss = 0.9240536689758301, acc = 0.69921875\n",
      "Batch 32: loss = 0.9979865550994873, acc = 0.68359375\n",
      "Batch 33: loss = 0.8185331225395203, acc = 0.73046875\n",
      "Batch 34: loss = 0.8494222164154053, acc = 0.7216796875\n",
      "Batch 35: loss = 0.8648436069488525, acc = 0.7216796875\n",
      "Batch 36: loss = 0.8056800365447998, acc = 0.7412109375\n",
      "Batch 37: loss = 0.855774998664856, acc = 0.73828125\n",
      "Batch 38: loss = 0.909232497215271, acc = 0.70703125\n",
      "Batch 39: loss = 0.866902232170105, acc = 0.7080078125\n",
      "Batch 40: loss = 0.8171667456626892, acc = 0.736328125\n",
      "Batch 41: loss = 0.7746171951293945, acc = 0.744140625\n",
      "Batch 42: loss = 0.7852986454963684, acc = 0.7451171875\n",
      "Batch 43: loss = 0.8336366415023804, acc = 0.7119140625\n",
      "Batch 44: loss = 0.7794913649559021, acc = 0.7548828125\n",
      "Batch 45: loss = 0.7458771467208862, acc = 0.751953125\n",
      "Batch 46: loss = 0.8253200054168701, acc = 0.7265625\n",
      "Batch 47: loss = 0.7875922918319702, acc = 0.7509765625\n",
      "Batch 48: loss = 0.7807426452636719, acc = 0.7333984375\n",
      "Batch 49: loss = 0.7294561266899109, acc = 0.7666015625\n",
      "Batch 50: loss = 0.7742539644241333, acc = 0.76171875\n",
      "Batch 51: loss = 0.7515060901641846, acc = 0.7451171875\n",
      "Batch 52: loss = 0.8210641145706177, acc = 0.7236328125\n",
      "Batch 53: loss = 0.8623054027557373, acc = 0.71484375\n",
      "Batch 54: loss = 0.7501857876777649, acc = 0.751953125\n",
      "Batch 55: loss = 0.7419402599334717, acc = 0.7646484375\n",
      "Batch 56: loss = 0.8152905106544495, acc = 0.7294921875\n",
      "Batch 57: loss = 0.865097165107727, acc = 0.703125\n",
      "Batch 58: loss = 0.8635834455490112, acc = 0.7109375\n",
      "Batch 59: loss = 0.6658921241760254, acc = 0.771484375\n",
      "Batch 60: loss = 0.8092523813247681, acc = 0.728515625\n",
      "Batch 61: loss = 0.8552309274673462, acc = 0.73046875\n",
      "Batch 62: loss = 1.0135772228240967, acc = 0.6572265625\n",
      "Batch 63: loss = 0.9478063583374023, acc = 0.6962890625\n",
      "Batch 64: loss = 0.7305631637573242, acc = 0.767578125\n",
      "Batch 65: loss = 0.8844600915908813, acc = 0.7197265625\n",
      "Batch 66: loss = 0.8058779835700989, acc = 0.7421875\n",
      "Batch 67: loss = 0.7476139664649963, acc = 0.755859375\n",
      "Batch 68: loss = 0.8302197456359863, acc = 0.7333984375\n",
      "Batch 69: loss = 0.7816075086593628, acc = 0.75390625\n",
      "Batch 70: loss = 0.8640059232711792, acc = 0.7216796875\n",
      "Batch 71: loss = 0.8422316312789917, acc = 0.7158203125\n",
      "Batch 72: loss = 0.7705408334732056, acc = 0.75390625\n",
      "Batch 73: loss = 0.9066893458366394, acc = 0.7060546875\n",
      "Batch 74: loss = 0.8809815645217896, acc = 0.693359375\n",
      "Batch 75: loss = 0.9723303318023682, acc = 0.67578125\n",
      "Batch 76: loss = 0.8776273727416992, acc = 0.7080078125\n",
      "Batch 77: loss = 0.7795391082763672, acc = 0.7431640625\n",
      "Batch 78: loss = 0.7736129760742188, acc = 0.7421875\n",
      "Batch 79: loss = 0.6961185932159424, acc = 0.759765625\n",
      "Batch 80: loss = 0.7371945977210999, acc = 0.734375\n",
      "Batch 81: loss = 0.7951761484146118, acc = 0.7236328125\n",
      "Batch 82: loss = 0.7337079644203186, acc = 0.7626953125\n",
      "Batch 83: loss = 0.8057821989059448, acc = 0.732421875\n",
      "Batch 84: loss = 0.7851991057395935, acc = 0.744140625\n",
      "Batch 85: loss = 0.8763848543167114, acc = 0.7099609375\n",
      "Batch 86: loss = 0.839020848274231, acc = 0.71875\n",
      "Batch 87: loss = 0.7699819803237915, acc = 0.744140625\n",
      "Batch 88: loss = 0.9707289934158325, acc = 0.6884765625\n",
      "Batch 89: loss = 0.8686165809631348, acc = 0.728515625\n",
      "Batch 90: loss = 0.8741781711578369, acc = 0.7265625\n",
      "Batch 91: loss = 0.8723711967468262, acc = 0.7001953125\n",
      "Batch 92: loss = 0.8429476022720337, acc = 0.7412109375\n",
      "Batch 93: loss = 0.718927800655365, acc = 0.755859375\n",
      "Batch 94: loss = 0.7595362663269043, acc = 0.755859375\n",
      "Batch 95: loss = 0.7905310988426208, acc = 0.71875\n",
      "Batch 96: loss = 0.8477315902709961, acc = 0.7216796875\n",
      "Batch 97: loss = 0.8248039484024048, acc = 0.7451171875\n",
      "Batch 98: loss = 0.8038731813430786, acc = 0.7333984375\n",
      "Batch 99: loss = 0.8153237104415894, acc = 0.7333984375\n",
      "Batch 100: loss = 0.8033915758132935, acc = 0.7265625\n",
      "Batch 101: loss = 0.7878708839416504, acc = 0.744140625\n",
      "Batch 102: loss = 0.8543736338615417, acc = 0.7265625\n",
      "Batch 103: loss = 0.8185248374938965, acc = 0.736328125\n",
      "Batch 104: loss = 0.7601374387741089, acc = 0.75\n",
      "Batch 105: loss = 0.7923647165298462, acc = 0.7275390625\n",
      "Batch 106: loss = 0.8424835801124573, acc = 0.7333984375\n",
      "Batch 107: loss = 0.7971314191818237, acc = 0.736328125\n",
      "Batch 108: loss = 0.7742424607276917, acc = 0.7333984375\n",
      "Batch 109: loss = 0.7763743996620178, acc = 0.755859375\n",
      "Batch 110: loss = 0.7524706125259399, acc = 0.7587890625\n",
      "Batch 111: loss = 0.875145435333252, acc = 0.7177734375\n",
      "Batch 112: loss = 0.781808614730835, acc = 0.7373046875\n",
      "Batch 113: loss = 0.8495068550109863, acc = 0.71875\n",
      "Batch 114: loss = 0.8785430192947388, acc = 0.724609375\n",
      "Batch 115: loss = 0.8587990999221802, acc = 0.734375\n",
      "Batch 116: loss = 0.9245849847793579, acc = 0.71484375\n",
      "Batch 117: loss = 0.7847252488136292, acc = 0.7392578125\n",
      "Batch 118: loss = 0.7227953672409058, acc = 0.75390625\n",
      "Batch 119: loss = 0.8160498142242432, acc = 0.7431640625\n",
      "Batch 120: loss = 0.8433114290237427, acc = 0.708984375\n",
      "Batch 121: loss = 0.8268588185310364, acc = 0.7216796875\n",
      "Batch 122: loss = 0.7746056318283081, acc = 0.74609375\n",
      "Batch 123: loss = 0.8219916820526123, acc = 0.73828125\n",
      "Batch 124: loss = 0.8535414934158325, acc = 0.7138671875\n",
      "Batch 125: loss = 0.8738679885864258, acc = 0.712890625\n",
      "Batch 126: loss = 0.9007928371429443, acc = 0.72265625\n",
      "\n",
      "Epoch 23/100\n",
      "Batch 1: loss = 1.0641248226165771, acc = 0.67578125\n",
      "Batch 2: loss = 0.9697743058204651, acc = 0.69921875\n",
      "Batch 3: loss = 0.8575920462608337, acc = 0.7294921875\n",
      "Batch 4: loss = 0.8560221195220947, acc = 0.728515625\n",
      "Batch 5: loss = 0.946145236492157, acc = 0.7001953125\n",
      "Batch 6: loss = 0.9747498035430908, acc = 0.685546875\n",
      "Batch 7: loss = 0.9177530407905579, acc = 0.705078125\n",
      "Batch 8: loss = 0.8504414558410645, acc = 0.7412109375\n",
      "Batch 9: loss = 0.8122632503509521, acc = 0.7265625\n",
      "Batch 10: loss = 0.7411324977874756, acc = 0.7578125\n",
      "Batch 11: loss = 0.8623700737953186, acc = 0.7041015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12: loss = 0.8604450225830078, acc = 0.7158203125\n",
      "Batch 13: loss = 0.8227533102035522, acc = 0.720703125\n",
      "Batch 14: loss = 0.7861216068267822, acc = 0.75\n",
      "Batch 15: loss = 0.7979940176010132, acc = 0.751953125\n",
      "Batch 16: loss = 0.866122841835022, acc = 0.72265625\n",
      "Batch 17: loss = 0.831655740737915, acc = 0.7470703125\n",
      "Batch 18: loss = 0.8719396591186523, acc = 0.7109375\n",
      "Batch 19: loss = 0.8166317939758301, acc = 0.740234375\n",
      "Batch 20: loss = 0.8132162094116211, acc = 0.732421875\n",
      "Batch 21: loss = 0.9246400594711304, acc = 0.6845703125\n",
      "Batch 22: loss = 0.7951823472976685, acc = 0.7412109375\n",
      "Batch 23: loss = 0.8021407127380371, acc = 0.7265625\n",
      "Batch 24: loss = 0.810773491859436, acc = 0.7265625\n",
      "Batch 25: loss = 0.7606050372123718, acc = 0.7470703125\n",
      "Batch 26: loss = 0.7564482688903809, acc = 0.7529296875\n",
      "Batch 27: loss = 0.875741720199585, acc = 0.701171875\n",
      "Batch 28: loss = 0.8294975757598877, acc = 0.732421875\n",
      "Batch 29: loss = 0.8376901745796204, acc = 0.728515625\n",
      "Batch 30: loss = 0.7482516765594482, acc = 0.748046875\n",
      "Batch 31: loss = 0.9260672926902771, acc = 0.7021484375\n",
      "Batch 32: loss = 0.971443772315979, acc = 0.6845703125\n",
      "Batch 33: loss = 0.7885092496871948, acc = 0.7353515625\n",
      "Batch 34: loss = 0.8183107376098633, acc = 0.7314453125\n",
      "Batch 35: loss = 0.8168601989746094, acc = 0.7431640625\n",
      "Batch 36: loss = 0.7966029047966003, acc = 0.7333984375\n",
      "Batch 37: loss = 0.8175925016403198, acc = 0.7392578125\n",
      "Batch 38: loss = 0.8539357781410217, acc = 0.734375\n",
      "Batch 39: loss = 0.8199487924575806, acc = 0.7392578125\n",
      "Batch 40: loss = 0.8081656694412231, acc = 0.7333984375\n",
      "Batch 41: loss = 0.7277894616127014, acc = 0.7607421875\n",
      "Batch 42: loss = 0.7640944719314575, acc = 0.7412109375\n",
      "Batch 43: loss = 0.8142882585525513, acc = 0.7158203125\n",
      "Batch 44: loss = 0.7492046356201172, acc = 0.7578125\n",
      "Batch 45: loss = 0.7274020910263062, acc = 0.75\n",
      "Batch 46: loss = 0.7581995129585266, acc = 0.7470703125\n",
      "Batch 47: loss = 0.7721773982048035, acc = 0.748046875\n",
      "Batch 48: loss = 0.7650631070137024, acc = 0.7529296875\n",
      "Batch 49: loss = 0.7011680006980896, acc = 0.7822265625\n",
      "Batch 50: loss = 0.7334391474723816, acc = 0.7802734375\n",
      "Batch 51: loss = 0.7379355430603027, acc = 0.744140625\n",
      "Batch 52: loss = 0.8075878620147705, acc = 0.724609375\n",
      "Batch 53: loss = 0.8361955881118774, acc = 0.7138671875\n",
      "Batch 54: loss = 0.7163290977478027, acc = 0.7578125\n",
      "Batch 55: loss = 0.6976654529571533, acc = 0.7666015625\n",
      "Batch 56: loss = 0.8323879241943359, acc = 0.7177734375\n",
      "Batch 57: loss = 0.8671280145645142, acc = 0.7060546875\n",
      "Batch 58: loss = 0.8831271529197693, acc = 0.712890625\n",
      "Batch 59: loss = 0.6461737155914307, acc = 0.78515625\n",
      "Batch 60: loss = 0.8146777749061584, acc = 0.740234375\n",
      "Batch 61: loss = 0.8234673738479614, acc = 0.732421875\n",
      "Batch 62: loss = 0.9730028510093689, acc = 0.666015625\n",
      "Batch 63: loss = 0.8969333171844482, acc = 0.7177734375\n",
      "Batch 64: loss = 0.7028517723083496, acc = 0.765625\n",
      "Batch 65: loss = 0.8554101586341858, acc = 0.7392578125\n",
      "Batch 66: loss = 0.8083995580673218, acc = 0.7314453125\n",
      "Batch 67: loss = 0.7547551393508911, acc = 0.75\n",
      "Batch 68: loss = 0.827901303768158, acc = 0.732421875\n",
      "Batch 69: loss = 0.7583279013633728, acc = 0.7529296875\n",
      "Batch 70: loss = 0.8729202747344971, acc = 0.708984375\n",
      "Batch 71: loss = 0.8134424090385437, acc = 0.7333984375\n",
      "Batch 72: loss = 0.7363895177841187, acc = 0.755859375\n",
      "Batch 73: loss = 0.8492079973220825, acc = 0.7197265625\n",
      "Batch 74: loss = 0.8429036140441895, acc = 0.72265625\n",
      "Batch 75: loss = 0.9273096919059753, acc = 0.69140625\n",
      "Batch 76: loss = 0.8284070491790771, acc = 0.72265625\n",
      "Batch 77: loss = 0.7617339491844177, acc = 0.763671875\n",
      "Batch 78: loss = 0.774340033531189, acc = 0.7548828125\n",
      "Batch 79: loss = 0.6772690415382385, acc = 0.767578125\n",
      "Batch 80: loss = 0.7155567407608032, acc = 0.7490234375\n",
      "Batch 81: loss = 0.7994979619979858, acc = 0.7431640625\n",
      "Batch 82: loss = 0.7205235362052917, acc = 0.7646484375\n",
      "Batch 83: loss = 0.7684686183929443, acc = 0.7353515625\n",
      "Batch 84: loss = 0.7757847309112549, acc = 0.7568359375\n",
      "Batch 85: loss = 0.852864146232605, acc = 0.71875\n",
      "Batch 86: loss = 0.8131886720657349, acc = 0.7158203125\n",
      "Batch 87: loss = 0.770074725151062, acc = 0.7587890625\n",
      "Batch 88: loss = 0.9243948459625244, acc = 0.6953125\n",
      "Batch 89: loss = 0.7987194061279297, acc = 0.7568359375\n",
      "Batch 90: loss = 0.8696075081825256, acc = 0.7099609375\n",
      "Batch 91: loss = 0.8464303612709045, acc = 0.7197265625\n",
      "Batch 92: loss = 0.8377638459205627, acc = 0.734375\n",
      "Batch 93: loss = 0.6832493543624878, acc = 0.78125\n",
      "Batch 94: loss = 0.7583779096603394, acc = 0.7568359375\n",
      "Batch 95: loss = 0.7572465538978577, acc = 0.740234375\n",
      "Batch 96: loss = 0.8416392803192139, acc = 0.7275390625\n",
      "Batch 97: loss = 0.8006331920623779, acc = 0.7421875\n",
      "Batch 98: loss = 0.8143002986907959, acc = 0.7412109375\n",
      "Batch 99: loss = 0.8051477670669556, acc = 0.7412109375\n",
      "Batch 100: loss = 0.8027323484420776, acc = 0.7294921875\n",
      "Batch 101: loss = 0.7723791003227234, acc = 0.7470703125\n",
      "Batch 102: loss = 0.8441380262374878, acc = 0.73046875\n",
      "Batch 103: loss = 0.7973651885986328, acc = 0.734375\n",
      "Batch 104: loss = 0.7525033950805664, acc = 0.76953125\n",
      "Batch 105: loss = 0.7875676155090332, acc = 0.7255859375\n",
      "Batch 106: loss = 0.8132762908935547, acc = 0.7373046875\n",
      "Batch 107: loss = 0.7679810523986816, acc = 0.7509765625\n",
      "Batch 108: loss = 0.7786663770675659, acc = 0.7353515625\n",
      "Batch 109: loss = 0.77596515417099, acc = 0.7587890625\n",
      "Batch 110: loss = 0.7368544340133667, acc = 0.7626953125\n",
      "Batch 111: loss = 0.8520261645317078, acc = 0.71484375\n",
      "Batch 112: loss = 0.7884291410446167, acc = 0.7421875\n",
      "Batch 113: loss = 0.8045070767402649, acc = 0.7255859375\n",
      "Batch 114: loss = 0.8449799418449402, acc = 0.73828125\n",
      "Batch 115: loss = 0.8342969417572021, acc = 0.7353515625\n",
      "Batch 116: loss = 0.8990305662155151, acc = 0.720703125\n",
      "Batch 117: loss = 0.7891877293586731, acc = 0.7421875\n",
      "Batch 118: loss = 0.7193616628646851, acc = 0.75\n",
      "Batch 119: loss = 0.7975869178771973, acc = 0.7275390625\n",
      "Batch 120: loss = 0.8131390810012817, acc = 0.73046875\n",
      "Batch 121: loss = 0.8118780851364136, acc = 0.7236328125\n",
      "Batch 122: loss = 0.7709161639213562, acc = 0.7490234375\n",
      "Batch 123: loss = 0.7915136218070984, acc = 0.740234375\n",
      "Batch 124: loss = 0.8342901468276978, acc = 0.7119140625\n",
      "Batch 125: loss = 0.8702727556228638, acc = 0.716796875\n",
      "Batch 126: loss = 0.8702107667922974, acc = 0.7216796875\n",
      "\n",
      "Epoch 24/100\n",
      "Batch 1: loss = 1.0609369277954102, acc = 0.689453125\n",
      "Batch 2: loss = 0.8967812657356262, acc = 0.7314453125\n",
      "Batch 3: loss = 0.8393266201019287, acc = 0.7421875\n",
      "Batch 4: loss = 0.8212815523147583, acc = 0.736328125\n",
      "Batch 5: loss = 0.9003146886825562, acc = 0.7109375\n",
      "Batch 6: loss = 0.9463986158370972, acc = 0.6962890625\n",
      "Batch 7: loss = 0.8674182891845703, acc = 0.72265625\n",
      "Batch 8: loss = 0.8429169058799744, acc = 0.736328125\n",
      "Batch 9: loss = 0.7607948780059814, acc = 0.76171875\n",
      "Batch 10: loss = 0.711266815662384, acc = 0.7626953125\n",
      "Batch 11: loss = 0.8241050839424133, acc = 0.7177734375\n",
      "Batch 12: loss = 0.8296002745628357, acc = 0.7099609375\n",
      "Batch 13: loss = 0.7993958592414856, acc = 0.7353515625\n",
      "Batch 14: loss = 0.7799522876739502, acc = 0.751953125\n",
      "Batch 15: loss = 0.7709144353866577, acc = 0.763671875\n",
      "Batch 16: loss = 0.8529007434844971, acc = 0.7158203125\n",
      "Batch 17: loss = 0.803955078125, acc = 0.7373046875\n",
      "Batch 18: loss = 0.8306994438171387, acc = 0.7236328125\n",
      "Batch 19: loss = 0.7794963121414185, acc = 0.7470703125\n",
      "Batch 20: loss = 0.7958447337150574, acc = 0.736328125\n",
      "Batch 21: loss = 0.8770660758018494, acc = 0.7099609375\n",
      "Batch 22: loss = 0.7767636775970459, acc = 0.7421875\n",
      "Batch 23: loss = 0.7768384218215942, acc = 0.7294921875\n",
      "Batch 24: loss = 0.7885136008262634, acc = 0.7548828125\n",
      "Batch 25: loss = 0.7261184453964233, acc = 0.77734375\n",
      "Batch 26: loss = 0.7297425866127014, acc = 0.76171875\n",
      "Batch 27: loss = 0.8916459083557129, acc = 0.6923828125\n",
      "Batch 28: loss = 0.8153473138809204, acc = 0.7373046875\n",
      "Batch 29: loss = 0.7874186038970947, acc = 0.7412109375\n",
      "Batch 30: loss = 0.7371088862419128, acc = 0.744140625\n",
      "Batch 31: loss = 0.8718658685684204, acc = 0.7197265625\n",
      "Batch 32: loss = 0.9449543952941895, acc = 0.6845703125\n",
      "Batch 33: loss = 0.791495144367218, acc = 0.7392578125\n",
      "Batch 34: loss = 0.817177414894104, acc = 0.716796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 35: loss = 0.8249387741088867, acc = 0.7294921875\n",
      "Batch 36: loss = 0.7711520195007324, acc = 0.7392578125\n",
      "Batch 37: loss = 0.7896512746810913, acc = 0.7412109375\n",
      "Batch 38: loss = 0.8482925891876221, acc = 0.7236328125\n",
      "Batch 39: loss = 0.7889859080314636, acc = 0.7216796875\n",
      "Batch 40: loss = 0.7785359025001526, acc = 0.7529296875\n",
      "Batch 41: loss = 0.7106114625930786, acc = 0.7587890625\n",
      "Batch 42: loss = 0.7531538605690002, acc = 0.744140625\n",
      "Batch 43: loss = 0.8023474216461182, acc = 0.732421875\n",
      "Batch 44: loss = 0.7446455359458923, acc = 0.751953125\n",
      "Batch 45: loss = 0.6910250782966614, acc = 0.775390625\n",
      "Batch 46: loss = 0.7387000322341919, acc = 0.76171875\n",
      "Batch 47: loss = 0.7410485148429871, acc = 0.76171875\n",
      "Batch 48: loss = 0.7241582870483398, acc = 0.740234375\n",
      "Batch 49: loss = 0.6700192093849182, acc = 0.7939453125\n",
      "Batch 50: loss = 0.7300755977630615, acc = 0.7724609375\n",
      "Batch 51: loss = 0.6842569708824158, acc = 0.7724609375\n",
      "Batch 52: loss = 0.7750439643859863, acc = 0.748046875\n",
      "Batch 53: loss = 0.8181018829345703, acc = 0.7294921875\n",
      "Batch 54: loss = 0.7033709287643433, acc = 0.775390625\n",
      "Batch 55: loss = 0.7051211595535278, acc = 0.77734375\n",
      "Batch 56: loss = 0.7595564126968384, acc = 0.736328125\n",
      "Batch 57: loss = 0.8441175222396851, acc = 0.7255859375\n",
      "Batch 58: loss = 0.8786417841911316, acc = 0.7158203125\n",
      "Batch 59: loss = 0.631554126739502, acc = 0.7900390625\n",
      "Batch 60: loss = 0.7843337059020996, acc = 0.7431640625\n",
      "Batch 61: loss = 0.7813224196434021, acc = 0.7548828125\n",
      "Batch 62: loss = 0.9521064758300781, acc = 0.6806640625\n",
      "Batch 63: loss = 0.8613508939743042, acc = 0.7138671875\n",
      "Batch 64: loss = 0.6810293197631836, acc = 0.78515625\n",
      "Batch 65: loss = 0.8369621634483337, acc = 0.734375\n",
      "Batch 66: loss = 0.7831263542175293, acc = 0.736328125\n",
      "Batch 67: loss = 0.7179430723190308, acc = 0.7607421875\n",
      "Batch 68: loss = 0.8011521100997925, acc = 0.7646484375\n",
      "Batch 69: loss = 0.7178088426589966, acc = 0.7578125\n",
      "Batch 70: loss = 0.8444601893424988, acc = 0.720703125\n",
      "Batch 71: loss = 0.7977195978164673, acc = 0.7333984375\n",
      "Batch 72: loss = 0.7219675779342651, acc = 0.75\n",
      "Batch 73: loss = 0.8305268287658691, acc = 0.728515625\n",
      "Batch 74: loss = 0.8310642242431641, acc = 0.72265625\n",
      "Batch 75: loss = 0.9237493872642517, acc = 0.6796875\n",
      "Batch 76: loss = 0.8201777338981628, acc = 0.7373046875\n",
      "Batch 77: loss = 0.7391407489776611, acc = 0.7568359375\n",
      "Batch 78: loss = 0.7321323156356812, acc = 0.759765625\n",
      "Batch 79: loss = 0.6717555522918701, acc = 0.7705078125\n",
      "Batch 80: loss = 0.6721323728561401, acc = 0.7626953125\n",
      "Batch 81: loss = 0.7753102779388428, acc = 0.7509765625\n",
      "Batch 82: loss = 0.6835875511169434, acc = 0.7744140625\n",
      "Batch 83: loss = 0.7460330128669739, acc = 0.7490234375\n",
      "Batch 84: loss = 0.7377170324325562, acc = 0.7529296875\n",
      "Batch 85: loss = 0.8165194988250732, acc = 0.728515625\n",
      "Batch 86: loss = 0.8090224266052246, acc = 0.720703125\n",
      "Batch 87: loss = 0.7440137267112732, acc = 0.7568359375\n",
      "Batch 88: loss = 0.9158317446708679, acc = 0.701171875\n",
      "Batch 89: loss = 0.7913582921028137, acc = 0.7529296875\n",
      "Batch 90: loss = 0.8501546382904053, acc = 0.7255859375\n",
      "Batch 91: loss = 0.8329501152038574, acc = 0.71484375\n",
      "Batch 92: loss = 0.7905715107917786, acc = 0.7431640625\n",
      "Batch 93: loss = 0.6769789457321167, acc = 0.779296875\n",
      "Batch 94: loss = 0.72185218334198, acc = 0.759765625\n",
      "Batch 95: loss = 0.7418862581253052, acc = 0.744140625\n",
      "Batch 96: loss = 0.8108969926834106, acc = 0.7265625\n",
      "Batch 97: loss = 0.7781285047531128, acc = 0.75\n",
      "Batch 98: loss = 0.7727970480918884, acc = 0.75\n",
      "Batch 99: loss = 0.7598245143890381, acc = 0.7646484375\n",
      "Batch 100: loss = 0.7794214487075806, acc = 0.73828125\n",
      "Batch 101: loss = 0.7634944319725037, acc = 0.7431640625\n",
      "Batch 102: loss = 0.8255152106285095, acc = 0.7373046875\n",
      "Batch 103: loss = 0.7798131704330444, acc = 0.7412109375\n",
      "Batch 104: loss = 0.7161714434623718, acc = 0.771484375\n",
      "Batch 105: loss = 0.7544584274291992, acc = 0.751953125\n",
      "Batch 106: loss = 0.7981126308441162, acc = 0.7509765625\n",
      "Batch 107: loss = 0.7143458127975464, acc = 0.771484375\n",
      "Batch 108: loss = 0.7403121590614319, acc = 0.75\n",
      "Batch 109: loss = 0.7323159575462341, acc = 0.7646484375\n",
      "Batch 110: loss = 0.7102144956588745, acc = 0.7744140625\n",
      "Batch 111: loss = 0.8639291524887085, acc = 0.716796875\n",
      "Batch 112: loss = 0.7399654984474182, acc = 0.759765625\n",
      "Batch 113: loss = 0.7903923392295837, acc = 0.7314453125\n",
      "Batch 114: loss = 0.8225201368331909, acc = 0.7373046875\n",
      "Batch 115: loss = 0.8115383386611938, acc = 0.7431640625\n",
      "Batch 116: loss = 0.8419487476348877, acc = 0.7197265625\n",
      "Batch 117: loss = 0.7446483373641968, acc = 0.7578125\n",
      "Batch 118: loss = 0.7012439370155334, acc = 0.7578125\n",
      "Batch 119: loss = 0.7574805021286011, acc = 0.7587890625\n",
      "Batch 120: loss = 0.7879160046577454, acc = 0.74609375\n",
      "Batch 121: loss = 0.7725185751914978, acc = 0.7421875\n",
      "Batch 122: loss = 0.7418102622032166, acc = 0.748046875\n",
      "Batch 123: loss = 0.786131739616394, acc = 0.75\n",
      "Batch 124: loss = 0.8347723484039307, acc = 0.705078125\n",
      "Batch 125: loss = 0.8702652454376221, acc = 0.71875\n",
      "Batch 126: loss = 0.8664992451667786, acc = 0.7265625\n",
      "\n",
      "Epoch 25/100\n",
      "Batch 1: loss = 1.0280451774597168, acc = 0.6943359375\n",
      "Batch 2: loss = 0.8956044912338257, acc = 0.7138671875\n",
      "Batch 3: loss = 0.8287641406059265, acc = 0.7568359375\n",
      "Batch 4: loss = 0.792505145072937, acc = 0.7490234375\n",
      "Batch 5: loss = 0.894996166229248, acc = 0.705078125\n",
      "Batch 6: loss = 0.8800256252288818, acc = 0.708984375\n",
      "Batch 7: loss = 0.8463391065597534, acc = 0.7236328125\n",
      "Batch 8: loss = 0.8275790214538574, acc = 0.73828125\n",
      "Batch 9: loss = 0.7583041191101074, acc = 0.7607421875\n",
      "Batch 10: loss = 0.7119307518005371, acc = 0.7578125\n",
      "Batch 11: loss = 0.8181362152099609, acc = 0.73046875\n",
      "Batch 12: loss = 0.8299075961112976, acc = 0.7294921875\n",
      "Batch 13: loss = 0.7796649932861328, acc = 0.751953125\n",
      "Batch 14: loss = 0.776086688041687, acc = 0.744140625\n",
      "Batch 15: loss = 0.7362706661224365, acc = 0.7666015625\n",
      "Batch 16: loss = 0.8288806676864624, acc = 0.72265625\n",
      "Batch 17: loss = 0.807019829750061, acc = 0.7421875\n",
      "Batch 18: loss = 0.8061110973358154, acc = 0.7373046875\n",
      "Batch 19: loss = 0.7757874727249146, acc = 0.7333984375\n",
      "Batch 20: loss = 0.7807708978652954, acc = 0.7236328125\n",
      "Batch 21: loss = 0.8718694448471069, acc = 0.7109375\n",
      "Batch 22: loss = 0.7517498135566711, acc = 0.7548828125\n",
      "Batch 23: loss = 0.7650097608566284, acc = 0.73828125\n",
      "Batch 24: loss = 0.7923587560653687, acc = 0.7314453125\n",
      "Batch 25: loss = 0.7330982685089111, acc = 0.7578125\n",
      "Batch 26: loss = 0.7344275712966919, acc = 0.7490234375\n",
      "Batch 27: loss = 0.8767412900924683, acc = 0.7119140625\n",
      "Batch 28: loss = 0.775792121887207, acc = 0.75\n",
      "Batch 29: loss = 0.802441418170929, acc = 0.7421875\n",
      "Batch 30: loss = 0.7094243168830872, acc = 0.763671875\n",
      "Batch 31: loss = 0.8533178567886353, acc = 0.732421875\n",
      "Batch 32: loss = 0.914352536201477, acc = 0.69140625\n",
      "Batch 33: loss = 0.7460469007492065, acc = 0.7626953125\n",
      "Batch 34: loss = 0.7831127643585205, acc = 0.7421875\n",
      "Batch 35: loss = 0.7937967777252197, acc = 0.734375\n",
      "Batch 36: loss = 0.7421889305114746, acc = 0.765625\n",
      "Batch 37: loss = 0.762155294418335, acc = 0.7578125\n",
      "Batch 38: loss = 0.8001315593719482, acc = 0.7373046875\n",
      "Batch 39: loss = 0.772040069103241, acc = 0.75\n",
      "Batch 40: loss = 0.7702311277389526, acc = 0.7578125\n",
      "Batch 41: loss = 0.694988489151001, acc = 0.7763671875\n",
      "Batch 42: loss = 0.7246637344360352, acc = 0.767578125\n",
      "Batch 43: loss = 0.7843546867370605, acc = 0.7373046875\n",
      "Batch 44: loss = 0.7095611691474915, acc = 0.765625\n",
      "Batch 45: loss = 0.6908618211746216, acc = 0.759765625\n",
      "Batch 46: loss = 0.7252475023269653, acc = 0.759765625\n",
      "Batch 47: loss = 0.7257801294326782, acc = 0.765625\n",
      "Batch 48: loss = 0.7240377068519592, acc = 0.7548828125\n",
      "Batch 49: loss = 0.6549943685531616, acc = 0.791015625\n",
      "Batch 50: loss = 0.7011511325836182, acc = 0.7744140625\n",
      "Batch 51: loss = 0.6999087333679199, acc = 0.767578125\n",
      "Batch 52: loss = 0.7466843724250793, acc = 0.7568359375\n",
      "Batch 53: loss = 0.7803622484207153, acc = 0.7421875\n",
      "Batch 54: loss = 0.656175971031189, acc = 0.7919921875\n",
      "Batch 55: loss = 0.6695758104324341, acc = 0.767578125\n",
      "Batch 56: loss = 0.733802318572998, acc = 0.7529296875\n",
      "Batch 57: loss = 0.7733471393585205, acc = 0.7373046875\n",
      "Batch 58: loss = 0.8112626075744629, acc = 0.7294921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 59: loss = 0.6219222545623779, acc = 0.7900390625\n",
      "Batch 60: loss = 0.7397533655166626, acc = 0.7607421875\n",
      "Batch 61: loss = 0.7559143304824829, acc = 0.7548828125\n",
      "Batch 62: loss = 0.920194149017334, acc = 0.6953125\n",
      "Batch 63: loss = 0.8563300371170044, acc = 0.7255859375\n",
      "Batch 64: loss = 0.669394314289093, acc = 0.7783203125\n",
      "Batch 65: loss = 0.7898366451263428, acc = 0.7568359375\n",
      "Batch 66: loss = 0.7677141427993774, acc = 0.7431640625\n",
      "Batch 67: loss = 0.6945653557777405, acc = 0.775390625\n",
      "Batch 68: loss = 0.7603510022163391, acc = 0.76171875\n",
      "Batch 69: loss = 0.7066548466682434, acc = 0.7734375\n",
      "Batch 70: loss = 0.8156876564025879, acc = 0.7373046875\n",
      "Batch 71: loss = 0.779573917388916, acc = 0.736328125\n",
      "Batch 72: loss = 0.7065697312355042, acc = 0.77734375\n",
      "Batch 73: loss = 0.8208818435668945, acc = 0.72265625\n",
      "Batch 74: loss = 0.7768159508705139, acc = 0.7412109375\n",
      "Batch 75: loss = 0.8514612317085266, acc = 0.7216796875\n",
      "Batch 76: loss = 0.8111150860786438, acc = 0.7255859375\n",
      "Batch 77: loss = 0.709473729133606, acc = 0.765625\n",
      "Batch 78: loss = 0.7286273241043091, acc = 0.7607421875\n",
      "Batch 79: loss = 0.6491082310676575, acc = 0.78125\n",
      "Batch 80: loss = 0.7056083679199219, acc = 0.7548828125\n",
      "Batch 81: loss = 0.7606684565544128, acc = 0.7490234375\n",
      "Batch 82: loss = 0.688055694103241, acc = 0.77734375\n",
      "Batch 83: loss = 0.7378149032592773, acc = 0.7509765625\n",
      "Batch 84: loss = 0.722547173500061, acc = 0.7646484375\n",
      "Batch 85: loss = 0.8244902491569519, acc = 0.7392578125\n",
      "Batch 86: loss = 0.7861183881759644, acc = 0.734375\n",
      "Batch 87: loss = 0.709708571434021, acc = 0.7646484375\n",
      "Batch 88: loss = 0.8775809407234192, acc = 0.708984375\n",
      "Batch 89: loss = 0.7860981822013855, acc = 0.7509765625\n",
      "Batch 90: loss = 0.8119546175003052, acc = 0.7392578125\n",
      "Batch 91: loss = 0.797368049621582, acc = 0.7392578125\n",
      "Batch 92: loss = 0.788608729839325, acc = 0.7529296875\n",
      "Batch 93: loss = 0.6508653163909912, acc = 0.783203125\n",
      "Batch 94: loss = 0.7080732583999634, acc = 0.7890625\n",
      "Batch 95: loss = 0.7026032209396362, acc = 0.7724609375\n",
      "Batch 96: loss = 0.7674969434738159, acc = 0.7451171875\n",
      "Batch 97: loss = 0.7607864141464233, acc = 0.7587890625\n",
      "Batch 98: loss = 0.7650763392448425, acc = 0.7607421875\n",
      "Batch 99: loss = 0.7301256656646729, acc = 0.7626953125\n",
      "Batch 100: loss = 0.7504328489303589, acc = 0.748046875\n",
      "Batch 101: loss = 0.730933427810669, acc = 0.751953125\n",
      "Batch 102: loss = 0.7989295721054077, acc = 0.736328125\n",
      "Batch 103: loss = 0.7364537715911865, acc = 0.765625\n",
      "Batch 104: loss = 0.6809234023094177, acc = 0.7880859375\n",
      "Batch 105: loss = 0.7255896925926208, acc = 0.75\n",
      "Batch 106: loss = 0.7682958841323853, acc = 0.7509765625\n",
      "Batch 107: loss = 0.7109761238098145, acc = 0.7744140625\n",
      "Batch 108: loss = 0.7398785352706909, acc = 0.7509765625\n",
      "Batch 109: loss = 0.7252798080444336, acc = 0.7685546875\n",
      "Batch 110: loss = 0.6835120916366577, acc = 0.77734375\n",
      "Batch 111: loss = 0.8149845004081726, acc = 0.7421875\n",
      "Batch 112: loss = 0.7505639791488647, acc = 0.7587890625\n",
      "Batch 113: loss = 0.7586344480514526, acc = 0.7392578125\n",
      "Batch 114: loss = 0.7775193452835083, acc = 0.7666015625\n",
      "Batch 115: loss = 0.785006046295166, acc = 0.7548828125\n",
      "Batch 116: loss = 0.8517998456954956, acc = 0.732421875\n",
      "Batch 117: loss = 0.7321456670761108, acc = 0.7646484375\n",
      "Batch 118: loss = 0.6538565158843994, acc = 0.779296875\n",
      "Batch 119: loss = 0.7399346828460693, acc = 0.7724609375\n",
      "Batch 120: loss = 0.7627050876617432, acc = 0.7509765625\n",
      "Batch 121: loss = 0.7365463972091675, acc = 0.7578125\n",
      "Batch 122: loss = 0.7354279160499573, acc = 0.7529296875\n",
      "Batch 123: loss = 0.7714523673057556, acc = 0.7578125\n",
      "Batch 124: loss = 0.794269323348999, acc = 0.7216796875\n",
      "Batch 125: loss = 0.8389878869056702, acc = 0.7373046875\n",
      "Batch 126: loss = 0.8202095031738281, acc = 0.736328125\n",
      "\n",
      "Epoch 26/100\n",
      "Batch 1: loss = 1.0281939506530762, acc = 0.69921875\n",
      "Batch 2: loss = 0.8787431120872498, acc = 0.71484375\n",
      "Batch 3: loss = 0.8005980253219604, acc = 0.76171875\n",
      "Batch 4: loss = 0.7864934206008911, acc = 0.763671875\n",
      "Batch 5: loss = 0.8511251211166382, acc = 0.732421875\n",
      "Batch 6: loss = 0.8763977289199829, acc = 0.7021484375\n",
      "Batch 7: loss = 0.8152705430984497, acc = 0.740234375\n",
      "Batch 8: loss = 0.7751407623291016, acc = 0.7529296875\n",
      "Batch 9: loss = 0.7556909322738647, acc = 0.759765625\n",
      "Batch 10: loss = 0.6905108690261841, acc = 0.77734375\n",
      "Batch 11: loss = 0.7931777238845825, acc = 0.744140625\n",
      "Batch 12: loss = 0.81626957654953, acc = 0.7236328125\n",
      "Batch 13: loss = 0.7698980569839478, acc = 0.755859375\n",
      "Batch 14: loss = 0.7414098978042603, acc = 0.7568359375\n",
      "Batch 15: loss = 0.7333886027336121, acc = 0.7783203125\n",
      "Batch 16: loss = 0.8082127571105957, acc = 0.7294921875\n",
      "Batch 17: loss = 0.7601614594459534, acc = 0.759765625\n",
      "Batch 18: loss = 0.7957361936569214, acc = 0.7470703125\n",
      "Batch 19: loss = 0.7477271556854248, acc = 0.7578125\n",
      "Batch 20: loss = 0.7628970146179199, acc = 0.748046875\n",
      "Batch 21: loss = 0.8213188052177429, acc = 0.732421875\n",
      "Batch 22: loss = 0.7417981624603271, acc = 0.7392578125\n",
      "Batch 23: loss = 0.7425779104232788, acc = 0.751953125\n",
      "Batch 24: loss = 0.7433837652206421, acc = 0.7431640625\n",
      "Batch 25: loss = 0.7089692950248718, acc = 0.767578125\n",
      "Batch 26: loss = 0.7260908484458923, acc = 0.7509765625\n",
      "Batch 27: loss = 0.8452173471450806, acc = 0.7353515625\n",
      "Batch 28: loss = 0.7417570352554321, acc = 0.7412109375\n",
      "Batch 29: loss = 0.7672866582870483, acc = 0.7509765625\n",
      "Batch 30: loss = 0.6817249059677124, acc = 0.77734375\n",
      "Batch 31: loss = 0.8178162574768066, acc = 0.736328125\n",
      "Batch 32: loss = 0.8856312036514282, acc = 0.7060546875\n",
      "Batch 33: loss = 0.7314234972000122, acc = 0.755859375\n",
      "Batch 34: loss = 0.7873753309249878, acc = 0.7431640625\n",
      "Batch 35: loss = 0.7761008739471436, acc = 0.748046875\n",
      "Batch 36: loss = 0.7424111366271973, acc = 0.763671875\n",
      "Batch 37: loss = 0.7367734909057617, acc = 0.7626953125\n",
      "Batch 38: loss = 0.7951682209968567, acc = 0.7373046875\n",
      "Batch 39: loss = 0.7803605198860168, acc = 0.7392578125\n",
      "Batch 40: loss = 0.7637884616851807, acc = 0.74609375\n",
      "Batch 41: loss = 0.6693512797355652, acc = 0.7861328125\n",
      "Batch 42: loss = 0.7110849618911743, acc = 0.7578125\n",
      "Batch 43: loss = 0.7418612241744995, acc = 0.74609375\n",
      "Batch 44: loss = 0.7001807689666748, acc = 0.7724609375\n",
      "Batch 45: loss = 0.6735129952430725, acc = 0.7841796875\n",
      "Batch 46: loss = 0.6838729381561279, acc = 0.765625\n",
      "Batch 47: loss = 0.706718921661377, acc = 0.7685546875\n",
      "Batch 48: loss = 0.6947712302207947, acc = 0.7646484375\n",
      "Batch 49: loss = 0.6301954984664917, acc = 0.798828125\n",
      "Batch 50: loss = 0.6776807308197021, acc = 0.7841796875\n",
      "Batch 51: loss = 0.6985655426979065, acc = 0.7666015625\n",
      "Batch 52: loss = 0.7488466501235962, acc = 0.7431640625\n",
      "Batch 53: loss = 0.7932182550430298, acc = 0.740234375\n",
      "Batch 54: loss = 0.654791533946991, acc = 0.787109375\n",
      "Batch 55: loss = 0.6539711952209473, acc = 0.7861328125\n",
      "Batch 56: loss = 0.746803879737854, acc = 0.7548828125\n",
      "Batch 57: loss = 0.7749978303909302, acc = 0.7275390625\n",
      "Batch 58: loss = 0.828652024269104, acc = 0.73046875\n",
      "Batch 59: loss = 0.5997294187545776, acc = 0.8134765625\n",
      "Batch 60: loss = 0.7454073429107666, acc = 0.75\n",
      "Batch 61: loss = 0.7295374274253845, acc = 0.765625\n",
      "Batch 62: loss = 0.9056063294410706, acc = 0.6962890625\n",
      "Batch 63: loss = 0.8010175824165344, acc = 0.740234375\n",
      "Batch 64: loss = 0.6629250049591064, acc = 0.7734375\n",
      "Batch 65: loss = 0.7817294597625732, acc = 0.7451171875\n",
      "Batch 66: loss = 0.7644380927085876, acc = 0.7451171875\n",
      "Batch 67: loss = 0.6812341213226318, acc = 0.7802734375\n",
      "Batch 68: loss = 0.7293311953544617, acc = 0.755859375\n",
      "Batch 69: loss = 0.690969705581665, acc = 0.78125\n",
      "Batch 70: loss = 0.7838850617408752, acc = 0.7451171875\n",
      "Batch 71: loss = 0.7501886487007141, acc = 0.7548828125\n",
      "Batch 72: loss = 0.6776158809661865, acc = 0.77734375\n",
      "Batch 73: loss = 0.8104486465454102, acc = 0.7392578125\n",
      "Batch 74: loss = 0.7788037061691284, acc = 0.7509765625\n",
      "Batch 75: loss = 0.8702112436294556, acc = 0.705078125\n",
      "Batch 76: loss = 0.7973042726516724, acc = 0.740234375\n",
      "Batch 77: loss = 0.7054542303085327, acc = 0.765625\n",
      "Batch 78: loss = 0.7260130643844604, acc = 0.7685546875\n",
      "Batch 79: loss = 0.613796591758728, acc = 0.796875\n",
      "Batch 80: loss = 0.6727628707885742, acc = 0.7705078125\n",
      "Batch 81: loss = 0.7037423253059387, acc = 0.7646484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 82: loss = 0.6704403758049011, acc = 0.787109375\n",
      "Batch 83: loss = 0.7212497591972351, acc = 0.76171875\n",
      "Batch 84: loss = 0.709979772567749, acc = 0.7607421875\n",
      "Batch 85: loss = 0.8102346658706665, acc = 0.73046875\n",
      "Batch 86: loss = 0.7829192280769348, acc = 0.740234375\n",
      "Batch 87: loss = 0.6955391764640808, acc = 0.7578125\n",
      "Batch 88: loss = 0.8615909218788147, acc = 0.7197265625\n",
      "Batch 89: loss = 0.753237247467041, acc = 0.7548828125\n",
      "Batch 90: loss = 0.7900176048278809, acc = 0.75390625\n",
      "Batch 91: loss = 0.7877323031425476, acc = 0.7373046875\n",
      "Batch 92: loss = 0.7291193604469299, acc = 0.763671875\n",
      "Batch 93: loss = 0.652185320854187, acc = 0.7890625\n",
      "Batch 94: loss = 0.6812738180160522, acc = 0.7666015625\n",
      "Batch 95: loss = 0.6727328300476074, acc = 0.763671875\n",
      "Batch 96: loss = 0.7714449167251587, acc = 0.7587890625\n",
      "Batch 97: loss = 0.733818769454956, acc = 0.779296875\n",
      "Batch 98: loss = 0.7222492098808289, acc = 0.771484375\n",
      "Batch 99: loss = 0.7045415639877319, acc = 0.7568359375\n",
      "Batch 100: loss = 0.7563933730125427, acc = 0.7587890625\n",
      "Batch 101: loss = 0.683068037033081, acc = 0.7783203125\n",
      "Batch 102: loss = 0.7637210488319397, acc = 0.7529296875\n",
      "Batch 103: loss = 0.7489511370658875, acc = 0.751953125\n",
      "Batch 104: loss = 0.6488016247749329, acc = 0.7822265625\n",
      "Batch 105: loss = 0.6891791820526123, acc = 0.767578125\n",
      "Batch 106: loss = 0.7342996597290039, acc = 0.77734375\n",
      "Batch 107: loss = 0.7160717248916626, acc = 0.765625\n",
      "Batch 108: loss = 0.7310317158699036, acc = 0.759765625\n",
      "Batch 109: loss = 0.7123603224754333, acc = 0.7626953125\n",
      "Batch 110: loss = 0.6872216463088989, acc = 0.7822265625\n",
      "Batch 111: loss = 0.8169798851013184, acc = 0.740234375\n",
      "Batch 112: loss = 0.7262606024742126, acc = 0.765625\n",
      "Batch 113: loss = 0.7396987676620483, acc = 0.765625\n",
      "Batch 114: loss = 0.7641797065734863, acc = 0.763671875\n",
      "Batch 115: loss = 0.7734296321868896, acc = 0.7431640625\n",
      "Batch 116: loss = 0.8319583535194397, acc = 0.732421875\n",
      "Batch 117: loss = 0.6708577871322632, acc = 0.7783203125\n",
      "Batch 118: loss = 0.6343867182731628, acc = 0.7880859375\n",
      "Batch 119: loss = 0.7199455499649048, acc = 0.7568359375\n",
      "Batch 120: loss = 0.7214956283569336, acc = 0.7626953125\n",
      "Batch 121: loss = 0.7286679148674011, acc = 0.7578125\n",
      "Batch 122: loss = 0.7005266547203064, acc = 0.775390625\n",
      "Batch 123: loss = 0.7399077415466309, acc = 0.7568359375\n",
      "Batch 124: loss = 0.7663333415985107, acc = 0.7392578125\n",
      "Batch 125: loss = 0.8242098689079285, acc = 0.7265625\n",
      "Batch 126: loss = 0.7929251194000244, acc = 0.740234375\n",
      "\n",
      "Epoch 27/100\n",
      "Batch 1: loss = 1.0130085945129395, acc = 0.70703125\n",
      "Batch 2: loss = 0.867440938949585, acc = 0.7158203125\n",
      "Batch 3: loss = 0.7825791835784912, acc = 0.75390625\n",
      "Batch 4: loss = 0.7609580755233765, acc = 0.7568359375\n",
      "Batch 5: loss = 0.8649457693099976, acc = 0.7109375\n",
      "Batch 6: loss = 0.8481051921844482, acc = 0.7099609375\n",
      "Batch 7: loss = 0.787661075592041, acc = 0.7451171875\n",
      "Batch 8: loss = 0.7718462944030762, acc = 0.7578125\n",
      "Batch 9: loss = 0.6990386247634888, acc = 0.7724609375\n",
      "Batch 10: loss = 0.6818047165870667, acc = 0.7685546875\n",
      "Batch 11: loss = 0.7917568683624268, acc = 0.7412109375\n",
      "Batch 12: loss = 0.7739977836608887, acc = 0.7431640625\n",
      "Batch 13: loss = 0.7300617694854736, acc = 0.7578125\n",
      "Batch 14: loss = 0.7446842789649963, acc = 0.75390625\n",
      "Batch 15: loss = 0.7127243280410767, acc = 0.76953125\n",
      "Batch 16: loss = 0.8063491582870483, acc = 0.7373046875\n",
      "Batch 17: loss = 0.7842714786529541, acc = 0.75\n",
      "Batch 18: loss = 0.7984322309494019, acc = 0.744140625\n",
      "Batch 19: loss = 0.732138454914093, acc = 0.783203125\n",
      "Batch 20: loss = 0.7332479953765869, acc = 0.74609375\n",
      "Batch 21: loss = 0.8086665868759155, acc = 0.73046875\n",
      "Batch 22: loss = 0.7041499018669128, acc = 0.7705078125\n",
      "Batch 23: loss = 0.7111095190048218, acc = 0.76953125\n",
      "Batch 24: loss = 0.7048678994178772, acc = 0.7685546875\n",
      "Batch 25: loss = 0.6786542534828186, acc = 0.775390625\n",
      "Batch 26: loss = 0.6681169271469116, acc = 0.7783203125\n",
      "Batch 27: loss = 0.8250448703765869, acc = 0.73046875\n",
      "Batch 28: loss = 0.7647785544395447, acc = 0.748046875\n",
      "Batch 29: loss = 0.7467331886291504, acc = 0.75390625\n",
      "Batch 30: loss = 0.686416506767273, acc = 0.7666015625\n",
      "Batch 31: loss = 0.8291114568710327, acc = 0.7294921875\n",
      "Batch 32: loss = 0.8763918876647949, acc = 0.7080078125\n",
      "Batch 33: loss = 0.6880465745925903, acc = 0.7705078125\n",
      "Batch 34: loss = 0.7448296546936035, acc = 0.75\n",
      "Batch 35: loss = 0.7311040163040161, acc = 0.767578125\n",
      "Batch 36: loss = 0.7242195010185242, acc = 0.767578125\n",
      "Batch 37: loss = 0.7373239994049072, acc = 0.75\n",
      "Batch 38: loss = 0.7876772284507751, acc = 0.748046875\n",
      "Batch 39: loss = 0.7440905570983887, acc = 0.75390625\n",
      "Batch 40: loss = 0.7544992566108704, acc = 0.7470703125\n",
      "Batch 41: loss = 0.6354774236679077, acc = 0.78125\n",
      "Batch 42: loss = 0.6865048408508301, acc = 0.7724609375\n",
      "Batch 43: loss = 0.7563404440879822, acc = 0.748046875\n",
      "Batch 44: loss = 0.6681510806083679, acc = 0.7900390625\n",
      "Batch 45: loss = 0.6789926290512085, acc = 0.7607421875\n",
      "Batch 46: loss = 0.660737156867981, acc = 0.78515625\n",
      "Batch 47: loss = 0.6935211420059204, acc = 0.78125\n",
      "Batch 48: loss = 0.6840807795524597, acc = 0.7646484375\n",
      "Batch 49: loss = 0.6281119585037231, acc = 0.7998046875\n",
      "Batch 50: loss = 0.6571983098983765, acc = 0.7890625\n",
      "Batch 51: loss = 0.6730679273605347, acc = 0.7724609375\n",
      "Batch 52: loss = 0.7297950983047485, acc = 0.759765625\n",
      "Batch 53: loss = 0.7641910314559937, acc = 0.74609375\n",
      "Batch 54: loss = 0.638054370880127, acc = 0.791015625\n",
      "Batch 55: loss = 0.6316874027252197, acc = 0.8037109375\n",
      "Batch 56: loss = 0.7293354868888855, acc = 0.755859375\n",
      "Batch 57: loss = 0.761396050453186, acc = 0.744140625\n",
      "Batch 58: loss = 0.7949116230010986, acc = 0.7412109375\n",
      "Batch 59: loss = 0.5993115305900574, acc = 0.8076171875\n",
      "Batch 60: loss = 0.722487211227417, acc = 0.76953125\n",
      "Batch 61: loss = 0.7237118482589722, acc = 0.76953125\n",
      "Batch 62: loss = 0.8934394717216492, acc = 0.6962890625\n",
      "Batch 63: loss = 0.8170166015625, acc = 0.7275390625\n",
      "Batch 64: loss = 0.6298174262046814, acc = 0.787109375\n",
      "Batch 65: loss = 0.7823808193206787, acc = 0.7529296875\n",
      "Batch 66: loss = 0.7535504102706909, acc = 0.74609375\n",
      "Batch 67: loss = 0.6667304635047913, acc = 0.783203125\n",
      "Batch 68: loss = 0.7272732257843018, acc = 0.7744140625\n",
      "Batch 69: loss = 0.6603239178657532, acc = 0.7919921875\n",
      "Batch 70: loss = 0.7787815928459167, acc = 0.7353515625\n",
      "Batch 71: loss = 0.7481429576873779, acc = 0.734375\n",
      "Batch 72: loss = 0.6745574474334717, acc = 0.7802734375\n",
      "Batch 73: loss = 0.7753978967666626, acc = 0.7470703125\n",
      "Batch 74: loss = 0.7792285084724426, acc = 0.734375\n",
      "Batch 75: loss = 0.8271418809890747, acc = 0.7333984375\n",
      "Batch 76: loss = 0.774327278137207, acc = 0.75390625\n",
      "Batch 77: loss = 0.6860458254814148, acc = 0.7841796875\n",
      "Batch 78: loss = 0.6956337094306946, acc = 0.7822265625\n",
      "Batch 79: loss = 0.5913413763046265, acc = 0.798828125\n",
      "Batch 80: loss = 0.6546914577484131, acc = 0.7548828125\n",
      "Batch 81: loss = 0.7180459499359131, acc = 0.7626953125\n",
      "Batch 82: loss = 0.6473771333694458, acc = 0.7880859375\n",
      "Batch 83: loss = 0.679164469242096, acc = 0.7763671875\n",
      "Batch 84: loss = 0.6898425817489624, acc = 0.7724609375\n",
      "Batch 85: loss = 0.7854875326156616, acc = 0.7373046875\n",
      "Batch 86: loss = 0.7498276233673096, acc = 0.7490234375\n",
      "Batch 87: loss = 0.6727714538574219, acc = 0.7841796875\n",
      "Batch 88: loss = 0.8803614974021912, acc = 0.712890625\n",
      "Batch 89: loss = 0.749929666519165, acc = 0.7578125\n",
      "Batch 90: loss = 0.7720329165458679, acc = 0.7587890625\n",
      "Batch 91: loss = 0.771359384059906, acc = 0.73046875\n",
      "Batch 92: loss = 0.7289788126945496, acc = 0.7578125\n",
      "Batch 93: loss = 0.6164249181747437, acc = 0.796875\n",
      "Batch 94: loss = 0.644123911857605, acc = 0.7919921875\n",
      "Batch 95: loss = 0.6697763204574585, acc = 0.7841796875\n",
      "Batch 96: loss = 0.7532108426094055, acc = 0.7548828125\n",
      "Batch 97: loss = 0.7429671883583069, acc = 0.7744140625\n",
      "Batch 98: loss = 0.7029818296432495, acc = 0.7783203125\n",
      "Batch 99: loss = 0.6997424364089966, acc = 0.7734375\n",
      "Batch 100: loss = 0.7192296385765076, acc = 0.755859375\n",
      "Batch 101: loss = 0.7062426805496216, acc = 0.7705078125\n",
      "Batch 102: loss = 0.753831148147583, acc = 0.7626953125\n",
      "Batch 103: loss = 0.7046663761138916, acc = 0.765625\n",
      "Batch 104: loss = 0.6468377113342285, acc = 0.7744140625\n",
      "Batch 105: loss = 0.676842451095581, acc = 0.775390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 106: loss = 0.701911211013794, acc = 0.7919921875\n",
      "Batch 107: loss = 0.6723561882972717, acc = 0.7890625\n",
      "Batch 108: loss = 0.6857321262359619, acc = 0.771484375\n",
      "Batch 109: loss = 0.6709640622138977, acc = 0.787109375\n",
      "Batch 110: loss = 0.6491221785545349, acc = 0.7861328125\n",
      "Batch 111: loss = 0.7638524770736694, acc = 0.7607421875\n",
      "Batch 112: loss = 0.7017677426338196, acc = 0.767578125\n",
      "Batch 113: loss = 0.721766471862793, acc = 0.75390625\n",
      "Batch 114: loss = 0.764025092124939, acc = 0.7734375\n",
      "Batch 115: loss = 0.7503057718276978, acc = 0.751953125\n",
      "Batch 116: loss = 0.7709766626358032, acc = 0.7490234375\n",
      "Batch 117: loss = 0.6713457107543945, acc = 0.779296875\n",
      "Batch 118: loss = 0.6079581379890442, acc = 0.7958984375\n",
      "Batch 119: loss = 0.6861197352409363, acc = 0.775390625\n",
      "Batch 120: loss = 0.7200592756271362, acc = 0.7490234375\n",
      "Batch 121: loss = 0.7211465835571289, acc = 0.75\n",
      "Batch 122: loss = 0.6622510552406311, acc = 0.77734375\n",
      "Batch 123: loss = 0.7350753545761108, acc = 0.7666015625\n",
      "Batch 124: loss = 0.7444347739219666, acc = 0.7421875\n",
      "Batch 125: loss = 0.7688651084899902, acc = 0.75\n",
      "Batch 126: loss = 0.7547780275344849, acc = 0.7685546875\n",
      "\n",
      "Epoch 28/100\n",
      "Batch 1: loss = 0.9182942509651184, acc = 0.7255859375\n",
      "Batch 2: loss = 0.8073837757110596, acc = 0.7451171875\n",
      "Batch 3: loss = 0.7462683916091919, acc = 0.7783203125\n",
      "Batch 4: loss = 0.7043174505233765, acc = 0.7744140625\n",
      "Batch 5: loss = 0.8010554909706116, acc = 0.74609375\n",
      "Batch 6: loss = 0.7788568735122681, acc = 0.744140625\n",
      "Batch 7: loss = 0.7426608204841614, acc = 0.7568359375\n",
      "Batch 8: loss = 0.7364559769630432, acc = 0.76171875\n",
      "Batch 9: loss = 0.6819222569465637, acc = 0.7666015625\n",
      "Batch 10: loss = 0.6464560031890869, acc = 0.7900390625\n",
      "Batch 11: loss = 0.7282875776290894, acc = 0.767578125\n",
      "Batch 12: loss = 0.7422215938568115, acc = 0.7529296875\n",
      "Batch 13: loss = 0.7073637247085571, acc = 0.7734375\n",
      "Batch 14: loss = 0.7128199338912964, acc = 0.7705078125\n",
      "Batch 15: loss = 0.6878133416175842, acc = 0.7724609375\n",
      "Batch 16: loss = 0.7823542356491089, acc = 0.7275390625\n",
      "Batch 17: loss = 0.7352252006530762, acc = 0.7626953125\n",
      "Batch 18: loss = 0.78443443775177, acc = 0.7392578125\n",
      "Batch 19: loss = 0.6910104155540466, acc = 0.7724609375\n",
      "Batch 20: loss = 0.7166045308113098, acc = 0.76171875\n",
      "Batch 21: loss = 0.7761349678039551, acc = 0.7333984375\n",
      "Batch 22: loss = 0.6994555592536926, acc = 0.759765625\n",
      "Batch 23: loss = 0.7111320495605469, acc = 0.75\n",
      "Batch 24: loss = 0.7114486694335938, acc = 0.7685546875\n",
      "Batch 25: loss = 0.6680147647857666, acc = 0.78515625\n",
      "Batch 26: loss = 0.6658496856689453, acc = 0.7734375\n",
      "Batch 27: loss = 0.7745926976203918, acc = 0.744140625\n",
      "Batch 28: loss = 0.7593436241149902, acc = 0.7509765625\n",
      "Batch 29: loss = 0.7244347333908081, acc = 0.7763671875\n",
      "Batch 30: loss = 0.6678467392921448, acc = 0.7744140625\n",
      "Batch 31: loss = 0.7645014524459839, acc = 0.740234375\n",
      "Batch 32: loss = 0.8566849231719971, acc = 0.7236328125\n",
      "Batch 33: loss = 0.6655508279800415, acc = 0.76953125\n",
      "Batch 34: loss = 0.7356483936309814, acc = 0.74609375\n",
      "Batch 35: loss = 0.708580493927002, acc = 0.759765625\n",
      "Batch 36: loss = 0.6891286969184875, acc = 0.7734375\n",
      "Batch 37: loss = 0.7337883710861206, acc = 0.7626953125\n",
      "Batch 38: loss = 0.7422834634780884, acc = 0.7548828125\n",
      "Batch 39: loss = 0.7348259687423706, acc = 0.7568359375\n",
      "Batch 40: loss = 0.7160404920578003, acc = 0.759765625\n",
      "Batch 41: loss = 0.6279788017272949, acc = 0.7880859375\n",
      "Batch 42: loss = 0.691374659538269, acc = 0.7685546875\n",
      "Batch 43: loss = 0.7226242423057556, acc = 0.7529296875\n",
      "Batch 44: loss = 0.6467673182487488, acc = 0.78515625\n",
      "Batch 45: loss = 0.6162596940994263, acc = 0.7978515625\n",
      "Batch 46: loss = 0.6424818634986877, acc = 0.783203125\n",
      "Batch 47: loss = 0.6463595628738403, acc = 0.7880859375\n",
      "Batch 48: loss = 0.6532629728317261, acc = 0.7734375\n",
      "Batch 49: loss = 0.6103445291519165, acc = 0.8125\n",
      "Batch 50: loss = 0.6683616638183594, acc = 0.7861328125\n",
      "Batch 51: loss = 0.673683226108551, acc = 0.767578125\n",
      "Batch 52: loss = 0.7077702283859253, acc = 0.77734375\n",
      "Batch 53: loss = 0.7347064018249512, acc = 0.7705078125\n",
      "Batch 54: loss = 0.6176645755767822, acc = 0.7939453125\n",
      "Batch 55: loss = 0.6199911832809448, acc = 0.7890625\n",
      "Batch 56: loss = 0.6751832962036133, acc = 0.7578125\n",
      "Batch 57: loss = 0.7292116284370422, acc = 0.7529296875\n",
      "Batch 58: loss = 0.7518437504768372, acc = 0.748046875\n",
      "Batch 59: loss = 0.5612214803695679, acc = 0.8095703125\n",
      "Batch 60: loss = 0.725296676158905, acc = 0.7734375\n",
      "Batch 61: loss = 0.6958486437797546, acc = 0.779296875\n",
      "Batch 62: loss = 0.8427587747573853, acc = 0.7001953125\n",
      "Batch 63: loss = 0.7921723127365112, acc = 0.734375\n",
      "Batch 64: loss = 0.6181695461273193, acc = 0.80078125\n",
      "Batch 65: loss = 0.7478896379470825, acc = 0.759765625\n",
      "Batch 66: loss = 0.6896003484725952, acc = 0.7646484375\n",
      "Batch 67: loss = 0.658085823059082, acc = 0.779296875\n",
      "Batch 68: loss = 0.7222661972045898, acc = 0.7705078125\n",
      "Batch 69: loss = 0.6339209079742432, acc = 0.80078125\n",
      "Batch 70: loss = 0.7717786431312561, acc = 0.744140625\n",
      "Batch 71: loss = 0.7505908608436584, acc = 0.744140625\n",
      "Batch 72: loss = 0.6387026309967041, acc = 0.794921875\n",
      "Batch 73: loss = 0.7599075436592102, acc = 0.75390625\n",
      "Batch 74: loss = 0.7552457451820374, acc = 0.751953125\n",
      "Batch 75: loss = 0.8394432067871094, acc = 0.728515625\n",
      "Batch 76: loss = 0.74985671043396, acc = 0.748046875\n",
      "Batch 77: loss = 0.6746497750282288, acc = 0.7890625\n",
      "Batch 78: loss = 0.6799505949020386, acc = 0.7734375\n",
      "Batch 79: loss = 0.605310320854187, acc = 0.8046875\n",
      "Batch 80: loss = 0.6445268392562866, acc = 0.775390625\n",
      "Batch 81: loss = 0.6998246908187866, acc = 0.771484375\n",
      "Batch 82: loss = 0.6407502293586731, acc = 0.80078125\n",
      "Batch 83: loss = 0.6783859729766846, acc = 0.765625\n",
      "Batch 84: loss = 0.6602784395217896, acc = 0.78515625\n",
      "Batch 85: loss = 0.7703520059585571, acc = 0.748046875\n",
      "Batch 86: loss = 0.7277518510818481, acc = 0.7685546875\n",
      "Batch 87: loss = 0.6651878952980042, acc = 0.7861328125\n",
      "Batch 88: loss = 0.8198003768920898, acc = 0.74609375\n",
      "Batch 89: loss = 0.7337610721588135, acc = 0.77734375\n",
      "Batch 90: loss = 0.7612276673316956, acc = 0.7470703125\n",
      "Batch 91: loss = 0.7408635020256042, acc = 0.7353515625\n",
      "Batch 92: loss = 0.7297515869140625, acc = 0.76171875\n",
      "Batch 93: loss = 0.6235059499740601, acc = 0.78515625\n",
      "Batch 94: loss = 0.638607382774353, acc = 0.794921875\n",
      "Batch 95: loss = 0.6623419523239136, acc = 0.7705078125\n",
      "Batch 96: loss = 0.714476466178894, acc = 0.7548828125\n",
      "Batch 97: loss = 0.6857174634933472, acc = 0.7919921875\n",
      "Batch 98: loss = 0.7076157331466675, acc = 0.755859375\n",
      "Batch 99: loss = 0.6699306964874268, acc = 0.7861328125\n",
      "Batch 100: loss = 0.7227762341499329, acc = 0.7587890625\n",
      "Batch 101: loss = 0.6890535354614258, acc = 0.783203125\n",
      "Batch 102: loss = 0.7377039194107056, acc = 0.7548828125\n",
      "Batch 103: loss = 0.6902226805686951, acc = 0.763671875\n",
      "Batch 104: loss = 0.6148808002471924, acc = 0.798828125\n",
      "Batch 105: loss = 0.6810988187789917, acc = 0.7724609375\n",
      "Batch 106: loss = 0.7402380108833313, acc = 0.7802734375\n",
      "Batch 107: loss = 0.6624898910522461, acc = 0.7890625\n",
      "Batch 108: loss = 0.6846742630004883, acc = 0.7607421875\n",
      "Batch 109: loss = 0.6716163158416748, acc = 0.7734375\n",
      "Batch 110: loss = 0.635326623916626, acc = 0.80078125\n",
      "Batch 111: loss = 0.7861685752868652, acc = 0.7421875\n",
      "Batch 112: loss = 0.6821795701980591, acc = 0.78125\n",
      "Batch 113: loss = 0.6581838130950928, acc = 0.77734375\n",
      "Batch 114: loss = 0.7017711400985718, acc = 0.775390625\n",
      "Batch 115: loss = 0.7262927293777466, acc = 0.7646484375\n",
      "Batch 116: loss = 0.786609947681427, acc = 0.7607421875\n",
      "Batch 117: loss = 0.6623802781105042, acc = 0.7861328125\n",
      "Batch 118: loss = 0.5855981111526489, acc = 0.802734375\n",
      "Batch 119: loss = 0.6654473543167114, acc = 0.78125\n",
      "Batch 120: loss = 0.6672590970993042, acc = 0.7841796875\n",
      "Batch 121: loss = 0.6982730627059937, acc = 0.755859375\n",
      "Batch 122: loss = 0.6552138924598694, acc = 0.8017578125\n",
      "Batch 123: loss = 0.7211232781410217, acc = 0.7763671875\n",
      "Batch 124: loss = 0.7188823819160461, acc = 0.7587890625\n",
      "Batch 125: loss = 0.7536882162094116, acc = 0.7578125\n",
      "Batch 126: loss = 0.7351174354553223, acc = 0.7724609375\n",
      "\n",
      "Epoch 29/100\n",
      "Batch 1: loss = 0.9371011853218079, acc = 0.7275390625\n",
      "Batch 2: loss = 0.8287187814712524, acc = 0.740234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3: loss = 0.7494544982910156, acc = 0.7763671875\n",
      "Batch 4: loss = 0.6862561702728271, acc = 0.7880859375\n",
      "Batch 5: loss = 0.7732797861099243, acc = 0.7490234375\n",
      "Batch 6: loss = 0.7790623307228088, acc = 0.7314453125\n",
      "Batch 7: loss = 0.727632999420166, acc = 0.771484375\n",
      "Batch 8: loss = 0.7146709561347961, acc = 0.76953125\n",
      "Batch 9: loss = 0.6569064259529114, acc = 0.78515625\n",
      "Batch 10: loss = 0.6523317098617554, acc = 0.78515625\n",
      "Batch 11: loss = 0.7157498598098755, acc = 0.7734375\n",
      "Batch 12: loss = 0.7280961275100708, acc = 0.75\n",
      "Batch 13: loss = 0.6763249635696411, acc = 0.76953125\n",
      "Batch 14: loss = 0.6715708374977112, acc = 0.787109375\n",
      "Batch 15: loss = 0.6644688844680786, acc = 0.783203125\n",
      "Batch 16: loss = 0.7601844072341919, acc = 0.7578125\n",
      "Batch 17: loss = 0.7000443935394287, acc = 0.7666015625\n",
      "Batch 18: loss = 0.752619743347168, acc = 0.7578125\n",
      "Batch 19: loss = 0.6727650165557861, acc = 0.7900390625\n",
      "Batch 20: loss = 0.6871403455734253, acc = 0.767578125\n",
      "Batch 21: loss = 0.8072227239608765, acc = 0.7431640625\n",
      "Batch 22: loss = 0.6833075284957886, acc = 0.77734375\n",
      "Batch 23: loss = 0.6749042868614197, acc = 0.7744140625\n",
      "Batch 24: loss = 0.6893265247344971, acc = 0.7724609375\n",
      "Batch 25: loss = 0.6744133234024048, acc = 0.7802734375\n",
      "Batch 26: loss = 0.6813069581985474, acc = 0.7705078125\n",
      "Batch 27: loss = 0.7742324471473694, acc = 0.763671875\n",
      "Batch 28: loss = 0.7434942722320557, acc = 0.7548828125\n",
      "Batch 29: loss = 0.7272353172302246, acc = 0.7666015625\n",
      "Batch 30: loss = 0.6449739933013916, acc = 0.7822265625\n",
      "Batch 31: loss = 0.7555548548698425, acc = 0.75\n",
      "Batch 32: loss = 0.8247822523117065, acc = 0.73046875\n",
      "Batch 33: loss = 0.6769286394119263, acc = 0.771484375\n",
      "Batch 34: loss = 0.7381746172904968, acc = 0.75390625\n",
      "Batch 35: loss = 0.7019190192222595, acc = 0.767578125\n",
      "Batch 36: loss = 0.6760380268096924, acc = 0.783203125\n",
      "Batch 37: loss = 0.6637855768203735, acc = 0.775390625\n",
      "Batch 38: loss = 0.7394828200340271, acc = 0.7587890625\n",
      "Batch 39: loss = 0.6889306306838989, acc = 0.76171875\n",
      "Batch 40: loss = 0.7171993255615234, acc = 0.7666015625\n",
      "Batch 41: loss = 0.607726514339447, acc = 0.8037109375\n",
      "Batch 42: loss = 0.6746305227279663, acc = 0.791015625\n",
      "Batch 43: loss = 0.7134003043174744, acc = 0.763671875\n",
      "Batch 44: loss = 0.6437975168228149, acc = 0.80078125\n",
      "Batch 45: loss = 0.6221997737884521, acc = 0.796875\n",
      "Batch 46: loss = 0.6561012268066406, acc = 0.78515625\n",
      "Batch 47: loss = 0.6689767241477966, acc = 0.787109375\n",
      "Batch 48: loss = 0.6414706707000732, acc = 0.791015625\n",
      "Batch 49: loss = 0.5853272676467896, acc = 0.810546875\n",
      "Batch 50: loss = 0.6528098583221436, acc = 0.78515625\n",
      "Batch 51: loss = 0.629798412322998, acc = 0.78515625\n",
      "Batch 52: loss = 0.6702720522880554, acc = 0.7822265625\n",
      "Batch 53: loss = 0.7256940603256226, acc = 0.7685546875\n",
      "Batch 54: loss = 0.6272404193878174, acc = 0.7978515625\n",
      "Batch 55: loss = 0.6029421091079712, acc = 0.8095703125\n",
      "Batch 56: loss = 0.6753065586090088, acc = 0.7685546875\n",
      "Batch 57: loss = 0.7190461754798889, acc = 0.7587890625\n",
      "Batch 58: loss = 0.7071809768676758, acc = 0.7490234375\n",
      "Batch 59: loss = 0.5615044832229614, acc = 0.826171875\n",
      "Batch 60: loss = 0.6680970191955566, acc = 0.7861328125\n",
      "Batch 61: loss = 0.6653137803077698, acc = 0.791015625\n",
      "Batch 62: loss = 0.8293260931968689, acc = 0.728515625\n",
      "Batch 63: loss = 0.7709710597991943, acc = 0.744140625\n",
      "Batch 64: loss = 0.606147050857544, acc = 0.810546875\n",
      "Batch 65: loss = 0.7142454385757446, acc = 0.7607421875\n",
      "Batch 66: loss = 0.7096605896949768, acc = 0.7626953125\n",
      "Batch 67: loss = 0.6599318385124207, acc = 0.7822265625\n",
      "Batch 68: loss = 0.7200102806091309, acc = 0.76953125\n",
      "Batch 69: loss = 0.616730272769928, acc = 0.7998046875\n",
      "Batch 70: loss = 0.7468966245651245, acc = 0.755859375\n",
      "Batch 71: loss = 0.7390098571777344, acc = 0.759765625\n",
      "Batch 72: loss = 0.6374548077583313, acc = 0.79296875\n",
      "Batch 73: loss = 0.7273575067520142, acc = 0.76171875\n",
      "Batch 74: loss = 0.7624828815460205, acc = 0.75\n",
      "Batch 75: loss = 0.8223444819450378, acc = 0.7197265625\n",
      "Batch 76: loss = 0.7426431775093079, acc = 0.7568359375\n",
      "Batch 77: loss = 0.6812459230422974, acc = 0.767578125\n",
      "Batch 78: loss = 0.6874011754989624, acc = 0.779296875\n",
      "Batch 79: loss = 0.5948868989944458, acc = 0.802734375\n",
      "Batch 80: loss = 0.6398775577545166, acc = 0.779296875\n",
      "Batch 81: loss = 0.690085768699646, acc = 0.765625\n",
      "Batch 82: loss = 0.597046971321106, acc = 0.8037109375\n",
      "Batch 83: loss = 0.684190034866333, acc = 0.775390625\n",
      "Batch 84: loss = 0.6792038679122925, acc = 0.775390625\n",
      "Batch 85: loss = 0.737006425857544, acc = 0.7490234375\n",
      "Batch 86: loss = 0.709220290184021, acc = 0.765625\n",
      "Batch 87: loss = 0.6509236097335815, acc = 0.7958984375\n",
      "Batch 88: loss = 0.8301560282707214, acc = 0.73828125\n",
      "Batch 89: loss = 0.6853996515274048, acc = 0.7861328125\n",
      "Batch 90: loss = 0.7289240956306458, acc = 0.76171875\n",
      "Batch 91: loss = 0.7048757076263428, acc = 0.7626953125\n",
      "Batch 92: loss = 0.7362804412841797, acc = 0.7666015625\n",
      "Batch 93: loss = 0.6117785573005676, acc = 0.791015625\n",
      "Batch 94: loss = 0.6275098919868469, acc = 0.8037109375\n",
      "Batch 95: loss = 0.6453025937080383, acc = 0.7841796875\n",
      "Batch 96: loss = 0.7411699891090393, acc = 0.7548828125\n",
      "Batch 97: loss = 0.6885233521461487, acc = 0.77734375\n",
      "Batch 98: loss = 0.6837875843048096, acc = 0.7861328125\n",
      "Batch 99: loss = 0.6831190586090088, acc = 0.771484375\n",
      "Batch 100: loss = 0.7108055949211121, acc = 0.7724609375\n",
      "Batch 101: loss = 0.6952450275421143, acc = 0.7822265625\n",
      "Batch 102: loss = 0.7445451021194458, acc = 0.751953125\n",
      "Batch 103: loss = 0.6794756650924683, acc = 0.7744140625\n",
      "Batch 104: loss = 0.6676559448242188, acc = 0.7783203125\n",
      "Batch 105: loss = 0.6624170541763306, acc = 0.7685546875\n",
      "Batch 106: loss = 0.694746732711792, acc = 0.7744140625\n",
      "Batch 107: loss = 0.6209228038787842, acc = 0.8056640625\n",
      "Batch 108: loss = 0.6665792465209961, acc = 0.77734375\n",
      "Batch 109: loss = 0.6456031799316406, acc = 0.783203125\n",
      "Batch 110: loss = 0.6343846321105957, acc = 0.8017578125\n",
      "Batch 111: loss = 0.7453917264938354, acc = 0.755859375\n",
      "Batch 112: loss = 0.6838623881340027, acc = 0.7705078125\n",
      "Batch 113: loss = 0.6889662146568298, acc = 0.7646484375\n",
      "Batch 114: loss = 0.6968204975128174, acc = 0.77734375\n",
      "Batch 115: loss = 0.7667692303657532, acc = 0.75390625\n",
      "Batch 116: loss = 0.7774379253387451, acc = 0.7548828125\n",
      "Batch 117: loss = 0.6519920825958252, acc = 0.7919921875\n",
      "Batch 118: loss = 0.5880881547927856, acc = 0.8017578125\n",
      "Batch 119: loss = 0.6568615436553955, acc = 0.7900390625\n",
      "Batch 120: loss = 0.6923165321350098, acc = 0.7724609375\n",
      "Batch 121: loss = 0.6735008955001831, acc = 0.7890625\n",
      "Batch 122: loss = 0.6340782046318054, acc = 0.7958984375\n",
      "Batch 123: loss = 0.7032199501991272, acc = 0.7744140625\n",
      "Batch 124: loss = 0.724994421005249, acc = 0.74609375\n",
      "Batch 125: loss = 0.7341995239257812, acc = 0.7587890625\n",
      "Batch 126: loss = 0.710023045539856, acc = 0.7734375\n",
      "\n",
      "Epoch 30/100\n",
      "Batch 1: loss = 0.8976413607597351, acc = 0.73828125\n",
      "Batch 2: loss = 0.7873803377151489, acc = 0.75\n",
      "Batch 3: loss = 0.7002543210983276, acc = 0.7763671875\n",
      "Batch 4: loss = 0.6960557699203491, acc = 0.7705078125\n",
      "Batch 5: loss = 0.7638688087463379, acc = 0.7490234375\n",
      "Batch 6: loss = 0.7607465982437134, acc = 0.7548828125\n",
      "Batch 7: loss = 0.6786414384841919, acc = 0.7900390625\n",
      "Batch 8: loss = 0.69843590259552, acc = 0.78515625\n",
      "Batch 9: loss = 0.6470547914505005, acc = 0.794921875\n",
      "Batch 10: loss = 0.616539716720581, acc = 0.8046875\n",
      "Batch 11: loss = 0.6941996812820435, acc = 0.78515625\n",
      "Batch 12: loss = 0.6892207860946655, acc = 0.765625\n",
      "Batch 13: loss = 0.6517851948738098, acc = 0.79296875\n",
      "Batch 14: loss = 0.6710514426231384, acc = 0.7822265625\n",
      "Batch 15: loss = 0.623176634311676, acc = 0.8017578125\n",
      "Batch 16: loss = 0.6922318935394287, acc = 0.7822265625\n",
      "Batch 17: loss = 0.6751627922058105, acc = 0.7841796875\n",
      "Batch 18: loss = 0.7067801356315613, acc = 0.7568359375\n",
      "Batch 19: loss = 0.6803897619247437, acc = 0.791015625\n",
      "Batch 20: loss = 0.6747888922691345, acc = 0.77734375\n",
      "Batch 21: loss = 0.7657490372657776, acc = 0.732421875\n",
      "Batch 22: loss = 0.6806274652481079, acc = 0.779296875\n",
      "Batch 23: loss = 0.657120943069458, acc = 0.7783203125\n",
      "Batch 24: loss = 0.6356658935546875, acc = 0.7998046875\n",
      "Batch 25: loss = 0.6403040885925293, acc = 0.7822265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 26: loss = 0.6610913276672363, acc = 0.783203125\n",
      "Batch 27: loss = 0.7642342448234558, acc = 0.76171875\n",
      "Batch 28: loss = 0.7173289060592651, acc = 0.763671875\n",
      "Batch 29: loss = 0.6905892491340637, acc = 0.7841796875\n",
      "Batch 30: loss = 0.6403251886367798, acc = 0.779296875\n",
      "Batch 31: loss = 0.7542694807052612, acc = 0.7548828125\n",
      "Batch 32: loss = 0.7946558594703674, acc = 0.7412109375\n",
      "Batch 33: loss = 0.6733121275901794, acc = 0.7724609375\n",
      "Batch 34: loss = 0.6787834763526917, acc = 0.7763671875\n",
      "Batch 35: loss = 0.6752132177352905, acc = 0.78515625\n",
      "Batch 36: loss = 0.6852862238883972, acc = 0.7744140625\n",
      "Batch 37: loss = 0.6698055267333984, acc = 0.775390625\n",
      "Batch 38: loss = 0.715901255607605, acc = 0.763671875\n",
      "Batch 39: loss = 0.6845817565917969, acc = 0.77734375\n",
      "Batch 40: loss = 0.6866649389266968, acc = 0.767578125\n",
      "Batch 41: loss = 0.6160828471183777, acc = 0.7939453125\n",
      "Batch 42: loss = 0.6270928382873535, acc = 0.7763671875\n",
      "Batch 43: loss = 0.6995023488998413, acc = 0.765625\n",
      "Batch 44: loss = 0.6236696243286133, acc = 0.802734375\n",
      "Batch 45: loss = 0.5916196703910828, acc = 0.8095703125\n",
      "Batch 46: loss = 0.6339198350906372, acc = 0.798828125\n",
      "Batch 47: loss = 0.6616742610931396, acc = 0.7939453125\n",
      "Batch 48: loss = 0.6294029951095581, acc = 0.78125\n",
      "Batch 49: loss = 0.5752130746841431, acc = 0.8134765625\n",
      "Batch 50: loss = 0.6329879760742188, acc = 0.78515625\n",
      "Batch 51: loss = 0.6435905694961548, acc = 0.783203125\n",
      "Batch 52: loss = 0.7072675228118896, acc = 0.76953125\n",
      "Batch 53: loss = 0.6991249322891235, acc = 0.7626953125\n",
      "Batch 54: loss = 0.5956853032112122, acc = 0.8037109375\n",
      "Batch 55: loss = 0.5694831013679504, acc = 0.8037109375\n",
      "Batch 56: loss = 0.6660784482955933, acc = 0.7666015625\n",
      "Batch 57: loss = 0.71849125623703, acc = 0.7607421875\n",
      "Batch 58: loss = 0.7195085287094116, acc = 0.7509765625\n",
      "Batch 59: loss = 0.5435254573822021, acc = 0.81640625\n",
      "Batch 60: loss = 0.6856154799461365, acc = 0.7724609375\n",
      "Batch 61: loss = 0.6515945792198181, acc = 0.775390625\n",
      "Batch 62: loss = 0.8026831150054932, acc = 0.736328125\n",
      "Batch 63: loss = 0.7518556714057922, acc = 0.7666015625\n",
      "Batch 64: loss = 0.6046562790870667, acc = 0.802734375\n",
      "Batch 65: loss = 0.6839010715484619, acc = 0.7685546875\n",
      "Batch 66: loss = 0.6683796644210815, acc = 0.78125\n",
      "Batch 67: loss = 0.6198417544364929, acc = 0.787109375\n",
      "Batch 68: loss = 0.6894456148147583, acc = 0.787109375\n",
      "Batch 69: loss = 0.6045612096786499, acc = 0.802734375\n",
      "Batch 70: loss = 0.708489179611206, acc = 0.76953125\n",
      "Batch 71: loss = 0.6969927549362183, acc = 0.7685546875\n",
      "Batch 72: loss = 0.6168689727783203, acc = 0.8037109375\n",
      "Batch 73: loss = 0.7135167717933655, acc = 0.771484375\n",
      "Batch 74: loss = 0.7059396505355835, acc = 0.763671875\n",
      "Batch 75: loss = 0.7875577807426453, acc = 0.7490234375\n",
      "Batch 76: loss = 0.7131667137145996, acc = 0.7666015625\n",
      "Batch 77: loss = 0.6728228330612183, acc = 0.78125\n",
      "Batch 78: loss = 0.6525466442108154, acc = 0.7919921875\n",
      "Batch 79: loss = 0.576332688331604, acc = 0.8095703125\n",
      "Batch 80: loss = 0.5874289870262146, acc = 0.798828125\n",
      "Batch 81: loss = 0.6524646282196045, acc = 0.7822265625\n",
      "Batch 82: loss = 0.5990630388259888, acc = 0.8115234375\n",
      "Batch 83: loss = 0.6339960694313049, acc = 0.7919921875\n",
      "Batch 84: loss = 0.6278068423271179, acc = 0.7998046875\n",
      "Batch 85: loss = 0.7255187630653381, acc = 0.759765625\n",
      "Batch 86: loss = 0.6783772110939026, acc = 0.765625\n",
      "Batch 87: loss = 0.6560857892036438, acc = 0.7783203125\n",
      "Batch 88: loss = 0.7767931818962097, acc = 0.728515625\n",
      "Batch 89: loss = 0.652667760848999, acc = 0.7880859375\n",
      "Batch 90: loss = 0.6972259283065796, acc = 0.767578125\n",
      "Batch 91: loss = 0.7143405079841614, acc = 0.7548828125\n",
      "Batch 92: loss = 0.6833807826042175, acc = 0.771484375\n",
      "Batch 93: loss = 0.5727126598358154, acc = 0.8203125\n",
      "Batch 94: loss = 0.6036202907562256, acc = 0.802734375\n",
      "Batch 95: loss = 0.6190866231918335, acc = 0.78515625\n",
      "Batch 96: loss = 0.7128764390945435, acc = 0.763671875\n",
      "Batch 97: loss = 0.6612148284912109, acc = 0.79296875\n",
      "Batch 98: loss = 0.6809486150741577, acc = 0.7734375\n",
      "Batch 99: loss = 0.6829516291618347, acc = 0.77734375\n",
      "Batch 100: loss = 0.6652355790138245, acc = 0.7783203125\n",
      "Batch 101: loss = 0.6702735424041748, acc = 0.779296875\n",
      "Batch 102: loss = 0.7200394868850708, acc = 0.779296875\n",
      "Batch 103: loss = 0.7071295380592346, acc = 0.763671875\n",
      "Batch 104: loss = 0.6158444285392761, acc = 0.7880859375\n",
      "Batch 105: loss = 0.6310893297195435, acc = 0.7939453125\n",
      "Batch 106: loss = 0.6806083917617798, acc = 0.7734375\n",
      "Batch 107: loss = 0.6317555904388428, acc = 0.806640625\n",
      "Batch 108: loss = 0.6440379619598389, acc = 0.77734375\n",
      "Batch 109: loss = 0.6651865243911743, acc = 0.7734375\n",
      "Batch 110: loss = 0.6278476715087891, acc = 0.794921875\n",
      "Batch 111: loss = 0.7044569849967957, acc = 0.7763671875\n",
      "Batch 112: loss = 0.645034909248352, acc = 0.7841796875\n",
      "Batch 113: loss = 0.6926852464675903, acc = 0.7568359375\n",
      "Batch 114: loss = 0.7020466327667236, acc = 0.76953125\n",
      "Batch 115: loss = 0.7200105786323547, acc = 0.7578125\n",
      "Batch 116: loss = 0.7163311839103699, acc = 0.7734375\n",
      "Batch 117: loss = 0.6559838056564331, acc = 0.7783203125\n",
      "Batch 118: loss = 0.5602263808250427, acc = 0.8115234375\n",
      "Batch 119: loss = 0.6440707445144653, acc = 0.7900390625\n",
      "Batch 120: loss = 0.6399179697036743, acc = 0.7802734375\n",
      "Batch 121: loss = 0.6619375944137573, acc = 0.7626953125\n",
      "Batch 122: loss = 0.6327612400054932, acc = 0.796875\n",
      "Batch 123: loss = 0.6854866743087769, acc = 0.783203125\n",
      "Batch 124: loss = 0.7072204351425171, acc = 0.75\n",
      "Batch 125: loss = 0.7136710286140442, acc = 0.7587890625\n",
      "Batch 126: loss = 0.7189732789993286, acc = 0.7783203125\n",
      "Saved checkpoint to weights.30.h5\n",
      "\n",
      "Epoch 31/100\n",
      "Batch 1: loss = 0.8700391054153442, acc = 0.7490234375\n",
      "Batch 2: loss = 0.8025770783424377, acc = 0.7470703125\n",
      "Batch 3: loss = 0.7153655290603638, acc = 0.7802734375\n",
      "Batch 4: loss = 0.6377649307250977, acc = 0.80078125\n",
      "Batch 5: loss = 0.7235358357429504, acc = 0.76171875\n",
      "Batch 6: loss = 0.7194473743438721, acc = 0.7587890625\n",
      "Batch 7: loss = 0.6943190693855286, acc = 0.7841796875\n",
      "Batch 8: loss = 0.6476061344146729, acc = 0.7978515625\n",
      "Batch 9: loss = 0.6286023259162903, acc = 0.8056640625\n",
      "Batch 10: loss = 0.5925447344779968, acc = 0.8046875\n",
      "Batch 11: loss = 0.7094981670379639, acc = 0.7744140625\n",
      "Batch 12: loss = 0.6805515289306641, acc = 0.76171875\n",
      "Batch 13: loss = 0.6438153982162476, acc = 0.7958984375\n",
      "Batch 14: loss = 0.6636914014816284, acc = 0.783203125\n",
      "Batch 15: loss = 0.6352390050888062, acc = 0.798828125\n",
      "Batch 16: loss = 0.687109112739563, acc = 0.7880859375\n",
      "Batch 17: loss = 0.656427800655365, acc = 0.7900390625\n",
      "Batch 18: loss = 0.6655547618865967, acc = 0.77734375\n",
      "Batch 19: loss = 0.6478594541549683, acc = 0.7939453125\n",
      "Batch 20: loss = 0.6642401218414307, acc = 0.7734375\n",
      "Batch 21: loss = 0.7221620678901672, acc = 0.7509765625\n",
      "Batch 22: loss = 0.6573852896690369, acc = 0.77734375\n",
      "Batch 23: loss = 0.6647476553916931, acc = 0.779296875\n",
      "Batch 24: loss = 0.6512069702148438, acc = 0.7890625\n",
      "Batch 25: loss = 0.628322958946228, acc = 0.79296875\n",
      "Batch 26: loss = 0.6138852834701538, acc = 0.796875\n",
      "Batch 27: loss = 0.7627873420715332, acc = 0.755859375\n",
      "Batch 28: loss = 0.7079919576644897, acc = 0.76171875\n",
      "Batch 29: loss = 0.6857993602752686, acc = 0.7734375\n",
      "Batch 30: loss = 0.6361851096153259, acc = 0.7861328125\n",
      "Batch 31: loss = 0.7329592704772949, acc = 0.7626953125\n",
      "Batch 32: loss = 0.7848733067512512, acc = 0.736328125\n",
      "Batch 33: loss = 0.5988138914108276, acc = 0.8037109375\n",
      "Batch 34: loss = 0.701120138168335, acc = 0.759765625\n",
      "Batch 35: loss = 0.6442320346832275, acc = 0.78515625\n",
      "Batch 36: loss = 0.6322216987609863, acc = 0.79296875\n",
      "Batch 37: loss = 0.6239391565322876, acc = 0.806640625\n",
      "Batch 38: loss = 0.6915764212608337, acc = 0.7744140625\n",
      "Batch 39: loss = 0.6574615240097046, acc = 0.7783203125\n",
      "Batch 40: loss = 0.6561970710754395, acc = 0.79296875\n",
      "Batch 41: loss = 0.578579843044281, acc = 0.8076171875\n",
      "Batch 42: loss = 0.6526697278022766, acc = 0.7822265625\n",
      "Batch 43: loss = 0.6803003549575806, acc = 0.7734375\n",
      "Batch 44: loss = 0.6149875521659851, acc = 0.7919921875\n",
      "Batch 45: loss = 0.6047120094299316, acc = 0.8056640625\n",
      "Batch 46: loss = 0.5904420614242554, acc = 0.7978515625\n",
      "Batch 47: loss = 0.6349265575408936, acc = 0.7939453125\n",
      "Batch 48: loss = 0.6111282110214233, acc = 0.7890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 49: loss = 0.5699137449264526, acc = 0.81640625\n",
      "Batch 50: loss = 0.5785132050514221, acc = 0.8173828125\n",
      "Batch 51: loss = 0.5990007519721985, acc = 0.7978515625\n",
      "Batch 52: loss = 0.6401088237762451, acc = 0.7724609375\n",
      "Batch 53: loss = 0.6574352383613586, acc = 0.7841796875\n",
      "Batch 54: loss = 0.5796362161636353, acc = 0.8037109375\n",
      "Batch 55: loss = 0.5591510534286499, acc = 0.8173828125\n",
      "Batch 56: loss = 0.6558358669281006, acc = 0.779296875\n",
      "Batch 57: loss = 0.6765644550323486, acc = 0.7744140625\n",
      "Batch 58: loss = 0.7065279483795166, acc = 0.765625\n",
      "Batch 59: loss = 0.5461279153823853, acc = 0.833984375\n",
      "Batch 60: loss = 0.6603474617004395, acc = 0.783203125\n",
      "Batch 61: loss = 0.6394188404083252, acc = 0.7861328125\n",
      "Batch 62: loss = 0.7598073482513428, acc = 0.75\n",
      "Batch 63: loss = 0.6984507441520691, acc = 0.7861328125\n",
      "Batch 64: loss = 0.5858629941940308, acc = 0.80859375\n",
      "Batch 65: loss = 0.7079464197158813, acc = 0.7646484375\n",
      "Batch 66: loss = 0.6637468338012695, acc = 0.78125\n",
      "Batch 67: loss = 0.5986003875732422, acc = 0.794921875\n",
      "Batch 68: loss = 0.6640685200691223, acc = 0.79296875\n",
      "Batch 69: loss = 0.5519940257072449, acc = 0.826171875\n",
      "Batch 70: loss = 0.7051299810409546, acc = 0.765625\n",
      "Batch 71: loss = 0.6514471173286438, acc = 0.79296875\n",
      "Batch 72: loss = 0.6041730046272278, acc = 0.8037109375\n",
      "Batch 73: loss = 0.6803045272827148, acc = 0.7705078125\n",
      "Batch 74: loss = 0.6864761710166931, acc = 0.7783203125\n",
      "Batch 75: loss = 0.754711389541626, acc = 0.73828125\n",
      "Batch 76: loss = 0.6622488498687744, acc = 0.7822265625\n",
      "Batch 77: loss = 0.6336190700531006, acc = 0.8017578125\n",
      "Batch 78: loss = 0.6456784605979919, acc = 0.7900390625\n",
      "Batch 79: loss = 0.5581610202789307, acc = 0.814453125\n",
      "Batch 80: loss = 0.606537938117981, acc = 0.783203125\n",
      "Batch 81: loss = 0.6622960567474365, acc = 0.7841796875\n",
      "Batch 82: loss = 0.5900634527206421, acc = 0.8173828125\n",
      "Batch 83: loss = 0.6486421823501587, acc = 0.7802734375\n",
      "Batch 84: loss = 0.5961382389068604, acc = 0.787109375\n",
      "Batch 85: loss = 0.6965481042861938, acc = 0.767578125\n",
      "Batch 86: loss = 0.6775698661804199, acc = 0.7763671875\n",
      "Batch 87: loss = 0.6294584274291992, acc = 0.78515625\n",
      "Batch 88: loss = 0.753856897354126, acc = 0.75390625\n",
      "Batch 89: loss = 0.6545405387878418, acc = 0.7861328125\n",
      "Batch 90: loss = 0.687785267829895, acc = 0.767578125\n",
      "Batch 91: loss = 0.7014880180358887, acc = 0.763671875\n",
      "Batch 92: loss = 0.6723204255104065, acc = 0.783203125\n",
      "Batch 93: loss = 0.5618033409118652, acc = 0.822265625\n",
      "Batch 94: loss = 0.5748080015182495, acc = 0.8232421875\n",
      "Batch 95: loss = 0.6021742224693298, acc = 0.7958984375\n",
      "Batch 96: loss = 0.7108270525932312, acc = 0.7646484375\n",
      "Batch 97: loss = 0.6295924782752991, acc = 0.8017578125\n",
      "Batch 98: loss = 0.6589299440383911, acc = 0.7861328125\n",
      "Batch 99: loss = 0.6189556121826172, acc = 0.7880859375\n",
      "Batch 100: loss = 0.6524060964584351, acc = 0.765625\n",
      "Batch 101: loss = 0.6208836436271667, acc = 0.783203125\n",
      "Batch 102: loss = 0.6878371238708496, acc = 0.7646484375\n",
      "Batch 103: loss = 0.636644721031189, acc = 0.78515625\n",
      "Batch 104: loss = 0.5813016891479492, acc = 0.8125\n",
      "Batch 105: loss = 0.6084181070327759, acc = 0.798828125\n",
      "Batch 106: loss = 0.6597938537597656, acc = 0.779296875\n",
      "Batch 107: loss = 0.6079410314559937, acc = 0.794921875\n",
      "Batch 108: loss = 0.642227828502655, acc = 0.7861328125\n",
      "Batch 109: loss = 0.6265723705291748, acc = 0.798828125\n",
      "Batch 110: loss = 0.6123385429382324, acc = 0.8115234375\n",
      "Batch 111: loss = 0.6949903964996338, acc = 0.76953125\n",
      "Batch 112: loss = 0.6346701383590698, acc = 0.783203125\n",
      "Batch 113: loss = 0.6392735242843628, acc = 0.7861328125\n",
      "Batch 114: loss = 0.6795073747634888, acc = 0.7890625\n",
      "Batch 115: loss = 0.6743515729904175, acc = 0.7822265625\n",
      "Batch 116: loss = 0.6921222805976868, acc = 0.77734375\n",
      "Batch 117: loss = 0.6263110637664795, acc = 0.7900390625\n",
      "Batch 118: loss = 0.5623550415039062, acc = 0.818359375\n",
      "Batch 119: loss = 0.6442884802818298, acc = 0.7890625\n",
      "Batch 120: loss = 0.6111830472946167, acc = 0.7890625\n",
      "Batch 121: loss = 0.6313198804855347, acc = 0.791015625\n",
      "Batch 122: loss = 0.6056488752365112, acc = 0.7978515625\n",
      "Batch 123: loss = 0.6665520071983337, acc = 0.783203125\n",
      "Batch 124: loss = 0.6728658676147461, acc = 0.765625\n",
      "Batch 125: loss = 0.7141324281692505, acc = 0.7626953125\n",
      "Batch 126: loss = 0.686111330986023, acc = 0.79296875\n",
      "\n",
      "Epoch 32/100\n",
      "Batch 1: loss = 0.8249945640563965, acc = 0.7548828125\n",
      "Batch 2: loss = 0.7506840229034424, acc = 0.775390625\n",
      "Batch 3: loss = 0.6689754724502563, acc = 0.791015625\n",
      "Batch 4: loss = 0.6227551698684692, acc = 0.8017578125\n",
      "Batch 5: loss = 0.7253040075302124, acc = 0.767578125\n",
      "Batch 6: loss = 0.6966713666915894, acc = 0.7724609375\n",
      "Batch 7: loss = 0.6684712171554565, acc = 0.7880859375\n",
      "Batch 8: loss = 0.6727096438407898, acc = 0.7841796875\n",
      "Batch 9: loss = 0.5776371955871582, acc = 0.814453125\n",
      "Batch 10: loss = 0.5772820711135864, acc = 0.8076171875\n",
      "Batch 11: loss = 0.681795597076416, acc = 0.783203125\n",
      "Batch 12: loss = 0.6610015034675598, acc = 0.779296875\n",
      "Batch 13: loss = 0.6116827130317688, acc = 0.8017578125\n",
      "Batch 14: loss = 0.6728494763374329, acc = 0.791015625\n",
      "Batch 15: loss = 0.632805585861206, acc = 0.810546875\n",
      "Batch 16: loss = 0.6835058331489563, acc = 0.7685546875\n",
      "Batch 17: loss = 0.651877760887146, acc = 0.78125\n",
      "Batch 18: loss = 0.7064037322998047, acc = 0.7734375\n",
      "Batch 19: loss = 0.6366847157478333, acc = 0.798828125\n",
      "Batch 20: loss = 0.6506072878837585, acc = 0.7783203125\n",
      "Batch 21: loss = 0.713119387626648, acc = 0.771484375\n",
      "Batch 22: loss = 0.6592497825622559, acc = 0.7734375\n",
      "Batch 23: loss = 0.626362681388855, acc = 0.7763671875\n",
      "Batch 24: loss = 0.6187303066253662, acc = 0.7978515625\n",
      "Batch 25: loss = 0.588201642036438, acc = 0.80859375\n",
      "Batch 26: loss = 0.635061502456665, acc = 0.779296875\n",
      "Batch 27: loss = 0.7221578359603882, acc = 0.75390625\n",
      "Batch 28: loss = 0.6934638023376465, acc = 0.7734375\n",
      "Batch 29: loss = 0.6435765027999878, acc = 0.7890625\n",
      "Batch 30: loss = 0.6274747252464294, acc = 0.7939453125\n",
      "Batch 31: loss = 0.7246842384338379, acc = 0.7763671875\n",
      "Batch 32: loss = 0.7630331516265869, acc = 0.7548828125\n",
      "Batch 33: loss = 0.6157106161117554, acc = 0.79296875\n",
      "Batch 34: loss = 0.6663836240768433, acc = 0.775390625\n",
      "Batch 35: loss = 0.6316933631896973, acc = 0.7978515625\n",
      "Batch 36: loss = 0.6395262479782104, acc = 0.7861328125\n",
      "Batch 37: loss = 0.6427072286605835, acc = 0.798828125\n",
      "Batch 38: loss = 0.679908037185669, acc = 0.76953125\n",
      "Batch 39: loss = 0.6216168403625488, acc = 0.8134765625\n",
      "Batch 40: loss = 0.6574259996414185, acc = 0.794921875\n",
      "Batch 41: loss = 0.5519298315048218, acc = 0.818359375\n",
      "Batch 42: loss = 0.6327400207519531, acc = 0.7919921875\n",
      "Batch 43: loss = 0.6772329807281494, acc = 0.7724609375\n",
      "Batch 44: loss = 0.5925148129463196, acc = 0.8193359375\n",
      "Batch 45: loss = 0.540608823299408, acc = 0.826171875\n",
      "Batch 46: loss = 0.5992285013198853, acc = 0.8125\n",
      "Batch 47: loss = 0.6045132875442505, acc = 0.8056640625\n",
      "Batch 48: loss = 0.6187073588371277, acc = 0.791015625\n",
      "Batch 49: loss = 0.5418516397476196, acc = 0.8232421875\n",
      "Batch 50: loss = 0.6033085584640503, acc = 0.8115234375\n",
      "Batch 51: loss = 0.5805919170379639, acc = 0.8046875\n",
      "Batch 52: loss = 0.6301289200782776, acc = 0.7822265625\n",
      "Batch 53: loss = 0.6393011212348938, acc = 0.779296875\n",
      "Batch 54: loss = 0.5778234004974365, acc = 0.8056640625\n",
      "Batch 55: loss = 0.5507068634033203, acc = 0.8251953125\n",
      "Batch 56: loss = 0.6191471219062805, acc = 0.79296875\n",
      "Batch 57: loss = 0.6597415208816528, acc = 0.771484375\n",
      "Batch 58: loss = 0.7096549272537231, acc = 0.7666015625\n",
      "Batch 59: loss = 0.5163341164588928, acc = 0.828125\n",
      "Batch 60: loss = 0.6345514059066772, acc = 0.79296875\n",
      "Batch 61: loss = 0.5963634252548218, acc = 0.8115234375\n",
      "Batch 62: loss = 0.7508708238601685, acc = 0.75\n",
      "Batch 63: loss = 0.6844879388809204, acc = 0.78515625\n",
      "Batch 64: loss = 0.5638130903244019, acc = 0.8232421875\n",
      "Batch 65: loss = 0.6287630200386047, acc = 0.7890625\n",
      "Batch 66: loss = 0.6342195868492126, acc = 0.791015625\n",
      "Batch 67: loss = 0.6019347310066223, acc = 0.7861328125\n",
      "Batch 68: loss = 0.6421022415161133, acc = 0.787109375\n",
      "Batch 69: loss = 0.5377843379974365, acc = 0.8125\n",
      "Batch 70: loss = 0.6724182367324829, acc = 0.7880859375\n",
      "Batch 71: loss = 0.6440654397010803, acc = 0.7763671875\n",
      "Batch 72: loss = 0.592205286026001, acc = 0.802734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 73: loss = 0.6631832122802734, acc = 0.7861328125\n",
      "Batch 74: loss = 0.6700371503829956, acc = 0.765625\n",
      "Batch 75: loss = 0.7346698641777039, acc = 0.736328125\n",
      "Batch 76: loss = 0.6794911026954651, acc = 0.7763671875\n",
      "Batch 77: loss = 0.6419118046760559, acc = 0.79296875\n",
      "Batch 78: loss = 0.6433366537094116, acc = 0.7998046875\n",
      "Batch 79: loss = 0.5538613796234131, acc = 0.8076171875\n",
      "Batch 80: loss = 0.5956292748451233, acc = 0.798828125\n",
      "Batch 81: loss = 0.6303695440292358, acc = 0.798828125\n",
      "Batch 82: loss = 0.5867612361907959, acc = 0.8076171875\n",
      "Batch 83: loss = 0.6011879444122314, acc = 0.8134765625\n",
      "Batch 84: loss = 0.604566216468811, acc = 0.7880859375\n",
      "Batch 85: loss = 0.6953039765357971, acc = 0.7626953125\n",
      "Batch 86: loss = 0.6563153266906738, acc = 0.791015625\n",
      "Batch 87: loss = 0.6236829161643982, acc = 0.80859375\n",
      "Batch 88: loss = 0.7506226897239685, acc = 0.763671875\n",
      "Batch 89: loss = 0.6399080753326416, acc = 0.796875\n",
      "Batch 90: loss = 0.6740506291389465, acc = 0.7734375\n",
      "Batch 91: loss = 0.6634858846664429, acc = 0.787109375\n",
      "Batch 92: loss = 0.6662421226501465, acc = 0.787109375\n",
      "Batch 93: loss = 0.5618237257003784, acc = 0.8056640625\n",
      "Batch 94: loss = 0.5614942312240601, acc = 0.8115234375\n",
      "Batch 95: loss = 0.5932670831680298, acc = 0.806640625\n",
      "Batch 96: loss = 0.6969759464263916, acc = 0.7666015625\n",
      "Batch 97: loss = 0.6352840065956116, acc = 0.7998046875\n",
      "Batch 98: loss = 0.6485750675201416, acc = 0.7890625\n",
      "Batch 99: loss = 0.6206940412521362, acc = 0.8125\n",
      "Batch 100: loss = 0.6720292568206787, acc = 0.763671875\n",
      "Batch 101: loss = 0.6077021360397339, acc = 0.791015625\n",
      "Batch 102: loss = 0.6650010347366333, acc = 0.78125\n",
      "Batch 103: loss = 0.6433018445968628, acc = 0.7919921875\n",
      "Batch 104: loss = 0.5599654912948608, acc = 0.814453125\n",
      "Batch 105: loss = 0.5859206914901733, acc = 0.8046875\n",
      "Batch 106: loss = 0.6291571855545044, acc = 0.79296875\n",
      "Batch 107: loss = 0.5805137157440186, acc = 0.8037109375\n",
      "Batch 108: loss = 0.6208900809288025, acc = 0.79296875\n",
      "Batch 109: loss = 0.5987305641174316, acc = 0.8046875\n",
      "Batch 110: loss = 0.5638001561164856, acc = 0.8125\n",
      "Batch 111: loss = 0.6829127073287964, acc = 0.783203125\n",
      "Batch 112: loss = 0.6082239747047424, acc = 0.798828125\n",
      "Batch 113: loss = 0.6459041833877563, acc = 0.7841796875\n",
      "Batch 114: loss = 0.6429491639137268, acc = 0.8037109375\n",
      "Batch 115: loss = 0.6623679399490356, acc = 0.7880859375\n",
      "Batch 116: loss = 0.6966027617454529, acc = 0.7763671875\n",
      "Batch 117: loss = 0.5884389877319336, acc = 0.8037109375\n",
      "Batch 118: loss = 0.5297624468803406, acc = 0.8271484375\n",
      "Batch 119: loss = 0.6281654834747314, acc = 0.7822265625\n",
      "Batch 120: loss = 0.6159335970878601, acc = 0.802734375\n",
      "Batch 121: loss = 0.643783450126648, acc = 0.7880859375\n",
      "Batch 122: loss = 0.5928478240966797, acc = 0.8046875\n",
      "Batch 123: loss = 0.6349986791610718, acc = 0.806640625\n",
      "Batch 124: loss = 0.6793479919433594, acc = 0.7763671875\n",
      "Batch 125: loss = 0.7054271697998047, acc = 0.7607421875\n",
      "Batch 126: loss = 0.6630301475524902, acc = 0.7919921875\n",
      "\n",
      "Epoch 33/100\n",
      "Batch 1: loss = 0.8485046625137329, acc = 0.7529296875\n",
      "Batch 2: loss = 0.7298848628997803, acc = 0.783203125\n",
      "Batch 3: loss = 0.6626349091529846, acc = 0.7919921875\n",
      "Batch 4: loss = 0.6292624473571777, acc = 0.802734375\n",
      "Batch 5: loss = 0.7302557826042175, acc = 0.775390625\n",
      "Batch 6: loss = 0.6888874173164368, acc = 0.7724609375\n",
      "Batch 7: loss = 0.6508818864822388, acc = 0.796875\n",
      "Batch 8: loss = 0.6415631771087646, acc = 0.7998046875\n",
      "Batch 9: loss = 0.5988028049468994, acc = 0.81640625\n",
      "Batch 10: loss = 0.5330579876899719, acc = 0.8310546875\n",
      "Batch 11: loss = 0.6411020159721375, acc = 0.7880859375\n",
      "Batch 12: loss = 0.6426940560340881, acc = 0.7783203125\n",
      "Batch 13: loss = 0.5853809118270874, acc = 0.8125\n",
      "Batch 14: loss = 0.653640627861023, acc = 0.7978515625\n",
      "Batch 15: loss = 0.5985287427902222, acc = 0.8017578125\n",
      "Batch 16: loss = 0.6851363778114319, acc = 0.765625\n",
      "Batch 17: loss = 0.6447609066963196, acc = 0.7802734375\n",
      "Batch 18: loss = 0.6722875833511353, acc = 0.7734375\n",
      "Batch 19: loss = 0.6500722169876099, acc = 0.791015625\n",
      "Batch 20: loss = 0.6603024005889893, acc = 0.7783203125\n",
      "Batch 21: loss = 0.7105056643486023, acc = 0.765625\n",
      "Batch 22: loss = 0.6187992691993713, acc = 0.7890625\n",
      "Batch 23: loss = 0.6246120929718018, acc = 0.7822265625\n",
      "Batch 24: loss = 0.6072379946708679, acc = 0.79296875\n",
      "Batch 25: loss = 0.6070053577423096, acc = 0.80859375\n",
      "Batch 26: loss = 0.6057316064834595, acc = 0.80859375\n",
      "Batch 27: loss = 0.700127363204956, acc = 0.7861328125\n",
      "Batch 28: loss = 0.6852937936782837, acc = 0.767578125\n",
      "Batch 29: loss = 0.6538969278335571, acc = 0.7861328125\n",
      "Batch 30: loss = 0.6180698871612549, acc = 0.80078125\n",
      "Batch 31: loss = 0.6948814392089844, acc = 0.7880859375\n",
      "Batch 32: loss = 0.7573584318161011, acc = 0.7548828125\n",
      "Batch 33: loss = 0.5905455350875854, acc = 0.8115234375\n",
      "Batch 34: loss = 0.6395727396011353, acc = 0.7900390625\n",
      "Batch 35: loss = 0.6170535087585449, acc = 0.802734375\n",
      "Batch 36: loss = 0.6113115549087524, acc = 0.8134765625\n",
      "Batch 37: loss = 0.6187257766723633, acc = 0.7998046875\n",
      "Batch 38: loss = 0.6429957747459412, acc = 0.787109375\n",
      "Batch 39: loss = 0.591211199760437, acc = 0.8046875\n",
      "Batch 40: loss = 0.6377689838409424, acc = 0.7880859375\n",
      "Batch 41: loss = 0.5536876320838928, acc = 0.8046875\n",
      "Batch 42: loss = 0.6250616312026978, acc = 0.7890625\n",
      "Batch 43: loss = 0.682360053062439, acc = 0.7666015625\n",
      "Batch 44: loss = 0.5557594895362854, acc = 0.8232421875\n",
      "Batch 45: loss = 0.5849432349205017, acc = 0.7919921875\n",
      "Batch 46: loss = 0.5563814640045166, acc = 0.8173828125\n",
      "Batch 47: loss = 0.582506537437439, acc = 0.8046875\n",
      "Batch 48: loss = 0.5961155295372009, acc = 0.80078125\n",
      "Batch 49: loss = 0.5213391780853271, acc = 0.833984375\n",
      "Batch 50: loss = 0.5911840200424194, acc = 0.8046875\n",
      "Batch 51: loss = 0.5561048984527588, acc = 0.8134765625\n",
      "Batch 52: loss = 0.6074788570404053, acc = 0.7978515625\n",
      "Batch 53: loss = 0.6441752314567566, acc = 0.7939453125\n",
      "Batch 54: loss = 0.5447738766670227, acc = 0.818359375\n",
      "Batch 55: loss = 0.5170891284942627, acc = 0.828125\n",
      "Batch 56: loss = 0.5833554267883301, acc = 0.79296875\n",
      "Batch 57: loss = 0.6526161432266235, acc = 0.7890625\n",
      "Batch 58: loss = 0.6611248254776001, acc = 0.7724609375\n",
      "Batch 59: loss = 0.5057618618011475, acc = 0.8310546875\n",
      "Batch 60: loss = 0.6487158536911011, acc = 0.775390625\n",
      "Batch 61: loss = 0.5884411931037903, acc = 0.8125\n",
      "Batch 62: loss = 0.7304449677467346, acc = 0.7509765625\n",
      "Batch 63: loss = 0.6495615243911743, acc = 0.7900390625\n",
      "Batch 64: loss = 0.5294967293739319, acc = 0.8310546875\n",
      "Batch 65: loss = 0.6468634605407715, acc = 0.7978515625\n",
      "Batch 66: loss = 0.5937296152114868, acc = 0.7958984375\n",
      "Batch 67: loss = 0.5947459936141968, acc = 0.79296875\n",
      "Batch 68: loss = 0.6313751935958862, acc = 0.791015625\n",
      "Batch 69: loss = 0.557889461517334, acc = 0.8125\n",
      "Batch 70: loss = 0.7100780606269836, acc = 0.763671875\n",
      "Batch 71: loss = 0.6388522386550903, acc = 0.787109375\n",
      "Batch 72: loss = 0.5899344086647034, acc = 0.81640625\n",
      "Batch 73: loss = 0.6627626419067383, acc = 0.7841796875\n",
      "Batch 74: loss = 0.6783196926116943, acc = 0.767578125\n",
      "Batch 75: loss = 0.726524829864502, acc = 0.7548828125\n",
      "Batch 76: loss = 0.6724709868431091, acc = 0.7841796875\n",
      "Batch 77: loss = 0.6179962158203125, acc = 0.810546875\n",
      "Batch 78: loss = 0.6163860559463501, acc = 0.798828125\n",
      "Batch 79: loss = 0.5474693775177002, acc = 0.8212890625\n",
      "Batch 80: loss = 0.5639432668685913, acc = 0.8017578125\n",
      "Batch 81: loss = 0.6228073835372925, acc = 0.7880859375\n",
      "Batch 82: loss = 0.5607020258903503, acc = 0.826171875\n",
      "Batch 83: loss = 0.6036242246627808, acc = 0.80078125\n",
      "Batch 84: loss = 0.5726467967033386, acc = 0.7958984375\n",
      "Batch 85: loss = 0.694341778755188, acc = 0.7626953125\n",
      "Batch 86: loss = 0.6397773027420044, acc = 0.7880859375\n",
      "Batch 87: loss = 0.6068440675735474, acc = 0.798828125\n",
      "Batch 88: loss = 0.7572090029716492, acc = 0.7548828125\n",
      "Batch 89: loss = 0.5883803367614746, acc = 0.8125\n",
      "Batch 90: loss = 0.6359888911247253, acc = 0.7783203125\n",
      "Batch 91: loss = 0.6667453646659851, acc = 0.779296875\n",
      "Batch 92: loss = 0.681448221206665, acc = 0.7734375\n",
      "Batch 93: loss = 0.5188422203063965, acc = 0.826171875\n",
      "Batch 94: loss = 0.5564442873001099, acc = 0.8125\n",
      "Batch 95: loss = 0.587239682674408, acc = 0.796875\n",
      "Batch 96: loss = 0.62732994556427, acc = 0.7998046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 97: loss = 0.6375037431716919, acc = 0.7900390625\n",
      "Batch 98: loss = 0.5961843132972717, acc = 0.8125\n",
      "Batch 99: loss = 0.6250982284545898, acc = 0.791015625\n",
      "Batch 100: loss = 0.6345332860946655, acc = 0.77734375\n",
      "Batch 101: loss = 0.5711435079574585, acc = 0.806640625\n",
      "Batch 102: loss = 0.6725306510925293, acc = 0.77734375\n",
      "Batch 103: loss = 0.6223150491714478, acc = 0.8037109375\n",
      "Batch 104: loss = 0.5761126279830933, acc = 0.806640625\n",
      "Batch 105: loss = 0.6116481423377991, acc = 0.814453125\n",
      "Batch 106: loss = 0.6116434335708618, acc = 0.8056640625\n",
      "Batch 107: loss = 0.5892667770385742, acc = 0.8017578125\n",
      "Batch 108: loss = 0.596961259841919, acc = 0.7978515625\n",
      "Batch 109: loss = 0.583419680595398, acc = 0.8115234375\n",
      "Batch 110: loss = 0.568452775478363, acc = 0.80078125\n",
      "Batch 111: loss = 0.6773805618286133, acc = 0.771484375\n",
      "Batch 112: loss = 0.5993363857269287, acc = 0.7978515625\n",
      "Batch 113: loss = 0.6279402375221252, acc = 0.783203125\n",
      "Batch 114: loss = 0.6100422143936157, acc = 0.8134765625\n",
      "Batch 115: loss = 0.6671966314315796, acc = 0.775390625\n",
      "Batch 116: loss = 0.6922003030776978, acc = 0.7763671875\n",
      "Batch 117: loss = 0.5700074434280396, acc = 0.806640625\n",
      "Batch 118: loss = 0.520229697227478, acc = 0.8310546875\n",
      "Batch 119: loss = 0.6263179779052734, acc = 0.7890625\n",
      "Batch 120: loss = 0.5948716402053833, acc = 0.8037109375\n",
      "Batch 121: loss = 0.6325787305831909, acc = 0.7880859375\n",
      "Batch 122: loss = 0.5964529514312744, acc = 0.8076171875\n",
      "Batch 123: loss = 0.6552407741546631, acc = 0.7822265625\n",
      "Batch 124: loss = 0.6493097543716431, acc = 0.7734375\n",
      "Batch 125: loss = 0.6666189432144165, acc = 0.7880859375\n",
      "Batch 126: loss = 0.6462639570236206, acc = 0.7978515625\n",
      "\n",
      "Epoch 34/100\n",
      "Batch 1: loss = 0.7331154346466064, acc = 0.7880859375\n",
      "Batch 2: loss = 0.6891477108001709, acc = 0.7783203125\n",
      "Batch 3: loss = 0.6661699414253235, acc = 0.7890625\n",
      "Batch 4: loss = 0.605536162853241, acc = 0.8076171875\n",
      "Batch 5: loss = 0.6634206175804138, acc = 0.7978515625\n",
      "Batch 6: loss = 0.6610761880874634, acc = 0.775390625\n",
      "Batch 7: loss = 0.6145501136779785, acc = 0.796875\n",
      "Batch 8: loss = 0.6535961627960205, acc = 0.7841796875\n",
      "Batch 9: loss = 0.598746657371521, acc = 0.7958984375\n",
      "Batch 10: loss = 0.5747328996658325, acc = 0.8076171875\n",
      "Batch 11: loss = 0.6426195502281189, acc = 0.779296875\n",
      "Batch 12: loss = 0.5910968780517578, acc = 0.802734375\n",
      "Batch 13: loss = 0.5734310150146484, acc = 0.81640625\n",
      "Batch 14: loss = 0.6105008125305176, acc = 0.8125\n",
      "Batch 15: loss = 0.5725481510162354, acc = 0.810546875\n",
      "Batch 16: loss = 0.6561932563781738, acc = 0.7841796875\n",
      "Batch 17: loss = 0.636664628982544, acc = 0.7880859375\n",
      "Batch 18: loss = 0.6967469453811646, acc = 0.78125\n",
      "Batch 19: loss = 0.6292905807495117, acc = 0.779296875\n",
      "Batch 20: loss = 0.6388500332832336, acc = 0.78515625\n",
      "Batch 21: loss = 0.6652413606643677, acc = 0.779296875\n",
      "Batch 22: loss = 0.6239818334579468, acc = 0.7861328125\n",
      "Batch 23: loss = 0.6231104135513306, acc = 0.796875\n",
      "Batch 24: loss = 0.5905585289001465, acc = 0.806640625\n",
      "Batch 25: loss = 0.5590641498565674, acc = 0.81640625\n",
      "Batch 26: loss = 0.575017511844635, acc = 0.8212890625\n",
      "Batch 27: loss = 0.6992624402046204, acc = 0.771484375\n",
      "Batch 28: loss = 0.6455393433570862, acc = 0.78125\n",
      "Batch 29: loss = 0.6265660524368286, acc = 0.7939453125\n",
      "Batch 30: loss = 0.5722583532333374, acc = 0.8095703125\n",
      "Batch 31: loss = 0.6928814649581909, acc = 0.7822265625\n",
      "Batch 32: loss = 0.7753751277923584, acc = 0.7587890625\n",
      "Batch 33: loss = 0.5959022641181946, acc = 0.7958984375\n",
      "Batch 34: loss = 0.6207751035690308, acc = 0.798828125\n",
      "Batch 35: loss = 0.6232506036758423, acc = 0.7939453125\n",
      "Batch 36: loss = 0.6033843159675598, acc = 0.806640625\n",
      "Batch 37: loss = 0.6127060651779175, acc = 0.806640625\n",
      "Batch 38: loss = 0.6181865930557251, acc = 0.7998046875\n",
      "Batch 39: loss = 0.5903841257095337, acc = 0.7978515625\n",
      "Batch 40: loss = 0.63676917552948, acc = 0.80078125\n",
      "Batch 41: loss = 0.5332932472229004, acc = 0.82421875\n",
      "Batch 42: loss = 0.625108003616333, acc = 0.7978515625\n",
      "Batch 43: loss = 0.6588095426559448, acc = 0.7880859375\n",
      "Batch 44: loss = 0.5992361307144165, acc = 0.796875\n",
      "Batch 45: loss = 0.5238935947418213, acc = 0.8193359375\n",
      "Batch 46: loss = 0.5679701566696167, acc = 0.814453125\n",
      "Batch 47: loss = 0.592154860496521, acc = 0.81640625\n",
      "Batch 48: loss = 0.5807105302810669, acc = 0.818359375\n",
      "Batch 49: loss = 0.5211659669876099, acc = 0.8310546875\n",
      "Batch 50: loss = 0.5762795805931091, acc = 0.814453125\n",
      "Batch 51: loss = 0.5543179512023926, acc = 0.810546875\n",
      "Batch 52: loss = 0.6221953630447388, acc = 0.79296875\n",
      "Batch 53: loss = 0.6176865100860596, acc = 0.7998046875\n",
      "Batch 54: loss = 0.5373562574386597, acc = 0.8310546875\n",
      "Batch 55: loss = 0.5276303291320801, acc = 0.8291015625\n",
      "Batch 56: loss = 0.6203691959381104, acc = 0.78515625\n",
      "Batch 57: loss = 0.6303795576095581, acc = 0.7939453125\n",
      "Batch 58: loss = 0.6627343893051147, acc = 0.791015625\n",
      "Batch 59: loss = 0.4765350818634033, acc = 0.841796875\n",
      "Batch 60: loss = 0.5913907289505005, acc = 0.8076171875\n",
      "Batch 61: loss = 0.5976460576057434, acc = 0.8095703125\n",
      "Batch 62: loss = 0.7159208059310913, acc = 0.7509765625\n",
      "Batch 63: loss = 0.6564172506332397, acc = 0.787109375\n",
      "Batch 64: loss = 0.5305560827255249, acc = 0.8212890625\n",
      "Batch 65: loss = 0.6705139875411987, acc = 0.7724609375\n",
      "Batch 66: loss = 0.6143182516098022, acc = 0.7958984375\n",
      "Batch 67: loss = 0.5753908157348633, acc = 0.796875\n",
      "Batch 68: loss = 0.6102792620658875, acc = 0.8076171875\n",
      "Batch 69: loss = 0.5291928648948669, acc = 0.8330078125\n",
      "Batch 70: loss = 0.6764807105064392, acc = 0.7724609375\n",
      "Batch 71: loss = 0.6154795289039612, acc = 0.79296875\n",
      "Batch 72: loss = 0.56525719165802, acc = 0.81640625\n",
      "Batch 73: loss = 0.6723602414131165, acc = 0.7783203125\n",
      "Batch 74: loss = 0.6757247447967529, acc = 0.775390625\n",
      "Batch 75: loss = 0.7224023342132568, acc = 0.765625\n",
      "Batch 76: loss = 0.6524948477745056, acc = 0.7744140625\n",
      "Batch 77: loss = 0.5512633323669434, acc = 0.8271484375\n",
      "Batch 78: loss = 0.6247978210449219, acc = 0.7998046875\n",
      "Batch 79: loss = 0.5275977849960327, acc = 0.8232421875\n",
      "Batch 80: loss = 0.5501797199249268, acc = 0.796875\n",
      "Batch 81: loss = 0.6368352174758911, acc = 0.7919921875\n",
      "Batch 82: loss = 0.5257352590560913, acc = 0.8232421875\n",
      "Batch 83: loss = 0.5909572243690491, acc = 0.8056640625\n",
      "Batch 84: loss = 0.5710278749465942, acc = 0.8076171875\n",
      "Batch 85: loss = 0.6712697744369507, acc = 0.7705078125\n",
      "Batch 86: loss = 0.6235417127609253, acc = 0.7939453125\n",
      "Batch 87: loss = 0.5754398107528687, acc = 0.8115234375\n",
      "Batch 88: loss = 0.68056720495224, acc = 0.76953125\n",
      "Batch 89: loss = 0.5942548513412476, acc = 0.810546875\n",
      "Batch 90: loss = 0.6382060647010803, acc = 0.8046875\n",
      "Batch 91: loss = 0.637546181678772, acc = 0.7958984375\n",
      "Batch 92: loss = 0.6564319133758545, acc = 0.7900390625\n",
      "Batch 93: loss = 0.5175017714500427, acc = 0.8369140625\n",
      "Batch 94: loss = 0.5742630958557129, acc = 0.8173828125\n",
      "Batch 95: loss = 0.554999589920044, acc = 0.828125\n",
      "Batch 96: loss = 0.6559587717056274, acc = 0.787109375\n",
      "Batch 97: loss = 0.615562915802002, acc = 0.8076171875\n",
      "Batch 98: loss = 0.6064208745956421, acc = 0.794921875\n",
      "Batch 99: loss = 0.5840821266174316, acc = 0.8056640625\n",
      "Batch 100: loss = 0.6056954860687256, acc = 0.794921875\n",
      "Batch 101: loss = 0.5928968191146851, acc = 0.80078125\n",
      "Batch 102: loss = 0.6335678100585938, acc = 0.7822265625\n",
      "Batch 103: loss = 0.5991509556770325, acc = 0.8115234375\n",
      "Batch 104: loss = 0.5713877081871033, acc = 0.8134765625\n",
      "Batch 105: loss = 0.5672769546508789, acc = 0.8076171875\n",
      "Batch 106: loss = 0.6020748019218445, acc = 0.8037109375\n",
      "Batch 107: loss = 0.5563616752624512, acc = 0.8291015625\n",
      "Batch 108: loss = 0.6051827669143677, acc = 0.8046875\n",
      "Batch 109: loss = 0.5990309119224548, acc = 0.802734375\n",
      "Batch 110: loss = 0.5832871198654175, acc = 0.810546875\n",
      "Batch 111: loss = 0.6576879024505615, acc = 0.78515625\n",
      "Batch 112: loss = 0.5687776803970337, acc = 0.7998046875\n",
      "Batch 113: loss = 0.6030099391937256, acc = 0.794921875\n",
      "Batch 114: loss = 0.6045964360237122, acc = 0.80078125\n",
      "Batch 115: loss = 0.6240459680557251, acc = 0.7939453125\n",
      "Batch 116: loss = 0.6639896035194397, acc = 0.7841796875\n",
      "Batch 117: loss = 0.5609750151634216, acc = 0.8232421875\n",
      "Batch 118: loss = 0.5283433198928833, acc = 0.8291015625\n",
      "Batch 119: loss = 0.5877711772918701, acc = 0.79296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 120: loss = 0.5587217211723328, acc = 0.8173828125\n",
      "Batch 121: loss = 0.5944061279296875, acc = 0.80078125\n",
      "Batch 122: loss = 0.5696922540664673, acc = 0.8046875\n",
      "Batch 123: loss = 0.6003409028053284, acc = 0.80078125\n",
      "Batch 124: loss = 0.6315155029296875, acc = 0.7822265625\n",
      "Batch 125: loss = 0.6894823312759399, acc = 0.7724609375\n",
      "Batch 126: loss = 0.6156150698661804, acc = 0.7998046875\n",
      "\n",
      "Epoch 35/100\n",
      "Batch 1: loss = 0.7756191492080688, acc = 0.7607421875\n",
      "Batch 2: loss = 0.72458416223526, acc = 0.765625\n",
      "Batch 3: loss = 0.6390347480773926, acc = 0.7998046875\n",
      "Batch 4: loss = 0.6254266500473022, acc = 0.8076171875\n",
      "Batch 5: loss = 0.6351949572563171, acc = 0.794921875\n",
      "Batch 6: loss = 0.6690874099731445, acc = 0.7783203125\n",
      "Batch 7: loss = 0.616773247718811, acc = 0.7958984375\n",
      "Batch 8: loss = 0.6250832080841064, acc = 0.8017578125\n",
      "Batch 9: loss = 0.5495937466621399, acc = 0.828125\n",
      "Batch 10: loss = 0.5279222726821899, acc = 0.8330078125\n",
      "Batch 11: loss = 0.6106826066970825, acc = 0.798828125\n",
      "Batch 12: loss = 0.6224086284637451, acc = 0.787109375\n",
      "Batch 13: loss = 0.5614323019981384, acc = 0.8193359375\n",
      "Batch 14: loss = 0.5965975522994995, acc = 0.810546875\n",
      "Batch 15: loss = 0.57823246717453, acc = 0.810546875\n",
      "Batch 16: loss = 0.5980480909347534, acc = 0.802734375\n",
      "Batch 17: loss = 0.603103756904602, acc = 0.8076171875\n",
      "Batch 18: loss = 0.6313188076019287, acc = 0.79296875\n",
      "Batch 19: loss = 0.6100326776504517, acc = 0.8037109375\n",
      "Batch 20: loss = 0.6258506774902344, acc = 0.79296875\n",
      "Batch 21: loss = 0.6853813529014587, acc = 0.771484375\n",
      "Batch 22: loss = 0.5982897877693176, acc = 0.80859375\n",
      "Batch 23: loss = 0.5970607399940491, acc = 0.7939453125\n",
      "Batch 24: loss = 0.5774229764938354, acc = 0.8017578125\n",
      "Batch 25: loss = 0.5707105398178101, acc = 0.8115234375\n",
      "Batch 26: loss = 0.6015867590904236, acc = 0.796875\n",
      "Batch 27: loss = 0.6896087527275085, acc = 0.775390625\n",
      "Batch 28: loss = 0.6268742084503174, acc = 0.7890625\n",
      "Batch 29: loss = 0.5974111557006836, acc = 0.8125\n",
      "Batch 30: loss = 0.5735151767730713, acc = 0.806640625\n",
      "Batch 31: loss = 0.6599575281143188, acc = 0.7822265625\n",
      "Batch 32: loss = 0.7075218558311462, acc = 0.7685546875\n",
      "Batch 33: loss = 0.5707634687423706, acc = 0.8203125\n",
      "Batch 34: loss = 0.6431190967559814, acc = 0.802734375\n",
      "Batch 35: loss = 0.6107184886932373, acc = 0.7939453125\n",
      "Batch 36: loss = 0.5829126834869385, acc = 0.818359375\n",
      "Batch 37: loss = 0.5867382884025574, acc = 0.8115234375\n",
      "Batch 38: loss = 0.6220109462738037, acc = 0.802734375\n",
      "Batch 39: loss = 0.5808690190315247, acc = 0.806640625\n",
      "Batch 40: loss = 0.6244988441467285, acc = 0.8076171875\n",
      "Batch 41: loss = 0.5229421854019165, acc = 0.8173828125\n",
      "Batch 42: loss = 0.5796443223953247, acc = 0.8037109375\n",
      "Batch 43: loss = 0.615319550037384, acc = 0.791015625\n",
      "Batch 44: loss = 0.5312594771385193, acc = 0.8359375\n",
      "Batch 45: loss = 0.5141242146492004, acc = 0.8359375\n",
      "Batch 46: loss = 0.5450899004936218, acc = 0.830078125\n",
      "Batch 47: loss = 0.561669647693634, acc = 0.8193359375\n",
      "Batch 48: loss = 0.5818147659301758, acc = 0.80078125\n",
      "Batch 49: loss = 0.5371763706207275, acc = 0.8212890625\n",
      "Batch 50: loss = 0.5347213745117188, acc = 0.83203125\n",
      "Batch 51: loss = 0.5708197355270386, acc = 0.810546875\n",
      "Batch 52: loss = 0.6046007871627808, acc = 0.7978515625\n",
      "Batch 53: loss = 0.6278589963912964, acc = 0.791015625\n",
      "Batch 54: loss = 0.5377871990203857, acc = 0.8212890625\n",
      "Batch 55: loss = 0.5283300876617432, acc = 0.8271484375\n",
      "Batch 56: loss = 0.6030264496803284, acc = 0.7900390625\n",
      "Batch 57: loss = 0.6377753019332886, acc = 0.7646484375\n",
      "Batch 58: loss = 0.6489209532737732, acc = 0.765625\n",
      "Batch 59: loss = 0.4915039837360382, acc = 0.8349609375\n",
      "Batch 60: loss = 0.5992014408111572, acc = 0.80859375\n",
      "Batch 61: loss = 0.5700755715370178, acc = 0.8173828125\n",
      "Batch 62: loss = 0.6914976239204407, acc = 0.7568359375\n",
      "Batch 63: loss = 0.6265222430229187, acc = 0.7919921875\n",
      "Batch 64: loss = 0.5103355050086975, acc = 0.828125\n",
      "Batch 65: loss = 0.6210595369338989, acc = 0.7822265625\n",
      "Batch 66: loss = 0.6023176312446594, acc = 0.7978515625\n",
      "Batch 67: loss = 0.5894752740859985, acc = 0.8125\n",
      "Batch 68: loss = 0.6336504220962524, acc = 0.798828125\n",
      "Batch 69: loss = 0.509960412979126, acc = 0.837890625\n",
      "Batch 70: loss = 0.6501539349555969, acc = 0.78125\n",
      "Batch 71: loss = 0.6091597676277161, acc = 0.7880859375\n",
      "Batch 72: loss = 0.5376230478286743, acc = 0.8173828125\n",
      "Batch 73: loss = 0.6284196376800537, acc = 0.7783203125\n",
      "Batch 74: loss = 0.629418134689331, acc = 0.7919921875\n",
      "Batch 75: loss = 0.6887029409408569, acc = 0.771484375\n",
      "Batch 76: loss = 0.6757251620292664, acc = 0.7861328125\n",
      "Batch 77: loss = 0.5898830890655518, acc = 0.8115234375\n",
      "Batch 78: loss = 0.589748740196228, acc = 0.8115234375\n",
      "Batch 79: loss = 0.5354026556015015, acc = 0.8291015625\n",
      "Batch 80: loss = 0.5595749616622925, acc = 0.7939453125\n",
      "Batch 81: loss = 0.6104538440704346, acc = 0.7880859375\n",
      "Batch 82: loss = 0.5594643354415894, acc = 0.8203125\n",
      "Batch 83: loss = 0.5683812499046326, acc = 0.7998046875\n",
      "Batch 84: loss = 0.571388304233551, acc = 0.8095703125\n",
      "Batch 85: loss = 0.6618732213973999, acc = 0.765625\n",
      "Batch 86: loss = 0.6218467354774475, acc = 0.7939453125\n",
      "Batch 87: loss = 0.5836530327796936, acc = 0.814453125\n",
      "Batch 88: loss = 0.7107772827148438, acc = 0.767578125\n",
      "Batch 89: loss = 0.5858046412467957, acc = 0.806640625\n",
      "Batch 90: loss = 0.6449729204177856, acc = 0.7958984375\n",
      "Batch 91: loss = 0.612169623374939, acc = 0.7978515625\n",
      "Batch 92: loss = 0.629840612411499, acc = 0.79296875\n",
      "Batch 93: loss = 0.530362606048584, acc = 0.822265625\n",
      "Batch 94: loss = 0.520585298538208, acc = 0.8388671875\n",
      "Batch 95: loss = 0.5432549118995667, acc = 0.81640625\n",
      "Batch 96: loss = 0.6393049955368042, acc = 0.7939453125\n",
      "Batch 97: loss = 0.6225359439849854, acc = 0.802734375\n",
      "Batch 98: loss = 0.6192163228988647, acc = 0.796875\n",
      "Batch 99: loss = 0.5959798097610474, acc = 0.8076171875\n",
      "Batch 100: loss = 0.5977006554603577, acc = 0.794921875\n",
      "Batch 101: loss = 0.54704749584198, acc = 0.814453125\n",
      "Batch 102: loss = 0.6130212545394897, acc = 0.8095703125\n",
      "Batch 103: loss = 0.5957794785499573, acc = 0.798828125\n",
      "Batch 104: loss = 0.5476940870285034, acc = 0.8076171875\n",
      "Batch 105: loss = 0.5758932828903198, acc = 0.8125\n",
      "Batch 106: loss = 0.6092888116836548, acc = 0.806640625\n",
      "Batch 107: loss = 0.5535696744918823, acc = 0.80859375\n",
      "Batch 108: loss = 0.5654075145721436, acc = 0.8046875\n",
      "Batch 109: loss = 0.6184145212173462, acc = 0.7998046875\n",
      "Batch 110: loss = 0.550175666809082, acc = 0.830078125\n",
      "Batch 111: loss = 0.6399469375610352, acc = 0.7880859375\n",
      "Batch 112: loss = 0.5673959851264954, acc = 0.8212890625\n",
      "Batch 113: loss = 0.6074824333190918, acc = 0.806640625\n",
      "Batch 114: loss = 0.6051093339920044, acc = 0.7978515625\n",
      "Batch 115: loss = 0.6109857559204102, acc = 0.7998046875\n",
      "Batch 116: loss = 0.6440911293029785, acc = 0.802734375\n",
      "Batch 117: loss = 0.5715631246566772, acc = 0.802734375\n",
      "Batch 118: loss = 0.4925248324871063, acc = 0.841796875\n",
      "Batch 119: loss = 0.6013901233673096, acc = 0.8095703125\n",
      "Batch 120: loss = 0.5918906927108765, acc = 0.7958984375\n",
      "Batch 121: loss = 0.581326425075531, acc = 0.8095703125\n",
      "Batch 122: loss = 0.5550637245178223, acc = 0.8134765625\n",
      "Batch 123: loss = 0.6029636859893799, acc = 0.8056640625\n",
      "Batch 124: loss = 0.6203420162200928, acc = 0.7890625\n",
      "Batch 125: loss = 0.673003613948822, acc = 0.775390625\n",
      "Batch 126: loss = 0.605247437953949, acc = 0.7958984375\n",
      "\n",
      "Epoch 36/100\n",
      "Batch 1: loss = 0.721246600151062, acc = 0.7900390625\n",
      "Batch 2: loss = 0.6801264882087708, acc = 0.7646484375\n",
      "Batch 3: loss = 0.6179349422454834, acc = 0.8173828125\n",
      "Batch 4: loss = 0.5951266288757324, acc = 0.8193359375\n",
      "Batch 5: loss = 0.6379084587097168, acc = 0.7978515625\n",
      "Batch 6: loss = 0.6576440334320068, acc = 0.775390625\n",
      "Batch 7: loss = 0.6086233854293823, acc = 0.810546875\n",
      "Batch 8: loss = 0.5835214853286743, acc = 0.8125\n",
      "Batch 9: loss = 0.54399573802948, acc = 0.828125\n",
      "Batch 10: loss = 0.532007098197937, acc = 0.8173828125\n",
      "Batch 11: loss = 0.6177976131439209, acc = 0.8017578125\n",
      "Batch 12: loss = 0.5866678953170776, acc = 0.8017578125\n",
      "Batch 13: loss = 0.5773426294326782, acc = 0.8193359375\n",
      "Batch 14: loss = 0.5727688670158386, acc = 0.8134765625\n",
      "Batch 15: loss = 0.5786795616149902, acc = 0.8115234375\n",
      "Batch 16: loss = 0.5987129211425781, acc = 0.80859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17: loss = 0.5872114896774292, acc = 0.8056640625\n",
      "Batch 18: loss = 0.6373844742774963, acc = 0.802734375\n",
      "Batch 19: loss = 0.5976606607437134, acc = 0.81640625\n",
      "Batch 20: loss = 0.5805903077125549, acc = 0.8095703125\n",
      "Batch 21: loss = 0.6244562864303589, acc = 0.802734375\n",
      "Batch 22: loss = 0.5845986604690552, acc = 0.796875\n",
      "Batch 23: loss = 0.5820152759552002, acc = 0.80078125\n",
      "Batch 24: loss = 0.6029289364814758, acc = 0.7978515625\n",
      "Batch 25: loss = 0.5367135405540466, acc = 0.82421875\n",
      "Batch 26: loss = 0.5560359954833984, acc = 0.82421875\n",
      "Batch 27: loss = 0.6607475280761719, acc = 0.7802734375\n",
      "Batch 28: loss = 0.6278241872787476, acc = 0.7998046875\n",
      "Batch 29: loss = 0.5872429609298706, acc = 0.8046875\n",
      "Batch 30: loss = 0.5761099457740784, acc = 0.8037109375\n",
      "Batch 31: loss = 0.6406235694885254, acc = 0.796875\n",
      "Batch 32: loss = 0.6855160593986511, acc = 0.7724609375\n",
      "Batch 33: loss = 0.557819128036499, acc = 0.8232421875\n",
      "Batch 34: loss = 0.6168591976165771, acc = 0.7890625\n",
      "Batch 35: loss = 0.5755081176757812, acc = 0.80078125\n",
      "Batch 36: loss = 0.5630007982254028, acc = 0.822265625\n",
      "Batch 37: loss = 0.5778000354766846, acc = 0.8017578125\n",
      "Batch 38: loss = 0.5992019176483154, acc = 0.796875\n",
      "Batch 39: loss = 0.5408406853675842, acc = 0.82421875\n",
      "Batch 40: loss = 0.594280481338501, acc = 0.8046875\n",
      "Batch 41: loss = 0.5183709263801575, acc = 0.8291015625\n",
      "Batch 42: loss = 0.5598897337913513, acc = 0.80859375\n",
      "Batch 43: loss = 0.5795911550521851, acc = 0.80078125\n",
      "Batch 44: loss = 0.5512526631355286, acc = 0.81640625\n",
      "Batch 45: loss = 0.5198620557785034, acc = 0.83203125\n",
      "Batch 46: loss = 0.5572428703308105, acc = 0.8212890625\n",
      "Batch 47: loss = 0.5617239475250244, acc = 0.8271484375\n",
      "Batch 48: loss = 0.5632908344268799, acc = 0.8154296875\n",
      "Batch 49: loss = 0.49479877948760986, acc = 0.837890625\n",
      "Batch 50: loss = 0.5318009853363037, acc = 0.8330078125\n",
      "Batch 51: loss = 0.5225069522857666, acc = 0.822265625\n",
      "Batch 52: loss = 0.6079410910606384, acc = 0.802734375\n",
      "Batch 53: loss = 0.6212633848190308, acc = 0.79296875\n",
      "Batch 54: loss = 0.4952172636985779, acc = 0.84765625\n",
      "Batch 55: loss = 0.4715777039527893, acc = 0.84765625\n",
      "Batch 56: loss = 0.5671258568763733, acc = 0.8076171875\n",
      "Batch 57: loss = 0.6224178075790405, acc = 0.796875\n",
      "Batch 58: loss = 0.650852382183075, acc = 0.7841796875\n",
      "Batch 59: loss = 0.46825361251831055, acc = 0.8466796875\n",
      "Batch 60: loss = 0.5906685590744019, acc = 0.8017578125\n",
      "Batch 61: loss = 0.5379951000213623, acc = 0.82421875\n",
      "Batch 62: loss = 0.6765686273574829, acc = 0.7587890625\n",
      "Batch 63: loss = 0.608041524887085, acc = 0.80078125\n",
      "Batch 64: loss = 0.5150079131126404, acc = 0.822265625\n",
      "Batch 65: loss = 0.6136846542358398, acc = 0.798828125\n",
      "Batch 66: loss = 0.5837128162384033, acc = 0.80859375\n",
      "Batch 67: loss = 0.5817822813987732, acc = 0.8046875\n",
      "Batch 68: loss = 0.5875850915908813, acc = 0.8154296875\n",
      "Batch 69: loss = 0.5260456800460815, acc = 0.8359375\n",
      "Batch 70: loss = 0.6586556434631348, acc = 0.796875\n",
      "Batch 71: loss = 0.6319552659988403, acc = 0.79296875\n",
      "Batch 72: loss = 0.5378472208976746, acc = 0.818359375\n",
      "Batch 73: loss = 0.6282011270523071, acc = 0.7890625\n",
      "Batch 74: loss = 0.6377930641174316, acc = 0.7861328125\n",
      "Batch 75: loss = 0.6954675912857056, acc = 0.7607421875\n",
      "Batch 76: loss = 0.627869188785553, acc = 0.7861328125\n",
      "Batch 77: loss = 0.5899662375450134, acc = 0.8046875\n",
      "Batch 78: loss = 0.6003639101982117, acc = 0.802734375\n",
      "Batch 79: loss = 0.5322850346565247, acc = 0.8271484375\n",
      "Batch 80: loss = 0.5545146465301514, acc = 0.796875\n",
      "Batch 81: loss = 0.5861185789108276, acc = 0.798828125\n",
      "Batch 82: loss = 0.5277851223945618, acc = 0.83984375\n",
      "Batch 83: loss = 0.59104323387146, acc = 0.7939453125\n",
      "Batch 84: loss = 0.5790221095085144, acc = 0.8037109375\n",
      "Batch 85: loss = 0.6417210698127747, acc = 0.7841796875\n",
      "Batch 86: loss = 0.5940582156181335, acc = 0.796875\n",
      "Batch 87: loss = 0.5391578674316406, acc = 0.8232421875\n",
      "Batch 88: loss = 0.7032973170280457, acc = 0.7548828125\n",
      "Batch 89: loss = 0.578127384185791, acc = 0.818359375\n",
      "Batch 90: loss = 0.6002070903778076, acc = 0.8095703125\n",
      "Batch 91: loss = 0.6055395603179932, acc = 0.8037109375\n",
      "Batch 92: loss = 0.630879282951355, acc = 0.8056640625\n",
      "Batch 93: loss = 0.5119031667709351, acc = 0.8349609375\n",
      "Batch 94: loss = 0.5330414175987244, acc = 0.8193359375\n",
      "Batch 95: loss = 0.50323885679245, acc = 0.830078125\n",
      "Batch 96: loss = 0.618295431137085, acc = 0.7958984375\n",
      "Batch 97: loss = 0.5886733531951904, acc = 0.810546875\n",
      "Batch 98: loss = 0.5746874809265137, acc = 0.8154296875\n",
      "Batch 99: loss = 0.5710673332214355, acc = 0.8125\n",
      "Batch 100: loss = 0.5813409090042114, acc = 0.798828125\n",
      "Batch 101: loss = 0.5922760963439941, acc = 0.7822265625\n",
      "Batch 102: loss = 0.6183644533157349, acc = 0.796875\n",
      "Batch 103: loss = 0.5971318483352661, acc = 0.796875\n",
      "Batch 104: loss = 0.5500931739807129, acc = 0.822265625\n",
      "Batch 105: loss = 0.5517045855522156, acc = 0.822265625\n",
      "Batch 106: loss = 0.5855019092559814, acc = 0.814453125\n",
      "Batch 107: loss = 0.5360568761825562, acc = 0.82421875\n",
      "Batch 108: loss = 0.5639960169792175, acc = 0.8046875\n",
      "Batch 109: loss = 0.5690733194351196, acc = 0.8056640625\n",
      "Batch 110: loss = 0.5436015129089355, acc = 0.8173828125\n",
      "Batch 111: loss = 0.5900665521621704, acc = 0.810546875\n",
      "Batch 112: loss = 0.5446314215660095, acc = 0.8173828125\n",
      "Batch 113: loss = 0.5987844467163086, acc = 0.7998046875\n",
      "Batch 114: loss = 0.6215119957923889, acc = 0.8037109375\n",
      "Batch 115: loss = 0.5871953368186951, acc = 0.80078125\n",
      "Batch 116: loss = 0.613466203212738, acc = 0.802734375\n",
      "Batch 117: loss = 0.5528013706207275, acc = 0.8134765625\n",
      "Batch 118: loss = 0.5015457272529602, acc = 0.8271484375\n",
      "Batch 119: loss = 0.5460877418518066, acc = 0.8203125\n",
      "Batch 120: loss = 0.529401421546936, acc = 0.8134765625\n",
      "Batch 121: loss = 0.5696882605552673, acc = 0.8154296875\n",
      "Batch 122: loss = 0.5219326615333557, acc = 0.8251953125\n",
      "Batch 123: loss = 0.559261679649353, acc = 0.8173828125\n",
      "Batch 124: loss = 0.6185030937194824, acc = 0.77734375\n",
      "Batch 125: loss = 0.6457947492599487, acc = 0.7900390625\n",
      "Batch 126: loss = 0.5957391262054443, acc = 0.8095703125\n",
      "\n",
      "Epoch 37/100\n",
      "Batch 1: loss = 0.7653980255126953, acc = 0.78125\n",
      "Batch 2: loss = 0.6640177965164185, acc = 0.7890625\n",
      "Batch 3: loss = 0.5839697122573853, acc = 0.81640625\n",
      "Batch 4: loss = 0.5575785636901855, acc = 0.83203125\n",
      "Batch 5: loss = 0.6319458484649658, acc = 0.794921875\n",
      "Batch 6: loss = 0.6221617460250854, acc = 0.7900390625\n",
      "Batch 7: loss = 0.5889972448348999, acc = 0.8076171875\n",
      "Batch 8: loss = 0.5985417366027832, acc = 0.8056640625\n",
      "Batch 9: loss = 0.5453629493713379, acc = 0.8203125\n",
      "Batch 10: loss = 0.5115768909454346, acc = 0.8291015625\n",
      "Batch 11: loss = 0.6037936210632324, acc = 0.7900390625\n",
      "Batch 12: loss = 0.5483422875404358, acc = 0.8154296875\n",
      "Batch 13: loss = 0.5353789329528809, acc = 0.826171875\n",
      "Batch 14: loss = 0.576977550983429, acc = 0.8125\n",
      "Batch 15: loss = 0.5498600602149963, acc = 0.8232421875\n",
      "Batch 16: loss = 0.5944068431854248, acc = 0.8134765625\n",
      "Batch 17: loss = 0.5791336297988892, acc = 0.8134765625\n",
      "Batch 18: loss = 0.5923550724983215, acc = 0.810546875\n",
      "Batch 19: loss = 0.5697002410888672, acc = 0.8154296875\n",
      "Batch 20: loss = 0.5546724796295166, acc = 0.8173828125\n",
      "Batch 21: loss = 0.6080318689346313, acc = 0.7958984375\n",
      "Batch 22: loss = 0.5620866417884827, acc = 0.8212890625\n",
      "Batch 23: loss = 0.5594998598098755, acc = 0.8134765625\n",
      "Batch 24: loss = 0.5804148316383362, acc = 0.8046875\n",
      "Batch 25: loss = 0.5015195608139038, acc = 0.8359375\n",
      "Batch 26: loss = 0.5363919734954834, acc = 0.8232421875\n",
      "Batch 27: loss = 0.6522048115730286, acc = 0.7958984375\n",
      "Batch 28: loss = 0.6207275390625, acc = 0.7900390625\n",
      "Batch 29: loss = 0.5936895608901978, acc = 0.810546875\n",
      "Batch 30: loss = 0.6076697111129761, acc = 0.7978515625\n",
      "Batch 31: loss = 0.6161709427833557, acc = 0.818359375\n",
      "Batch 32: loss = 0.7095721364021301, acc = 0.7587890625\n",
      "Batch 33: loss = 0.5731512904167175, acc = 0.8095703125\n",
      "Batch 34: loss = 0.576303243637085, acc = 0.80859375\n",
      "Batch 35: loss = 0.534296989440918, acc = 0.8291015625\n",
      "Batch 36: loss = 0.5364314317703247, acc = 0.83203125\n",
      "Batch 37: loss = 0.5288441181182861, acc = 0.82421875\n",
      "Batch 38: loss = 0.6036445498466492, acc = 0.7880859375\n",
      "Batch 39: loss = 0.5725348591804504, acc = 0.8134765625\n",
      "Batch 40: loss = 0.5762327909469604, acc = 0.8076171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 41: loss = 0.49623170495033264, acc = 0.8291015625\n",
      "Batch 42: loss = 0.5462969541549683, acc = 0.8115234375\n",
      "Batch 43: loss = 0.5704526901245117, acc = 0.8154296875\n",
      "Batch 44: loss = 0.5342689156532288, acc = 0.8369140625\n",
      "Batch 45: loss = 0.503369152545929, acc = 0.83203125\n",
      "Batch 46: loss = 0.5390182137489319, acc = 0.8291015625\n",
      "Batch 47: loss = 0.5539320707321167, acc = 0.8173828125\n",
      "Batch 48: loss = 0.5464892387390137, acc = 0.8125\n",
      "Batch 49: loss = 0.4665911793708801, acc = 0.8544921875\n",
      "Batch 50: loss = 0.5148547887802124, acc = 0.828125\n",
      "Batch 51: loss = 0.5054029226303101, acc = 0.83203125\n",
      "Batch 52: loss = 0.5568559169769287, acc = 0.8095703125\n",
      "Batch 53: loss = 0.5634890794754028, acc = 0.8134765625\n",
      "Batch 54: loss = 0.4771975874900818, acc = 0.8505859375\n",
      "Batch 55: loss = 0.5017992258071899, acc = 0.841796875\n",
      "Batch 56: loss = 0.5619718432426453, acc = 0.80859375\n",
      "Batch 57: loss = 0.6042047739028931, acc = 0.8046875\n",
      "Batch 58: loss = 0.6328121423721313, acc = 0.783203125\n",
      "Batch 59: loss = 0.4553517699241638, acc = 0.8544921875\n",
      "Batch 60: loss = 0.5633252859115601, acc = 0.814453125\n",
      "Batch 61: loss = 0.5376112461090088, acc = 0.8349609375\n",
      "Batch 62: loss = 0.636497437953949, acc = 0.7841796875\n",
      "Batch 63: loss = 0.6010643243789673, acc = 0.7978515625\n",
      "Batch 64: loss = 0.4736176133155823, acc = 0.8359375\n",
      "Batch 65: loss = 0.5773175954818726, acc = 0.810546875\n",
      "Batch 66: loss = 0.5745407342910767, acc = 0.8017578125\n",
      "Batch 67: loss = 0.5153788328170776, acc = 0.822265625\n",
      "Batch 68: loss = 0.5981690883636475, acc = 0.8125\n",
      "Batch 69: loss = 0.517421305179596, acc = 0.826171875\n",
      "Batch 70: loss = 0.6140904426574707, acc = 0.7919921875\n",
      "Batch 71: loss = 0.5767024755477905, acc = 0.7939453125\n",
      "Batch 72: loss = 0.52220618724823, acc = 0.8359375\n",
      "Batch 73: loss = 0.6263985633850098, acc = 0.7841796875\n",
      "Batch 74: loss = 0.6061898469924927, acc = 0.7919921875\n",
      "Batch 75: loss = 0.6537826657295227, acc = 0.7734375\n",
      "Batch 76: loss = 0.6067438721656799, acc = 0.7939453125\n",
      "Batch 77: loss = 0.5502933263778687, acc = 0.8173828125\n",
      "Batch 78: loss = 0.5670528411865234, acc = 0.828125\n",
      "Batch 79: loss = 0.5021191239356995, acc = 0.8388671875\n",
      "Batch 80: loss = 0.5320154428482056, acc = 0.814453125\n",
      "Batch 81: loss = 0.5821848511695862, acc = 0.8046875\n",
      "Batch 82: loss = 0.5293298363685608, acc = 0.8330078125\n",
      "Batch 83: loss = 0.5684158802032471, acc = 0.814453125\n",
      "Batch 84: loss = 0.5601768493652344, acc = 0.8017578125\n",
      "Batch 85: loss = 0.6425344944000244, acc = 0.7724609375\n",
      "Batch 86: loss = 0.5922345519065857, acc = 0.7958984375\n",
      "Batch 87: loss = 0.5393235683441162, acc = 0.833984375\n",
      "Batch 88: loss = 0.6397744417190552, acc = 0.7939453125\n",
      "Batch 89: loss = 0.5493416786193848, acc = 0.814453125\n",
      "Batch 90: loss = 0.5897133946418762, acc = 0.791015625\n",
      "Batch 91: loss = 0.6395649909973145, acc = 0.775390625\n",
      "Batch 92: loss = 0.6161140203475952, acc = 0.7998046875\n",
      "Batch 93: loss = 0.4928719699382782, acc = 0.830078125\n",
      "Batch 94: loss = 0.4942820966243744, acc = 0.833984375\n",
      "Batch 95: loss = 0.5308072566986084, acc = 0.8173828125\n",
      "Batch 96: loss = 0.6089961528778076, acc = 0.798828125\n",
      "Batch 97: loss = 0.5681338310241699, acc = 0.82421875\n",
      "Batch 98: loss = 0.557125985622406, acc = 0.83203125\n",
      "Batch 99: loss = 0.5740135312080383, acc = 0.814453125\n",
      "Batch 100: loss = 0.5878297686576843, acc = 0.796875\n",
      "Batch 101: loss = 0.5975471138954163, acc = 0.798828125\n",
      "Batch 102: loss = 0.5889764428138733, acc = 0.80859375\n",
      "Batch 103: loss = 0.5635709762573242, acc = 0.80859375\n",
      "Batch 104: loss = 0.5304195880889893, acc = 0.8369140625\n",
      "Batch 105: loss = 0.5291440486907959, acc = 0.830078125\n",
      "Batch 106: loss = 0.5535116195678711, acc = 0.8193359375\n",
      "Batch 107: loss = 0.5062439441680908, acc = 0.84765625\n",
      "Batch 108: loss = 0.5201376676559448, acc = 0.833984375\n",
      "Batch 109: loss = 0.5348061323165894, acc = 0.822265625\n",
      "Batch 110: loss = 0.5205436944961548, acc = 0.822265625\n",
      "Batch 111: loss = 0.6313768625259399, acc = 0.7802734375\n",
      "Batch 112: loss = 0.5389026999473572, acc = 0.818359375\n",
      "Batch 113: loss = 0.5572103261947632, acc = 0.80859375\n",
      "Batch 114: loss = 0.5857404470443726, acc = 0.814453125\n",
      "Batch 115: loss = 0.5696290731430054, acc = 0.8095703125\n",
      "Batch 116: loss = 0.5967334508895874, acc = 0.7958984375\n",
      "Batch 117: loss = 0.5620535016059875, acc = 0.814453125\n",
      "Batch 118: loss = 0.4680485725402832, acc = 0.833984375\n",
      "Batch 119: loss = 0.5531425476074219, acc = 0.8173828125\n",
      "Batch 120: loss = 0.5169419646263123, acc = 0.81640625\n",
      "Batch 121: loss = 0.5482146739959717, acc = 0.8271484375\n",
      "Batch 122: loss = 0.524094820022583, acc = 0.83203125\n",
      "Batch 123: loss = 0.5648379325866699, acc = 0.828125\n",
      "Batch 124: loss = 0.5844827890396118, acc = 0.794921875\n",
      "Batch 125: loss = 0.5999550223350525, acc = 0.802734375\n",
      "Batch 126: loss = 0.6014971733093262, acc = 0.8076171875\n",
      "\n",
      "Epoch 38/100\n",
      "Batch 1: loss = 0.7653377056121826, acc = 0.787109375\n",
      "Batch 2: loss = 0.6302489638328552, acc = 0.8056640625\n",
      "Batch 3: loss = 0.6289892792701721, acc = 0.80078125\n",
      "Batch 4: loss = 0.5608287453651428, acc = 0.828125\n",
      "Batch 5: loss = 0.5952374935150146, acc = 0.8056640625\n",
      "Batch 6: loss = 0.6278854012489319, acc = 0.798828125\n",
      "Batch 7: loss = 0.536596417427063, acc = 0.8232421875\n",
      "Batch 8: loss = 0.5472420454025269, acc = 0.81640625\n",
      "Batch 9: loss = 0.5218566060066223, acc = 0.8349609375\n",
      "Batch 10: loss = 0.513898491859436, acc = 0.8349609375\n",
      "Batch 11: loss = 0.5595438480377197, acc = 0.8115234375\n",
      "Batch 12: loss = 0.530830979347229, acc = 0.822265625\n",
      "Batch 13: loss = 0.5301625728607178, acc = 0.828125\n",
      "Batch 14: loss = 0.5428404211997986, acc = 0.8173828125\n",
      "Batch 15: loss = 0.5059597492218018, acc = 0.8369140625\n",
      "Batch 16: loss = 0.5607898831367493, acc = 0.828125\n",
      "Batch 17: loss = 0.5460996031761169, acc = 0.826171875\n",
      "Batch 18: loss = 0.5889227986335754, acc = 0.822265625\n",
      "Batch 19: loss = 0.5421422719955444, acc = 0.826171875\n",
      "Batch 20: loss = 0.5460432767868042, acc = 0.8173828125\n",
      "Batch 21: loss = 0.585284948348999, acc = 0.802734375\n",
      "Batch 22: loss = 0.5265272855758667, acc = 0.8291015625\n",
      "Batch 23: loss = 0.5620620846748352, acc = 0.796875\n",
      "Batch 24: loss = 0.5334893465042114, acc = 0.830078125\n",
      "Batch 25: loss = 0.5420617461204529, acc = 0.8212890625\n",
      "Batch 26: loss = 0.5378632545471191, acc = 0.8154296875\n",
      "Batch 27: loss = 0.6175758838653564, acc = 0.796875\n",
      "Batch 28: loss = 0.6278112530708313, acc = 0.7724609375\n",
      "Batch 29: loss = 0.5646732449531555, acc = 0.8173828125\n",
      "Batch 30: loss = 0.5403447151184082, acc = 0.814453125\n",
      "Batch 31: loss = 0.5670878887176514, acc = 0.8232421875\n",
      "Batch 32: loss = 0.6729784607887268, acc = 0.78515625\n",
      "Batch 33: loss = 0.5586621165275574, acc = 0.818359375\n",
      "Batch 34: loss = 0.5679354667663574, acc = 0.822265625\n",
      "Batch 35: loss = 0.5359467267990112, acc = 0.8291015625\n",
      "Batch 36: loss = 0.5452576279640198, acc = 0.8271484375\n",
      "Batch 37: loss = 0.5278916358947754, acc = 0.8212890625\n",
      "Batch 38: loss = 0.5477475523948669, acc = 0.8251953125\n",
      "Batch 39: loss = 0.5353708267211914, acc = 0.83203125\n",
      "Batch 40: loss = 0.5645321607589722, acc = 0.8037109375\n",
      "Batch 41: loss = 0.47395503520965576, acc = 0.837890625\n",
      "Batch 42: loss = 0.5491371154785156, acc = 0.8134765625\n",
      "Batch 43: loss = 0.600104808807373, acc = 0.8017578125\n",
      "Batch 44: loss = 0.5147199630737305, acc = 0.8486328125\n",
      "Batch 45: loss = 0.4660424590110779, acc = 0.84765625\n",
      "Batch 46: loss = 0.5135371685028076, acc = 0.8369140625\n",
      "Batch 47: loss = 0.5338178277015686, acc = 0.8291015625\n",
      "Batch 48: loss = 0.5298839807510376, acc = 0.8251953125\n",
      "Batch 49: loss = 0.45260143280029297, acc = 0.853515625\n",
      "Batch 50: loss = 0.5022265911102295, acc = 0.8388671875\n",
      "Batch 51: loss = 0.48303288221359253, acc = 0.841796875\n",
      "Batch 52: loss = 0.528012216091156, acc = 0.8212890625\n",
      "Batch 53: loss = 0.5473746061325073, acc = 0.8173828125\n",
      "Batch 54: loss = 0.4682248830795288, acc = 0.845703125\n",
      "Batch 55: loss = 0.4704592227935791, acc = 0.853515625\n",
      "Batch 56: loss = 0.5650979280471802, acc = 0.802734375\n",
      "Batch 57: loss = 0.6079345941543579, acc = 0.798828125\n",
      "Batch 58: loss = 0.592885434627533, acc = 0.7939453125\n",
      "Batch 59: loss = 0.4400574564933777, acc = 0.853515625\n",
      "Batch 60: loss = 0.5460116267204285, acc = 0.80859375\n",
      "Batch 61: loss = 0.513007402420044, acc = 0.841796875\n",
      "Batch 62: loss = 0.6700701713562012, acc = 0.7763671875\n",
      "Batch 63: loss = 0.5897375345230103, acc = 0.810546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 64: loss = 0.4688211679458618, acc = 0.84375\n",
      "Batch 65: loss = 0.5578808784484863, acc = 0.8076171875\n",
      "Batch 66: loss = 0.535666286945343, acc = 0.8125\n",
      "Batch 67: loss = 0.5399871468544006, acc = 0.8203125\n",
      "Batch 68: loss = 0.5709943771362305, acc = 0.8134765625\n",
      "Batch 69: loss = 0.49492865800857544, acc = 0.8408203125\n",
      "Batch 70: loss = 0.6482939720153809, acc = 0.78515625\n",
      "Batch 71: loss = 0.5459994077682495, acc = 0.806640625\n",
      "Batch 72: loss = 0.5258573293685913, acc = 0.8388671875\n",
      "Batch 73: loss = 0.5964784622192383, acc = 0.80859375\n",
      "Batch 74: loss = 0.5957088470458984, acc = 0.7978515625\n",
      "Batch 75: loss = 0.6652376651763916, acc = 0.7666015625\n",
      "Batch 76: loss = 0.5963574647903442, acc = 0.8017578125\n",
      "Batch 77: loss = 0.5435152053833008, acc = 0.818359375\n",
      "Batch 78: loss = 0.5585391521453857, acc = 0.81640625\n",
      "Batch 79: loss = 0.49748554825782776, acc = 0.8251953125\n",
      "Batch 80: loss = 0.5241595506668091, acc = 0.8125\n",
      "Batch 81: loss = 0.5465550422668457, acc = 0.80859375\n",
      "Batch 82: loss = 0.5179275274276733, acc = 0.828125\n",
      "Batch 83: loss = 0.5482505559921265, acc = 0.814453125\n",
      "Batch 84: loss = 0.5498653054237366, acc = 0.8134765625\n",
      "Batch 85: loss = 0.601719856262207, acc = 0.79296875\n",
      "Batch 86: loss = 0.5433076620101929, acc = 0.8203125\n",
      "Batch 87: loss = 0.5235946178436279, acc = 0.8271484375\n",
      "Batch 88: loss = 0.6572281718254089, acc = 0.77734375\n",
      "Batch 89: loss = 0.5472192764282227, acc = 0.8193359375\n",
      "Batch 90: loss = 0.6061849594116211, acc = 0.814453125\n",
      "Batch 91: loss = 0.566562294960022, acc = 0.8056640625\n",
      "Batch 92: loss = 0.5970317125320435, acc = 0.79296875\n",
      "Batch 93: loss = 0.4641648530960083, acc = 0.8525390625\n",
      "Batch 94: loss = 0.4834974706172943, acc = 0.833984375\n",
      "Batch 95: loss = 0.48291486501693726, acc = 0.83984375\n",
      "Batch 96: loss = 0.5841661691665649, acc = 0.8056640625\n",
      "Batch 97: loss = 0.5820387601852417, acc = 0.8212890625\n",
      "Batch 98: loss = 0.5486874580383301, acc = 0.82421875\n",
      "Batch 99: loss = 0.5452084541320801, acc = 0.8251953125\n",
      "Batch 100: loss = 0.5439683794975281, acc = 0.8076171875\n",
      "Batch 101: loss = 0.5443229079246521, acc = 0.8173828125\n",
      "Batch 102: loss = 0.5743199586868286, acc = 0.81640625\n",
      "Batch 103: loss = 0.567699134349823, acc = 0.806640625\n",
      "Batch 104: loss = 0.5246962308883667, acc = 0.82421875\n",
      "Batch 105: loss = 0.5588947534561157, acc = 0.822265625\n",
      "Batch 106: loss = 0.5542425513267517, acc = 0.822265625\n",
      "Batch 107: loss = 0.520159900188446, acc = 0.8203125\n",
      "Batch 108: loss = 0.517027735710144, acc = 0.8291015625\n",
      "Batch 109: loss = 0.5208081603050232, acc = 0.82421875\n",
      "Batch 110: loss = 0.4779789447784424, acc = 0.84375\n",
      "Batch 111: loss = 0.5757075548171997, acc = 0.7978515625\n",
      "Batch 112: loss = 0.5369772911071777, acc = 0.8154296875\n",
      "Batch 113: loss = 0.5740516185760498, acc = 0.8076171875\n",
      "Batch 114: loss = 0.5721336603164673, acc = 0.8232421875\n",
      "Batch 115: loss = 0.5683831572532654, acc = 0.8154296875\n",
      "Batch 116: loss = 0.5537126064300537, acc = 0.826171875\n",
      "Batch 117: loss = 0.5455777645111084, acc = 0.826171875\n",
      "Batch 118: loss = 0.4626171588897705, acc = 0.8505859375\n",
      "Batch 119: loss = 0.5393879413604736, acc = 0.8193359375\n",
      "Batch 120: loss = 0.5017791986465454, acc = 0.8408203125\n",
      "Batch 121: loss = 0.5508130788803101, acc = 0.818359375\n",
      "Batch 122: loss = 0.49398425221443176, acc = 0.8271484375\n",
      "Batch 123: loss = 0.5476959943771362, acc = 0.830078125\n",
      "Batch 124: loss = 0.5990246534347534, acc = 0.787109375\n",
      "Batch 125: loss = 0.5924344658851624, acc = 0.802734375\n",
      "Batch 126: loss = 0.5768084526062012, acc = 0.8115234375\n",
      "\n",
      "Epoch 39/100\n",
      "Batch 1: loss = 0.7298179864883423, acc = 0.783203125\n",
      "Batch 2: loss = 0.6061034798622131, acc = 0.80078125\n",
      "Batch 3: loss = 0.5726290345191956, acc = 0.822265625\n",
      "Batch 4: loss = 0.5592295527458191, acc = 0.826171875\n",
      "Batch 5: loss = 0.5676164627075195, acc = 0.8193359375\n",
      "Batch 6: loss = 0.5977991819381714, acc = 0.78125\n",
      "Batch 7: loss = 0.5456861853599548, acc = 0.8349609375\n",
      "Batch 8: loss = 0.54948890209198, acc = 0.8349609375\n",
      "Batch 9: loss = 0.526796817779541, acc = 0.8271484375\n",
      "Batch 10: loss = 0.4835137128829956, acc = 0.83203125\n",
      "Batch 11: loss = 0.5536632537841797, acc = 0.8251953125\n",
      "Batch 12: loss = 0.5285800695419312, acc = 0.8173828125\n",
      "Batch 13: loss = 0.5012251138687134, acc = 0.8203125\n",
      "Batch 14: loss = 0.5211861729621887, acc = 0.8388671875\n",
      "Batch 15: loss = 0.5168731808662415, acc = 0.828125\n",
      "Batch 16: loss = 0.5416308641433716, acc = 0.8193359375\n",
      "Batch 17: loss = 0.5333837270736694, acc = 0.833984375\n",
      "Batch 18: loss = 0.5516014099121094, acc = 0.818359375\n",
      "Batch 19: loss = 0.5380179286003113, acc = 0.828125\n",
      "Batch 20: loss = 0.5216268301010132, acc = 0.8232421875\n",
      "Batch 21: loss = 0.5660118460655212, acc = 0.818359375\n",
      "Batch 22: loss = 0.5584641695022583, acc = 0.810546875\n",
      "Batch 23: loss = 0.5217851996421814, acc = 0.8251953125\n",
      "Batch 24: loss = 0.5131152868270874, acc = 0.8251953125\n",
      "Batch 25: loss = 0.5221877694129944, acc = 0.83984375\n",
      "Batch 26: loss = 0.5333991646766663, acc = 0.8251953125\n",
      "Batch 27: loss = 0.633741021156311, acc = 0.7802734375\n",
      "Batch 28: loss = 0.603425920009613, acc = 0.7919921875\n",
      "Batch 29: loss = 0.5699763894081116, acc = 0.8203125\n",
      "Batch 30: loss = 0.5279185771942139, acc = 0.810546875\n",
      "Batch 31: loss = 0.5732098817825317, acc = 0.8291015625\n",
      "Batch 32: loss = 0.6533215045928955, acc = 0.78125\n",
      "Batch 33: loss = 0.5382035970687866, acc = 0.826171875\n",
      "Batch 34: loss = 0.558260977268219, acc = 0.8232421875\n",
      "Batch 35: loss = 0.5197340250015259, acc = 0.841796875\n",
      "Batch 36: loss = 0.5134492516517639, acc = 0.8251953125\n",
      "Batch 37: loss = 0.5181673765182495, acc = 0.83203125\n",
      "Batch 38: loss = 0.5467050075531006, acc = 0.822265625\n",
      "Batch 39: loss = 0.5072776079177856, acc = 0.828125\n",
      "Batch 40: loss = 0.5564130544662476, acc = 0.80078125\n",
      "Batch 41: loss = 0.5120111703872681, acc = 0.822265625\n",
      "Batch 42: loss = 0.5256823897361755, acc = 0.826171875\n",
      "Batch 43: loss = 0.5486421585083008, acc = 0.8193359375\n",
      "Batch 44: loss = 0.5071011781692505, acc = 0.8330078125\n",
      "Batch 45: loss = 0.4715440273284912, acc = 0.8427734375\n",
      "Batch 46: loss = 0.49640706181526184, acc = 0.8369140625\n",
      "Batch 47: loss = 0.5126404166221619, acc = 0.8369140625\n",
      "Batch 48: loss = 0.5485885739326477, acc = 0.8134765625\n",
      "Batch 49: loss = 0.4925538897514343, acc = 0.8349609375\n",
      "Batch 50: loss = 0.4904741644859314, acc = 0.8427734375\n",
      "Batch 51: loss = 0.5128783583641052, acc = 0.826171875\n",
      "Batch 52: loss = 0.518154501914978, acc = 0.82421875\n",
      "Batch 53: loss = 0.5563637018203735, acc = 0.8125\n",
      "Batch 54: loss = 0.4648837447166443, acc = 0.841796875\n",
      "Batch 55: loss = 0.4570382833480835, acc = 0.8515625\n",
      "Batch 56: loss = 0.5112513303756714, acc = 0.8271484375\n",
      "Batch 57: loss = 0.5806242227554321, acc = 0.8046875\n",
      "Batch 58: loss = 0.5680303573608398, acc = 0.796875\n",
      "Batch 59: loss = 0.424318790435791, acc = 0.861328125\n",
      "Batch 60: loss = 0.5271633863449097, acc = 0.8291015625\n",
      "Batch 61: loss = 0.4979192018508911, acc = 0.8388671875\n",
      "Batch 62: loss = 0.6382890939712524, acc = 0.787109375\n",
      "Batch 63: loss = 0.5357702970504761, acc = 0.818359375\n",
      "Batch 64: loss = 0.4730786085128784, acc = 0.841796875\n",
      "Batch 65: loss = 0.5485870838165283, acc = 0.818359375\n",
      "Batch 66: loss = 0.5565299987792969, acc = 0.80859375\n",
      "Batch 67: loss = 0.5222643613815308, acc = 0.8173828125\n",
      "Batch 68: loss = 0.549454927444458, acc = 0.8291015625\n",
      "Batch 69: loss = 0.46561944484710693, acc = 0.84375\n",
      "Batch 70: loss = 0.6199342012405396, acc = 0.7919921875\n",
      "Batch 71: loss = 0.5859358310699463, acc = 0.8037109375\n",
      "Batch 72: loss = 0.49585431814193726, acc = 0.849609375\n",
      "Batch 73: loss = 0.5817765593528748, acc = 0.80078125\n",
      "Batch 74: loss = 0.5941872596740723, acc = 0.806640625\n",
      "Batch 75: loss = 0.637649416923523, acc = 0.7919921875\n",
      "Batch 76: loss = 0.5934007167816162, acc = 0.798828125\n",
      "Batch 77: loss = 0.5556213855743408, acc = 0.814453125\n",
      "Batch 78: loss = 0.5379259586334229, acc = 0.8115234375\n",
      "Batch 79: loss = 0.4660030007362366, acc = 0.83984375\n",
      "Batch 80: loss = 0.5103869438171387, acc = 0.822265625\n",
      "Batch 81: loss = 0.5386325120925903, acc = 0.8212890625\n",
      "Batch 82: loss = 0.5138520002365112, acc = 0.8359375\n",
      "Batch 83: loss = 0.537992537021637, acc = 0.828125\n",
      "Batch 84: loss = 0.506248950958252, acc = 0.830078125\n",
      "Batch 85: loss = 0.5664111375808716, acc = 0.8154296875\n",
      "Batch 86: loss = 0.5280160307884216, acc = 0.814453125\n",
      "Batch 87: loss = 0.49887174367904663, acc = 0.833984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 88: loss = 0.6314699053764343, acc = 0.798828125\n",
      "Batch 89: loss = 0.5111581087112427, acc = 0.830078125\n",
      "Batch 90: loss = 0.5607823133468628, acc = 0.81640625\n",
      "Batch 91: loss = 0.5706008672714233, acc = 0.8017578125\n",
      "Batch 92: loss = 0.5500513911247253, acc = 0.8212890625\n",
      "Batch 93: loss = 0.44781821966171265, acc = 0.86328125\n",
      "Batch 94: loss = 0.47571122646331787, acc = 0.8447265625\n",
      "Batch 95: loss = 0.4834097623825073, acc = 0.84375\n",
      "Batch 96: loss = 0.5608240365982056, acc = 0.810546875\n",
      "Batch 97: loss = 0.5540503263473511, acc = 0.8330078125\n",
      "Batch 98: loss = 0.5519479513168335, acc = 0.8232421875\n",
      "Batch 99: loss = 0.544235348701477, acc = 0.818359375\n",
      "Batch 100: loss = 0.5508031845092773, acc = 0.8212890625\n",
      "Batch 101: loss = 0.5304598808288574, acc = 0.82421875\n",
      "Batch 102: loss = 0.5418335795402527, acc = 0.8271484375\n",
      "Batch 103: loss = 0.5240155458450317, acc = 0.8193359375\n",
      "Batch 104: loss = 0.49108564853668213, acc = 0.83203125\n",
      "Batch 105: loss = 0.5238724946975708, acc = 0.826171875\n",
      "Batch 106: loss = 0.5403803586959839, acc = 0.8251953125\n",
      "Batch 107: loss = 0.5216196775436401, acc = 0.830078125\n",
      "Batch 108: loss = 0.505444347858429, acc = 0.8212890625\n",
      "Batch 109: loss = 0.5532000064849854, acc = 0.8134765625\n",
      "Batch 110: loss = 0.48016542196273804, acc = 0.8359375\n",
      "Batch 111: loss = 0.5480916500091553, acc = 0.822265625\n",
      "Batch 112: loss = 0.5323183536529541, acc = 0.82421875\n",
      "Batch 113: loss = 0.550412118434906, acc = 0.81640625\n",
      "Batch 114: loss = 0.5323595404624939, acc = 0.8349609375\n",
      "Batch 115: loss = 0.5528033971786499, acc = 0.8154296875\n",
      "Batch 116: loss = 0.5923363566398621, acc = 0.8046875\n",
      "Batch 117: loss = 0.535902738571167, acc = 0.8349609375\n",
      "Batch 118: loss = 0.43473806977272034, acc = 0.85546875\n",
      "Batch 119: loss = 0.5204492211341858, acc = 0.8310546875\n",
      "Batch 120: loss = 0.5049660801887512, acc = 0.8203125\n",
      "Batch 121: loss = 0.5413988828659058, acc = 0.83203125\n",
      "Batch 122: loss = 0.5209582448005676, acc = 0.8251953125\n",
      "Batch 123: loss = 0.5459719896316528, acc = 0.8203125\n",
      "Batch 124: loss = 0.5595519542694092, acc = 0.8125\n",
      "Batch 125: loss = 0.6067822575569153, acc = 0.8046875\n",
      "Batch 126: loss = 0.5559890270233154, acc = 0.830078125\n",
      "\n",
      "Epoch 40/100\n",
      "Batch 1: loss = 0.7012898921966553, acc = 0.80078125\n",
      "Batch 2: loss = 0.5840071439743042, acc = 0.8134765625\n",
      "Batch 3: loss = 0.5922234058380127, acc = 0.814453125\n",
      "Batch 4: loss = 0.5250418186187744, acc = 0.833984375\n",
      "Batch 5: loss = 0.5941613912582397, acc = 0.8115234375\n",
      "Batch 6: loss = 0.5642799139022827, acc = 0.8154296875\n",
      "Batch 7: loss = 0.529435396194458, acc = 0.83203125\n",
      "Batch 8: loss = 0.5327135920524597, acc = 0.828125\n",
      "Batch 9: loss = 0.5163953304290771, acc = 0.8359375\n",
      "Batch 10: loss = 0.47835952043533325, acc = 0.833984375\n",
      "Batch 11: loss = 0.520142674446106, acc = 0.826171875\n",
      "Batch 12: loss = 0.5264912843704224, acc = 0.8251953125\n",
      "Batch 13: loss = 0.5197349190711975, acc = 0.8203125\n",
      "Batch 14: loss = 0.5480826497077942, acc = 0.826171875\n",
      "Batch 15: loss = 0.5333954095840454, acc = 0.828125\n",
      "Batch 16: loss = 0.5516660809516907, acc = 0.8095703125\n",
      "Batch 17: loss = 0.5210256576538086, acc = 0.8271484375\n",
      "Batch 18: loss = 0.5467172861099243, acc = 0.83203125\n",
      "Batch 19: loss = 0.5085039734840393, acc = 0.837890625\n",
      "Batch 20: loss = 0.5002285242080688, acc = 0.83203125\n",
      "Batch 21: loss = 0.5820721387863159, acc = 0.8056640625\n",
      "Batch 22: loss = 0.5569965839385986, acc = 0.8115234375\n",
      "Batch 23: loss = 0.5103538632392883, acc = 0.826171875\n",
      "Batch 24: loss = 0.510483980178833, acc = 0.8310546875\n",
      "Batch 25: loss = 0.5184013843536377, acc = 0.826171875\n",
      "Batch 26: loss = 0.5237826704978943, acc = 0.828125\n",
      "Batch 27: loss = 0.5962883234024048, acc = 0.810546875\n",
      "Batch 28: loss = 0.5878643989562988, acc = 0.7998046875\n",
      "Batch 29: loss = 0.5676517486572266, acc = 0.8173828125\n",
      "Batch 30: loss = 0.5430816411972046, acc = 0.8154296875\n",
      "Batch 31: loss = 0.5935215353965759, acc = 0.8125\n",
      "Batch 32: loss = 0.6476075649261475, acc = 0.787109375\n",
      "Batch 33: loss = 0.5536956787109375, acc = 0.8095703125\n",
      "Batch 34: loss = 0.5445070266723633, acc = 0.822265625\n",
      "Batch 35: loss = 0.521527886390686, acc = 0.830078125\n",
      "Batch 36: loss = 0.49587035179138184, acc = 0.833984375\n",
      "Batch 37: loss = 0.5028733015060425, acc = 0.8408203125\n",
      "Batch 38: loss = 0.5208656191825867, acc = 0.8291015625\n",
      "Batch 39: loss = 0.4847416877746582, acc = 0.833984375\n",
      "Batch 40: loss = 0.5499665141105652, acc = 0.8115234375\n",
      "Batch 41: loss = 0.4650229215621948, acc = 0.8447265625\n",
      "Batch 42: loss = 0.5212720632553101, acc = 0.8203125\n",
      "Batch 43: loss = 0.5374163389205933, acc = 0.814453125\n",
      "Batch 44: loss = 0.49708738923072815, acc = 0.84375\n",
      "Batch 45: loss = 0.4419214427471161, acc = 0.8447265625\n",
      "Batch 46: loss = 0.47321808338165283, acc = 0.8427734375\n",
      "Batch 47: loss = 0.5123888850212097, acc = 0.8330078125\n",
      "Batch 48: loss = 0.48657214641571045, acc = 0.841796875\n",
      "Batch 49: loss = 0.4308938980102539, acc = 0.853515625\n",
      "Batch 50: loss = 0.46626242995262146, acc = 0.84375\n",
      "Batch 51: loss = 0.4675929844379425, acc = 0.8408203125\n",
      "Batch 52: loss = 0.5326141119003296, acc = 0.8251953125\n",
      "Batch 53: loss = 0.5221025347709656, acc = 0.82421875\n",
      "Batch 54: loss = 0.43546605110168457, acc = 0.8642578125\n",
      "Batch 55: loss = 0.44754037261009216, acc = 0.8740234375\n",
      "Batch 56: loss = 0.5124965906143188, acc = 0.81640625\n",
      "Batch 57: loss = 0.5497635006904602, acc = 0.8173828125\n",
      "Batch 58: loss = 0.562613844871521, acc = 0.806640625\n",
      "Batch 59: loss = 0.4213523268699646, acc = 0.865234375\n",
      "Batch 60: loss = 0.5366737842559814, acc = 0.8125\n",
      "Batch 61: loss = 0.49292394518852234, acc = 0.841796875\n",
      "Batch 62: loss = 0.6272081136703491, acc = 0.783203125\n",
      "Batch 63: loss = 0.509358286857605, acc = 0.841796875\n",
      "Batch 64: loss = 0.47927412390708923, acc = 0.8447265625\n",
      "Batch 65: loss = 0.5403311252593994, acc = 0.818359375\n",
      "Batch 66: loss = 0.5201982259750366, acc = 0.818359375\n",
      "Batch 67: loss = 0.47821223735809326, acc = 0.8349609375\n",
      "Batch 68: loss = 0.5275474786758423, acc = 0.8349609375\n",
      "Batch 69: loss = 0.45482414960861206, acc = 0.853515625\n",
      "Batch 70: loss = 0.5958240628242493, acc = 0.802734375\n",
      "Batch 71: loss = 0.5542758703231812, acc = 0.802734375\n",
      "Batch 72: loss = 0.4952857196331024, acc = 0.84375\n",
      "Batch 73: loss = 0.553124189376831, acc = 0.8232421875\n",
      "Batch 74: loss = 0.5926780700683594, acc = 0.80859375\n",
      "Batch 75: loss = 0.6270461678504944, acc = 0.77734375\n",
      "Batch 76: loss = 0.5888720750808716, acc = 0.7978515625\n",
      "Batch 77: loss = 0.5126714706420898, acc = 0.8369140625\n",
      "Batch 78: loss = 0.5309168100357056, acc = 0.83203125\n",
      "Batch 79: loss = 0.44577014446258545, acc = 0.8525390625\n",
      "Batch 80: loss = 0.4729676842689514, acc = 0.8154296875\n",
      "Batch 81: loss = 0.5246182680130005, acc = 0.814453125\n",
      "Batch 82: loss = 0.4784831404685974, acc = 0.8466796875\n",
      "Batch 83: loss = 0.5097261667251587, acc = 0.822265625\n",
      "Batch 84: loss = 0.5164164304733276, acc = 0.8212890625\n",
      "Batch 85: loss = 0.585433840751648, acc = 0.8056640625\n",
      "Batch 86: loss = 0.5520071983337402, acc = 0.81640625\n",
      "Batch 87: loss = 0.5242197513580322, acc = 0.822265625\n",
      "Batch 88: loss = 0.6108616590499878, acc = 0.8017578125\n",
      "Batch 89: loss = 0.4946766197681427, acc = 0.8408203125\n",
      "Batch 90: loss = 0.5672070980072021, acc = 0.814453125\n",
      "Batch 91: loss = 0.568658173084259, acc = 0.8095703125\n",
      "Batch 92: loss = 0.5494866371154785, acc = 0.8232421875\n",
      "Batch 93: loss = 0.45742881298065186, acc = 0.84765625\n",
      "Batch 94: loss = 0.4781149625778198, acc = 0.8369140625\n",
      "Batch 95: loss = 0.5023611783981323, acc = 0.8359375\n",
      "Batch 96: loss = 0.5643799901008606, acc = 0.8154296875\n",
      "Batch 97: loss = 0.5501542091369629, acc = 0.828125\n",
      "Batch 98: loss = 0.5224270820617676, acc = 0.8427734375\n",
      "Batch 99: loss = 0.5185613632202148, acc = 0.8310546875\n",
      "Batch 100: loss = 0.5268070697784424, acc = 0.82421875\n",
      "Batch 101: loss = 0.4758429527282715, acc = 0.83984375\n",
      "Batch 102: loss = 0.5374375581741333, acc = 0.8291015625\n",
      "Batch 103: loss = 0.5287704467773438, acc = 0.8427734375\n",
      "Batch 104: loss = 0.4957443177700043, acc = 0.8466796875\n",
      "Batch 105: loss = 0.5012933611869812, acc = 0.8388671875\n",
      "Batch 106: loss = 0.517697811126709, acc = 0.8232421875\n",
      "Batch 107: loss = 0.5060769319534302, acc = 0.8408203125\n",
      "Batch 108: loss = 0.5059523582458496, acc = 0.8369140625\n",
      "Batch 109: loss = 0.4955544173717499, acc = 0.841796875\n",
      "Batch 110: loss = 0.47265350818634033, acc = 0.841796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 111: loss = 0.5528649091720581, acc = 0.806640625\n",
      "Batch 112: loss = 0.5346890687942505, acc = 0.8173828125\n",
      "Batch 113: loss = 0.5302765965461731, acc = 0.8154296875\n",
      "Batch 114: loss = 0.5420624017715454, acc = 0.833984375\n",
      "Batch 115: loss = 0.5441997647285461, acc = 0.828125\n",
      "Batch 116: loss = 0.5479592680931091, acc = 0.822265625\n",
      "Batch 117: loss = 0.500209629535675, acc = 0.833984375\n",
      "Batch 118: loss = 0.4187026023864746, acc = 0.853515625\n",
      "Batch 119: loss = 0.5140438675880432, acc = 0.8349609375\n",
      "Batch 120: loss = 0.4864858388900757, acc = 0.83203125\n",
      "Batch 121: loss = 0.5486366748809814, acc = 0.828125\n",
      "Batch 122: loss = 0.5003310441970825, acc = 0.8359375\n",
      "Batch 123: loss = 0.5207576751708984, acc = 0.8349609375\n",
      "Batch 124: loss = 0.559549868106842, acc = 0.806640625\n",
      "Batch 125: loss = 0.6079728603363037, acc = 0.791015625\n",
      "Batch 126: loss = 0.5231449604034424, acc = 0.833984375\n",
      "Saved checkpoint to weights.40.h5\n",
      "\n",
      "Epoch 41/100\n",
      "Batch 1: loss = 0.6933864951133728, acc = 0.791015625\n",
      "Batch 2: loss = 0.59336918592453, acc = 0.796875\n",
      "Batch 3: loss = 0.5513050556182861, acc = 0.8330078125\n",
      "Batch 4: loss = 0.5405212640762329, acc = 0.8447265625\n",
      "Batch 5: loss = 0.5592830181121826, acc = 0.8203125\n",
      "Batch 6: loss = 0.5656267404556274, acc = 0.8193359375\n",
      "Batch 7: loss = 0.551252007484436, acc = 0.814453125\n",
      "Batch 8: loss = 0.5378222465515137, acc = 0.8203125\n",
      "Batch 9: loss = 0.47914716601371765, acc = 0.841796875\n",
      "Batch 10: loss = 0.4772403836250305, acc = 0.841796875\n",
      "Batch 11: loss = 0.5368167161941528, acc = 0.8056640625\n",
      "Batch 12: loss = 0.536794900894165, acc = 0.814453125\n",
      "Batch 13: loss = 0.45180994272232056, acc = 0.8515625\n",
      "Batch 14: loss = 0.5241633653640747, acc = 0.837890625\n",
      "Batch 15: loss = 0.4965512752532959, acc = 0.8427734375\n",
      "Batch 16: loss = 0.5427237749099731, acc = 0.8203125\n",
      "Batch 17: loss = 0.49107325077056885, acc = 0.8359375\n",
      "Batch 18: loss = 0.5561606884002686, acc = 0.814453125\n",
      "Batch 19: loss = 0.5167920589447021, acc = 0.83203125\n",
      "Batch 20: loss = 0.48337358236312866, acc = 0.8369140625\n",
      "Batch 21: loss = 0.5352753400802612, acc = 0.814453125\n",
      "Batch 22: loss = 0.5095755457878113, acc = 0.82421875\n",
      "Batch 23: loss = 0.5086858868598938, acc = 0.833984375\n",
      "Batch 24: loss = 0.4989268481731415, acc = 0.828125\n",
      "Batch 25: loss = 0.4953986406326294, acc = 0.837890625\n",
      "Batch 26: loss = 0.4797104001045227, acc = 0.8427734375\n",
      "Batch 27: loss = 0.5905647277832031, acc = 0.798828125\n",
      "Batch 28: loss = 0.594437301158905, acc = 0.8037109375\n",
      "Batch 29: loss = 0.5579482316970825, acc = 0.8193359375\n",
      "Batch 30: loss = 0.5058478116989136, acc = 0.830078125\n",
      "Batch 31: loss = 0.5603636503219604, acc = 0.8173828125\n",
      "Batch 32: loss = 0.577802836894989, acc = 0.826171875\n",
      "Batch 33: loss = 0.4912271201610565, acc = 0.8388671875\n",
      "Batch 34: loss = 0.5225690007209778, acc = 0.8310546875\n",
      "Batch 35: loss = 0.5299012660980225, acc = 0.841796875\n",
      "Batch 36: loss = 0.5190087556838989, acc = 0.837890625\n",
      "Batch 37: loss = 0.5063438415527344, acc = 0.83984375\n",
      "Batch 38: loss = 0.5361915826797485, acc = 0.8310546875\n",
      "Batch 39: loss = 0.4819927513599396, acc = 0.8388671875\n",
      "Batch 40: loss = 0.533174991607666, acc = 0.82421875\n",
      "Batch 41: loss = 0.4426422715187073, acc = 0.861328125\n",
      "Batch 42: loss = 0.4975343942642212, acc = 0.8369140625\n",
      "Batch 43: loss = 0.5400463938713074, acc = 0.81640625\n",
      "Batch 44: loss = 0.5002720355987549, acc = 0.84765625\n",
      "Batch 45: loss = 0.4747610092163086, acc = 0.845703125\n",
      "Batch 46: loss = 0.48418599367141724, acc = 0.845703125\n",
      "Batch 47: loss = 0.47577452659606934, acc = 0.8447265625\n",
      "Batch 48: loss = 0.48957616090774536, acc = 0.8388671875\n",
      "Batch 49: loss = 0.4648623764514923, acc = 0.84375\n",
      "Batch 50: loss = 0.43736234307289124, acc = 0.857421875\n",
      "Batch 51: loss = 0.4654770493507385, acc = 0.8388671875\n",
      "Batch 52: loss = 0.5082764625549316, acc = 0.8408203125\n",
      "Batch 53: loss = 0.5275269746780396, acc = 0.8154296875\n",
      "Batch 54: loss = 0.4251047372817993, acc = 0.85546875\n",
      "Batch 55: loss = 0.4492921531200409, acc = 0.849609375\n",
      "Batch 56: loss = 0.5186179876327515, acc = 0.8173828125\n",
      "Batch 57: loss = 0.5155479907989502, acc = 0.8310546875\n",
      "Batch 58: loss = 0.5916693210601807, acc = 0.7880859375\n",
      "Batch 59: loss = 0.40376800298690796, acc = 0.8671875\n",
      "Batch 60: loss = 0.5096089839935303, acc = 0.828125\n",
      "Batch 61: loss = 0.4673214554786682, acc = 0.84765625\n",
      "Batch 62: loss = 0.587103545665741, acc = 0.8134765625\n",
      "Batch 63: loss = 0.5314433574676514, acc = 0.822265625\n",
      "Batch 64: loss = 0.4694167971611023, acc = 0.841796875\n",
      "Batch 65: loss = 0.515080988407135, acc = 0.8271484375\n",
      "Batch 66: loss = 0.5495407581329346, acc = 0.814453125\n",
      "Batch 67: loss = 0.49643880128860474, acc = 0.830078125\n",
      "Batch 68: loss = 0.5205891132354736, acc = 0.8310546875\n",
      "Batch 69: loss = 0.4521326422691345, acc = 0.8603515625\n",
      "Batch 70: loss = 0.5665966272354126, acc = 0.80859375\n",
      "Batch 71: loss = 0.5058508515357971, acc = 0.8310546875\n",
      "Batch 72: loss = 0.45321211218833923, acc = 0.859375\n",
      "Batch 73: loss = 0.5522191524505615, acc = 0.8154296875\n",
      "Batch 74: loss = 0.5457957983016968, acc = 0.814453125\n",
      "Batch 75: loss = 0.6388651728630066, acc = 0.7919921875\n",
      "Batch 76: loss = 0.548835277557373, acc = 0.8125\n",
      "Batch 77: loss = 0.50334233045578, acc = 0.8369140625\n",
      "Batch 78: loss = 0.5147313475608826, acc = 0.8349609375\n",
      "Batch 79: loss = 0.4549180269241333, acc = 0.841796875\n",
      "Batch 80: loss = 0.4858887791633606, acc = 0.8291015625\n",
      "Batch 81: loss = 0.5138781666755676, acc = 0.814453125\n",
      "Batch 82: loss = 0.491649329662323, acc = 0.8369140625\n",
      "Batch 83: loss = 0.5136759281158447, acc = 0.8232421875\n",
      "Batch 84: loss = 0.493405282497406, acc = 0.8291015625\n",
      "Batch 85: loss = 0.5830947160720825, acc = 0.798828125\n",
      "Batch 86: loss = 0.49801743030548096, acc = 0.8271484375\n",
      "Batch 87: loss = 0.4958544969558716, acc = 0.8427734375\n",
      "Batch 88: loss = 0.6016466617584229, acc = 0.8115234375\n",
      "Batch 89: loss = 0.5175420045852661, acc = 0.8359375\n",
      "Batch 90: loss = 0.540303111076355, acc = 0.8271484375\n",
      "Batch 91: loss = 0.5120867490768433, acc = 0.830078125\n",
      "Batch 92: loss = 0.5599772930145264, acc = 0.8076171875\n",
      "Batch 93: loss = 0.45445263385772705, acc = 0.8583984375\n",
      "Batch 94: loss = 0.46910688281059265, acc = 0.853515625\n",
      "Batch 95: loss = 0.47020140290260315, acc = 0.8447265625\n",
      "Batch 96: loss = 0.5607140064239502, acc = 0.80859375\n",
      "Batch 97: loss = 0.5246562957763672, acc = 0.8251953125\n",
      "Batch 98: loss = 0.517112135887146, acc = 0.8271484375\n",
      "Batch 99: loss = 0.5264142751693726, acc = 0.7978515625\n",
      "Batch 100: loss = 0.5156976580619812, acc = 0.822265625\n",
      "Batch 101: loss = 0.5139239430427551, acc = 0.822265625\n",
      "Batch 102: loss = 0.5419812202453613, acc = 0.822265625\n",
      "Batch 103: loss = 0.5296151638031006, acc = 0.8388671875\n",
      "Batch 104: loss = 0.4709705412387848, acc = 0.8349609375\n",
      "Batch 105: loss = 0.4908914268016815, acc = 0.83984375\n",
      "Batch 106: loss = 0.5111924409866333, acc = 0.8359375\n",
      "Batch 107: loss = 0.4926581382751465, acc = 0.8349609375\n",
      "Batch 108: loss = 0.47432050108909607, acc = 0.8388671875\n",
      "Batch 109: loss = 0.5060487389564514, acc = 0.8271484375\n",
      "Batch 110: loss = 0.4552760124206543, acc = 0.857421875\n",
      "Batch 111: loss = 0.5250062346458435, acc = 0.8291015625\n",
      "Batch 112: loss = 0.4829212427139282, acc = 0.84765625\n",
      "Batch 113: loss = 0.5107560157775879, acc = 0.8466796875\n",
      "Batch 114: loss = 0.501600980758667, acc = 0.837890625\n",
      "Batch 115: loss = 0.5153468251228333, acc = 0.8369140625\n",
      "Batch 116: loss = 0.5502110123634338, acc = 0.8193359375\n",
      "Batch 117: loss = 0.5278721451759338, acc = 0.83203125\n",
      "Batch 118: loss = 0.43807488679885864, acc = 0.8466796875\n",
      "Batch 119: loss = 0.4756048619747162, acc = 0.8349609375\n",
      "Batch 120: loss = 0.4770539402961731, acc = 0.8330078125\n",
      "Batch 121: loss = 0.5104513764381409, acc = 0.82421875\n",
      "Batch 122: loss = 0.4824564456939697, acc = 0.830078125\n",
      "Batch 123: loss = 0.5274287462234497, acc = 0.8330078125\n",
      "Batch 124: loss = 0.5420775413513184, acc = 0.8173828125\n",
      "Batch 125: loss = 0.5731135010719299, acc = 0.810546875\n",
      "Batch 126: loss = 0.5488240122795105, acc = 0.8046875\n",
      "\n",
      "Epoch 42/100\n",
      "Batch 1: loss = 0.6840693950653076, acc = 0.802734375\n",
      "Batch 2: loss = 0.5790146589279175, acc = 0.8046875\n",
      "Batch 3: loss = 0.5436502695083618, acc = 0.8330078125\n",
      "Batch 4: loss = 0.4837021231651306, acc = 0.84375\n",
      "Batch 5: loss = 0.5488307476043701, acc = 0.8232421875\n",
      "Batch 6: loss = 0.5333676934242249, acc = 0.822265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7: loss = 0.525088906288147, acc = 0.8251953125\n",
      "Batch 8: loss = 0.5373697876930237, acc = 0.8193359375\n",
      "Batch 9: loss = 0.5014705657958984, acc = 0.83984375\n",
      "Batch 10: loss = 0.46225547790527344, acc = 0.8525390625\n",
      "Batch 11: loss = 0.4992653429508209, acc = 0.83203125\n",
      "Batch 12: loss = 0.499875545501709, acc = 0.8203125\n",
      "Batch 13: loss = 0.4810311794281006, acc = 0.833984375\n",
      "Batch 14: loss = 0.5128082036972046, acc = 0.8291015625\n",
      "Batch 15: loss = 0.48749443888664246, acc = 0.8564453125\n",
      "Batch 16: loss = 0.506188154220581, acc = 0.8251953125\n",
      "Batch 17: loss = 0.5301966667175293, acc = 0.826171875\n",
      "Batch 18: loss = 0.5479601621627808, acc = 0.828125\n",
      "Batch 19: loss = 0.4934627413749695, acc = 0.841796875\n",
      "Batch 20: loss = 0.4847117066383362, acc = 0.826171875\n",
      "Batch 21: loss = 0.5184922218322754, acc = 0.822265625\n",
      "Batch 22: loss = 0.5199947357177734, acc = 0.8310546875\n",
      "Batch 23: loss = 0.48223137855529785, acc = 0.84375\n",
      "Batch 24: loss = 0.5074546337127686, acc = 0.818359375\n",
      "Batch 25: loss = 0.47594118118286133, acc = 0.84765625\n",
      "Batch 26: loss = 0.4947279989719391, acc = 0.8388671875\n",
      "Batch 27: loss = 0.5664169788360596, acc = 0.8125\n",
      "Batch 28: loss = 0.5671634674072266, acc = 0.8134765625\n",
      "Batch 29: loss = 0.5244959592819214, acc = 0.8349609375\n",
      "Batch 30: loss = 0.4848025441169739, acc = 0.83984375\n",
      "Batch 31: loss = 0.5703099966049194, acc = 0.8212890625\n",
      "Batch 32: loss = 0.6054818630218506, acc = 0.8056640625\n",
      "Batch 33: loss = 0.4528558850288391, acc = 0.8623046875\n",
      "Batch 34: loss = 0.5140154361724854, acc = 0.83203125\n",
      "Batch 35: loss = 0.5079312920570374, acc = 0.8388671875\n",
      "Batch 36: loss = 0.4974074959754944, acc = 0.8466796875\n",
      "Batch 37: loss = 0.4909936785697937, acc = 0.841796875\n",
      "Batch 38: loss = 0.5259765386581421, acc = 0.8330078125\n",
      "Batch 39: loss = 0.4673900008201599, acc = 0.833984375\n",
      "Batch 40: loss = 0.5171502232551575, acc = 0.828125\n",
      "Batch 41: loss = 0.4289446473121643, acc = 0.84765625\n",
      "Batch 42: loss = 0.5193648934364319, acc = 0.83203125\n",
      "Batch 43: loss = 0.5470765829086304, acc = 0.8154296875\n",
      "Batch 44: loss = 0.45604392886161804, acc = 0.8603515625\n",
      "Batch 45: loss = 0.48263978958129883, acc = 0.8349609375\n",
      "Batch 46: loss = 0.4752097427845001, acc = 0.84375\n",
      "Batch 47: loss = 0.49779462814331055, acc = 0.8330078125\n",
      "Batch 48: loss = 0.5135114192962646, acc = 0.8251953125\n",
      "Batch 49: loss = 0.44651544094085693, acc = 0.845703125\n",
      "Batch 50: loss = 0.4614880681037903, acc = 0.8525390625\n",
      "Batch 51: loss = 0.4490971267223358, acc = 0.8486328125\n",
      "Batch 52: loss = 0.4932446777820587, acc = 0.83203125\n",
      "Batch 53: loss = 0.5271649956703186, acc = 0.826171875\n",
      "Batch 54: loss = 0.3961002826690674, acc = 0.861328125\n",
      "Batch 55: loss = 0.4225667119026184, acc = 0.857421875\n",
      "Batch 56: loss = 0.4724890887737274, acc = 0.833984375\n",
      "Batch 57: loss = 0.4980592131614685, acc = 0.8349609375\n",
      "Batch 58: loss = 0.5207164883613586, acc = 0.82421875\n",
      "Batch 59: loss = 0.38833552598953247, acc = 0.8779296875\n",
      "Batch 60: loss = 0.5010836720466614, acc = 0.8349609375\n",
      "Batch 61: loss = 0.47829848527908325, acc = 0.8359375\n",
      "Batch 62: loss = 0.5547690987586975, acc = 0.8154296875\n",
      "Batch 63: loss = 0.5252630710601807, acc = 0.8330078125\n",
      "Batch 64: loss = 0.44336339831352234, acc = 0.8525390625\n",
      "Batch 65: loss = 0.5059123039245605, acc = 0.830078125\n",
      "Batch 66: loss = 0.49626481533050537, acc = 0.8232421875\n",
      "Batch 67: loss = 0.47854650020599365, acc = 0.8330078125\n",
      "Batch 68: loss = 0.4971301853656769, acc = 0.8349609375\n",
      "Batch 69: loss = 0.43705475330352783, acc = 0.857421875\n",
      "Batch 70: loss = 0.5719884634017944, acc = 0.8037109375\n",
      "Batch 71: loss = 0.5012491941452026, acc = 0.826171875\n",
      "Batch 72: loss = 0.45032042264938354, acc = 0.849609375\n",
      "Batch 73: loss = 0.5563050508499146, acc = 0.8212890625\n",
      "Batch 74: loss = 0.5655107498168945, acc = 0.8115234375\n",
      "Batch 75: loss = 0.598987340927124, acc = 0.8037109375\n",
      "Batch 76: loss = 0.5448180437088013, acc = 0.8115234375\n",
      "Batch 77: loss = 0.47733616828918457, acc = 0.8486328125\n",
      "Batch 78: loss = 0.49576014280319214, acc = 0.841796875\n",
      "Batch 79: loss = 0.4508077800273895, acc = 0.8505859375\n",
      "Batch 80: loss = 0.43155092000961304, acc = 0.8369140625\n",
      "Batch 81: loss = 0.5287704467773438, acc = 0.82421875\n",
      "Batch 82: loss = 0.46613165736198425, acc = 0.84375\n",
      "Batch 83: loss = 0.46090903878211975, acc = 0.8486328125\n",
      "Batch 84: loss = 0.49840906262397766, acc = 0.8310546875\n",
      "Batch 85: loss = 0.5766727328300476, acc = 0.80859375\n",
      "Batch 86: loss = 0.5032712817192078, acc = 0.8349609375\n",
      "Batch 87: loss = 0.5047106146812439, acc = 0.8427734375\n",
      "Batch 88: loss = 0.5887770652770996, acc = 0.8017578125\n",
      "Batch 89: loss = 0.48900023102760315, acc = 0.8486328125\n",
      "Batch 90: loss = 0.49656200408935547, acc = 0.85546875\n",
      "Batch 91: loss = 0.5089178085327148, acc = 0.837890625\n",
      "Batch 92: loss = 0.5247782468795776, acc = 0.8203125\n",
      "Batch 93: loss = 0.45839300751686096, acc = 0.8525390625\n",
      "Batch 94: loss = 0.44722047448158264, acc = 0.8447265625\n",
      "Batch 95: loss = 0.4272671937942505, acc = 0.8525390625\n",
      "Batch 96: loss = 0.5835952162742615, acc = 0.796875\n",
      "Batch 97: loss = 0.5377355813980103, acc = 0.83203125\n",
      "Batch 98: loss = 0.5026541948318481, acc = 0.8271484375\n",
      "Batch 99: loss = 0.49239465594291687, acc = 0.828125\n",
      "Batch 100: loss = 0.49316084384918213, acc = 0.830078125\n",
      "Batch 101: loss = 0.4736366271972656, acc = 0.8427734375\n",
      "Batch 102: loss = 0.517785906791687, acc = 0.833984375\n",
      "Batch 103: loss = 0.5461543202400208, acc = 0.8271484375\n",
      "Batch 104: loss = 0.4477697014808655, acc = 0.861328125\n",
      "Batch 105: loss = 0.4634731709957123, acc = 0.84765625\n",
      "Batch 106: loss = 0.4878515601158142, acc = 0.8408203125\n",
      "Batch 107: loss = 0.46682727336883545, acc = 0.8427734375\n",
      "Batch 108: loss = 0.47130072116851807, acc = 0.859375\n",
      "Batch 109: loss = 0.4877297878265381, acc = 0.8388671875\n",
      "Batch 110: loss = 0.472647488117218, acc = 0.8427734375\n",
      "Batch 111: loss = 0.5375049114227295, acc = 0.8232421875\n",
      "Batch 112: loss = 0.48883676528930664, acc = 0.8408203125\n",
      "Batch 113: loss = 0.4947982132434845, acc = 0.837890625\n",
      "Batch 114: loss = 0.4998975992202759, acc = 0.833984375\n",
      "Batch 115: loss = 0.5170184373855591, acc = 0.826171875\n",
      "Batch 116: loss = 0.5308565497398376, acc = 0.8173828125\n",
      "Batch 117: loss = 0.4998985826969147, acc = 0.845703125\n",
      "Batch 118: loss = 0.4158531427383423, acc = 0.8583984375\n",
      "Batch 119: loss = 0.47873470187187195, acc = 0.849609375\n",
      "Batch 120: loss = 0.46501874923706055, acc = 0.853515625\n",
      "Batch 121: loss = 0.5067130923271179, acc = 0.833984375\n",
      "Batch 122: loss = 0.48576614260673523, acc = 0.841796875\n",
      "Batch 123: loss = 0.511563777923584, acc = 0.8310546875\n",
      "Batch 124: loss = 0.5463218688964844, acc = 0.8095703125\n",
      "Batch 125: loss = 0.5551028251647949, acc = 0.818359375\n",
      "Batch 126: loss = 0.5098143815994263, acc = 0.8330078125\n",
      "\n",
      "Epoch 43/100\n",
      "Batch 1: loss = 0.695675253868103, acc = 0.7900390625\n",
      "Batch 2: loss = 0.5369048118591309, acc = 0.83203125\n",
      "Batch 3: loss = 0.5325547456741333, acc = 0.830078125\n",
      "Batch 4: loss = 0.5051873922348022, acc = 0.83203125\n",
      "Batch 5: loss = 0.5383602380752563, acc = 0.8134765625\n",
      "Batch 6: loss = 0.5448595881462097, acc = 0.8134765625\n",
      "Batch 7: loss = 0.5117334723472595, acc = 0.8310546875\n",
      "Batch 8: loss = 0.5221110582351685, acc = 0.8330078125\n",
      "Batch 9: loss = 0.4316662847995758, acc = 0.859375\n",
      "Batch 10: loss = 0.445951908826828, acc = 0.8515625\n",
      "Batch 11: loss = 0.5186573266983032, acc = 0.83203125\n",
      "Batch 12: loss = 0.4873967468738556, acc = 0.8388671875\n",
      "Batch 13: loss = 0.4723670780658722, acc = 0.84765625\n",
      "Batch 14: loss = 0.4816756844520569, acc = 0.8427734375\n",
      "Batch 15: loss = 0.4977151155471802, acc = 0.837890625\n",
      "Batch 16: loss = 0.5181515216827393, acc = 0.826171875\n",
      "Batch 17: loss = 0.49132585525512695, acc = 0.8251953125\n",
      "Batch 18: loss = 0.5658409595489502, acc = 0.814453125\n",
      "Batch 19: loss = 0.486236035823822, acc = 0.8466796875\n",
      "Batch 20: loss = 0.47152456641197205, acc = 0.8388671875\n",
      "Batch 21: loss = 0.5312681198120117, acc = 0.8154296875\n",
      "Batch 22: loss = 0.5033876895904541, acc = 0.8232421875\n",
      "Batch 23: loss = 0.5025560259819031, acc = 0.830078125\n",
      "Batch 24: loss = 0.48606401681900024, acc = 0.8359375\n",
      "Batch 25: loss = 0.4687044322490692, acc = 0.8408203125\n",
      "Batch 26: loss = 0.49448099732398987, acc = 0.8251953125\n",
      "Batch 27: loss = 0.6150990724563599, acc = 0.80859375\n",
      "Batch 28: loss = 0.53354412317276, acc = 0.8203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 29: loss = 0.5173412561416626, acc = 0.8203125\n",
      "Batch 30: loss = 0.4776688814163208, acc = 0.845703125\n",
      "Batch 31: loss = 0.5536639094352722, acc = 0.8291015625\n",
      "Batch 32: loss = 0.5994729995727539, acc = 0.8154296875\n",
      "Batch 33: loss = 0.46424615383148193, acc = 0.83984375\n",
      "Batch 34: loss = 0.5200861692428589, acc = 0.8271484375\n",
      "Batch 35: loss = 0.4920721650123596, acc = 0.8427734375\n",
      "Batch 36: loss = 0.4581165611743927, acc = 0.8388671875\n",
      "Batch 37: loss = 0.5048437714576721, acc = 0.8232421875\n",
      "Batch 38: loss = 0.5023913383483887, acc = 0.84375\n",
      "Batch 39: loss = 0.470819890499115, acc = 0.84375\n",
      "Batch 40: loss = 0.4962289035320282, acc = 0.830078125\n",
      "Batch 41: loss = 0.4335618019104004, acc = 0.84765625\n",
      "Batch 42: loss = 0.5003764033317566, acc = 0.84375\n",
      "Batch 43: loss = 0.5275676250457764, acc = 0.82421875\n",
      "Batch 44: loss = 0.46033206582069397, acc = 0.859375\n",
      "Batch 45: loss = 0.4567776918411255, acc = 0.845703125\n",
      "Batch 46: loss = 0.43442773818969727, acc = 0.8447265625\n",
      "Batch 47: loss = 0.49277985095977783, acc = 0.8388671875\n",
      "Batch 48: loss = 0.4624938368797302, acc = 0.84375\n",
      "Batch 49: loss = 0.42383497953414917, acc = 0.8681640625\n",
      "Batch 50: loss = 0.4544949531555176, acc = 0.85546875\n",
      "Batch 51: loss = 0.4533071517944336, acc = 0.837890625\n",
      "Batch 52: loss = 0.4755327105522156, acc = 0.83984375\n",
      "Batch 53: loss = 0.4920714199542999, acc = 0.8349609375\n",
      "Batch 54: loss = 0.3977794051170349, acc = 0.875\n",
      "Batch 55: loss = 0.4288301467895508, acc = 0.8564453125\n",
      "Batch 56: loss = 0.4824281930923462, acc = 0.8193359375\n",
      "Batch 57: loss = 0.5114145278930664, acc = 0.8388671875\n",
      "Batch 58: loss = 0.5239841341972351, acc = 0.81640625\n",
      "Batch 59: loss = 0.4013304114341736, acc = 0.873046875\n",
      "Batch 60: loss = 0.5174259543418884, acc = 0.8310546875\n",
      "Batch 61: loss = 0.4486267864704132, acc = 0.8740234375\n",
      "Batch 62: loss = 0.5699976086616516, acc = 0.810546875\n",
      "Batch 63: loss = 0.5148409605026245, acc = 0.82421875\n",
      "Batch 64: loss = 0.40835100412368774, acc = 0.859375\n",
      "Batch 65: loss = 0.5053443312644958, acc = 0.8271484375\n",
      "Batch 66: loss = 0.4809083640575409, acc = 0.83984375\n",
      "Batch 67: loss = 0.4734140634536743, acc = 0.833984375\n",
      "Batch 68: loss = 0.47721368074417114, acc = 0.8359375\n",
      "Batch 69: loss = 0.4540885090827942, acc = 0.8486328125\n",
      "Batch 70: loss = 0.5445194244384766, acc = 0.8095703125\n",
      "Batch 71: loss = 0.4984053671360016, acc = 0.833984375\n",
      "Batch 72: loss = 0.4475470185279846, acc = 0.8564453125\n",
      "Batch 73: loss = 0.5087741613388062, acc = 0.83203125\n",
      "Batch 74: loss = 0.4916256070137024, acc = 0.8251953125\n",
      "Batch 75: loss = 0.5955698490142822, acc = 0.798828125\n",
      "Batch 76: loss = 0.5505374073982239, acc = 0.8203125\n",
      "Batch 77: loss = 0.5190629363059998, acc = 0.826171875\n",
      "Batch 78: loss = 0.5059347152709961, acc = 0.8271484375\n",
      "Batch 79: loss = 0.42390793561935425, acc = 0.8505859375\n",
      "Batch 80: loss = 0.44977104663848877, acc = 0.8369140625\n",
      "Batch 81: loss = 0.5359171032905579, acc = 0.8232421875\n",
      "Batch 82: loss = 0.451679527759552, acc = 0.849609375\n",
      "Batch 83: loss = 0.47952800989151, acc = 0.822265625\n",
      "Batch 84: loss = 0.4901060461997986, acc = 0.83203125\n",
      "Batch 85: loss = 0.556358814239502, acc = 0.8076171875\n",
      "Batch 86: loss = 0.517238974571228, acc = 0.8212890625\n",
      "Batch 87: loss = 0.5180796384811401, acc = 0.8271484375\n",
      "Batch 88: loss = 0.5760231018066406, acc = 0.8115234375\n",
      "Batch 89: loss = 0.47466593980789185, acc = 0.841796875\n",
      "Batch 90: loss = 0.5235098600387573, acc = 0.8359375\n",
      "Batch 91: loss = 0.5003852844238281, acc = 0.8271484375\n",
      "Batch 92: loss = 0.5207704305648804, acc = 0.841796875\n",
      "Batch 93: loss = 0.4570986032485962, acc = 0.84765625\n",
      "Batch 94: loss = 0.4139783978462219, acc = 0.859375\n",
      "Batch 95: loss = 0.44270265102386475, acc = 0.8505859375\n",
      "Batch 96: loss = 0.4878871738910675, acc = 0.83203125\n",
      "Batch 97: loss = 0.5209282040596008, acc = 0.8359375\n",
      "Batch 98: loss = 0.4779835045337677, acc = 0.8427734375\n",
      "Batch 99: loss = 0.48732465505599976, acc = 0.8310546875\n",
      "Batch 100: loss = 0.5037330389022827, acc = 0.8330078125\n",
      "Batch 101: loss = 0.511879563331604, acc = 0.828125\n",
      "Batch 102: loss = 0.5025923252105713, acc = 0.8388671875\n",
      "Batch 103: loss = 0.5233398079872131, acc = 0.8349609375\n",
      "Batch 104: loss = 0.4310232996940613, acc = 0.8623046875\n",
      "Batch 105: loss = 0.49147748947143555, acc = 0.841796875\n",
      "Batch 106: loss = 0.44676026701927185, acc = 0.86328125\n",
      "Batch 107: loss = 0.44784730672836304, acc = 0.853515625\n",
      "Batch 108: loss = 0.47061681747436523, acc = 0.8369140625\n",
      "Batch 109: loss = 0.5044093728065491, acc = 0.8193359375\n",
      "Batch 110: loss = 0.4335450232028961, acc = 0.8447265625\n",
      "Batch 111: loss = 0.5126461386680603, acc = 0.8232421875\n",
      "Batch 112: loss = 0.47666147351264954, acc = 0.8408203125\n",
      "Batch 113: loss = 0.4850720167160034, acc = 0.833984375\n",
      "Batch 114: loss = 0.4926333427429199, acc = 0.83984375\n",
      "Batch 115: loss = 0.49763256311416626, acc = 0.83203125\n",
      "Batch 116: loss = 0.4990333914756775, acc = 0.837890625\n",
      "Batch 117: loss = 0.48529714345932007, acc = 0.8330078125\n",
      "Batch 118: loss = 0.4040651023387909, acc = 0.859375\n",
      "Batch 119: loss = 0.44179463386535645, acc = 0.8623046875\n",
      "Batch 120: loss = 0.4646974802017212, acc = 0.837890625\n",
      "Batch 121: loss = 0.4750552773475647, acc = 0.8349609375\n",
      "Batch 122: loss = 0.46873265504837036, acc = 0.8330078125\n",
      "Batch 123: loss = 0.4927469789981842, acc = 0.8427734375\n",
      "Batch 124: loss = 0.5244233012199402, acc = 0.8291015625\n",
      "Batch 125: loss = 0.5201308131217957, acc = 0.8203125\n",
      "Batch 126: loss = 0.528205931186676, acc = 0.8115234375\n",
      "\n",
      "Epoch 44/100\n",
      "Batch 1: loss = 0.6489758491516113, acc = 0.8115234375\n",
      "Batch 2: loss = 0.534654974937439, acc = 0.8193359375\n",
      "Batch 3: loss = 0.5278576016426086, acc = 0.8388671875\n",
      "Batch 4: loss = 0.47129368782043457, acc = 0.8701171875\n",
      "Batch 5: loss = 0.5356764793395996, acc = 0.8251953125\n",
      "Batch 6: loss = 0.5336261987686157, acc = 0.826171875\n",
      "Batch 7: loss = 0.5345532894134521, acc = 0.8349609375\n",
      "Batch 8: loss = 0.5281113386154175, acc = 0.84375\n",
      "Batch 9: loss = 0.46014463901519775, acc = 0.8505859375\n",
      "Batch 10: loss = 0.4584420621395111, acc = 0.8515625\n",
      "Batch 11: loss = 0.4718935191631317, acc = 0.837890625\n",
      "Batch 12: loss = 0.46674078702926636, acc = 0.841796875\n",
      "Batch 13: loss = 0.49523451924324036, acc = 0.837890625\n",
      "Batch 14: loss = 0.4790874719619751, acc = 0.84765625\n",
      "Batch 15: loss = 0.4603877663612366, acc = 0.8466796875\n",
      "Batch 16: loss = 0.5082453489303589, acc = 0.8369140625\n",
      "Batch 17: loss = 0.4677696228027344, acc = 0.849609375\n",
      "Batch 18: loss = 0.4944157004356384, acc = 0.8291015625\n",
      "Batch 19: loss = 0.4956260323524475, acc = 0.8388671875\n",
      "Batch 20: loss = 0.48160505294799805, acc = 0.8369140625\n",
      "Batch 21: loss = 0.5264809131622314, acc = 0.8154296875\n",
      "Batch 22: loss = 0.4847867488861084, acc = 0.841796875\n",
      "Batch 23: loss = 0.475956529378891, acc = 0.837890625\n",
      "Batch 24: loss = 0.5132865309715271, acc = 0.8291015625\n",
      "Batch 25: loss = 0.4563724994659424, acc = 0.8564453125\n",
      "Batch 26: loss = 0.4627041220664978, acc = 0.845703125\n",
      "Batch 27: loss = 0.5533647537231445, acc = 0.818359375\n",
      "Batch 28: loss = 0.5547932386398315, acc = 0.810546875\n",
      "Batch 29: loss = 0.5091263055801392, acc = 0.833984375\n",
      "Batch 30: loss = 0.5033372640609741, acc = 0.833984375\n",
      "Batch 31: loss = 0.5551836490631104, acc = 0.8291015625\n",
      "Batch 32: loss = 0.6167997121810913, acc = 0.7978515625\n",
      "Batch 33: loss = 0.4608975350856781, acc = 0.8447265625\n",
      "Batch 34: loss = 0.5285443663597107, acc = 0.8154296875\n",
      "Batch 35: loss = 0.5045284032821655, acc = 0.8466796875\n",
      "Batch 36: loss = 0.47181499004364014, acc = 0.8466796875\n",
      "Batch 37: loss = 0.4731261432170868, acc = 0.845703125\n",
      "Batch 38: loss = 0.47339147329330444, acc = 0.849609375\n",
      "Batch 39: loss = 0.46304500102996826, acc = 0.841796875\n",
      "Batch 40: loss = 0.5091859698295593, acc = 0.8291015625\n",
      "Batch 41: loss = 0.41158515214920044, acc = 0.86328125\n",
      "Batch 42: loss = 0.46640175580978394, acc = 0.8515625\n",
      "Batch 43: loss = 0.4961393475532532, acc = 0.8427734375\n",
      "Batch 44: loss = 0.452185720205307, acc = 0.8515625\n",
      "Batch 45: loss = 0.45167994499206543, acc = 0.84375\n",
      "Batch 46: loss = 0.4821456968784332, acc = 0.8427734375\n",
      "Batch 47: loss = 0.4557691514492035, acc = 0.8505859375\n",
      "Batch 48: loss = 0.4729296565055847, acc = 0.8447265625\n",
      "Batch 49: loss = 0.4212604761123657, acc = 0.8642578125\n",
      "Batch 50: loss = 0.4571153223514557, acc = 0.8369140625\n",
      "Batch 51: loss = 0.4380723237991333, acc = 0.8525390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 52: loss = 0.4809775650501251, acc = 0.8408203125\n",
      "Batch 53: loss = 0.48428893089294434, acc = 0.8310546875\n",
      "Batch 54: loss = 0.391988068819046, acc = 0.8603515625\n",
      "Batch 55: loss = 0.4171423017978668, acc = 0.8623046875\n",
      "Batch 56: loss = 0.46677666902542114, acc = 0.8291015625\n",
      "Batch 57: loss = 0.5245579481124878, acc = 0.822265625\n",
      "Batch 58: loss = 0.5122332572937012, acc = 0.8310546875\n",
      "Batch 59: loss = 0.40940359234809875, acc = 0.8671875\n",
      "Batch 60: loss = 0.5295872688293457, acc = 0.81640625\n",
      "Batch 61: loss = 0.44252267479896545, acc = 0.845703125\n",
      "Batch 62: loss = 0.5210555791854858, acc = 0.8291015625\n",
      "Batch 63: loss = 0.4625486135482788, acc = 0.8349609375\n",
      "Batch 64: loss = 0.4438984990119934, acc = 0.8623046875\n",
      "Batch 65: loss = 0.5343112349510193, acc = 0.8310546875\n",
      "Batch 66: loss = 0.4650186002254486, acc = 0.8330078125\n",
      "Batch 67: loss = 0.4597201943397522, acc = 0.83984375\n",
      "Batch 68: loss = 0.49076923727989197, acc = 0.84375\n",
      "Batch 69: loss = 0.4383099675178528, acc = 0.8623046875\n",
      "Batch 70: loss = 0.5107327699661255, acc = 0.8349609375\n",
      "Batch 71: loss = 0.4752284288406372, acc = 0.83203125\n",
      "Batch 72: loss = 0.4394817054271698, acc = 0.86328125\n",
      "Batch 73: loss = 0.5085905194282532, acc = 0.8466796875\n",
      "Batch 74: loss = 0.5013185143470764, acc = 0.8203125\n",
      "Batch 75: loss = 0.5470251441001892, acc = 0.806640625\n",
      "Batch 76: loss = 0.5225054025650024, acc = 0.8154296875\n",
      "Batch 77: loss = 0.4819272756576538, acc = 0.841796875\n",
      "Batch 78: loss = 0.45748960971832275, acc = 0.853515625\n",
      "Batch 79: loss = 0.43375322222709656, acc = 0.8525390625\n",
      "Batch 80: loss = 0.4342767000198364, acc = 0.845703125\n",
      "Batch 81: loss = 0.4721530079841614, acc = 0.8408203125\n",
      "Batch 82: loss = 0.4559938907623291, acc = 0.8583984375\n",
      "Batch 83: loss = 0.47791722416877747, acc = 0.8466796875\n",
      "Batch 84: loss = 0.4528123140335083, acc = 0.845703125\n",
      "Batch 85: loss = 0.5188184380531311, acc = 0.814453125\n",
      "Batch 86: loss = 0.5076680183410645, acc = 0.8359375\n",
      "Batch 87: loss = 0.4839024543762207, acc = 0.84765625\n",
      "Batch 88: loss = 0.558086097240448, acc = 0.82421875\n",
      "Batch 89: loss = 0.46203017234802246, acc = 0.8525390625\n",
      "Batch 90: loss = 0.5009322166442871, acc = 0.8447265625\n",
      "Batch 91: loss = 0.5111678242683411, acc = 0.8291015625\n",
      "Batch 92: loss = 0.5270386934280396, acc = 0.8271484375\n",
      "Batch 93: loss = 0.4191126227378845, acc = 0.8681640625\n",
      "Batch 94: loss = 0.43530160188674927, acc = 0.8603515625\n",
      "Batch 95: loss = 0.431471586227417, acc = 0.865234375\n",
      "Batch 96: loss = 0.4955609440803528, acc = 0.8310546875\n",
      "Batch 97: loss = 0.5197629332542419, acc = 0.83984375\n",
      "Batch 98: loss = 0.4994078278541565, acc = 0.83984375\n",
      "Batch 99: loss = 0.4861014485359192, acc = 0.826171875\n",
      "Batch 100: loss = 0.4915919601917267, acc = 0.8291015625\n",
      "Batch 101: loss = 0.448066771030426, acc = 0.8564453125\n",
      "Batch 102: loss = 0.45115962624549866, acc = 0.8486328125\n",
      "Batch 103: loss = 0.4680371880531311, acc = 0.8447265625\n",
      "Batch 104: loss = 0.4248565435409546, acc = 0.8544921875\n",
      "Batch 105: loss = 0.480796217918396, acc = 0.8427734375\n",
      "Batch 106: loss = 0.4550912380218506, acc = 0.845703125\n",
      "Batch 107: loss = 0.4495588541030884, acc = 0.8564453125\n",
      "Batch 108: loss = 0.46587133407592773, acc = 0.8515625\n",
      "Batch 109: loss = 0.46377670764923096, acc = 0.8564453125\n",
      "Batch 110: loss = 0.46420302987098694, acc = 0.8505859375\n",
      "Batch 111: loss = 0.46698975563049316, acc = 0.8427734375\n",
      "Batch 112: loss = 0.48492276668548584, acc = 0.8349609375\n",
      "Batch 113: loss = 0.4781476855278015, acc = 0.837890625\n",
      "Batch 114: loss = 0.49730536341667175, acc = 0.8349609375\n",
      "Batch 115: loss = 0.5195176601409912, acc = 0.833984375\n",
      "Batch 116: loss = 0.5048403143882751, acc = 0.826171875\n",
      "Batch 117: loss = 0.475838840007782, acc = 0.83984375\n",
      "Batch 118: loss = 0.4028548300266266, acc = 0.8603515625\n",
      "Batch 119: loss = 0.4555172920227051, acc = 0.849609375\n",
      "Batch 120: loss = 0.4408923387527466, acc = 0.857421875\n",
      "Batch 121: loss = 0.47370660305023193, acc = 0.841796875\n",
      "Batch 122: loss = 0.4398553967475891, acc = 0.8427734375\n",
      "Batch 123: loss = 0.45774054527282715, acc = 0.8583984375\n",
      "Batch 124: loss = 0.506657600402832, acc = 0.8154296875\n",
      "Batch 125: loss = 0.5242968797683716, acc = 0.83203125\n",
      "Batch 126: loss = 0.5110148191452026, acc = 0.83203125\n",
      "\n",
      "Epoch 45/100\n",
      "Batch 1: loss = 0.612991213798523, acc = 0.8125\n",
      "Batch 2: loss = 0.5379346609115601, acc = 0.8271484375\n",
      "Batch 3: loss = 0.49410074949264526, acc = 0.8466796875\n",
      "Batch 4: loss = 0.47101926803588867, acc = 0.8505859375\n",
      "Batch 5: loss = 0.5007848143577576, acc = 0.84375\n",
      "Batch 6: loss = 0.5115101337432861, acc = 0.8349609375\n",
      "Batch 7: loss = 0.49954086542129517, acc = 0.8447265625\n",
      "Batch 8: loss = 0.5070108771324158, acc = 0.83203125\n",
      "Batch 9: loss = 0.4640270173549652, acc = 0.83984375\n",
      "Batch 10: loss = 0.4205273985862732, acc = 0.8505859375\n",
      "Batch 11: loss = 0.5001925826072693, acc = 0.837890625\n",
      "Batch 12: loss = 0.4620590806007385, acc = 0.849609375\n",
      "Batch 13: loss = 0.45661887526512146, acc = 0.8427734375\n",
      "Batch 14: loss = 0.4893520474433899, acc = 0.8359375\n",
      "Batch 15: loss = 0.4486831724643707, acc = 0.8564453125\n",
      "Batch 16: loss = 0.4801349639892578, acc = 0.8447265625\n",
      "Batch 17: loss = 0.4510034918785095, acc = 0.8564453125\n",
      "Batch 18: loss = 0.4989641606807709, acc = 0.8369140625\n",
      "Batch 19: loss = 0.4932049512863159, acc = 0.84375\n",
      "Batch 20: loss = 0.48194631934165955, acc = 0.8408203125\n",
      "Batch 21: loss = 0.5099618434906006, acc = 0.828125\n",
      "Batch 22: loss = 0.489834189414978, acc = 0.8291015625\n",
      "Batch 23: loss = 0.47753676772117615, acc = 0.8330078125\n",
      "Batch 24: loss = 0.47417765855789185, acc = 0.837890625\n",
      "Batch 25: loss = 0.4746500253677368, acc = 0.8515625\n",
      "Batch 26: loss = 0.46444934606552124, acc = 0.849609375\n",
      "Batch 27: loss = 0.5130330324172974, acc = 0.826171875\n",
      "Batch 28: loss = 0.5049082040786743, acc = 0.8232421875\n",
      "Batch 29: loss = 0.4957937002182007, acc = 0.8310546875\n",
      "Batch 30: loss = 0.471948504447937, acc = 0.8408203125\n",
      "Batch 31: loss = 0.517099142074585, acc = 0.83984375\n",
      "Batch 32: loss = 0.5725774765014648, acc = 0.802734375\n",
      "Batch 33: loss = 0.43739527463912964, acc = 0.8525390625\n",
      "Batch 34: loss = 0.4927508533000946, acc = 0.83203125\n",
      "Batch 35: loss = 0.47966185212135315, acc = 0.8466796875\n",
      "Batch 36: loss = 0.44444507360458374, acc = 0.8525390625\n",
      "Batch 37: loss = 0.43112504482269287, acc = 0.857421875\n",
      "Batch 38: loss = 0.47608280181884766, acc = 0.845703125\n",
      "Batch 39: loss = 0.4465165138244629, acc = 0.8447265625\n",
      "Batch 40: loss = 0.475198358297348, acc = 0.8486328125\n",
      "Batch 41: loss = 0.4407866597175598, acc = 0.8505859375\n",
      "Batch 42: loss = 0.4679431617259979, acc = 0.83984375\n",
      "Batch 43: loss = 0.5235235691070557, acc = 0.8310546875\n",
      "Batch 44: loss = 0.43711057305336, acc = 0.869140625\n",
      "Batch 45: loss = 0.4098733067512512, acc = 0.865234375\n",
      "Batch 46: loss = 0.44226571917533875, acc = 0.8564453125\n",
      "Batch 47: loss = 0.44100433588027954, acc = 0.85546875\n",
      "Batch 48: loss = 0.45335114002227783, acc = 0.8466796875\n",
      "Batch 49: loss = 0.44097062945365906, acc = 0.845703125\n",
      "Batch 50: loss = 0.418883740901947, acc = 0.857421875\n",
      "Batch 51: loss = 0.44811153411865234, acc = 0.8486328125\n",
      "Batch 52: loss = 0.4708513617515564, acc = 0.841796875\n",
      "Batch 53: loss = 0.4946814179420471, acc = 0.8369140625\n",
      "Batch 54: loss = 0.409423291683197, acc = 0.857421875\n",
      "Batch 55: loss = 0.4038829505443573, acc = 0.8603515625\n",
      "Batch 56: loss = 0.4570452570915222, acc = 0.8369140625\n",
      "Batch 57: loss = 0.4947652518749237, acc = 0.82421875\n",
      "Batch 58: loss = 0.5372426509857178, acc = 0.814453125\n",
      "Batch 59: loss = 0.3923417925834656, acc = 0.8671875\n",
      "Batch 60: loss = 0.4760684370994568, acc = 0.8359375\n",
      "Batch 61: loss = 0.41379314661026, acc = 0.861328125\n",
      "Batch 62: loss = 0.5566871762275696, acc = 0.8076171875\n",
      "Batch 63: loss = 0.4566164016723633, acc = 0.8525390625\n",
      "Batch 64: loss = 0.42363712191581726, acc = 0.865234375\n",
      "Batch 65: loss = 0.5166391134262085, acc = 0.826171875\n",
      "Batch 66: loss = 0.5014646053314209, acc = 0.8271484375\n",
      "Batch 67: loss = 0.43958181142807007, acc = 0.853515625\n",
      "Batch 68: loss = 0.46888086199760437, acc = 0.845703125\n",
      "Batch 69: loss = 0.4168379008769989, acc = 0.861328125\n",
      "Batch 70: loss = 0.5366687774658203, acc = 0.828125\n",
      "Batch 71: loss = 0.4926331043243408, acc = 0.8427734375\n",
      "Batch 72: loss = 0.45258891582489014, acc = 0.84765625\n",
      "Batch 73: loss = 0.46000486612319946, acc = 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 74: loss = 0.5149270296096802, acc = 0.8251953125\n",
      "Batch 75: loss = 0.5803478956222534, acc = 0.8154296875\n",
      "Batch 76: loss = 0.48117420077323914, acc = 0.8427734375\n",
      "Batch 77: loss = 0.4575464427471161, acc = 0.8564453125\n",
      "Batch 78: loss = 0.4877164661884308, acc = 0.8427734375\n",
      "Batch 79: loss = 0.4222140908241272, acc = 0.865234375\n",
      "Batch 80: loss = 0.4568691849708557, acc = 0.8408203125\n",
      "Batch 81: loss = 0.45169171690940857, acc = 0.845703125\n",
      "Batch 82: loss = 0.46300721168518066, acc = 0.8388671875\n",
      "Batch 83: loss = 0.46885138750076294, acc = 0.828125\n",
      "Batch 84: loss = 0.47763195633888245, acc = 0.8369140625\n",
      "Batch 85: loss = 0.49004530906677246, acc = 0.8359375\n",
      "Batch 86: loss = 0.49714842438697815, acc = 0.83203125\n",
      "Batch 87: loss = 0.4727695882320404, acc = 0.8486328125\n",
      "Batch 88: loss = 0.5423425436019897, acc = 0.8212890625\n",
      "Batch 89: loss = 0.4698106646537781, acc = 0.8388671875\n",
      "Batch 90: loss = 0.5117654800415039, acc = 0.8359375\n",
      "Batch 91: loss = 0.4900807738304138, acc = 0.830078125\n",
      "Batch 92: loss = 0.5167992115020752, acc = 0.8291015625\n",
      "Batch 93: loss = 0.4105713963508606, acc = 0.8642578125\n",
      "Batch 94: loss = 0.43341392278671265, acc = 0.8544921875\n",
      "Batch 95: loss = 0.4232541620731354, acc = 0.8525390625\n",
      "Batch 96: loss = 0.49066174030303955, acc = 0.8271484375\n",
      "Batch 97: loss = 0.500421404838562, acc = 0.837890625\n",
      "Batch 98: loss = 0.48152005672454834, acc = 0.8310546875\n",
      "Batch 99: loss = 0.47481653094291687, acc = 0.8271484375\n",
      "Batch 100: loss = 0.4990050196647644, acc = 0.8349609375\n",
      "Batch 101: loss = 0.48019325733184814, acc = 0.83203125\n",
      "Batch 102: loss = 0.48434531688690186, acc = 0.83984375\n",
      "Batch 103: loss = 0.4721517562866211, acc = 0.8447265625\n",
      "Batch 104: loss = 0.42332378029823303, acc = 0.8564453125\n",
      "Batch 105: loss = 0.4437132775783539, acc = 0.8583984375\n",
      "Batch 106: loss = 0.4566113352775574, acc = 0.8427734375\n",
      "Batch 107: loss = 0.4355538487434387, acc = 0.8564453125\n",
      "Batch 108: loss = 0.4784761667251587, acc = 0.8447265625\n",
      "Batch 109: loss = 0.44773387908935547, acc = 0.8349609375\n",
      "Batch 110: loss = 0.4095221757888794, acc = 0.8623046875\n",
      "Batch 111: loss = 0.5172556638717651, acc = 0.8310546875\n",
      "Batch 112: loss = 0.4588451385498047, acc = 0.853515625\n",
      "Batch 113: loss = 0.5036690831184387, acc = 0.8271484375\n",
      "Batch 114: loss = 0.454214870929718, acc = 0.857421875\n",
      "Batch 115: loss = 0.4761074185371399, acc = 0.8525390625\n",
      "Batch 116: loss = 0.49054691195487976, acc = 0.8408203125\n",
      "Batch 117: loss = 0.4753037691116333, acc = 0.83984375\n",
      "Batch 118: loss = 0.42146986722946167, acc = 0.8583984375\n",
      "Batch 119: loss = 0.47318026423454285, acc = 0.8408203125\n",
      "Batch 120: loss = 0.4345231056213379, acc = 0.8564453125\n",
      "Batch 121: loss = 0.4577863812446594, acc = 0.8525390625\n",
      "Batch 122: loss = 0.4442128539085388, acc = 0.849609375\n",
      "Batch 123: loss = 0.47900229692459106, acc = 0.845703125\n",
      "Batch 124: loss = 0.46769392490386963, acc = 0.8427734375\n",
      "Batch 125: loss = 0.5087225437164307, acc = 0.826171875\n",
      "Batch 126: loss = 0.49322572350502014, acc = 0.8291015625\n",
      "\n",
      "Epoch 46/100\n",
      "Batch 1: loss = 0.6460938453674316, acc = 0.80859375\n",
      "Batch 2: loss = 0.4990503191947937, acc = 0.841796875\n",
      "Batch 3: loss = 0.4816794693470001, acc = 0.84765625\n",
      "Batch 4: loss = 0.48717033863067627, acc = 0.8369140625\n",
      "Batch 5: loss = 0.47804874181747437, acc = 0.8388671875\n",
      "Batch 6: loss = 0.49452847242355347, acc = 0.8291015625\n",
      "Batch 7: loss = 0.472911536693573, acc = 0.84765625\n",
      "Batch 8: loss = 0.4606499671936035, acc = 0.849609375\n",
      "Batch 9: loss = 0.4375859498977661, acc = 0.857421875\n",
      "Batch 10: loss = 0.4196521043777466, acc = 0.86328125\n",
      "Batch 11: loss = 0.4642391502857208, acc = 0.8408203125\n",
      "Batch 12: loss = 0.459149569272995, acc = 0.8330078125\n",
      "Batch 13: loss = 0.42743200063705444, acc = 0.853515625\n",
      "Batch 14: loss = 0.46134454011917114, acc = 0.849609375\n",
      "Batch 15: loss = 0.4233630299568176, acc = 0.865234375\n",
      "Batch 16: loss = 0.4299561381340027, acc = 0.853515625\n",
      "Batch 17: loss = 0.4818808436393738, acc = 0.845703125\n",
      "Batch 18: loss = 0.48175808787345886, acc = 0.833984375\n",
      "Batch 19: loss = 0.47502219676971436, acc = 0.84765625\n",
      "Batch 20: loss = 0.46432048082351685, acc = 0.8447265625\n",
      "Batch 21: loss = 0.5091069340705872, acc = 0.8232421875\n",
      "Batch 22: loss = 0.46242472529411316, acc = 0.8447265625\n",
      "Batch 23: loss = 0.4693725109100342, acc = 0.837890625\n",
      "Batch 24: loss = 0.44323933124542236, acc = 0.861328125\n",
      "Batch 25: loss = 0.4324086308479309, acc = 0.8544921875\n",
      "Batch 26: loss = 0.4403436779975891, acc = 0.8486328125\n",
      "Batch 27: loss = 0.5255597829818726, acc = 0.8291015625\n",
      "Batch 28: loss = 0.516756534576416, acc = 0.830078125\n",
      "Batch 29: loss = 0.45981428027153015, acc = 0.845703125\n",
      "Batch 30: loss = 0.44783756136894226, acc = 0.8447265625\n",
      "Batch 31: loss = 0.507591724395752, acc = 0.8447265625\n",
      "Batch 32: loss = 0.535546064376831, acc = 0.833984375\n",
      "Batch 33: loss = 0.4345007538795471, acc = 0.8486328125\n",
      "Batch 34: loss = 0.49356138706207275, acc = 0.8330078125\n",
      "Batch 35: loss = 0.4859655201435089, acc = 0.83984375\n",
      "Batch 36: loss = 0.4531162977218628, acc = 0.8388671875\n",
      "Batch 37: loss = 0.4493374228477478, acc = 0.8505859375\n",
      "Batch 38: loss = 0.465008020401001, acc = 0.84765625\n",
      "Batch 39: loss = 0.4095109701156616, acc = 0.876953125\n",
      "Batch 40: loss = 0.45818600058555603, acc = 0.85546875\n",
      "Batch 41: loss = 0.4100548028945923, acc = 0.8544921875\n",
      "Batch 42: loss = 0.4496529996395111, acc = 0.8466796875\n",
      "Batch 43: loss = 0.5006051063537598, acc = 0.8330078125\n",
      "Batch 44: loss = 0.41972047090530396, acc = 0.8701171875\n",
      "Batch 45: loss = 0.4230894148349762, acc = 0.853515625\n",
      "Batch 46: loss = 0.396916925907135, acc = 0.87109375\n",
      "Batch 47: loss = 0.44491690397262573, acc = 0.853515625\n",
      "Batch 48: loss = 0.4758938252925873, acc = 0.8359375\n",
      "Batch 49: loss = 0.4204246401786804, acc = 0.85546875\n",
      "Batch 50: loss = 0.4501952528953552, acc = 0.8486328125\n",
      "Batch 51: loss = 0.4240279197692871, acc = 0.8505859375\n",
      "Batch 52: loss = 0.46133333444595337, acc = 0.8447265625\n",
      "Batch 53: loss = 0.464881956577301, acc = 0.8466796875\n",
      "Batch 54: loss = 0.3906678557395935, acc = 0.8662109375\n",
      "Batch 55: loss = 0.4005288779735565, acc = 0.8623046875\n",
      "Batch 56: loss = 0.4591889977455139, acc = 0.84375\n",
      "Batch 57: loss = 0.48143431544303894, acc = 0.841796875\n",
      "Batch 58: loss = 0.46689850091934204, acc = 0.8427734375\n",
      "Batch 59: loss = 0.3473518490791321, acc = 0.890625\n",
      "Batch 60: loss = 0.46503543853759766, acc = 0.84765625\n",
      "Batch 61: loss = 0.3950168490409851, acc = 0.86328125\n",
      "Batch 62: loss = 0.5270544290542603, acc = 0.8251953125\n",
      "Batch 63: loss = 0.4527203440666199, acc = 0.8583984375\n",
      "Batch 64: loss = 0.4095437228679657, acc = 0.857421875\n",
      "Batch 65: loss = 0.452204167842865, acc = 0.8447265625\n",
      "Batch 66: loss = 0.46531498432159424, acc = 0.8427734375\n",
      "Batch 67: loss = 0.4490959346294403, acc = 0.8447265625\n",
      "Batch 68: loss = 0.4953959584236145, acc = 0.8330078125\n",
      "Batch 69: loss = 0.43133217096328735, acc = 0.857421875\n",
      "Batch 70: loss = 0.4945782721042633, acc = 0.8388671875\n",
      "Batch 71: loss = 0.47384634613990784, acc = 0.8330078125\n",
      "Batch 72: loss = 0.45940589904785156, acc = 0.8486328125\n",
      "Batch 73: loss = 0.4832192063331604, acc = 0.83203125\n",
      "Batch 74: loss = 0.5137451887130737, acc = 0.83203125\n",
      "Batch 75: loss = 0.5327387452125549, acc = 0.822265625\n",
      "Batch 76: loss = 0.5216873288154602, acc = 0.82421875\n",
      "Batch 77: loss = 0.4618672728538513, acc = 0.84375\n",
      "Batch 78: loss = 0.48990145325660706, acc = 0.841796875\n",
      "Batch 79: loss = 0.4195852279663086, acc = 0.84375\n",
      "Batch 80: loss = 0.4262238144874573, acc = 0.845703125\n",
      "Batch 81: loss = 0.46270957589149475, acc = 0.830078125\n",
      "Batch 82: loss = 0.41455718874931335, acc = 0.8701171875\n",
      "Batch 83: loss = 0.42854171991348267, acc = 0.8525390625\n",
      "Batch 84: loss = 0.4465225338935852, acc = 0.849609375\n",
      "Batch 85: loss = 0.5013155937194824, acc = 0.8232421875\n",
      "Batch 86: loss = 0.47667449712753296, acc = 0.837890625\n",
      "Batch 87: loss = 0.49933695793151855, acc = 0.8349609375\n",
      "Batch 88: loss = 0.5378884077072144, acc = 0.8232421875\n",
      "Batch 89: loss = 0.48197442293167114, acc = 0.8447265625\n",
      "Batch 90: loss = 0.49365827441215515, acc = 0.833984375\n",
      "Batch 91: loss = 0.5108532905578613, acc = 0.8212890625\n",
      "Batch 92: loss = 0.49362385272979736, acc = 0.8408203125\n",
      "Batch 93: loss = 0.39809179306030273, acc = 0.8779296875\n",
      "Batch 94: loss = 0.39503979682922363, acc = 0.865234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 95: loss = 0.4160943031311035, acc = 0.8662109375\n",
      "Batch 96: loss = 0.46461308002471924, acc = 0.845703125\n",
      "Batch 97: loss = 0.47387176752090454, acc = 0.84765625\n",
      "Batch 98: loss = 0.4700857400894165, acc = 0.8466796875\n",
      "Batch 99: loss = 0.5038882493972778, acc = 0.83203125\n",
      "Batch 100: loss = 0.49585723876953125, acc = 0.81640625\n",
      "Batch 101: loss = 0.4629193842411041, acc = 0.8525390625\n",
      "Batch 102: loss = 0.4647853374481201, acc = 0.857421875\n",
      "Batch 103: loss = 0.46751099824905396, acc = 0.849609375\n",
      "Batch 104: loss = 0.4064348638057709, acc = 0.8642578125\n",
      "Batch 105: loss = 0.43132221698760986, acc = 0.85546875\n",
      "Batch 106: loss = 0.46916550397872925, acc = 0.83984375\n",
      "Batch 107: loss = 0.4251708388328552, acc = 0.8564453125\n",
      "Batch 108: loss = 0.42987456917762756, acc = 0.85546875\n",
      "Batch 109: loss = 0.4563620686531067, acc = 0.84765625\n",
      "Batch 110: loss = 0.43772226572036743, acc = 0.8466796875\n",
      "Batch 111: loss = 0.45430129766464233, acc = 0.84765625\n",
      "Batch 112: loss = 0.4584572911262512, acc = 0.845703125\n",
      "Batch 113: loss = 0.4685307443141937, acc = 0.8525390625\n",
      "Batch 114: loss = 0.4785642623901367, acc = 0.8564453125\n",
      "Batch 115: loss = 0.49211519956588745, acc = 0.8388671875\n",
      "Batch 116: loss = 0.4886259436607361, acc = 0.84765625\n",
      "Batch 117: loss = 0.48165351152420044, acc = 0.8447265625\n",
      "Batch 118: loss = 0.3672415614128113, acc = 0.8798828125\n",
      "Batch 119: loss = 0.43341368436813354, acc = 0.861328125\n",
      "Batch 120: loss = 0.4164666533470154, acc = 0.865234375\n",
      "Batch 121: loss = 0.46447789669036865, acc = 0.8447265625\n",
      "Batch 122: loss = 0.41780927777290344, acc = 0.857421875\n",
      "Batch 123: loss = 0.45115259289741516, acc = 0.849609375\n",
      "Batch 124: loss = 0.5229449272155762, acc = 0.8251953125\n",
      "Batch 125: loss = 0.4822852313518524, acc = 0.828125\n",
      "Batch 126: loss = 0.48313063383102417, acc = 0.8388671875\n",
      "\n",
      "Epoch 47/100\n",
      "Batch 1: loss = 0.6070365309715271, acc = 0.830078125\n",
      "Batch 2: loss = 0.4838719964027405, acc = 0.833984375\n",
      "Batch 3: loss = 0.47740352153778076, acc = 0.8408203125\n",
      "Batch 4: loss = 0.4423931837081909, acc = 0.8515625\n",
      "Batch 5: loss = 0.4381755590438843, acc = 0.85546875\n",
      "Batch 6: loss = 0.4918420612812042, acc = 0.8310546875\n",
      "Batch 7: loss = 0.4653783440589905, acc = 0.853515625\n",
      "Batch 8: loss = 0.47688284516334534, acc = 0.8486328125\n",
      "Batch 9: loss = 0.4581780433654785, acc = 0.84765625\n",
      "Batch 10: loss = 0.4087086319923401, acc = 0.861328125\n",
      "Batch 11: loss = 0.46898603439331055, acc = 0.8408203125\n",
      "Batch 12: loss = 0.42733412981033325, acc = 0.859375\n",
      "Batch 13: loss = 0.44787585735321045, acc = 0.8427734375\n",
      "Batch 14: loss = 0.4320116639137268, acc = 0.8671875\n",
      "Batch 15: loss = 0.42762941122055054, acc = 0.8564453125\n",
      "Batch 16: loss = 0.44859617948532104, acc = 0.8359375\n",
      "Batch 17: loss = 0.4301898777484894, acc = 0.8583984375\n",
      "Batch 18: loss = 0.45792168378829956, acc = 0.8505859375\n",
      "Batch 19: loss = 0.46983325481414795, acc = 0.8505859375\n",
      "Batch 20: loss = 0.4156605303287506, acc = 0.8544921875\n",
      "Batch 21: loss = 0.46182337403297424, acc = 0.8310546875\n",
      "Batch 22: loss = 0.4673972427845001, acc = 0.8515625\n",
      "Batch 23: loss = 0.46910199522972107, acc = 0.8408203125\n",
      "Batch 24: loss = 0.4719817042350769, acc = 0.833984375\n",
      "Batch 25: loss = 0.4263480305671692, acc = 0.8583984375\n",
      "Batch 26: loss = 0.4506593644618988, acc = 0.8408203125\n",
      "Batch 27: loss = 0.5020428895950317, acc = 0.83203125\n",
      "Batch 28: loss = 0.5075817108154297, acc = 0.82421875\n",
      "Batch 29: loss = 0.4847843647003174, acc = 0.837890625\n",
      "Batch 30: loss = 0.438077449798584, acc = 0.853515625\n",
      "Batch 31: loss = 0.4842015504837036, acc = 0.8544921875\n",
      "Batch 32: loss = 0.5189191699028015, acc = 0.830078125\n",
      "Batch 33: loss = 0.43651747703552246, acc = 0.857421875\n",
      "Batch 34: loss = 0.4761752188205719, acc = 0.84375\n",
      "Batch 35: loss = 0.4668174386024475, acc = 0.857421875\n",
      "Batch 36: loss = 0.4362601041793823, acc = 0.859375\n",
      "Batch 37: loss = 0.39617207646369934, acc = 0.8818359375\n",
      "Batch 38: loss = 0.4438902735710144, acc = 0.8603515625\n",
      "Batch 39: loss = 0.41171443462371826, acc = 0.8759765625\n",
      "Batch 40: loss = 0.46489283442497253, acc = 0.845703125\n",
      "Batch 41: loss = 0.4077434241771698, acc = 0.8583984375\n",
      "Batch 42: loss = 0.46770724654197693, acc = 0.845703125\n",
      "Batch 43: loss = 0.4747921824455261, acc = 0.8408203125\n",
      "Batch 44: loss = 0.43313226103782654, acc = 0.869140625\n",
      "Batch 45: loss = 0.401989609003067, acc = 0.859375\n",
      "Batch 46: loss = 0.4064958095550537, acc = 0.8603515625\n",
      "Batch 47: loss = 0.4449308216571808, acc = 0.8623046875\n",
      "Batch 48: loss = 0.4396992623806, acc = 0.849609375\n",
      "Batch 49: loss = 0.38951122760772705, acc = 0.8720703125\n",
      "Batch 50: loss = 0.40396082401275635, acc = 0.87109375\n",
      "Batch 51: loss = 0.42203378677368164, acc = 0.8515625\n",
      "Batch 52: loss = 0.44868990778923035, acc = 0.8515625\n",
      "Batch 53: loss = 0.44384750723838806, acc = 0.8505859375\n",
      "Batch 54: loss = 0.36340099573135376, acc = 0.87890625\n",
      "Batch 55: loss = 0.40389180183410645, acc = 0.8662109375\n",
      "Batch 56: loss = 0.45806676149368286, acc = 0.833984375\n",
      "Batch 57: loss = 0.4831185042858124, acc = 0.8505859375\n",
      "Batch 58: loss = 0.4758143126964569, acc = 0.8310546875\n",
      "Batch 59: loss = 0.345725417137146, acc = 0.88671875\n",
      "Batch 60: loss = 0.47666865587234497, acc = 0.83984375\n",
      "Batch 61: loss = 0.4083234965801239, acc = 0.8681640625\n",
      "Batch 62: loss = 0.5386349558830261, acc = 0.818359375\n",
      "Batch 63: loss = 0.45226967334747314, acc = 0.85546875\n",
      "Batch 64: loss = 0.3888104259967804, acc = 0.87109375\n",
      "Batch 65: loss = 0.47535258531570435, acc = 0.828125\n",
      "Batch 66: loss = 0.4309716522693634, acc = 0.857421875\n",
      "Batch 67: loss = 0.4180029332637787, acc = 0.8603515625\n",
      "Batch 68: loss = 0.43886512517929077, acc = 0.8505859375\n",
      "Batch 69: loss = 0.4009280502796173, acc = 0.869140625\n",
      "Batch 70: loss = 0.48795896768569946, acc = 0.83203125\n",
      "Batch 71: loss = 0.45623207092285156, acc = 0.8388671875\n",
      "Batch 72: loss = 0.44009774923324585, acc = 0.857421875\n",
      "Batch 73: loss = 0.48912858963012695, acc = 0.8330078125\n",
      "Batch 74: loss = 0.4985223412513733, acc = 0.822265625\n",
      "Batch 75: loss = 0.539537787437439, acc = 0.8095703125\n",
      "Batch 76: loss = 0.5055047273635864, acc = 0.8212890625\n",
      "Batch 77: loss = 0.43584904074668884, acc = 0.8505859375\n",
      "Batch 78: loss = 0.44991910457611084, acc = 0.853515625\n",
      "Batch 79: loss = 0.3740999400615692, acc = 0.8759765625\n",
      "Batch 80: loss = 0.4115329086780548, acc = 0.83984375\n",
      "Batch 81: loss = 0.453805536031723, acc = 0.8427734375\n",
      "Batch 82: loss = 0.4158531427383423, acc = 0.857421875\n",
      "Batch 83: loss = 0.482175350189209, acc = 0.8291015625\n",
      "Batch 84: loss = 0.44173699617385864, acc = 0.861328125\n",
      "Batch 85: loss = 0.5106855630874634, acc = 0.830078125\n",
      "Batch 86: loss = 0.4442172050476074, acc = 0.8466796875\n",
      "Batch 87: loss = 0.42552465200424194, acc = 0.853515625\n",
      "Batch 88: loss = 0.5189927816390991, acc = 0.8291015625\n",
      "Batch 89: loss = 0.4363301396369934, acc = 0.857421875\n",
      "Batch 90: loss = 0.4734748601913452, acc = 0.861328125\n",
      "Batch 91: loss = 0.48671337962150574, acc = 0.83203125\n",
      "Batch 92: loss = 0.5068999528884888, acc = 0.828125\n",
      "Batch 93: loss = 0.417591392993927, acc = 0.8642578125\n",
      "Batch 94: loss = 0.4147173762321472, acc = 0.8642578125\n",
      "Batch 95: loss = 0.424410343170166, acc = 0.86328125\n",
      "Batch 96: loss = 0.4698626697063446, acc = 0.841796875\n",
      "Batch 97: loss = 0.46135616302490234, acc = 0.8544921875\n",
      "Batch 98: loss = 0.4535446763038635, acc = 0.8505859375\n",
      "Batch 99: loss = 0.4493262767791748, acc = 0.849609375\n",
      "Batch 100: loss = 0.4843035042285919, acc = 0.8251953125\n",
      "Batch 101: loss = 0.4450359046459198, acc = 0.8369140625\n",
      "Batch 102: loss = 0.47474396228790283, acc = 0.8486328125\n",
      "Batch 103: loss = 0.46516749262809753, acc = 0.8583984375\n",
      "Batch 104: loss = 0.4117056131362915, acc = 0.859375\n",
      "Batch 105: loss = 0.4473293423652649, acc = 0.8525390625\n",
      "Batch 106: loss = 0.42379868030548096, acc = 0.8564453125\n",
      "Batch 107: loss = 0.41147375106811523, acc = 0.8642578125\n",
      "Batch 108: loss = 0.4124819040298462, acc = 0.8681640625\n",
      "Batch 109: loss = 0.43509966135025024, acc = 0.8505859375\n",
      "Batch 110: loss = 0.4455489218235016, acc = 0.8466796875\n",
      "Batch 111: loss = 0.4404900372028351, acc = 0.857421875\n",
      "Batch 112: loss = 0.4280022978782654, acc = 0.8662109375\n",
      "Batch 113: loss = 0.441764771938324, acc = 0.85546875\n",
      "Batch 114: loss = 0.4670368432998657, acc = 0.849609375\n",
      "Batch 115: loss = 0.4375145435333252, acc = 0.8662109375\n",
      "Batch 116: loss = 0.49555298686027527, acc = 0.8359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 117: loss = 0.43650496006011963, acc = 0.8486328125\n",
      "Batch 118: loss = 0.37188613414764404, acc = 0.8798828125\n",
      "Batch 119: loss = 0.4325542449951172, acc = 0.8544921875\n",
      "Batch 120: loss = 0.41824910044670105, acc = 0.8544921875\n",
      "Batch 121: loss = 0.4676230847835541, acc = 0.8310546875\n",
      "Batch 122: loss = 0.4138370156288147, acc = 0.8564453125\n",
      "Batch 123: loss = 0.4499860405921936, acc = 0.8505859375\n",
      "Batch 124: loss = 0.48103979229927063, acc = 0.830078125\n",
      "Batch 125: loss = 0.5164016485214233, acc = 0.8154296875\n",
      "Batch 126: loss = 0.4287568926811218, acc = 0.857421875\n",
      "\n",
      "Epoch 48/100\n",
      "Batch 1: loss = 0.5926735997200012, acc = 0.82421875\n",
      "Batch 2: loss = 0.4996225833892822, acc = 0.828125\n",
      "Batch 3: loss = 0.44336220622062683, acc = 0.8681640625\n",
      "Batch 4: loss = 0.45903968811035156, acc = 0.83984375\n",
      "Batch 5: loss = 0.46584203839302063, acc = 0.8515625\n",
      "Batch 6: loss = 0.4458421468734741, acc = 0.8505859375\n",
      "Batch 7: loss = 0.46625664830207825, acc = 0.8408203125\n",
      "Batch 8: loss = 0.4674612879753113, acc = 0.8505859375\n",
      "Batch 9: loss = 0.40503111481666565, acc = 0.865234375\n",
      "Batch 10: loss = 0.41130679845809937, acc = 0.85546875\n",
      "Batch 11: loss = 0.4484889507293701, acc = 0.857421875\n",
      "Batch 12: loss = 0.4379017949104309, acc = 0.8564453125\n",
      "Batch 13: loss = 0.425362229347229, acc = 0.861328125\n",
      "Batch 14: loss = 0.4543858766555786, acc = 0.8505859375\n",
      "Batch 15: loss = 0.4221356511116028, acc = 0.8662109375\n",
      "Batch 16: loss = 0.45416539907455444, acc = 0.8427734375\n",
      "Batch 17: loss = 0.43053770065307617, acc = 0.8671875\n",
      "Batch 18: loss = 0.46827811002731323, acc = 0.8486328125\n",
      "Batch 19: loss = 0.45133331418037415, acc = 0.85546875\n",
      "Batch 20: loss = 0.4664459824562073, acc = 0.8515625\n",
      "Batch 21: loss = 0.46291476488113403, acc = 0.8515625\n",
      "Batch 22: loss = 0.46869784593582153, acc = 0.8486328125\n",
      "Batch 23: loss = 0.47563624382019043, acc = 0.841796875\n",
      "Batch 24: loss = 0.43103256821632385, acc = 0.857421875\n",
      "Batch 25: loss = 0.455135315656662, acc = 0.853515625\n",
      "Batch 26: loss = 0.42666518688201904, acc = 0.865234375\n",
      "Batch 27: loss = 0.49368369579315186, acc = 0.8369140625\n",
      "Batch 28: loss = 0.4602000117301941, acc = 0.8505859375\n",
      "Batch 29: loss = 0.4799131751060486, acc = 0.841796875\n",
      "Batch 30: loss = 0.4423665404319763, acc = 0.8525390625\n",
      "Batch 31: loss = 0.4680563509464264, acc = 0.853515625\n",
      "Batch 32: loss = 0.5429569482803345, acc = 0.828125\n",
      "Batch 33: loss = 0.4176328182220459, acc = 0.8662109375\n",
      "Batch 34: loss = 0.4686697721481323, acc = 0.84375\n",
      "Batch 35: loss = 0.4783405661582947, acc = 0.8466796875\n",
      "Batch 36: loss = 0.39166679978370667, acc = 0.861328125\n",
      "Batch 37: loss = 0.4203205704689026, acc = 0.86328125\n",
      "Batch 38: loss = 0.45080316066741943, acc = 0.8505859375\n",
      "Batch 39: loss = 0.38881927728652954, acc = 0.8828125\n",
      "Batch 40: loss = 0.4463074803352356, acc = 0.8447265625\n",
      "Batch 41: loss = 0.40333616733551025, acc = 0.869140625\n",
      "Batch 42: loss = 0.4267679750919342, acc = 0.84765625\n",
      "Batch 43: loss = 0.47718900442123413, acc = 0.849609375\n",
      "Batch 44: loss = 0.40316975116729736, acc = 0.8720703125\n",
      "Batch 45: loss = 0.40410470962524414, acc = 0.865234375\n",
      "Batch 46: loss = 0.4308333396911621, acc = 0.8681640625\n",
      "Batch 47: loss = 0.4597959816455841, acc = 0.8486328125\n",
      "Batch 48: loss = 0.4085257053375244, acc = 0.869140625\n",
      "Batch 49: loss = 0.38963380455970764, acc = 0.875\n",
      "Batch 50: loss = 0.40060144662857056, acc = 0.8701171875\n",
      "Batch 51: loss = 0.4146859347820282, acc = 0.8544921875\n",
      "Batch 52: loss = 0.4343491792678833, acc = 0.8623046875\n",
      "Batch 53: loss = 0.4179832339286804, acc = 0.861328125\n",
      "Batch 54: loss = 0.3570764660835266, acc = 0.87109375\n",
      "Batch 55: loss = 0.41121864318847656, acc = 0.8701171875\n",
      "Batch 56: loss = 0.43093550205230713, acc = 0.85546875\n",
      "Batch 57: loss = 0.48180025815963745, acc = 0.8349609375\n",
      "Batch 58: loss = 0.45027148723602295, acc = 0.84765625\n",
      "Batch 59: loss = 0.3651934266090393, acc = 0.875\n",
      "Batch 60: loss = 0.44797441363334656, acc = 0.8525390625\n",
      "Batch 61: loss = 0.3965388536453247, acc = 0.8740234375\n",
      "Batch 62: loss = 0.5153300762176514, acc = 0.8291015625\n",
      "Batch 63: loss = 0.44710028171539307, acc = 0.8564453125\n",
      "Batch 64: loss = 0.4117633104324341, acc = 0.8701171875\n",
      "Batch 65: loss = 0.47070491313934326, acc = 0.8486328125\n",
      "Batch 66: loss = 0.44161003828048706, acc = 0.8466796875\n",
      "Batch 67: loss = 0.4113253951072693, acc = 0.8544921875\n",
      "Batch 68: loss = 0.4497362971305847, acc = 0.845703125\n",
      "Batch 69: loss = 0.39930257201194763, acc = 0.86328125\n",
      "Batch 70: loss = 0.5030139088630676, acc = 0.8251953125\n",
      "Batch 71: loss = 0.42655834555625916, acc = 0.8525390625\n",
      "Batch 72: loss = 0.4130250811576843, acc = 0.8642578125\n",
      "Batch 73: loss = 0.4391944408416748, acc = 0.8505859375\n",
      "Batch 74: loss = 0.4486675262451172, acc = 0.8515625\n",
      "Batch 75: loss = 0.5263420343399048, acc = 0.80859375\n",
      "Batch 76: loss = 0.4840869903564453, acc = 0.8427734375\n",
      "Batch 77: loss = 0.4421536922454834, acc = 0.84765625\n",
      "Batch 78: loss = 0.45106756687164307, acc = 0.8427734375\n",
      "Batch 79: loss = 0.3815113306045532, acc = 0.8671875\n",
      "Batch 80: loss = 0.3855460584163666, acc = 0.869140625\n",
      "Batch 81: loss = 0.4431510865688324, acc = 0.845703125\n",
      "Batch 82: loss = 0.41138955950737, acc = 0.8564453125\n",
      "Batch 83: loss = 0.3944573402404785, acc = 0.8671875\n",
      "Batch 84: loss = 0.4275393784046173, acc = 0.83984375\n",
      "Batch 85: loss = 0.4781970679759979, acc = 0.8447265625\n",
      "Batch 86: loss = 0.4228490889072418, acc = 0.8564453125\n",
      "Batch 87: loss = 0.43387407064437866, acc = 0.8583984375\n",
      "Batch 88: loss = 0.5028989315032959, acc = 0.8359375\n",
      "Batch 89: loss = 0.4419935643672943, acc = 0.853515625\n",
      "Batch 90: loss = 0.4651116728782654, acc = 0.853515625\n",
      "Batch 91: loss = 0.45572707056999207, acc = 0.8564453125\n",
      "Batch 92: loss = 0.46729645133018494, acc = 0.8349609375\n",
      "Batch 93: loss = 0.36975061893463135, acc = 0.8779296875\n",
      "Batch 94: loss = 0.36892783641815186, acc = 0.8681640625\n",
      "Batch 95: loss = 0.384918749332428, acc = 0.873046875\n",
      "Batch 96: loss = 0.4340769946575165, acc = 0.8544921875\n",
      "Batch 97: loss = 0.46791958808898926, acc = 0.857421875\n",
      "Batch 98: loss = 0.4489201009273529, acc = 0.8447265625\n",
      "Batch 99: loss = 0.41427913308143616, acc = 0.859375\n",
      "Batch 100: loss = 0.46344923973083496, acc = 0.8408203125\n",
      "Batch 101: loss = 0.41735997796058655, acc = 0.865234375\n",
      "Batch 102: loss = 0.43376198410987854, acc = 0.8583984375\n",
      "Batch 103: loss = 0.42620015144348145, acc = 0.8583984375\n",
      "Batch 104: loss = 0.4415576457977295, acc = 0.8544921875\n",
      "Batch 105: loss = 0.42652949690818787, acc = 0.8671875\n",
      "Batch 106: loss = 0.40074622631073, acc = 0.873046875\n",
      "Batch 107: loss = 0.41740912199020386, acc = 0.865234375\n",
      "Batch 108: loss = 0.4009723663330078, acc = 0.8603515625\n",
      "Batch 109: loss = 0.4105626940727234, acc = 0.8544921875\n",
      "Batch 110: loss = 0.4006476402282715, acc = 0.865234375\n",
      "Batch 111: loss = 0.4332779049873352, acc = 0.8486328125\n",
      "Batch 112: loss = 0.4187702536582947, acc = 0.869140625\n",
      "Batch 113: loss = 0.45293766260147095, acc = 0.8583984375\n",
      "Batch 114: loss = 0.4542396068572998, acc = 0.853515625\n",
      "Batch 115: loss = 0.4700454771518707, acc = 0.84375\n",
      "Batch 116: loss = 0.5001590847969055, acc = 0.8330078125\n",
      "Batch 117: loss = 0.43625593185424805, acc = 0.857421875\n",
      "Batch 118: loss = 0.4173998534679413, acc = 0.861328125\n",
      "Batch 119: loss = 0.4232204556465149, acc = 0.8583984375\n",
      "Batch 120: loss = 0.3928624987602234, acc = 0.8740234375\n",
      "Batch 121: loss = 0.43095001578330994, acc = 0.8603515625\n",
      "Batch 122: loss = 0.40872135758399963, acc = 0.857421875\n",
      "Batch 123: loss = 0.41708308458328247, acc = 0.861328125\n",
      "Batch 124: loss = 0.46392595767974854, acc = 0.8388671875\n",
      "Batch 125: loss = 0.4773153066635132, acc = 0.8486328125\n",
      "Batch 126: loss = 0.4619826376438141, acc = 0.8486328125\n",
      "\n",
      "Epoch 49/100\n",
      "Batch 1: loss = 0.5999546647071838, acc = 0.82421875\n",
      "Batch 2: loss = 0.4728776216506958, acc = 0.8349609375\n",
      "Batch 3: loss = 0.39804261922836304, acc = 0.8701171875\n",
      "Batch 4: loss = 0.44084715843200684, acc = 0.8701171875\n",
      "Batch 5: loss = 0.4557529091835022, acc = 0.8505859375\n",
      "Batch 6: loss = 0.4616268277168274, acc = 0.8544921875\n",
      "Batch 7: loss = 0.4327986538410187, acc = 0.8623046875\n",
      "Batch 8: loss = 0.47072988748550415, acc = 0.845703125\n",
      "Batch 9: loss = 0.44107621908187866, acc = 0.849609375\n",
      "Batch 10: loss = 0.406779408454895, acc = 0.8642578125\n",
      "Batch 11: loss = 0.43103811144828796, acc = 0.8564453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12: loss = 0.4493285119533539, acc = 0.8486328125\n",
      "Batch 13: loss = 0.4012826085090637, acc = 0.8623046875\n",
      "Batch 14: loss = 0.4455983638763428, acc = 0.857421875\n",
      "Batch 15: loss = 0.41470009088516235, acc = 0.87109375\n",
      "Batch 16: loss = 0.4383743405342102, acc = 0.8525390625\n",
      "Batch 17: loss = 0.43356603384017944, acc = 0.85546875\n",
      "Batch 18: loss = 0.45737412571907043, acc = 0.8369140625\n",
      "Batch 19: loss = 0.46040788292884827, acc = 0.84765625\n",
      "Batch 20: loss = 0.41261130571365356, acc = 0.8681640625\n",
      "Batch 21: loss = 0.45091965794563293, acc = 0.8466796875\n",
      "Batch 22: loss = 0.4571383595466614, acc = 0.830078125\n",
      "Batch 23: loss = 0.42554914951324463, acc = 0.8525390625\n",
      "Batch 24: loss = 0.43223753571510315, acc = 0.8447265625\n",
      "Batch 25: loss = 0.40264952182769775, acc = 0.873046875\n",
      "Batch 26: loss = 0.41378045082092285, acc = 0.8759765625\n",
      "Batch 27: loss = 0.5001305341720581, acc = 0.833984375\n",
      "Batch 28: loss = 0.48562270402908325, acc = 0.8349609375\n",
      "Batch 29: loss = 0.48078426718711853, acc = 0.8525390625\n",
      "Batch 30: loss = 0.43574970960617065, acc = 0.84765625\n",
      "Batch 31: loss = 0.4896739721298218, acc = 0.849609375\n",
      "Batch 32: loss = 0.5072957873344421, acc = 0.830078125\n",
      "Batch 33: loss = 0.41676539182662964, acc = 0.8564453125\n",
      "Batch 34: loss = 0.4324650764465332, acc = 0.8515625\n",
      "Batch 35: loss = 0.46886110305786133, acc = 0.8408203125\n",
      "Batch 36: loss = 0.4159083962440491, acc = 0.85546875\n",
      "Batch 37: loss = 0.4167103171348572, acc = 0.8544921875\n",
      "Batch 38: loss = 0.4360193610191345, acc = 0.859375\n",
      "Batch 39: loss = 0.40977683663368225, acc = 0.861328125\n",
      "Batch 40: loss = 0.4283592104911804, acc = 0.861328125\n",
      "Batch 41: loss = 0.38729625940322876, acc = 0.8671875\n",
      "Batch 42: loss = 0.4348592162132263, acc = 0.8583984375\n",
      "Batch 43: loss = 0.4534015953540802, acc = 0.8583984375\n",
      "Batch 44: loss = 0.43070271611213684, acc = 0.857421875\n",
      "Batch 45: loss = 0.38261377811431885, acc = 0.8720703125\n",
      "Batch 46: loss = 0.38866162300109863, acc = 0.869140625\n",
      "Batch 47: loss = 0.41253629326820374, acc = 0.8564453125\n",
      "Batch 48: loss = 0.4035504460334778, acc = 0.87890625\n",
      "Batch 49: loss = 0.3682369589805603, acc = 0.8623046875\n",
      "Batch 50: loss = 0.39751407504081726, acc = 0.8662109375\n",
      "Batch 51: loss = 0.4232157766819, acc = 0.8525390625\n",
      "Batch 52: loss = 0.4339744746685028, acc = 0.8466796875\n",
      "Batch 53: loss = 0.41860055923461914, acc = 0.865234375\n",
      "Batch 54: loss = 0.3501371145248413, acc = 0.87890625\n",
      "Batch 55: loss = 0.3957960605621338, acc = 0.87890625\n",
      "Batch 56: loss = 0.4208306074142456, acc = 0.8525390625\n",
      "Batch 57: loss = 0.46569472551345825, acc = 0.845703125\n",
      "Batch 58: loss = 0.4741494059562683, acc = 0.8408203125\n",
      "Batch 59: loss = 0.38670384883880615, acc = 0.8662109375\n",
      "Batch 60: loss = 0.44677814841270447, acc = 0.8505859375\n",
      "Batch 61: loss = 0.4328603148460388, acc = 0.8544921875\n",
      "Batch 62: loss = 0.48767805099487305, acc = 0.837890625\n",
      "Batch 63: loss = 0.45658406615257263, acc = 0.853515625\n",
      "Batch 64: loss = 0.3776829242706299, acc = 0.8759765625\n",
      "Batch 65: loss = 0.42313700914382935, acc = 0.8564453125\n",
      "Batch 66: loss = 0.45809024572372437, acc = 0.8515625\n",
      "Batch 67: loss = 0.43880701065063477, acc = 0.845703125\n",
      "Batch 68: loss = 0.4592567980289459, acc = 0.8505859375\n",
      "Batch 69: loss = 0.3735242187976837, acc = 0.8837890625\n",
      "Batch 70: loss = 0.4861561059951782, acc = 0.83984375\n",
      "Batch 71: loss = 0.45706161856651306, acc = 0.8349609375\n",
      "Batch 72: loss = 0.4486326575279236, acc = 0.841796875\n",
      "Batch 73: loss = 0.4766945540904999, acc = 0.833984375\n",
      "Batch 74: loss = 0.4568369388580322, acc = 0.8369140625\n",
      "Batch 75: loss = 0.5271161198616028, acc = 0.8330078125\n",
      "Batch 76: loss = 0.4768965244293213, acc = 0.8359375\n",
      "Batch 77: loss = 0.45531898736953735, acc = 0.85546875\n",
      "Batch 78: loss = 0.41664791107177734, acc = 0.861328125\n",
      "Batch 79: loss = 0.38761526346206665, acc = 0.8701171875\n",
      "Batch 80: loss = 0.41579070687294006, acc = 0.8466796875\n",
      "Batch 81: loss = 0.4277513921260834, acc = 0.87109375\n",
      "Batch 82: loss = 0.42730286717414856, acc = 0.8720703125\n",
      "Batch 83: loss = 0.4251142740249634, acc = 0.8486328125\n",
      "Batch 84: loss = 0.4117736220359802, acc = 0.85546875\n",
      "Batch 85: loss = 0.4655786156654358, acc = 0.8388671875\n",
      "Batch 86: loss = 0.4363703429698944, acc = 0.8564453125\n",
      "Batch 87: loss = 0.4405089318752289, acc = 0.8544921875\n",
      "Batch 88: loss = 0.5139821767807007, acc = 0.828125\n",
      "Batch 89: loss = 0.4326494336128235, acc = 0.869140625\n",
      "Batch 90: loss = 0.44934192299842834, acc = 0.8515625\n",
      "Batch 91: loss = 0.47080785036087036, acc = 0.8359375\n",
      "Batch 92: loss = 0.4997631013393402, acc = 0.8369140625\n",
      "Batch 93: loss = 0.38861069083213806, acc = 0.87890625\n",
      "Batch 94: loss = 0.3993114233016968, acc = 0.8740234375\n",
      "Batch 95: loss = 0.4250220060348511, acc = 0.8486328125\n",
      "Batch 96: loss = 0.4897427558898926, acc = 0.830078125\n",
      "Batch 97: loss = 0.4595472812652588, acc = 0.859375\n",
      "Batch 98: loss = 0.43791183829307556, acc = 0.84375\n",
      "Batch 99: loss = 0.45860975980758667, acc = 0.845703125\n",
      "Batch 100: loss = 0.4516153931617737, acc = 0.84375\n",
      "Batch 101: loss = 0.4274832606315613, acc = 0.8662109375\n",
      "Batch 102: loss = 0.4659367501735687, acc = 0.85546875\n",
      "Batch 103: loss = 0.4464433789253235, acc = 0.8583984375\n",
      "Batch 104: loss = 0.41778725385665894, acc = 0.8525390625\n",
      "Batch 105: loss = 0.41236355900764465, acc = 0.8662109375\n",
      "Batch 106: loss = 0.44897937774658203, acc = 0.859375\n",
      "Batch 107: loss = 0.4059131443500519, acc = 0.86328125\n",
      "Batch 108: loss = 0.4242355227470398, acc = 0.865234375\n",
      "Batch 109: loss = 0.3918514549732208, acc = 0.8671875\n",
      "Batch 110: loss = 0.3755561411380768, acc = 0.8896484375\n",
      "Batch 111: loss = 0.4387596845626831, acc = 0.8447265625\n",
      "Batch 112: loss = 0.4335036873817444, acc = 0.853515625\n",
      "Batch 113: loss = 0.4529954791069031, acc = 0.84375\n",
      "Batch 114: loss = 0.41566890478134155, acc = 0.87109375\n",
      "Batch 115: loss = 0.43316638469696045, acc = 0.859375\n",
      "Batch 116: loss = 0.4919130206108093, acc = 0.8369140625\n",
      "Batch 117: loss = 0.42486336827278137, acc = 0.8623046875\n",
      "Batch 118: loss = 0.38361963629722595, acc = 0.869140625\n",
      "Batch 119: loss = 0.4109063744544983, acc = 0.8623046875\n",
      "Batch 120: loss = 0.3785163462162018, acc = 0.87890625\n",
      "Batch 121: loss = 0.46106231212615967, acc = 0.8369140625\n",
      "Batch 122: loss = 0.3890547454357147, acc = 0.869140625\n",
      "Batch 123: loss = 0.446563184261322, acc = 0.85546875\n",
      "Batch 124: loss = 0.44268888235092163, acc = 0.8466796875\n",
      "Batch 125: loss = 0.4588940143585205, acc = 0.8447265625\n",
      "Batch 126: loss = 0.41965144872665405, acc = 0.861328125\n",
      "\n",
      "Epoch 50/100\n",
      "Batch 1: loss = 0.5884828567504883, acc = 0.8369140625\n",
      "Batch 2: loss = 0.45614123344421387, acc = 0.8408203125\n",
      "Batch 3: loss = 0.4458516240119934, acc = 0.8603515625\n",
      "Batch 4: loss = 0.4269932508468628, acc = 0.865234375\n",
      "Batch 5: loss = 0.4789378046989441, acc = 0.845703125\n",
      "Batch 6: loss = 0.4600244164466858, acc = 0.8515625\n",
      "Batch 7: loss = 0.4372689723968506, acc = 0.8583984375\n",
      "Batch 8: loss = 0.41473206877708435, acc = 0.869140625\n",
      "Batch 9: loss = 0.40547919273376465, acc = 0.8671875\n",
      "Batch 10: loss = 0.37085121870040894, acc = 0.875\n",
      "Batch 11: loss = 0.4061645567417145, acc = 0.857421875\n",
      "Batch 12: loss = 0.42955613136291504, acc = 0.8515625\n",
      "Batch 13: loss = 0.40152591466903687, acc = 0.869140625\n",
      "Batch 14: loss = 0.4116225242614746, acc = 0.8701171875\n",
      "Batch 15: loss = 0.40937718749046326, acc = 0.857421875\n",
      "Batch 16: loss = 0.43466657400131226, acc = 0.8544921875\n",
      "Batch 17: loss = 0.4444991946220398, acc = 0.8466796875\n",
      "Batch 18: loss = 0.4486086368560791, acc = 0.8544921875\n",
      "Batch 19: loss = 0.4287419617176056, acc = 0.8623046875\n",
      "Batch 20: loss = 0.4206179678440094, acc = 0.8564453125\n",
      "Batch 21: loss = 0.4593724012374878, acc = 0.8515625\n",
      "Batch 22: loss = 0.43313050270080566, acc = 0.8486328125\n",
      "Batch 23: loss = 0.4022689759731293, acc = 0.8583984375\n",
      "Batch 24: loss = 0.4096258878707886, acc = 0.861328125\n",
      "Batch 25: loss = 0.4132368564605713, acc = 0.857421875\n",
      "Batch 26: loss = 0.4343227744102478, acc = 0.859375\n",
      "Batch 27: loss = 0.45391058921813965, acc = 0.84375\n",
      "Batch 28: loss = 0.4721018671989441, acc = 0.8525390625\n",
      "Batch 29: loss = 0.4298866391181946, acc = 0.86328125\n",
      "Batch 30: loss = 0.41962510347366333, acc = 0.859375\n",
      "Batch 31: loss = 0.44169843196868896, acc = 0.8701171875\n",
      "Batch 32: loss = 0.5132436752319336, acc = 0.8232421875\n",
      "Batch 33: loss = 0.4056277871131897, acc = 0.8583984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 34: loss = 0.4646786153316498, acc = 0.8486328125\n",
      "Batch 35: loss = 0.4472009539604187, acc = 0.8564453125\n",
      "Batch 36: loss = 0.41576531529426575, acc = 0.859375\n",
      "Batch 37: loss = 0.4177808165550232, acc = 0.8759765625\n",
      "Batch 38: loss = 0.44521477818489075, acc = 0.8486328125\n",
      "Batch 39: loss = 0.412014901638031, acc = 0.8544921875\n",
      "Batch 40: loss = 0.4300810992717743, acc = 0.865234375\n",
      "Batch 41: loss = 0.4003942906856537, acc = 0.869140625\n",
      "Batch 42: loss = 0.39367708563804626, acc = 0.8720703125\n",
      "Batch 43: loss = 0.4347332715988159, acc = 0.8505859375\n",
      "Batch 44: loss = 0.4077063202857971, acc = 0.8681640625\n",
      "Batch 45: loss = 0.4155428409576416, acc = 0.8642578125\n",
      "Batch 46: loss = 0.39469417929649353, acc = 0.8720703125\n",
      "Batch 47: loss = 0.4156368374824524, acc = 0.859375\n",
      "Batch 48: loss = 0.41847383975982666, acc = 0.86328125\n",
      "Batch 49: loss = 0.39273130893707275, acc = 0.87109375\n",
      "Batch 50: loss = 0.41014522314071655, acc = 0.87109375\n",
      "Batch 51: loss = 0.35512611269950867, acc = 0.873046875\n",
      "Batch 52: loss = 0.424630343914032, acc = 0.859375\n",
      "Batch 53: loss = 0.4494553208351135, acc = 0.8466796875\n",
      "Batch 54: loss = 0.3474805951118469, acc = 0.8837890625\n",
      "Batch 55: loss = 0.4034131169319153, acc = 0.87109375\n",
      "Batch 56: loss = 0.4394422173500061, acc = 0.8427734375\n",
      "Batch 57: loss = 0.4569913148880005, acc = 0.8427734375\n",
      "Batch 58: loss = 0.4783610999584198, acc = 0.8388671875\n",
      "Batch 59: loss = 0.3486122488975525, acc = 0.876953125\n",
      "Batch 60: loss = 0.455095112323761, acc = 0.85546875\n",
      "Batch 61: loss = 0.4047108292579651, acc = 0.8603515625\n",
      "Batch 62: loss = 0.5009059906005859, acc = 0.8212890625\n",
      "Batch 63: loss = 0.4523441791534424, acc = 0.83984375\n",
      "Batch 64: loss = 0.3883891999721527, acc = 0.8740234375\n",
      "Batch 65: loss = 0.4419695734977722, acc = 0.8544921875\n",
      "Batch 66: loss = 0.4368281364440918, acc = 0.8388671875\n",
      "Batch 67: loss = 0.4110233783721924, acc = 0.8642578125\n",
      "Batch 68: loss = 0.46359699964523315, acc = 0.84765625\n",
      "Batch 69: loss = 0.4035370349884033, acc = 0.8662109375\n",
      "Batch 70: loss = 0.4780552089214325, acc = 0.8427734375\n",
      "Batch 71: loss = 0.4635854959487915, acc = 0.8310546875\n",
      "Batch 72: loss = 0.42288607358932495, acc = 0.857421875\n",
      "Batch 73: loss = 0.46101805567741394, acc = 0.837890625\n",
      "Batch 74: loss = 0.4344852566719055, acc = 0.8564453125\n",
      "Batch 75: loss = 0.502813994884491, acc = 0.83203125\n",
      "Batch 76: loss = 0.4421582818031311, acc = 0.8544921875\n",
      "Batch 77: loss = 0.41109955310821533, acc = 0.8662109375\n",
      "Batch 78: loss = 0.44529399275779724, acc = 0.8544921875\n",
      "Batch 79: loss = 0.3903971016407013, acc = 0.8740234375\n",
      "Batch 80: loss = 0.39625227451324463, acc = 0.8544921875\n",
      "Batch 81: loss = 0.4197688698768616, acc = 0.8583984375\n",
      "Batch 82: loss = 0.4198877215385437, acc = 0.849609375\n",
      "Batch 83: loss = 0.42152154445648193, acc = 0.8623046875\n",
      "Batch 84: loss = 0.4077184200286865, acc = 0.8603515625\n",
      "Batch 85: loss = 0.4486653208732605, acc = 0.8544921875\n",
      "Batch 86: loss = 0.4188562035560608, acc = 0.861328125\n",
      "Batch 87: loss = 0.43004459142684937, acc = 0.8583984375\n",
      "Batch 88: loss = 0.48764413595199585, acc = 0.8330078125\n",
      "Batch 89: loss = 0.4508633613586426, acc = 0.83984375\n",
      "Batch 90: loss = 0.4191340208053589, acc = 0.859375\n",
      "Batch 91: loss = 0.4501066207885742, acc = 0.8505859375\n",
      "Batch 92: loss = 0.45849448442459106, acc = 0.8408203125\n",
      "Batch 93: loss = 0.39032745361328125, acc = 0.8779296875\n",
      "Batch 94: loss = 0.4136793613433838, acc = 0.8671875\n",
      "Batch 95: loss = 0.39472395181655884, acc = 0.8662109375\n",
      "Batch 96: loss = 0.4287826716899872, acc = 0.8525390625\n",
      "Batch 97: loss = 0.44679856300354004, acc = 0.8583984375\n",
      "Batch 98: loss = 0.44103747606277466, acc = 0.8544921875\n",
      "Batch 99: loss = 0.42170512676239014, acc = 0.861328125\n",
      "Batch 100: loss = 0.45691215991973877, acc = 0.8515625\n",
      "Batch 101: loss = 0.39942312240600586, acc = 0.8671875\n",
      "Batch 102: loss = 0.4464111328125, acc = 0.8505859375\n",
      "Batch 103: loss = 0.42250025272369385, acc = 0.8603515625\n",
      "Batch 104: loss = 0.37711402773857117, acc = 0.8837890625\n",
      "Batch 105: loss = 0.41597825288772583, acc = 0.8603515625\n",
      "Batch 106: loss = 0.41643208265304565, acc = 0.8583984375\n",
      "Batch 107: loss = 0.40407902002334595, acc = 0.85546875\n",
      "Batch 108: loss = 0.3994382619857788, acc = 0.8671875\n",
      "Batch 109: loss = 0.4047723412513733, acc = 0.8603515625\n",
      "Batch 110: loss = 0.38704538345336914, acc = 0.8798828125\n",
      "Batch 111: loss = 0.4466553330421448, acc = 0.8525390625\n",
      "Batch 112: loss = 0.41271868348121643, acc = 0.8525390625\n",
      "Batch 113: loss = 0.4089507460594177, acc = 0.86328125\n",
      "Batch 114: loss = 0.40837520360946655, acc = 0.86328125\n",
      "Batch 115: loss = 0.4352657198905945, acc = 0.8671875\n",
      "Batch 116: loss = 0.43162429332733154, acc = 0.8583984375\n",
      "Batch 117: loss = 0.4345075488090515, acc = 0.86328125\n",
      "Batch 118: loss = 0.3773716688156128, acc = 0.8720703125\n",
      "Batch 119: loss = 0.41711848974227905, acc = 0.865234375\n",
      "Batch 120: loss = 0.3905205726623535, acc = 0.8740234375\n",
      "Batch 121: loss = 0.4370097517967224, acc = 0.8486328125\n",
      "Batch 122: loss = 0.41070783138275146, acc = 0.8515625\n",
      "Batch 123: loss = 0.41822847723960876, acc = 0.8701171875\n",
      "Batch 124: loss = 0.4508858919143677, acc = 0.8447265625\n",
      "Batch 125: loss = 0.47098392248153687, acc = 0.8427734375\n",
      "Batch 126: loss = 0.4499809443950653, acc = 0.8466796875\n",
      "Saved checkpoint to weights.50.h5\n",
      "\n",
      "Epoch 51/100\n",
      "Batch 1: loss = 0.5951605439186096, acc = 0.837890625\n",
      "Batch 2: loss = 0.47855040431022644, acc = 0.833984375\n",
      "Batch 3: loss = 0.4399356245994568, acc = 0.8681640625\n",
      "Batch 4: loss = 0.43886905908584595, acc = 0.85546875\n",
      "Batch 5: loss = 0.4649851322174072, acc = 0.8466796875\n",
      "Batch 6: loss = 0.4742532968521118, acc = 0.8359375\n",
      "Batch 7: loss = 0.44984450936317444, acc = 0.8583984375\n",
      "Batch 8: loss = 0.41692763566970825, acc = 0.8701171875\n",
      "Batch 9: loss = 0.43203628063201904, acc = 0.8623046875\n",
      "Batch 10: loss = 0.40694305300712585, acc = 0.8583984375\n",
      "Batch 11: loss = 0.4304225444793701, acc = 0.853515625\n",
      "Batch 12: loss = 0.46365219354629517, acc = 0.8466796875\n",
      "Batch 13: loss = 0.38282251358032227, acc = 0.8798828125\n",
      "Batch 14: loss = 0.4300795793533325, acc = 0.8720703125\n",
      "Batch 15: loss = 0.42905887961387634, acc = 0.8583984375\n",
      "Batch 16: loss = 0.42094188928604126, acc = 0.861328125\n",
      "Batch 17: loss = 0.4068322479724884, acc = 0.8525390625\n",
      "Batch 18: loss = 0.45210713148117065, acc = 0.8505859375\n",
      "Batch 19: loss = 0.43199703097343445, acc = 0.86328125\n",
      "Batch 20: loss = 0.40873414278030396, acc = 0.8623046875\n",
      "Batch 21: loss = 0.4422740340232849, acc = 0.845703125\n",
      "Batch 22: loss = 0.43793201446533203, acc = 0.8583984375\n",
      "Batch 23: loss = 0.42452526092529297, acc = 0.8681640625\n",
      "Batch 24: loss = 0.4196568727493286, acc = 0.857421875\n",
      "Batch 25: loss = 0.4199270009994507, acc = 0.849609375\n",
      "Batch 26: loss = 0.42440080642700195, acc = 0.859375\n",
      "Batch 27: loss = 0.4496322274208069, acc = 0.8544921875\n",
      "Batch 28: loss = 0.4863691031932831, acc = 0.8505859375\n",
      "Batch 29: loss = 0.4226001501083374, acc = 0.857421875\n",
      "Batch 30: loss = 0.3950982689857483, acc = 0.87109375\n",
      "Batch 31: loss = 0.4555756449699402, acc = 0.8525390625\n",
      "Batch 32: loss = 0.4852561950683594, acc = 0.8515625\n",
      "Batch 33: loss = 0.41331031918525696, acc = 0.8603515625\n",
      "Batch 34: loss = 0.4309455156326294, acc = 0.8671875\n",
      "Batch 35: loss = 0.4183562994003296, acc = 0.880859375\n",
      "Batch 36: loss = 0.369079053401947, acc = 0.8671875\n",
      "Batch 37: loss = 0.386324018239975, acc = 0.8720703125\n",
      "Batch 38: loss = 0.42333316802978516, acc = 0.8583984375\n",
      "Batch 39: loss = 0.3993140161037445, acc = 0.8671875\n",
      "Batch 40: loss = 0.4317331314086914, acc = 0.8486328125\n",
      "Batch 41: loss = 0.39317649602890015, acc = 0.875\n",
      "Batch 42: loss = 0.42293357849121094, acc = 0.859375\n",
      "Batch 43: loss = 0.41402655839920044, acc = 0.859375\n",
      "Batch 44: loss = 0.40593576431274414, acc = 0.869140625\n",
      "Batch 45: loss = 0.4066336154937744, acc = 0.8583984375\n",
      "Batch 46: loss = 0.3660454750061035, acc = 0.8720703125\n",
      "Batch 47: loss = 0.4050174057483673, acc = 0.8681640625\n",
      "Batch 48: loss = 0.4051215946674347, acc = 0.8662109375\n",
      "Batch 49: loss = 0.3285239040851593, acc = 0.8857421875\n",
      "Batch 50: loss = 0.3921774625778198, acc = 0.8681640625\n",
      "Batch 51: loss = 0.4157361388206482, acc = 0.8515625\n",
      "Batch 52: loss = 0.4405241906642914, acc = 0.8486328125\n",
      "Batch 53: loss = 0.42254626750946045, acc = 0.86328125\n",
      "Batch 54: loss = 0.3446301221847534, acc = 0.8828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 55: loss = 0.345187783241272, acc = 0.88671875\n",
      "Batch 56: loss = 0.4205288290977478, acc = 0.8583984375\n",
      "Batch 57: loss = 0.4509332478046417, acc = 0.85546875\n",
      "Batch 58: loss = 0.44546574354171753, acc = 0.8388671875\n",
      "Batch 59: loss = 0.3474579453468323, acc = 0.880859375\n",
      "Batch 60: loss = 0.4455440044403076, acc = 0.8525390625\n",
      "Batch 61: loss = 0.36764973402023315, acc = 0.880859375\n",
      "Batch 62: loss = 0.44762730598449707, acc = 0.8447265625\n",
      "Batch 63: loss = 0.41355228424072266, acc = 0.8603515625\n",
      "Batch 64: loss = 0.3529520630836487, acc = 0.8857421875\n",
      "Batch 65: loss = 0.4306223392486572, acc = 0.8671875\n",
      "Batch 66: loss = 0.4122662842273712, acc = 0.8583984375\n",
      "Batch 67: loss = 0.4102444350719452, acc = 0.8642578125\n",
      "Batch 68: loss = 0.40357285737991333, acc = 0.865234375\n",
      "Batch 69: loss = 0.38306567072868347, acc = 0.876953125\n",
      "Batch 70: loss = 0.4950734078884125, acc = 0.845703125\n",
      "Batch 71: loss = 0.45562463998794556, acc = 0.8349609375\n",
      "Batch 72: loss = 0.4320334196090698, acc = 0.86328125\n",
      "Batch 73: loss = 0.46464794874191284, acc = 0.8525390625\n",
      "Batch 74: loss = 0.4677335023880005, acc = 0.84375\n",
      "Batch 75: loss = 0.4944252371788025, acc = 0.845703125\n",
      "Batch 76: loss = 0.4550190567970276, acc = 0.8447265625\n",
      "Batch 77: loss = 0.39771878719329834, acc = 0.865234375\n",
      "Batch 78: loss = 0.4368095099925995, acc = 0.8525390625\n",
      "Batch 79: loss = 0.3761085271835327, acc = 0.8759765625\n",
      "Batch 80: loss = 0.39662420749664307, acc = 0.853515625\n",
      "Batch 81: loss = 0.3690919876098633, acc = 0.875\n",
      "Batch 82: loss = 0.4111596643924713, acc = 0.865234375\n",
      "Batch 83: loss = 0.41695737838745117, acc = 0.8525390625\n",
      "Batch 84: loss = 0.4252476692199707, acc = 0.8544921875\n",
      "Batch 85: loss = 0.4863857626914978, acc = 0.8310546875\n",
      "Batch 86: loss = 0.4142828583717346, acc = 0.8583984375\n",
      "Batch 87: loss = 0.443866491317749, acc = 0.8486328125\n",
      "Batch 88: loss = 0.48867636919021606, acc = 0.837890625\n",
      "Batch 89: loss = 0.4270894527435303, acc = 0.86328125\n",
      "Batch 90: loss = 0.40445592999458313, acc = 0.869140625\n",
      "Batch 91: loss = 0.4294022023677826, acc = 0.8544921875\n",
      "Batch 92: loss = 0.4461972117424011, acc = 0.84375\n",
      "Batch 93: loss = 0.37629514932632446, acc = 0.884765625\n",
      "Batch 94: loss = 0.40073370933532715, acc = 0.873046875\n",
      "Batch 95: loss = 0.369606077671051, acc = 0.8720703125\n",
      "Batch 96: loss = 0.4550420641899109, acc = 0.841796875\n",
      "Batch 97: loss = 0.46388691663742065, acc = 0.849609375\n",
      "Batch 98: loss = 0.43603581190109253, acc = 0.8408203125\n",
      "Batch 99: loss = 0.4115893244743347, acc = 0.849609375\n",
      "Batch 100: loss = 0.4473378658294678, acc = 0.849609375\n",
      "Batch 101: loss = 0.4137592911720276, acc = 0.8564453125\n",
      "Batch 102: loss = 0.44006800651550293, acc = 0.8603515625\n",
      "Batch 103: loss = 0.41426610946655273, acc = 0.857421875\n",
      "Batch 104: loss = 0.3644997179508209, acc = 0.8779296875\n",
      "Batch 105: loss = 0.3895356059074402, acc = 0.875\n",
      "Batch 106: loss = 0.4065741002559662, acc = 0.8603515625\n",
      "Batch 107: loss = 0.4167887270450592, acc = 0.8642578125\n",
      "Batch 108: loss = 0.39071422815322876, acc = 0.8671875\n",
      "Batch 109: loss = 0.4061731696128845, acc = 0.8642578125\n",
      "Batch 110: loss = 0.3778005838394165, acc = 0.8837890625\n",
      "Batch 111: loss = 0.4284108281135559, acc = 0.853515625\n",
      "Batch 112: loss = 0.43211492896080017, acc = 0.8525390625\n",
      "Batch 113: loss = 0.38481152057647705, acc = 0.869140625\n",
      "Batch 114: loss = 0.3979894816875458, acc = 0.8662109375\n",
      "Batch 115: loss = 0.4413944482803345, acc = 0.86328125\n",
      "Batch 116: loss = 0.4534098505973816, acc = 0.8515625\n",
      "Batch 117: loss = 0.41964125633239746, acc = 0.8671875\n",
      "Batch 118: loss = 0.3686927258968353, acc = 0.8779296875\n",
      "Batch 119: loss = 0.3856305480003357, acc = 0.8671875\n",
      "Batch 120: loss = 0.37830835580825806, acc = 0.8701171875\n",
      "Batch 121: loss = 0.43521377444267273, acc = 0.85546875\n",
      "Batch 122: loss = 0.4148436188697815, acc = 0.8662109375\n",
      "Batch 123: loss = 0.41056376695632935, acc = 0.8671875\n",
      "Batch 124: loss = 0.44438469409942627, acc = 0.84765625\n",
      "Batch 125: loss = 0.47886502742767334, acc = 0.845703125\n",
      "Batch 126: loss = 0.4259278476238251, acc = 0.8671875\n",
      "\n",
      "Epoch 52/100\n",
      "Batch 1: loss = 0.5629738569259644, acc = 0.8310546875\n",
      "Batch 2: loss = 0.4222429692745209, acc = 0.8544921875\n",
      "Batch 3: loss = 0.4768548607826233, acc = 0.857421875\n",
      "Batch 4: loss = 0.41435688734054565, acc = 0.8798828125\n",
      "Batch 5: loss = 0.4067896008491516, acc = 0.8662109375\n",
      "Batch 6: loss = 0.46671515703201294, acc = 0.84375\n",
      "Batch 7: loss = 0.4236094355583191, acc = 0.8642578125\n",
      "Batch 8: loss = 0.4063986539840698, acc = 0.8779296875\n",
      "Batch 9: loss = 0.4124525785446167, acc = 0.8623046875\n",
      "Batch 10: loss = 0.3569396734237671, acc = 0.8896484375\n",
      "Batch 11: loss = 0.42405563592910767, acc = 0.8515625\n",
      "Batch 12: loss = 0.3837309181690216, acc = 0.8720703125\n",
      "Batch 13: loss = 0.38534682989120483, acc = 0.8740234375\n",
      "Batch 14: loss = 0.3894869089126587, acc = 0.869140625\n",
      "Batch 15: loss = 0.3975837826728821, acc = 0.869140625\n",
      "Batch 16: loss = 0.4506869316101074, acc = 0.84375\n",
      "Batch 17: loss = 0.4007304310798645, acc = 0.8681640625\n",
      "Batch 18: loss = 0.42420774698257446, acc = 0.85546875\n",
      "Batch 19: loss = 0.4117931127548218, acc = 0.8662109375\n",
      "Batch 20: loss = 0.3992491364479065, acc = 0.86328125\n",
      "Batch 21: loss = 0.41878125071525574, acc = 0.8515625\n",
      "Batch 22: loss = 0.42967891693115234, acc = 0.8583984375\n",
      "Batch 23: loss = 0.42510300874710083, acc = 0.859375\n",
      "Batch 24: loss = 0.4163782000541687, acc = 0.861328125\n",
      "Batch 25: loss = 0.39149683713912964, acc = 0.8740234375\n",
      "Batch 26: loss = 0.39810559153556824, acc = 0.86328125\n",
      "Batch 27: loss = 0.4464712142944336, acc = 0.84765625\n",
      "Batch 28: loss = 0.4344080090522766, acc = 0.8564453125\n",
      "Batch 29: loss = 0.4334864020347595, acc = 0.8515625\n",
      "Batch 30: loss = 0.39748549461364746, acc = 0.865234375\n",
      "Batch 31: loss = 0.469766229391098, acc = 0.8408203125\n",
      "Batch 32: loss = 0.4767059087753296, acc = 0.84375\n",
      "Batch 33: loss = 0.39522719383239746, acc = 0.8740234375\n",
      "Batch 34: loss = 0.42656221985816956, acc = 0.857421875\n",
      "Batch 35: loss = 0.42576152086257935, acc = 0.86328125\n",
      "Batch 36: loss = 0.3830542266368866, acc = 0.8798828125\n",
      "Batch 37: loss = 0.41969406604766846, acc = 0.8623046875\n",
      "Batch 38: loss = 0.40556466579437256, acc = 0.87109375\n",
      "Batch 39: loss = 0.37527263164520264, acc = 0.876953125\n",
      "Batch 40: loss = 0.39781737327575684, acc = 0.869140625\n",
      "Batch 41: loss = 0.380459725856781, acc = 0.8642578125\n",
      "Batch 42: loss = 0.3896118998527527, acc = 0.8720703125\n",
      "Batch 43: loss = 0.422733873128891, acc = 0.8603515625\n",
      "Batch 44: loss = 0.38564059138298035, acc = 0.8818359375\n",
      "Batch 45: loss = 0.3738846182823181, acc = 0.880859375\n",
      "Batch 46: loss = 0.36350569128990173, acc = 0.87890625\n",
      "Batch 47: loss = 0.3925682306289673, acc = 0.873046875\n",
      "Batch 48: loss = 0.40720880031585693, acc = 0.865234375\n",
      "Batch 49: loss = 0.3592939078807831, acc = 0.88671875\n",
      "Batch 50: loss = 0.3536330759525299, acc = 0.890625\n",
      "Batch 51: loss = 0.3703415095806122, acc = 0.8701171875\n",
      "Batch 52: loss = 0.3943050503730774, acc = 0.876953125\n",
      "Batch 53: loss = 0.4063124656677246, acc = 0.8662109375\n",
      "Batch 54: loss = 0.32032978534698486, acc = 0.90234375\n",
      "Batch 55: loss = 0.35490167140960693, acc = 0.888671875\n",
      "Batch 56: loss = 0.42270323634147644, acc = 0.8525390625\n",
      "Batch 57: loss = 0.4457194209098816, acc = 0.8486328125\n",
      "Batch 58: loss = 0.4279937744140625, acc = 0.8603515625\n",
      "Batch 59: loss = 0.3326084017753601, acc = 0.896484375\n",
      "Batch 60: loss = 0.40061068534851074, acc = 0.8671875\n",
      "Batch 61: loss = 0.39027270674705505, acc = 0.876953125\n",
      "Batch 62: loss = 0.4655829668045044, acc = 0.849609375\n",
      "Batch 63: loss = 0.41584521532058716, acc = 0.857421875\n",
      "Batch 64: loss = 0.34950631856918335, acc = 0.8818359375\n",
      "Batch 65: loss = 0.4065795838832855, acc = 0.87109375\n",
      "Batch 66: loss = 0.4264047145843506, acc = 0.8486328125\n",
      "Batch 67: loss = 0.39625298976898193, acc = 0.8681640625\n",
      "Batch 68: loss = 0.3902379274368286, acc = 0.869140625\n",
      "Batch 69: loss = 0.37582963705062866, acc = 0.8798828125\n",
      "Batch 70: loss = 0.4343913197517395, acc = 0.861328125\n",
      "Batch 71: loss = 0.43806982040405273, acc = 0.857421875\n",
      "Batch 72: loss = 0.378836452960968, acc = 0.880859375\n",
      "Batch 73: loss = 0.4252074360847473, acc = 0.8544921875\n",
      "Batch 74: loss = 0.4191848635673523, acc = 0.8603515625\n",
      "Batch 75: loss = 0.49496030807495117, acc = 0.83984375\n",
      "Batch 76: loss = 0.4591062068939209, acc = 0.8427734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 77: loss = 0.41094690561294556, acc = 0.8466796875\n",
      "Batch 78: loss = 0.4363976716995239, acc = 0.8603515625\n",
      "Batch 79: loss = 0.35223299264907837, acc = 0.876953125\n",
      "Batch 80: loss = 0.37064793705940247, acc = 0.8662109375\n",
      "Batch 81: loss = 0.4209149181842804, acc = 0.8564453125\n",
      "Batch 82: loss = 0.38772714138031006, acc = 0.888671875\n",
      "Batch 83: loss = 0.4221700429916382, acc = 0.845703125\n",
      "Batch 84: loss = 0.41628068685531616, acc = 0.845703125\n",
      "Batch 85: loss = 0.4287185072898865, acc = 0.849609375\n",
      "Batch 86: loss = 0.4082093834877014, acc = 0.8662109375\n",
      "Batch 87: loss = 0.4201710820198059, acc = 0.86328125\n",
      "Batch 88: loss = 0.45254430174827576, acc = 0.8544921875\n",
      "Batch 89: loss = 0.39559030532836914, acc = 0.8642578125\n",
      "Batch 90: loss = 0.43458110094070435, acc = 0.8505859375\n",
      "Batch 91: loss = 0.42782098054885864, acc = 0.8671875\n",
      "Batch 92: loss = 0.4431610107421875, acc = 0.84765625\n",
      "Batch 93: loss = 0.3939594626426697, acc = 0.8662109375\n",
      "Batch 94: loss = 0.38464635610580444, acc = 0.873046875\n",
      "Batch 95: loss = 0.35775622725486755, acc = 0.8857421875\n",
      "Batch 96: loss = 0.41184723377227783, acc = 0.8544921875\n",
      "Batch 97: loss = 0.45262742042541504, acc = 0.849609375\n",
      "Batch 98: loss = 0.4506978988647461, acc = 0.8515625\n",
      "Batch 99: loss = 0.40936559438705444, acc = 0.859375\n",
      "Batch 100: loss = 0.41564619541168213, acc = 0.853515625\n",
      "Batch 101: loss = 0.39774954319000244, acc = 0.8720703125\n",
      "Batch 102: loss = 0.43223950266838074, acc = 0.8642578125\n",
      "Batch 103: loss = 0.4261723756790161, acc = 0.8740234375\n",
      "Batch 104: loss = 0.3636457920074463, acc = 0.8779296875\n",
      "Batch 105: loss = 0.4105794429779053, acc = 0.8642578125\n",
      "Batch 106: loss = 0.40748244524002075, acc = 0.8603515625\n",
      "Batch 107: loss = 0.3888883590698242, acc = 0.8671875\n",
      "Batch 108: loss = 0.3861943483352661, acc = 0.87890625\n",
      "Batch 109: loss = 0.3905971944332123, acc = 0.86328125\n",
      "Batch 110: loss = 0.4199411869049072, acc = 0.8671875\n",
      "Batch 111: loss = 0.41390031576156616, acc = 0.8642578125\n",
      "Batch 112: loss = 0.40560510754585266, acc = 0.86328125\n",
      "Batch 113: loss = 0.4003937244415283, acc = 0.8603515625\n",
      "Batch 114: loss = 0.4308193325996399, acc = 0.86328125\n",
      "Batch 115: loss = 0.42505520582199097, acc = 0.853515625\n",
      "Batch 116: loss = 0.410564124584198, acc = 0.8544921875\n",
      "Batch 117: loss = 0.39210090041160583, acc = 0.8671875\n",
      "Batch 118: loss = 0.3753439486026764, acc = 0.876953125\n",
      "Batch 119: loss = 0.3898158371448517, acc = 0.8740234375\n",
      "Batch 120: loss = 0.3665980100631714, acc = 0.87109375\n",
      "Batch 121: loss = 0.413237988948822, acc = 0.8505859375\n",
      "Batch 122: loss = 0.39324188232421875, acc = 0.865234375\n",
      "Batch 123: loss = 0.39439982175827026, acc = 0.8671875\n",
      "Batch 124: loss = 0.427172988653183, acc = 0.8505859375\n",
      "Batch 125: loss = 0.4337577819824219, acc = 0.86328125\n",
      "Batch 126: loss = 0.416299968957901, acc = 0.865234375\n",
      "\n",
      "Epoch 53/100\n",
      "Batch 1: loss = 0.541652500629425, acc = 0.84765625\n",
      "Batch 2: loss = 0.4056259095668793, acc = 0.8671875\n",
      "Batch 3: loss = 0.4282575845718384, acc = 0.861328125\n",
      "Batch 4: loss = 0.38717716932296753, acc = 0.8720703125\n",
      "Batch 5: loss = 0.416828453540802, acc = 0.8681640625\n",
      "Batch 6: loss = 0.43820130825042725, acc = 0.853515625\n",
      "Batch 7: loss = 0.4207454025745392, acc = 0.8681640625\n",
      "Batch 8: loss = 0.4106757938861847, acc = 0.875\n",
      "Batch 9: loss = 0.39552322030067444, acc = 0.87109375\n",
      "Batch 10: loss = 0.3637908399105072, acc = 0.8681640625\n",
      "Batch 11: loss = 0.4149293303489685, acc = 0.8681640625\n",
      "Batch 12: loss = 0.3950692415237427, acc = 0.861328125\n",
      "Batch 13: loss = 0.3987005352973938, acc = 0.8740234375\n",
      "Batch 14: loss = 0.4254872798919678, acc = 0.875\n",
      "Batch 15: loss = 0.365666002035141, acc = 0.884765625\n",
      "Batch 16: loss = 0.3970692455768585, acc = 0.873046875\n",
      "Batch 17: loss = 0.4080345332622528, acc = 0.8642578125\n",
      "Batch 18: loss = 0.42328089475631714, acc = 0.8583984375\n",
      "Batch 19: loss = 0.3966522216796875, acc = 0.8740234375\n",
      "Batch 20: loss = 0.3932100534439087, acc = 0.8671875\n",
      "Batch 21: loss = 0.43463456630706787, acc = 0.857421875\n",
      "Batch 22: loss = 0.41527992486953735, acc = 0.85546875\n",
      "Batch 23: loss = 0.4185674786567688, acc = 0.8681640625\n",
      "Batch 24: loss = 0.39165911078453064, acc = 0.8740234375\n",
      "Batch 25: loss = 0.38928812742233276, acc = 0.8642578125\n",
      "Batch 26: loss = 0.40691328048706055, acc = 0.8603515625\n",
      "Batch 27: loss = 0.4560052454471588, acc = 0.841796875\n",
      "Batch 28: loss = 0.45907485485076904, acc = 0.837890625\n",
      "Batch 29: loss = 0.44712841510772705, acc = 0.84375\n",
      "Batch 30: loss = 0.37205076217651367, acc = 0.8837890625\n",
      "Batch 31: loss = 0.44565343856811523, acc = 0.8525390625\n",
      "Batch 32: loss = 0.4750356376171112, acc = 0.8505859375\n",
      "Batch 33: loss = 0.4068067669868469, acc = 0.8642578125\n",
      "Batch 34: loss = 0.40092843770980835, acc = 0.8701171875\n",
      "Batch 35: loss = 0.3966684937477112, acc = 0.869140625\n",
      "Batch 36: loss = 0.38118451833724976, acc = 0.87109375\n",
      "Batch 37: loss = 0.38325250148773193, acc = 0.876953125\n",
      "Batch 38: loss = 0.4169124364852905, acc = 0.8515625\n",
      "Batch 39: loss = 0.3880065679550171, acc = 0.86328125\n",
      "Batch 40: loss = 0.42714062333106995, acc = 0.85546875\n",
      "Batch 41: loss = 0.3724677562713623, acc = 0.880859375\n",
      "Batch 42: loss = 0.3846047520637512, acc = 0.8720703125\n",
      "Batch 43: loss = 0.4026029706001282, acc = 0.8681640625\n",
      "Batch 44: loss = 0.40999388694763184, acc = 0.8681640625\n",
      "Batch 45: loss = 0.3709492087364197, acc = 0.880859375\n",
      "Batch 46: loss = 0.3667736053466797, acc = 0.8818359375\n",
      "Batch 47: loss = 0.3884502053260803, acc = 0.8662109375\n",
      "Batch 48: loss = 0.3895946145057678, acc = 0.8759765625\n",
      "Batch 49: loss = 0.3708914518356323, acc = 0.8828125\n",
      "Batch 50: loss = 0.3910369873046875, acc = 0.8740234375\n",
      "Batch 51: loss = 0.37884920835494995, acc = 0.8779296875\n",
      "Batch 52: loss = 0.39664870500564575, acc = 0.859375\n",
      "Batch 53: loss = 0.40892136096954346, acc = 0.8623046875\n",
      "Batch 54: loss = 0.34777960181236267, acc = 0.8896484375\n",
      "Batch 55: loss = 0.35282206535339355, acc = 0.880859375\n",
      "Batch 56: loss = 0.4230859875679016, acc = 0.8603515625\n",
      "Batch 57: loss = 0.41769495606422424, acc = 0.8662109375\n",
      "Batch 58: loss = 0.4310300350189209, acc = 0.8515625\n",
      "Batch 59: loss = 0.3340442478656769, acc = 0.884765625\n",
      "Batch 60: loss = 0.40827706456184387, acc = 0.869140625\n",
      "Batch 61: loss = 0.3518582582473755, acc = 0.88671875\n",
      "Batch 62: loss = 0.4706878662109375, acc = 0.83984375\n",
      "Batch 63: loss = 0.4306904673576355, acc = 0.8623046875\n",
      "Batch 64: loss = 0.35416531562805176, acc = 0.880859375\n",
      "Batch 65: loss = 0.41550761461257935, acc = 0.859375\n",
      "Batch 66: loss = 0.428744375705719, acc = 0.8564453125\n",
      "Batch 67: loss = 0.37703612446784973, acc = 0.8662109375\n",
      "Batch 68: loss = 0.3971489667892456, acc = 0.876953125\n",
      "Batch 69: loss = 0.3508690595626831, acc = 0.87109375\n",
      "Batch 70: loss = 0.4405578374862671, acc = 0.8525390625\n",
      "Batch 71: loss = 0.39713233709335327, acc = 0.861328125\n",
      "Batch 72: loss = 0.36965155601501465, acc = 0.876953125\n",
      "Batch 73: loss = 0.43186596035957336, acc = 0.853515625\n",
      "Batch 74: loss = 0.4149754047393799, acc = 0.8642578125\n",
      "Batch 75: loss = 0.4750209152698517, acc = 0.83984375\n",
      "Batch 76: loss = 0.4462042450904846, acc = 0.853515625\n",
      "Batch 77: loss = 0.4212207794189453, acc = 0.85546875\n",
      "Batch 78: loss = 0.42914265394210815, acc = 0.8642578125\n",
      "Batch 79: loss = 0.3581213355064392, acc = 0.8779296875\n",
      "Batch 80: loss = 0.4038028120994568, acc = 0.857421875\n",
      "Batch 81: loss = 0.3928193151950836, acc = 0.857421875\n",
      "Batch 82: loss = 0.3739214241504669, acc = 0.884765625\n",
      "Batch 83: loss = 0.3862062394618988, acc = 0.8642578125\n",
      "Batch 84: loss = 0.40970465540885925, acc = 0.8583984375\n",
      "Batch 85: loss = 0.45540910959243774, acc = 0.84765625\n",
      "Batch 86: loss = 0.42661720514297485, acc = 0.8623046875\n",
      "Batch 87: loss = 0.4020158052444458, acc = 0.8720703125\n",
      "Batch 88: loss = 0.46743080019950867, acc = 0.8408203125\n",
      "Batch 89: loss = 0.40577203035354614, acc = 0.8671875\n",
      "Batch 90: loss = 0.4484146237373352, acc = 0.8505859375\n",
      "Batch 91: loss = 0.40545061230659485, acc = 0.85546875\n",
      "Batch 92: loss = 0.40839099884033203, acc = 0.8671875\n",
      "Batch 93: loss = 0.36178892850875854, acc = 0.8798828125\n",
      "Batch 94: loss = 0.3805619776248932, acc = 0.87890625\n",
      "Batch 95: loss = 0.34631311893463135, acc = 0.890625\n",
      "Batch 96: loss = 0.3938925862312317, acc = 0.859375\n",
      "Batch 97: loss = 0.4318959414958954, acc = 0.86328125\n",
      "Batch 98: loss = 0.4240662455558777, acc = 0.857421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 99: loss = 0.42402687668800354, acc = 0.857421875\n",
      "Batch 100: loss = 0.430424302816391, acc = 0.865234375\n",
      "Batch 101: loss = 0.427197128534317, acc = 0.8544921875\n",
      "Batch 102: loss = 0.4164099395275116, acc = 0.86328125\n",
      "Batch 103: loss = 0.3958890736103058, acc = 0.8828125\n",
      "Batch 104: loss = 0.3629327416419983, acc = 0.884765625\n",
      "Batch 105: loss = 0.3745259642601013, acc = 0.8740234375\n",
      "Batch 106: loss = 0.4176744520664215, acc = 0.8603515625\n",
      "Batch 107: loss = 0.3601453900337219, acc = 0.8759765625\n",
      "Batch 108: loss = 0.39442288875579834, acc = 0.865234375\n",
      "Batch 109: loss = 0.3961971700191498, acc = 0.8662109375\n",
      "Batch 110: loss = 0.36765286326408386, acc = 0.869140625\n",
      "Batch 111: loss = 0.42455241084098816, acc = 0.8564453125\n",
      "Batch 112: loss = 0.41732877492904663, acc = 0.869140625\n",
      "Batch 113: loss = 0.4374992847442627, acc = 0.84765625\n",
      "Batch 114: loss = 0.3949035108089447, acc = 0.8623046875\n",
      "Batch 115: loss = 0.39713290333747864, acc = 0.8662109375\n",
      "Batch 116: loss = 0.45559483766555786, acc = 0.84375\n",
      "Batch 117: loss = 0.408714234828949, acc = 0.8603515625\n",
      "Batch 118: loss = 0.3599623441696167, acc = 0.8779296875\n",
      "Batch 119: loss = 0.3641781806945801, acc = 0.8818359375\n",
      "Batch 120: loss = 0.35402026772499084, acc = 0.88671875\n",
      "Batch 121: loss = 0.4144090414047241, acc = 0.8642578125\n",
      "Batch 122: loss = 0.35411393642425537, acc = 0.8740234375\n",
      "Batch 123: loss = 0.3996441960334778, acc = 0.8720703125\n",
      "Batch 124: loss = 0.4412153959274292, acc = 0.8505859375\n",
      "Batch 125: loss = 0.44288626313209534, acc = 0.853515625\n",
      "Batch 126: loss = 0.39640241861343384, acc = 0.875\n",
      "\n",
      "Epoch 54/100\n",
      "Batch 1: loss = 0.5503079891204834, acc = 0.84765625\n",
      "Batch 2: loss = 0.42255425453186035, acc = 0.8583984375\n",
      "Batch 3: loss = 0.4175528287887573, acc = 0.8671875\n",
      "Batch 4: loss = 0.40099745988845825, acc = 0.8818359375\n",
      "Batch 5: loss = 0.39244991540908813, acc = 0.8857421875\n",
      "Batch 6: loss = 0.4286080300807953, acc = 0.8662109375\n",
      "Batch 7: loss = 0.4139957129955292, acc = 0.8701171875\n",
      "Batch 8: loss = 0.4177178144454956, acc = 0.8662109375\n",
      "Batch 9: loss = 0.40166622400283813, acc = 0.873046875\n",
      "Batch 10: loss = 0.37127628922462463, acc = 0.88671875\n",
      "Batch 11: loss = 0.3965766429901123, acc = 0.853515625\n",
      "Batch 12: loss = 0.39162078499794006, acc = 0.869140625\n",
      "Batch 13: loss = 0.36834806203842163, acc = 0.8828125\n",
      "Batch 14: loss = 0.4075181484222412, acc = 0.8740234375\n",
      "Batch 15: loss = 0.35304778814315796, acc = 0.88671875\n",
      "Batch 16: loss = 0.3999308943748474, acc = 0.8681640625\n",
      "Batch 17: loss = 0.40303727984428406, acc = 0.8642578125\n",
      "Batch 18: loss = 0.4039234519004822, acc = 0.8642578125\n",
      "Batch 19: loss = 0.3875565528869629, acc = 0.8720703125\n",
      "Batch 20: loss = 0.3647642135620117, acc = 0.873046875\n",
      "Batch 21: loss = 0.4546416103839874, acc = 0.849609375\n",
      "Batch 22: loss = 0.42856013774871826, acc = 0.857421875\n",
      "Batch 23: loss = 0.41781291365623474, acc = 0.8564453125\n",
      "Batch 24: loss = 0.39856743812561035, acc = 0.849609375\n",
      "Batch 25: loss = 0.36343955993652344, acc = 0.8759765625\n",
      "Batch 26: loss = 0.3969675302505493, acc = 0.8662109375\n",
      "Batch 27: loss = 0.42443567514419556, acc = 0.8701171875\n",
      "Batch 28: loss = 0.4618593156337738, acc = 0.84375\n",
      "Batch 29: loss = 0.4610595703125, acc = 0.8525390625\n",
      "Batch 30: loss = 0.4069194197654724, acc = 0.875\n",
      "Batch 31: loss = 0.4271884858608246, acc = 0.849609375\n",
      "Batch 32: loss = 0.4475504159927368, acc = 0.8486328125\n",
      "Batch 33: loss = 0.3743153512477875, acc = 0.8798828125\n",
      "Batch 34: loss = 0.38901033997535706, acc = 0.8828125\n",
      "Batch 35: loss = 0.41132378578186035, acc = 0.8603515625\n",
      "Batch 36: loss = 0.37727993726730347, acc = 0.87890625\n",
      "Batch 37: loss = 0.3733609914779663, acc = 0.890625\n",
      "Batch 38: loss = 0.38441962003707886, acc = 0.873046875\n",
      "Batch 39: loss = 0.3750942349433899, acc = 0.8642578125\n",
      "Batch 40: loss = 0.43576180934906006, acc = 0.853515625\n",
      "Batch 41: loss = 0.38212838768959045, acc = 0.8642578125\n",
      "Batch 42: loss = 0.4095514714717865, acc = 0.865234375\n",
      "Batch 43: loss = 0.40791141986846924, acc = 0.8701171875\n",
      "Batch 44: loss = 0.3957904577255249, acc = 0.873046875\n",
      "Batch 45: loss = 0.3796428442001343, acc = 0.876953125\n",
      "Batch 46: loss = 0.3812568187713623, acc = 0.8779296875\n",
      "Batch 47: loss = 0.4175872206687927, acc = 0.8642578125\n",
      "Batch 48: loss = 0.3777737617492676, acc = 0.876953125\n",
      "Batch 49: loss = 0.35290300846099854, acc = 0.8837890625\n",
      "Batch 50: loss = 0.3469887375831604, acc = 0.8837890625\n",
      "Batch 51: loss = 0.3773398995399475, acc = 0.87109375\n",
      "Batch 52: loss = 0.3818408250808716, acc = 0.8740234375\n",
      "Batch 53: loss = 0.38642561435699463, acc = 0.859375\n",
      "Batch 54: loss = 0.323175847530365, acc = 0.89453125\n",
      "Batch 55: loss = 0.3712361752986908, acc = 0.8837890625\n",
      "Batch 56: loss = 0.4232998490333557, acc = 0.84765625\n",
      "Batch 57: loss = 0.4227253794670105, acc = 0.8681640625\n",
      "Batch 58: loss = 0.4281536340713501, acc = 0.859375\n",
      "Batch 59: loss = 0.3363107442855835, acc = 0.884765625\n",
      "Batch 60: loss = 0.4190518856048584, acc = 0.8603515625\n",
      "Batch 61: loss = 0.37504562735557556, acc = 0.8798828125\n",
      "Batch 62: loss = 0.45371776819229126, acc = 0.849609375\n",
      "Batch 63: loss = 0.41963499784469604, acc = 0.8515625\n",
      "Batch 64: loss = 0.3370515704154968, acc = 0.892578125\n",
      "Batch 65: loss = 0.3944975733757019, acc = 0.865234375\n",
      "Batch 66: loss = 0.3891872763633728, acc = 0.873046875\n",
      "Batch 67: loss = 0.41012778878211975, acc = 0.8515625\n",
      "Batch 68: loss = 0.4004053771495819, acc = 0.8583984375\n",
      "Batch 69: loss = 0.3611755669116974, acc = 0.8828125\n",
      "Batch 70: loss = 0.42148566246032715, acc = 0.8671875\n",
      "Batch 71: loss = 0.3884603977203369, acc = 0.8662109375\n",
      "Batch 72: loss = 0.36564913392066956, acc = 0.8818359375\n",
      "Batch 73: loss = 0.41805046796798706, acc = 0.85546875\n",
      "Batch 74: loss = 0.43976283073425293, acc = 0.853515625\n",
      "Batch 75: loss = 0.45704737305641174, acc = 0.8388671875\n",
      "Batch 76: loss = 0.4250776171684265, acc = 0.8662109375\n",
      "Batch 77: loss = 0.3936687707901001, acc = 0.8759765625\n",
      "Batch 78: loss = 0.3943342864513397, acc = 0.861328125\n",
      "Batch 79: loss = 0.37084364891052246, acc = 0.876953125\n",
      "Batch 80: loss = 0.3482661247253418, acc = 0.876953125\n",
      "Batch 81: loss = 0.3844904899597168, acc = 0.873046875\n",
      "Batch 82: loss = 0.3638877868652344, acc = 0.8740234375\n",
      "Batch 83: loss = 0.3911139667034149, acc = 0.869140625\n",
      "Batch 84: loss = 0.378537118434906, acc = 0.8720703125\n",
      "Batch 85: loss = 0.44016003608703613, acc = 0.857421875\n",
      "Batch 86: loss = 0.3756954073905945, acc = 0.888671875\n",
      "Batch 87: loss = 0.39505472779273987, acc = 0.8759765625\n",
      "Batch 88: loss = 0.4862378239631653, acc = 0.8271484375\n",
      "Batch 89: loss = 0.3506735563278198, acc = 0.8857421875\n",
      "Batch 90: loss = 0.4023498296737671, acc = 0.873046875\n",
      "Batch 91: loss = 0.429038405418396, acc = 0.8583984375\n",
      "Batch 92: loss = 0.4254639744758606, acc = 0.853515625\n",
      "Batch 93: loss = 0.34664812684059143, acc = 0.8828125\n",
      "Batch 94: loss = 0.37455564737319946, acc = 0.8779296875\n",
      "Batch 95: loss = 0.3584791421890259, acc = 0.8779296875\n",
      "Batch 96: loss = 0.4120262861251831, acc = 0.8662109375\n",
      "Batch 97: loss = 0.41936761140823364, acc = 0.86328125\n",
      "Batch 98: loss = 0.4309060275554657, acc = 0.853515625\n",
      "Batch 99: loss = 0.41235488653182983, acc = 0.8671875\n",
      "Batch 100: loss = 0.4024440348148346, acc = 0.8603515625\n",
      "Batch 101: loss = 0.3713160455226898, acc = 0.8662109375\n",
      "Batch 102: loss = 0.4219982624053955, acc = 0.8662109375\n",
      "Batch 103: loss = 0.3847464919090271, acc = 0.8798828125\n",
      "Batch 104: loss = 0.3653040826320648, acc = 0.8779296875\n",
      "Batch 105: loss = 0.35699981451034546, acc = 0.8857421875\n",
      "Batch 106: loss = 0.38733211159706116, acc = 0.876953125\n",
      "Batch 107: loss = 0.38013821840286255, acc = 0.876953125\n",
      "Batch 108: loss = 0.3835563659667969, acc = 0.86328125\n",
      "Batch 109: loss = 0.37847456336021423, acc = 0.876953125\n",
      "Batch 110: loss = 0.3750830888748169, acc = 0.873046875\n",
      "Batch 111: loss = 0.3907262086868286, acc = 0.873046875\n",
      "Batch 112: loss = 0.3909416198730469, acc = 0.8759765625\n",
      "Batch 113: loss = 0.3765254616737366, acc = 0.87109375\n",
      "Batch 114: loss = 0.4216444492340088, acc = 0.84765625\n",
      "Batch 115: loss = 0.3815186321735382, acc = 0.8720703125\n",
      "Batch 116: loss = 0.4422656297683716, acc = 0.865234375\n",
      "Batch 117: loss = 0.40090253949165344, acc = 0.8720703125\n",
      "Batch 118: loss = 0.3543879985809326, acc = 0.8740234375\n",
      "Batch 119: loss = 0.335671603679657, acc = 0.888671875\n",
      "Batch 120: loss = 0.3536972403526306, acc = 0.876953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 121: loss = 0.4252026677131653, acc = 0.8525390625\n",
      "Batch 122: loss = 0.3610525131225586, acc = 0.8759765625\n",
      "Batch 123: loss = 0.4073469042778015, acc = 0.869140625\n",
      "Batch 124: loss = 0.4318878650665283, acc = 0.8505859375\n",
      "Batch 125: loss = 0.4035944938659668, acc = 0.8603515625\n",
      "Batch 126: loss = 0.4432903528213501, acc = 0.85546875\n",
      "\n",
      "Epoch 55/100\n",
      "Batch 1: loss = 0.5419843792915344, acc = 0.8466796875\n",
      "Batch 2: loss = 0.39231839776039124, acc = 0.8720703125\n",
      "Batch 3: loss = 0.4088560938835144, acc = 0.8623046875\n",
      "Batch 4: loss = 0.4095744490623474, acc = 0.8603515625\n",
      "Batch 5: loss = 0.3941330015659332, acc = 0.8701171875\n",
      "Batch 6: loss = 0.3963201642036438, acc = 0.8642578125\n",
      "Batch 7: loss = 0.4000437557697296, acc = 0.8662109375\n",
      "Batch 8: loss = 0.396555095911026, acc = 0.8662109375\n",
      "Batch 9: loss = 0.38617122173309326, acc = 0.875\n",
      "Batch 10: loss = 0.34111177921295166, acc = 0.8935546875\n",
      "Batch 11: loss = 0.3935551047325134, acc = 0.87109375\n",
      "Batch 12: loss = 0.4101972281932831, acc = 0.8544921875\n",
      "Batch 13: loss = 0.3907822370529175, acc = 0.8740234375\n",
      "Batch 14: loss = 0.3993607759475708, acc = 0.861328125\n",
      "Batch 15: loss = 0.37859201431274414, acc = 0.88671875\n",
      "Batch 16: loss = 0.3719300329685211, acc = 0.8642578125\n",
      "Batch 17: loss = 0.4050218462944031, acc = 0.8544921875\n",
      "Batch 18: loss = 0.38946905732154846, acc = 0.86328125\n",
      "Batch 19: loss = 0.407301127910614, acc = 0.875\n",
      "Batch 20: loss = 0.37264686822891235, acc = 0.8759765625\n",
      "Batch 21: loss = 0.4526327848434448, acc = 0.857421875\n",
      "Batch 22: loss = 0.4026992917060852, acc = 0.853515625\n",
      "Batch 23: loss = 0.43049678206443787, acc = 0.849609375\n",
      "Batch 24: loss = 0.3920314908027649, acc = 0.86328125\n",
      "Batch 25: loss = 0.38537752628326416, acc = 0.8837890625\n",
      "Batch 26: loss = 0.3927617073059082, acc = 0.8603515625\n",
      "Batch 27: loss = 0.42514872550964355, acc = 0.8623046875\n",
      "Batch 28: loss = 0.4259890913963318, acc = 0.84375\n",
      "Batch 29: loss = 0.4134284257888794, acc = 0.8681640625\n",
      "Batch 30: loss = 0.402425080537796, acc = 0.8681640625\n",
      "Batch 31: loss = 0.43327009677886963, acc = 0.86328125\n",
      "Batch 32: loss = 0.4779396057128906, acc = 0.8388671875\n",
      "Batch 33: loss = 0.35053449869155884, acc = 0.888671875\n",
      "Batch 34: loss = 0.4007008969783783, acc = 0.8740234375\n",
      "Batch 35: loss = 0.4053935408592224, acc = 0.865234375\n",
      "Batch 36: loss = 0.358863890171051, acc = 0.8818359375\n",
      "Batch 37: loss = 0.37887337803840637, acc = 0.8818359375\n",
      "Batch 38: loss = 0.39691948890686035, acc = 0.87890625\n",
      "Batch 39: loss = 0.37364661693573, acc = 0.8720703125\n",
      "Batch 40: loss = 0.40221163630485535, acc = 0.875\n",
      "Batch 41: loss = 0.33476871252059937, acc = 0.8876953125\n",
      "Batch 42: loss = 0.38522639870643616, acc = 0.8662109375\n",
      "Batch 43: loss = 0.41898781061172485, acc = 0.8681640625\n",
      "Batch 44: loss = 0.3723188638687134, acc = 0.8876953125\n",
      "Batch 45: loss = 0.3738885521888733, acc = 0.875\n",
      "Batch 46: loss = 0.3917924165725708, acc = 0.873046875\n",
      "Batch 47: loss = 0.37649571895599365, acc = 0.884765625\n",
      "Batch 48: loss = 0.39217790961265564, acc = 0.8603515625\n",
      "Batch 49: loss = 0.32920387387275696, acc = 0.896484375\n",
      "Batch 50: loss = 0.37160927057266235, acc = 0.8671875\n",
      "Batch 51: loss = 0.353675901889801, acc = 0.88671875\n",
      "Batch 52: loss = 0.40012499690055847, acc = 0.8623046875\n",
      "Batch 53: loss = 0.39604616165161133, acc = 0.86328125\n",
      "Batch 54: loss = 0.3541449308395386, acc = 0.8896484375\n",
      "Batch 55: loss = 0.35081151127815247, acc = 0.884765625\n",
      "Batch 56: loss = 0.4037604331970215, acc = 0.8623046875\n",
      "Batch 57: loss = 0.41213393211364746, acc = 0.8583984375\n",
      "Batch 58: loss = 0.4105393588542938, acc = 0.853515625\n",
      "Batch 59: loss = 0.33110296726226807, acc = 0.8857421875\n",
      "Batch 60: loss = 0.3754439055919647, acc = 0.876953125\n",
      "Batch 61: loss = 0.35417383909225464, acc = 0.8798828125\n",
      "Batch 62: loss = 0.4091348946094513, acc = 0.8623046875\n",
      "Batch 63: loss = 0.35282760858535767, acc = 0.8876953125\n",
      "Batch 64: loss = 0.31866002082824707, acc = 0.8955078125\n",
      "Batch 65: loss = 0.38029780983924866, acc = 0.875\n",
      "Batch 66: loss = 0.3961809575557709, acc = 0.8505859375\n",
      "Batch 67: loss = 0.4118896424770355, acc = 0.873046875\n",
      "Batch 68: loss = 0.38142889738082886, acc = 0.8740234375\n",
      "Batch 69: loss = 0.3793504238128662, acc = 0.865234375\n",
      "Batch 70: loss = 0.42278578877449036, acc = 0.8603515625\n",
      "Batch 71: loss = 0.43775010108947754, acc = 0.8427734375\n",
      "Batch 72: loss = 0.3880111873149872, acc = 0.8701171875\n",
      "Batch 73: loss = 0.43510839343070984, acc = 0.8564453125\n",
      "Batch 74: loss = 0.4256577789783478, acc = 0.8623046875\n",
      "Batch 75: loss = 0.45251762866973877, acc = 0.837890625\n",
      "Batch 76: loss = 0.4246184229850769, acc = 0.8564453125\n",
      "Batch 77: loss = 0.39267659187316895, acc = 0.87109375\n",
      "Batch 78: loss = 0.3749789595603943, acc = 0.8876953125\n",
      "Batch 79: loss = 0.34691256284713745, acc = 0.8857421875\n",
      "Batch 80: loss = 0.36211323738098145, acc = 0.8681640625\n",
      "Batch 81: loss = 0.38675305247306824, acc = 0.8623046875\n",
      "Batch 82: loss = 0.39114296436309814, acc = 0.87109375\n",
      "Batch 83: loss = 0.39274686574935913, acc = 0.8701171875\n",
      "Batch 84: loss = 0.3998698592185974, acc = 0.865234375\n",
      "Batch 85: loss = 0.4613640308380127, acc = 0.8349609375\n",
      "Batch 86: loss = 0.3511303663253784, acc = 0.8837890625\n",
      "Batch 87: loss = 0.3831676244735718, acc = 0.87890625\n",
      "Batch 88: loss = 0.46252259612083435, acc = 0.85546875\n",
      "Batch 89: loss = 0.4057084918022156, acc = 0.8671875\n",
      "Batch 90: loss = 0.3906670808792114, acc = 0.86328125\n",
      "Batch 91: loss = 0.40591540932655334, acc = 0.859375\n",
      "Batch 92: loss = 0.417952299118042, acc = 0.865234375\n",
      "Batch 93: loss = 0.3599141240119934, acc = 0.880859375\n",
      "Batch 94: loss = 0.36391374468803406, acc = 0.8818359375\n",
      "Batch 95: loss = 0.33418142795562744, acc = 0.890625\n",
      "Batch 96: loss = 0.4178446829319, acc = 0.85546875\n",
      "Batch 97: loss = 0.4057052731513977, acc = 0.86328125\n",
      "Batch 98: loss = 0.40202727913856506, acc = 0.861328125\n",
      "Batch 99: loss = 0.4067976474761963, acc = 0.8857421875\n",
      "Batch 100: loss = 0.40380653738975525, acc = 0.8623046875\n",
      "Batch 101: loss = 0.4032350182533264, acc = 0.86328125\n",
      "Batch 102: loss = 0.3909783363342285, acc = 0.8681640625\n",
      "Batch 103: loss = 0.38705533742904663, acc = 0.8759765625\n",
      "Batch 104: loss = 0.35746556520462036, acc = 0.88671875\n",
      "Batch 105: loss = 0.36091387271881104, acc = 0.8818359375\n",
      "Batch 106: loss = 0.38517388701438904, acc = 0.869140625\n",
      "Batch 107: loss = 0.3998551070690155, acc = 0.8837890625\n",
      "Batch 108: loss = 0.3708774447441101, acc = 0.8779296875\n",
      "Batch 109: loss = 0.36085331439971924, acc = 0.8837890625\n",
      "Batch 110: loss = 0.38821688294410706, acc = 0.8681640625\n",
      "Batch 111: loss = 0.4011688828468323, acc = 0.8583984375\n",
      "Batch 112: loss = 0.3801875710487366, acc = 0.8798828125\n",
      "Batch 113: loss = 0.3914109468460083, acc = 0.8818359375\n",
      "Batch 114: loss = 0.43038755655288696, acc = 0.86328125\n",
      "Batch 115: loss = 0.3800005614757538, acc = 0.8798828125\n",
      "Batch 116: loss = 0.4172554612159729, acc = 0.8662109375\n",
      "Batch 117: loss = 0.4163370728492737, acc = 0.861328125\n",
      "Batch 118: loss = 0.36829909682273865, acc = 0.875\n",
      "Batch 119: loss = 0.394581139087677, acc = 0.8623046875\n",
      "Batch 120: loss = 0.3264234662055969, acc = 0.8818359375\n",
      "Batch 121: loss = 0.40196409821510315, acc = 0.8583984375\n",
      "Batch 122: loss = 0.3565152883529663, acc = 0.873046875\n",
      "Batch 123: loss = 0.3854295611381531, acc = 0.87109375\n",
      "Batch 124: loss = 0.4168854355812073, acc = 0.85546875\n",
      "Batch 125: loss = 0.4169727563858032, acc = 0.8662109375\n",
      "Batch 126: loss = 0.39612090587615967, acc = 0.8779296875\n",
      "\n",
      "Epoch 56/100\n",
      "Batch 1: loss = 0.5343198776245117, acc = 0.8525390625\n",
      "Batch 2: loss = 0.41115617752075195, acc = 0.861328125\n",
      "Batch 3: loss = 0.38708460330963135, acc = 0.87890625\n",
      "Batch 4: loss = 0.4068848192691803, acc = 0.8681640625\n",
      "Batch 5: loss = 0.3922393321990967, acc = 0.86328125\n",
      "Batch 6: loss = 0.4082987308502197, acc = 0.859375\n",
      "Batch 7: loss = 0.392511785030365, acc = 0.87109375\n",
      "Batch 8: loss = 0.3534158766269684, acc = 0.884765625\n",
      "Batch 9: loss = 0.38237297534942627, acc = 0.8681640625\n",
      "Batch 10: loss = 0.32142603397369385, acc = 0.896484375\n",
      "Batch 11: loss = 0.37133267521858215, acc = 0.86328125\n",
      "Batch 12: loss = 0.36011314392089844, acc = 0.8740234375\n",
      "Batch 13: loss = 0.3748091161251068, acc = 0.8720703125\n",
      "Batch 14: loss = 0.39270925521850586, acc = 0.875\n",
      "Batch 15: loss = 0.3853302001953125, acc = 0.875\n",
      "Batch 16: loss = 0.3972361087799072, acc = 0.87109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17: loss = 0.41625410318374634, acc = 0.86328125\n",
      "Batch 18: loss = 0.38526055216789246, acc = 0.87890625\n",
      "Batch 19: loss = 0.39757242798805237, acc = 0.875\n",
      "Batch 20: loss = 0.3815358877182007, acc = 0.8740234375\n",
      "Batch 21: loss = 0.43119120597839355, acc = 0.8583984375\n",
      "Batch 22: loss = 0.4021033048629761, acc = 0.865234375\n",
      "Batch 23: loss = 0.4111180305480957, acc = 0.85546875\n",
      "Batch 24: loss = 0.3712691068649292, acc = 0.880859375\n",
      "Batch 25: loss = 0.39117109775543213, acc = 0.876953125\n",
      "Batch 26: loss = 0.34650588035583496, acc = 0.8798828125\n",
      "Batch 27: loss = 0.42957180738449097, acc = 0.8583984375\n",
      "Batch 28: loss = 0.4254493713378906, acc = 0.8583984375\n",
      "Batch 29: loss = 0.42649045586586, acc = 0.8662109375\n",
      "Batch 30: loss = 0.4154673218727112, acc = 0.8671875\n",
      "Batch 31: loss = 0.3952343761920929, acc = 0.869140625\n",
      "Batch 32: loss = 0.4574967622756958, acc = 0.8642578125\n",
      "Batch 33: loss = 0.3698272407054901, acc = 0.8837890625\n",
      "Batch 34: loss = 0.39233851432800293, acc = 0.8779296875\n",
      "Batch 35: loss = 0.40080246329307556, acc = 0.8603515625\n",
      "Batch 36: loss = 0.3888738453388214, acc = 0.8779296875\n",
      "Batch 37: loss = 0.36203765869140625, acc = 0.8779296875\n",
      "Batch 38: loss = 0.41276705265045166, acc = 0.876953125\n",
      "Batch 39: loss = 0.370974063873291, acc = 0.8798828125\n",
      "Batch 40: loss = 0.4326152801513672, acc = 0.8583984375\n",
      "Batch 41: loss = 0.3485259711742401, acc = 0.8798828125\n",
      "Batch 42: loss = 0.3914790153503418, acc = 0.869140625\n",
      "Batch 43: loss = 0.4185773730278015, acc = 0.85546875\n",
      "Batch 44: loss = 0.3406006693840027, acc = 0.8837890625\n",
      "Batch 45: loss = 0.347947895526886, acc = 0.8779296875\n",
      "Batch 46: loss = 0.3449409008026123, acc = 0.884765625\n",
      "Batch 47: loss = 0.35489124059677124, acc = 0.8837890625\n",
      "Batch 48: loss = 0.37626752257347107, acc = 0.880859375\n",
      "Batch 49: loss = 0.3527712821960449, acc = 0.8837890625\n",
      "Batch 50: loss = 0.37022238969802856, acc = 0.8701171875\n",
      "Batch 51: loss = 0.3535045385360718, acc = 0.8759765625\n",
      "Batch 52: loss = 0.3923734128475189, acc = 0.869140625\n",
      "Batch 53: loss = 0.37046927213668823, acc = 0.87890625\n",
      "Batch 54: loss = 0.3269055485725403, acc = 0.8994140625\n",
      "Batch 55: loss = 0.3291224539279938, acc = 0.8984375\n",
      "Batch 56: loss = 0.39929988980293274, acc = 0.865234375\n",
      "Batch 57: loss = 0.4294587969779968, acc = 0.8544921875\n",
      "Batch 58: loss = 0.4200277030467987, acc = 0.8583984375\n",
      "Batch 59: loss = 0.3037497401237488, acc = 0.8955078125\n",
      "Batch 60: loss = 0.39524179697036743, acc = 0.869140625\n",
      "Batch 61: loss = 0.33756253123283386, acc = 0.8896484375\n",
      "Batch 62: loss = 0.4617989659309387, acc = 0.841796875\n",
      "Batch 63: loss = 0.38954463601112366, acc = 0.8740234375\n",
      "Batch 64: loss = 0.3333050012588501, acc = 0.900390625\n",
      "Batch 65: loss = 0.3992009460926056, acc = 0.865234375\n",
      "Batch 66: loss = 0.40133965015411377, acc = 0.8671875\n",
      "Batch 67: loss = 0.4017420709133148, acc = 0.8701171875\n",
      "Batch 68: loss = 0.3764031231403351, acc = 0.880859375\n",
      "Batch 69: loss = 0.3314739167690277, acc = 0.8916015625\n",
      "Batch 70: loss = 0.42912015318870544, acc = 0.85546875\n",
      "Batch 71: loss = 0.38652700185775757, acc = 0.8681640625\n",
      "Batch 72: loss = 0.3767046630382538, acc = 0.880859375\n",
      "Batch 73: loss = 0.4325985610485077, acc = 0.8642578125\n",
      "Batch 74: loss = 0.43137526512145996, acc = 0.849609375\n",
      "Batch 75: loss = 0.4168756306171417, acc = 0.8564453125\n",
      "Batch 76: loss = 0.38805538415908813, acc = 0.8671875\n",
      "Batch 77: loss = 0.38359713554382324, acc = 0.87109375\n",
      "Batch 78: loss = 0.3918168544769287, acc = 0.87109375\n",
      "Batch 79: loss = 0.3504892587661743, acc = 0.8818359375\n",
      "Batch 80: loss = 0.3437129557132721, acc = 0.8720703125\n",
      "Batch 81: loss = 0.3607844114303589, acc = 0.875\n",
      "Batch 82: loss = 0.3698437809944153, acc = 0.8740234375\n",
      "Batch 83: loss = 0.3686616122722626, acc = 0.876953125\n",
      "Batch 84: loss = 0.37685924768447876, acc = 0.8740234375\n",
      "Batch 85: loss = 0.4296361207962036, acc = 0.8544921875\n",
      "Batch 86: loss = 0.3821576237678528, acc = 0.87109375\n",
      "Batch 87: loss = 0.38164031505584717, acc = 0.875\n",
      "Batch 88: loss = 0.4297153949737549, acc = 0.8623046875\n",
      "Batch 89: loss = 0.37158769369125366, acc = 0.880859375\n",
      "Batch 90: loss = 0.4025152027606964, acc = 0.865234375\n",
      "Batch 91: loss = 0.3986540734767914, acc = 0.8759765625\n",
      "Batch 92: loss = 0.41057276725769043, acc = 0.8564453125\n",
      "Batch 93: loss = 0.376552551984787, acc = 0.8876953125\n",
      "Batch 94: loss = 0.37064674496650696, acc = 0.8837890625\n",
      "Batch 95: loss = 0.3403761386871338, acc = 0.876953125\n",
      "Batch 96: loss = 0.42885810136795044, acc = 0.8486328125\n",
      "Batch 97: loss = 0.4157830476760864, acc = 0.85546875\n",
      "Batch 98: loss = 0.3903173506259918, acc = 0.8623046875\n",
      "Batch 99: loss = 0.36699122190475464, acc = 0.8759765625\n",
      "Batch 100: loss = 0.3968487083911896, acc = 0.8681640625\n",
      "Batch 101: loss = 0.3839140236377716, acc = 0.869140625\n",
      "Batch 102: loss = 0.434474915266037, acc = 0.859375\n",
      "Batch 103: loss = 0.3806731104850769, acc = 0.875\n",
      "Batch 104: loss = 0.3274071216583252, acc = 0.8876953125\n",
      "Batch 105: loss = 0.3256950080394745, acc = 0.8994140625\n",
      "Batch 106: loss = 0.3807356059551239, acc = 0.8671875\n",
      "Batch 107: loss = 0.36677128076553345, acc = 0.8828125\n",
      "Batch 108: loss = 0.3874545693397522, acc = 0.87109375\n",
      "Batch 109: loss = 0.39148277044296265, acc = 0.8671875\n",
      "Batch 110: loss = 0.37209779024124146, acc = 0.87890625\n",
      "Batch 111: loss = 0.400348961353302, acc = 0.85546875\n",
      "Batch 112: loss = 0.3655945062637329, acc = 0.8837890625\n",
      "Batch 113: loss = 0.3789069652557373, acc = 0.8701171875\n",
      "Batch 114: loss = 0.38898032903671265, acc = 0.8779296875\n",
      "Batch 115: loss = 0.38398846983909607, acc = 0.873046875\n",
      "Batch 116: loss = 0.424474835395813, acc = 0.859375\n",
      "Batch 117: loss = 0.3892069458961487, acc = 0.87109375\n",
      "Batch 118: loss = 0.36600667238235474, acc = 0.8779296875\n",
      "Batch 119: loss = 0.36212828755378723, acc = 0.8759765625\n",
      "Batch 120: loss = 0.354752779006958, acc = 0.8818359375\n",
      "Batch 121: loss = 0.36781543493270874, acc = 0.8681640625\n",
      "Batch 122: loss = 0.36178767681121826, acc = 0.8740234375\n",
      "Batch 123: loss = 0.35441747307777405, acc = 0.880859375\n",
      "Batch 124: loss = 0.39400526881217957, acc = 0.8583984375\n",
      "Batch 125: loss = 0.4692195653915405, acc = 0.8525390625\n",
      "Batch 126: loss = 0.4056791067123413, acc = 0.8671875\n",
      "\n",
      "Epoch 57/100\n",
      "Batch 1: loss = 0.5425397157669067, acc = 0.841796875\n",
      "Batch 2: loss = 0.40631547570228577, acc = 0.861328125\n",
      "Batch 3: loss = 0.405428946018219, acc = 0.8759765625\n",
      "Batch 4: loss = 0.38045018911361694, acc = 0.8779296875\n",
      "Batch 5: loss = 0.40593189001083374, acc = 0.865234375\n",
      "Batch 6: loss = 0.38084256649017334, acc = 0.8701171875\n",
      "Batch 7: loss = 0.40575647354125977, acc = 0.8681640625\n",
      "Batch 8: loss = 0.3860674798488617, acc = 0.869140625\n",
      "Batch 9: loss = 0.3687790334224701, acc = 0.8798828125\n",
      "Batch 10: loss = 0.329323947429657, acc = 0.880859375\n",
      "Batch 11: loss = 0.4104333519935608, acc = 0.861328125\n",
      "Batch 12: loss = 0.3466251790523529, acc = 0.8798828125\n",
      "Batch 13: loss = 0.383672297000885, acc = 0.880859375\n",
      "Batch 14: loss = 0.3718597888946533, acc = 0.8935546875\n",
      "Batch 15: loss = 0.33164194226264954, acc = 0.888671875\n",
      "Batch 16: loss = 0.3522369861602783, acc = 0.896484375\n",
      "Batch 17: loss = 0.4083596169948578, acc = 0.8642578125\n",
      "Batch 18: loss = 0.37844419479370117, acc = 0.87109375\n",
      "Batch 19: loss = 0.3762790262699127, acc = 0.876953125\n",
      "Batch 20: loss = 0.3748662769794464, acc = 0.8720703125\n",
      "Batch 21: loss = 0.3945499658584595, acc = 0.8671875\n",
      "Batch 22: loss = 0.40697261691093445, acc = 0.8681640625\n",
      "Batch 23: loss = 0.38056665658950806, acc = 0.8828125\n",
      "Batch 24: loss = 0.3779899477958679, acc = 0.8681640625\n",
      "Batch 25: loss = 0.37027186155319214, acc = 0.8779296875\n",
      "Batch 26: loss = 0.39435142278671265, acc = 0.8623046875\n",
      "Batch 27: loss = 0.4182087182998657, acc = 0.8623046875\n",
      "Batch 28: loss = 0.39903974533081055, acc = 0.8662109375\n",
      "Batch 29: loss = 0.4059946835041046, acc = 0.8671875\n",
      "Batch 30: loss = 0.4083523452281952, acc = 0.8662109375\n",
      "Batch 31: loss = 0.40074270963668823, acc = 0.880859375\n",
      "Batch 32: loss = 0.4335113763809204, acc = 0.8583984375\n",
      "Batch 33: loss = 0.3582916259765625, acc = 0.87109375\n",
      "Batch 34: loss = 0.38190168142318726, acc = 0.87109375\n",
      "Batch 35: loss = 0.3890812397003174, acc = 0.8671875\n",
      "Batch 36: loss = 0.31965208053588867, acc = 0.892578125\n",
      "Batch 37: loss = 0.3484994173049927, acc = 0.8876953125\n",
      "Batch 38: loss = 0.39753150939941406, acc = 0.8681640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 39: loss = 0.36543571949005127, acc = 0.8818359375\n",
      "Batch 40: loss = 0.39257997274398804, acc = 0.8662109375\n",
      "Batch 41: loss = 0.3505462408065796, acc = 0.8720703125\n",
      "Batch 42: loss = 0.37293314933776855, acc = 0.8876953125\n",
      "Batch 43: loss = 0.41495752334594727, acc = 0.865234375\n",
      "Batch 44: loss = 0.3622495234012604, acc = 0.884765625\n",
      "Batch 45: loss = 0.342751145362854, acc = 0.8837890625\n",
      "Batch 46: loss = 0.345381498336792, acc = 0.8818359375\n",
      "Batch 47: loss = 0.36358219385147095, acc = 0.8759765625\n",
      "Batch 48: loss = 0.3722267746925354, acc = 0.869140625\n",
      "Batch 49: loss = 0.3117673397064209, acc = 0.8935546875\n",
      "Batch 50: loss = 0.3547148108482361, acc = 0.8837890625\n",
      "Batch 51: loss = 0.3730027377605438, acc = 0.869140625\n",
      "Batch 52: loss = 0.3725006580352783, acc = 0.8740234375\n",
      "Batch 53: loss = 0.3698155879974365, acc = 0.8779296875\n",
      "Batch 54: loss = 0.2943271994590759, acc = 0.9013671875\n",
      "Batch 55: loss = 0.3098701536655426, acc = 0.900390625\n",
      "Batch 56: loss = 0.3665297031402588, acc = 0.876953125\n",
      "Batch 57: loss = 0.40752050280570984, acc = 0.8671875\n",
      "Batch 58: loss = 0.40545427799224854, acc = 0.87109375\n",
      "Batch 59: loss = 0.30494797229766846, acc = 0.9052734375\n",
      "Batch 60: loss = 0.3763975501060486, acc = 0.8681640625\n",
      "Batch 61: loss = 0.3577094078063965, acc = 0.8876953125\n",
      "Batch 62: loss = 0.4534305930137634, acc = 0.8486328125\n",
      "Batch 63: loss = 0.3912121057510376, acc = 0.875\n",
      "Batch 64: loss = 0.34633949398994446, acc = 0.8828125\n",
      "Batch 65: loss = 0.40995728969573975, acc = 0.8681640625\n",
      "Batch 66: loss = 0.3866174817085266, acc = 0.86328125\n",
      "Batch 67: loss = 0.36000150442123413, acc = 0.880859375\n",
      "Batch 68: loss = 0.3689337372779846, acc = 0.8701171875\n",
      "Batch 69: loss = 0.3479410707950592, acc = 0.8935546875\n",
      "Batch 70: loss = 0.4003397226333618, acc = 0.857421875\n",
      "Batch 71: loss = 0.39312103390693665, acc = 0.859375\n",
      "Batch 72: loss = 0.3679806590080261, acc = 0.8740234375\n",
      "Batch 73: loss = 0.41323333978652954, acc = 0.857421875\n",
      "Batch 74: loss = 0.42131170630455017, acc = 0.849609375\n",
      "Batch 75: loss = 0.422471821308136, acc = 0.8544921875\n",
      "Batch 76: loss = 0.41186606884002686, acc = 0.8583984375\n",
      "Batch 77: loss = 0.35423988103866577, acc = 0.8896484375\n",
      "Batch 78: loss = 0.38187044858932495, acc = 0.8779296875\n",
      "Batch 79: loss = 0.36732977628707886, acc = 0.869140625\n",
      "Batch 80: loss = 0.32751181721687317, acc = 0.8876953125\n",
      "Batch 81: loss = 0.37988948822021484, acc = 0.873046875\n",
      "Batch 82: loss = 0.3682953119277954, acc = 0.87890625\n",
      "Batch 83: loss = 0.3788270652294159, acc = 0.8701171875\n",
      "Batch 84: loss = 0.3840702474117279, acc = 0.8740234375\n",
      "Batch 85: loss = 0.4231775403022766, acc = 0.859375\n",
      "Batch 86: loss = 0.36494338512420654, acc = 0.8720703125\n",
      "Batch 87: loss = 0.3697306513786316, acc = 0.87890625\n",
      "Batch 88: loss = 0.41725099086761475, acc = 0.861328125\n",
      "Batch 89: loss = 0.35045450925827026, acc = 0.8857421875\n",
      "Batch 90: loss = 0.3760456442832947, acc = 0.890625\n",
      "Batch 91: loss = 0.3641965985298157, acc = 0.8818359375\n",
      "Batch 92: loss = 0.38989126682281494, acc = 0.87109375\n",
      "Batch 93: loss = 0.3272380828857422, acc = 0.8837890625\n",
      "Batch 94: loss = 0.3253067135810852, acc = 0.89453125\n",
      "Batch 95: loss = 0.3089141845703125, acc = 0.8935546875\n",
      "Batch 96: loss = 0.41683337092399597, acc = 0.84765625\n",
      "Batch 97: loss = 0.4048762321472168, acc = 0.8720703125\n",
      "Batch 98: loss = 0.38751447200775146, acc = 0.8818359375\n",
      "Batch 99: loss = 0.3826703727245331, acc = 0.8818359375\n",
      "Batch 100: loss = 0.37807637453079224, acc = 0.873046875\n",
      "Batch 101: loss = 0.34705764055252075, acc = 0.8857421875\n",
      "Batch 102: loss = 0.39646410942077637, acc = 0.86328125\n",
      "Batch 103: loss = 0.3502741754055023, acc = 0.8876953125\n",
      "Batch 104: loss = 0.32801157236099243, acc = 0.8896484375\n",
      "Batch 105: loss = 0.3923371136188507, acc = 0.87890625\n",
      "Batch 106: loss = 0.3544023334980011, acc = 0.8818359375\n",
      "Batch 107: loss = 0.3569577932357788, acc = 0.8779296875\n",
      "Batch 108: loss = 0.33697378635406494, acc = 0.8779296875\n",
      "Batch 109: loss = 0.3486296534538269, acc = 0.8818359375\n",
      "Batch 110: loss = 0.34582385420799255, acc = 0.8955078125\n",
      "Batch 111: loss = 0.3613950312137604, acc = 0.87890625\n",
      "Batch 112: loss = 0.36517828702926636, acc = 0.8798828125\n",
      "Batch 113: loss = 0.36351311206817627, acc = 0.876953125\n",
      "Batch 114: loss = 0.3592551648616791, acc = 0.8896484375\n",
      "Batch 115: loss = 0.4015533924102783, acc = 0.87109375\n",
      "Batch 116: loss = 0.39689213037490845, acc = 0.875\n",
      "Batch 117: loss = 0.40940189361572266, acc = 0.8681640625\n",
      "Batch 118: loss = 0.2968869209289551, acc = 0.9013671875\n",
      "Batch 119: loss = 0.34886258840560913, acc = 0.8896484375\n",
      "Batch 120: loss = 0.3559948801994324, acc = 0.884765625\n",
      "Batch 121: loss = 0.35339200496673584, acc = 0.876953125\n",
      "Batch 122: loss = 0.37994831800460815, acc = 0.865234375\n",
      "Batch 123: loss = 0.373482346534729, acc = 0.875\n",
      "Batch 124: loss = 0.39121758937835693, acc = 0.8662109375\n",
      "Batch 125: loss = 0.4102039337158203, acc = 0.8701171875\n",
      "Batch 126: loss = 0.3861267566680908, acc = 0.876953125\n",
      "\n",
      "Epoch 58/100\n",
      "Batch 1: loss = 0.5315103530883789, acc = 0.84765625\n",
      "Batch 2: loss = 0.38958558440208435, acc = 0.869140625\n",
      "Batch 3: loss = 0.39705604314804077, acc = 0.86328125\n",
      "Batch 4: loss = 0.3551134467124939, acc = 0.8837890625\n",
      "Batch 5: loss = 0.3967079520225525, acc = 0.865234375\n",
      "Batch 6: loss = 0.4108685851097107, acc = 0.869140625\n",
      "Batch 7: loss = 0.3770673871040344, acc = 0.875\n",
      "Batch 8: loss = 0.3417167663574219, acc = 0.89453125\n",
      "Batch 9: loss = 0.32680508494377136, acc = 0.8994140625\n",
      "Batch 10: loss = 0.3261410593986511, acc = 0.88671875\n",
      "Batch 11: loss = 0.34094753861427307, acc = 0.8896484375\n",
      "Batch 12: loss = 0.38434600830078125, acc = 0.857421875\n",
      "Batch 13: loss = 0.3532788157463074, acc = 0.8818359375\n",
      "Batch 14: loss = 0.36816906929016113, acc = 0.8818359375\n",
      "Batch 15: loss = 0.36266857385635376, acc = 0.8857421875\n",
      "Batch 16: loss = 0.3683243989944458, acc = 0.875\n",
      "Batch 17: loss = 0.36441153287887573, acc = 0.8876953125\n",
      "Batch 18: loss = 0.38628971576690674, acc = 0.8759765625\n",
      "Batch 19: loss = 0.37898391485214233, acc = 0.8720703125\n",
      "Batch 20: loss = 0.3642738163471222, acc = 0.8798828125\n",
      "Batch 21: loss = 0.3994706869125366, acc = 0.8740234375\n",
      "Batch 22: loss = 0.387287437915802, acc = 0.873046875\n",
      "Batch 23: loss = 0.41241925954818726, acc = 0.8603515625\n",
      "Batch 24: loss = 0.3673587441444397, acc = 0.8701171875\n",
      "Batch 25: loss = 0.36111125349998474, acc = 0.8837890625\n",
      "Batch 26: loss = 0.36999455094337463, acc = 0.875\n",
      "Batch 27: loss = 0.4277890920639038, acc = 0.85546875\n",
      "Batch 28: loss = 0.40802207589149475, acc = 0.8603515625\n",
      "Batch 29: loss = 0.4429149031639099, acc = 0.853515625\n",
      "Batch 30: loss = 0.399562269449234, acc = 0.875\n",
      "Batch 31: loss = 0.43324345350265503, acc = 0.859375\n",
      "Batch 32: loss = 0.4498918950557709, acc = 0.83984375\n",
      "Batch 33: loss = 0.34700915217399597, acc = 0.88671875\n",
      "Batch 34: loss = 0.3968600332736969, acc = 0.861328125\n",
      "Batch 35: loss = 0.38443490862846375, acc = 0.87109375\n",
      "Batch 36: loss = 0.3588477373123169, acc = 0.876953125\n",
      "Batch 37: loss = 0.3599095940589905, acc = 0.8740234375\n",
      "Batch 38: loss = 0.36831849813461304, acc = 0.888671875\n",
      "Batch 39: loss = 0.3535541892051697, acc = 0.8837890625\n",
      "Batch 40: loss = 0.3835872411727905, acc = 0.8720703125\n",
      "Batch 41: loss = 0.3243595361709595, acc = 0.8876953125\n",
      "Batch 42: loss = 0.37694621086120605, acc = 0.8720703125\n",
      "Batch 43: loss = 0.39125657081604004, acc = 0.8740234375\n",
      "Batch 44: loss = 0.3697932958602905, acc = 0.880859375\n",
      "Batch 45: loss = 0.3288327753543854, acc = 0.890625\n",
      "Batch 46: loss = 0.31630975008010864, acc = 0.888671875\n",
      "Batch 47: loss = 0.36292874813079834, acc = 0.880859375\n",
      "Batch 48: loss = 0.377148300409317, acc = 0.87890625\n",
      "Batch 49: loss = 0.3285302221775055, acc = 0.890625\n",
      "Batch 50: loss = 0.33139967918395996, acc = 0.8857421875\n",
      "Batch 51: loss = 0.34309011697769165, acc = 0.8876953125\n",
      "Batch 52: loss = 0.34277430176734924, acc = 0.8720703125\n",
      "Batch 53: loss = 0.37141820788383484, acc = 0.8798828125\n",
      "Batch 54: loss = 0.29246604442596436, acc = 0.89453125\n",
      "Batch 55: loss = 0.3282528519630432, acc = 0.89453125\n",
      "Batch 56: loss = 0.36647650599479675, acc = 0.8701171875\n",
      "Batch 57: loss = 0.39961153268814087, acc = 0.8759765625\n",
      "Batch 58: loss = 0.40182334184646606, acc = 0.8701171875\n",
      "Batch 59: loss = 0.29642194509506226, acc = 0.900390625\n",
      "Batch 60: loss = 0.40553537011146545, acc = 0.8642578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 61: loss = 0.37237492203712463, acc = 0.87890625\n",
      "Batch 62: loss = 0.4591616094112396, acc = 0.8515625\n",
      "Batch 63: loss = 0.37765395641326904, acc = 0.876953125\n",
      "Batch 64: loss = 0.33760005235671997, acc = 0.89453125\n",
      "Batch 65: loss = 0.3731003999710083, acc = 0.8828125\n",
      "Batch 66: loss = 0.35215145349502563, acc = 0.8798828125\n",
      "Batch 67: loss = 0.37669381499290466, acc = 0.8759765625\n",
      "Batch 68: loss = 0.35324591398239136, acc = 0.8701171875\n",
      "Batch 69: loss = 0.3581022620201111, acc = 0.8935546875\n",
      "Batch 70: loss = 0.39811384677886963, acc = 0.8623046875\n",
      "Batch 71: loss = 0.3811763823032379, acc = 0.876953125\n",
      "Batch 72: loss = 0.36640673875808716, acc = 0.8759765625\n",
      "Batch 73: loss = 0.38494449853897095, acc = 0.8671875\n",
      "Batch 74: loss = 0.43852412700653076, acc = 0.8642578125\n",
      "Batch 75: loss = 0.44128844141960144, acc = 0.84375\n",
      "Batch 76: loss = 0.375540554523468, acc = 0.8701171875\n",
      "Batch 77: loss = 0.3635837435722351, acc = 0.8671875\n",
      "Batch 78: loss = 0.3650526702404022, acc = 0.88671875\n",
      "Batch 79: loss = 0.31704699993133545, acc = 0.8876953125\n",
      "Batch 80: loss = 0.33978840708732605, acc = 0.8740234375\n",
      "Batch 81: loss = 0.37372955679893494, acc = 0.876953125\n",
      "Batch 82: loss = 0.3644760847091675, acc = 0.87890625\n",
      "Batch 83: loss = 0.3546759784221649, acc = 0.892578125\n",
      "Batch 84: loss = 0.35180896520614624, acc = 0.8896484375\n",
      "Batch 85: loss = 0.39422714710235596, acc = 0.8701171875\n",
      "Batch 86: loss = 0.3606029748916626, acc = 0.8779296875\n",
      "Batch 87: loss = 0.351444810628891, acc = 0.8876953125\n",
      "Batch 88: loss = 0.4512672424316406, acc = 0.853515625\n",
      "Batch 89: loss = 0.3685314655303955, acc = 0.880859375\n",
      "Batch 90: loss = 0.3409138023853302, acc = 0.8896484375\n",
      "Batch 91: loss = 0.3683537244796753, acc = 0.884765625\n",
      "Batch 92: loss = 0.38801079988479614, acc = 0.8671875\n",
      "Batch 93: loss = 0.3278583884239197, acc = 0.8916015625\n",
      "Batch 94: loss = 0.3805543780326843, acc = 0.8740234375\n",
      "Batch 95: loss = 0.33844590187072754, acc = 0.8818359375\n",
      "Batch 96: loss = 0.4009174108505249, acc = 0.853515625\n",
      "Batch 97: loss = 0.42982184886932373, acc = 0.8603515625\n",
      "Batch 98: loss = 0.3975210189819336, acc = 0.859375\n",
      "Batch 99: loss = 0.38063758611679077, acc = 0.8720703125\n",
      "Batch 100: loss = 0.3697291612625122, acc = 0.8671875\n",
      "Batch 101: loss = 0.3658822774887085, acc = 0.8759765625\n",
      "Batch 102: loss = 0.40135300159454346, acc = 0.869140625\n",
      "Batch 103: loss = 0.37882328033447266, acc = 0.8720703125\n",
      "Batch 104: loss = 0.3398711681365967, acc = 0.88671875\n",
      "Batch 105: loss = 0.3729523718357086, acc = 0.8759765625\n",
      "Batch 106: loss = 0.3997823894023895, acc = 0.8671875\n",
      "Batch 107: loss = 0.3516072928905487, acc = 0.87890625\n",
      "Batch 108: loss = 0.3155232071876526, acc = 0.8916015625\n",
      "Batch 109: loss = 0.35133591294288635, acc = 0.8798828125\n",
      "Batch 110: loss = 0.34901490807533264, acc = 0.884765625\n",
      "Batch 111: loss = 0.3904125988483429, acc = 0.8603515625\n",
      "Batch 112: loss = 0.3761420249938965, acc = 0.875\n",
      "Batch 113: loss = 0.35978221893310547, acc = 0.8779296875\n",
      "Batch 114: loss = 0.3715479075908661, acc = 0.87890625\n",
      "Batch 115: loss = 0.3551765978336334, acc = 0.876953125\n",
      "Batch 116: loss = 0.39718934893608093, acc = 0.87109375\n",
      "Batch 117: loss = 0.3907407522201538, acc = 0.8720703125\n",
      "Batch 118: loss = 0.3322564363479614, acc = 0.8896484375\n",
      "Batch 119: loss = 0.340364933013916, acc = 0.8857421875\n",
      "Batch 120: loss = 0.33382248878479004, acc = 0.8974609375\n",
      "Batch 121: loss = 0.3733760118484497, acc = 0.875\n",
      "Batch 122: loss = 0.34471675753593445, acc = 0.87890625\n",
      "Batch 123: loss = 0.37678930163383484, acc = 0.8681640625\n",
      "Batch 124: loss = 0.4007088840007782, acc = 0.8671875\n",
      "Batch 125: loss = 0.3686125874519348, acc = 0.8779296875\n",
      "Batch 126: loss = 0.3967450261116028, acc = 0.8720703125\n",
      "\n",
      "Epoch 59/100\n",
      "Batch 1: loss = 0.515438437461853, acc = 0.8466796875\n",
      "Batch 2: loss = 0.3806736469268799, acc = 0.8701171875\n",
      "Batch 3: loss = 0.37240666151046753, acc = 0.8857421875\n",
      "Batch 4: loss = 0.37885749340057373, acc = 0.8701171875\n",
      "Batch 5: loss = 0.3694148361682892, acc = 0.876953125\n",
      "Batch 6: loss = 0.39782488346099854, acc = 0.875\n",
      "Batch 7: loss = 0.3745821714401245, acc = 0.87890625\n",
      "Batch 8: loss = 0.3789874017238617, acc = 0.8740234375\n",
      "Batch 9: loss = 0.32463687658309937, acc = 0.896484375\n",
      "Batch 10: loss = 0.31760960817337036, acc = 0.8876953125\n",
      "Batch 11: loss = 0.3705555200576782, acc = 0.865234375\n",
      "Batch 12: loss = 0.3646894097328186, acc = 0.8759765625\n",
      "Batch 13: loss = 0.3212670385837555, acc = 0.88671875\n",
      "Batch 14: loss = 0.3701510429382324, acc = 0.8876953125\n",
      "Batch 15: loss = 0.34428834915161133, acc = 0.8818359375\n",
      "Batch 16: loss = 0.3583751618862152, acc = 0.8798828125\n",
      "Batch 17: loss = 0.3689613342285156, acc = 0.869140625\n",
      "Batch 18: loss = 0.3640318810939789, acc = 0.88671875\n",
      "Batch 19: loss = 0.3773609399795532, acc = 0.8828125\n",
      "Batch 20: loss = 0.33300596475601196, acc = 0.8916015625\n",
      "Batch 21: loss = 0.4043548107147217, acc = 0.8740234375\n",
      "Batch 22: loss = 0.38541942834854126, acc = 0.8623046875\n",
      "Batch 23: loss = 0.3518780767917633, acc = 0.8740234375\n",
      "Batch 24: loss = 0.3610033392906189, acc = 0.876953125\n",
      "Batch 25: loss = 0.36481577157974243, acc = 0.8857421875\n",
      "Batch 26: loss = 0.3566153645515442, acc = 0.8662109375\n",
      "Batch 27: loss = 0.37695688009262085, acc = 0.884765625\n",
      "Batch 28: loss = 0.42086803913116455, acc = 0.8466796875\n",
      "Batch 29: loss = 0.42777812480926514, acc = 0.861328125\n",
      "Batch 30: loss = 0.3744334578514099, acc = 0.8818359375\n",
      "Batch 31: loss = 0.3983709514141083, acc = 0.8759765625\n",
      "Batch 32: loss = 0.44344866275787354, acc = 0.8486328125\n",
      "Batch 33: loss = 0.3650990426540375, acc = 0.8759765625\n",
      "Batch 34: loss = 0.3897648751735687, acc = 0.8798828125\n",
      "Batch 35: loss = 0.37372887134552, acc = 0.8876953125\n",
      "Batch 36: loss = 0.32998770475387573, acc = 0.8837890625\n",
      "Batch 37: loss = 0.352422297000885, acc = 0.8779296875\n",
      "Batch 38: loss = 0.3634517192840576, acc = 0.8896484375\n",
      "Batch 39: loss = 0.35432782769203186, acc = 0.8876953125\n",
      "Batch 40: loss = 0.36624041199684143, acc = 0.8818359375\n",
      "Batch 41: loss = 0.31022173166275024, acc = 0.9013671875\n",
      "Batch 42: loss = 0.3437950611114502, acc = 0.884765625\n",
      "Batch 43: loss = 0.3640151619911194, acc = 0.8798828125\n",
      "Batch 44: loss = 0.3526792824268341, acc = 0.8896484375\n",
      "Batch 45: loss = 0.31376320123672485, acc = 0.8974609375\n",
      "Batch 46: loss = 0.33150726556777954, acc = 0.8857421875\n",
      "Batch 47: loss = 0.35633355379104614, acc = 0.880859375\n",
      "Batch 48: loss = 0.34238338470458984, acc = 0.888671875\n",
      "Batch 49: loss = 0.32982969284057617, acc = 0.900390625\n",
      "Batch 50: loss = 0.3589954972267151, acc = 0.87890625\n",
      "Batch 51: loss = 0.33783578872680664, acc = 0.8974609375\n",
      "Batch 52: loss = 0.3514907956123352, acc = 0.8759765625\n",
      "Batch 53: loss = 0.3635697364807129, acc = 0.8779296875\n",
      "Batch 54: loss = 0.30699825286865234, acc = 0.89453125\n",
      "Batch 55: loss = 0.34311920404434204, acc = 0.8896484375\n",
      "Batch 56: loss = 0.3577439785003662, acc = 0.8837890625\n",
      "Batch 57: loss = 0.41857773065567017, acc = 0.84765625\n",
      "Batch 58: loss = 0.40478193759918213, acc = 0.8642578125\n",
      "Batch 59: loss = 0.3075362741947174, acc = 0.890625\n",
      "Batch 60: loss = 0.3491222858428955, acc = 0.8818359375\n",
      "Batch 61: loss = 0.3259769678115845, acc = 0.9033203125\n",
      "Batch 62: loss = 0.3968159556388855, acc = 0.8740234375\n",
      "Batch 63: loss = 0.36679261922836304, acc = 0.8828125\n",
      "Batch 64: loss = 0.33762332797050476, acc = 0.8828125\n",
      "Batch 65: loss = 0.3600769340991974, acc = 0.87890625\n",
      "Batch 66: loss = 0.3506614565849304, acc = 0.884765625\n",
      "Batch 67: loss = 0.35482358932495117, acc = 0.88671875\n",
      "Batch 68: loss = 0.38311344385147095, acc = 0.873046875\n",
      "Batch 69: loss = 0.36517900228500366, acc = 0.88671875\n",
      "Batch 70: loss = 0.39523082971572876, acc = 0.873046875\n",
      "Batch 71: loss = 0.35761046409606934, acc = 0.8720703125\n",
      "Batch 72: loss = 0.33792054653167725, acc = 0.8828125\n",
      "Batch 73: loss = 0.37785017490386963, acc = 0.8671875\n",
      "Batch 74: loss = 0.439155638217926, acc = 0.857421875\n",
      "Batch 75: loss = 0.46372711658477783, acc = 0.84765625\n",
      "Batch 76: loss = 0.3756740391254425, acc = 0.873046875\n",
      "Batch 77: loss = 0.37222349643707275, acc = 0.8662109375\n",
      "Batch 78: loss = 0.39726221561431885, acc = 0.8720703125\n",
      "Batch 79: loss = 0.34726229310035706, acc = 0.8896484375\n",
      "Batch 80: loss = 0.3284876346588135, acc = 0.87890625\n",
      "Batch 81: loss = 0.3530220091342926, acc = 0.876953125\n",
      "Batch 82: loss = 0.34496819972991943, acc = 0.88671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 83: loss = 0.3405243754386902, acc = 0.8779296875\n",
      "Batch 84: loss = 0.40980643033981323, acc = 0.8603515625\n",
      "Batch 85: loss = 0.41766712069511414, acc = 0.8583984375\n",
      "Batch 86: loss = 0.4017828404903412, acc = 0.8662109375\n",
      "Batch 87: loss = 0.3911738395690918, acc = 0.8759765625\n",
      "Batch 88: loss = 0.39872491359710693, acc = 0.86328125\n",
      "Batch 89: loss = 0.35845717787742615, acc = 0.8837890625\n",
      "Batch 90: loss = 0.3598487079143524, acc = 0.8916015625\n",
      "Batch 91: loss = 0.36735838651657104, acc = 0.880859375\n",
      "Batch 92: loss = 0.39055874943733215, acc = 0.869140625\n",
      "Batch 93: loss = 0.3411722779273987, acc = 0.88671875\n",
      "Batch 94: loss = 0.31864628195762634, acc = 0.888671875\n",
      "Batch 95: loss = 0.3295424282550812, acc = 0.8896484375\n",
      "Batch 96: loss = 0.36013704538345337, acc = 0.8623046875\n",
      "Batch 97: loss = 0.3921003043651581, acc = 0.86328125\n",
      "Batch 98: loss = 0.3653184771537781, acc = 0.8779296875\n",
      "Batch 99: loss = 0.3947371542453766, acc = 0.8779296875\n",
      "Batch 100: loss = 0.42238616943359375, acc = 0.8525390625\n",
      "Batch 101: loss = 0.37323853373527527, acc = 0.873046875\n",
      "Batch 102: loss = 0.3623867332935333, acc = 0.87109375\n",
      "Batch 103: loss = 0.40346628427505493, acc = 0.869140625\n",
      "Batch 104: loss = 0.33566814661026, acc = 0.8876953125\n",
      "Batch 105: loss = 0.3585984706878662, acc = 0.87890625\n",
      "Batch 106: loss = 0.35694101452827454, acc = 0.8779296875\n",
      "Batch 107: loss = 0.3436625003814697, acc = 0.875\n",
      "Batch 108: loss = 0.3488672375679016, acc = 0.873046875\n",
      "Batch 109: loss = 0.3483060896396637, acc = 0.8857421875\n",
      "Batch 110: loss = 0.36935919523239136, acc = 0.8798828125\n",
      "Batch 111: loss = 0.35769712924957275, acc = 0.8798828125\n",
      "Batch 112: loss = 0.37853100895881653, acc = 0.8681640625\n",
      "Batch 113: loss = 0.3505703806877136, acc = 0.880859375\n",
      "Batch 114: loss = 0.37173742055892944, acc = 0.8837890625\n",
      "Batch 115: loss = 0.3716893196105957, acc = 0.8857421875\n",
      "Batch 116: loss = 0.38753998279571533, acc = 0.87890625\n",
      "Batch 117: loss = 0.37987080216407776, acc = 0.8779296875\n",
      "Batch 118: loss = 0.3266953229904175, acc = 0.888671875\n",
      "Batch 119: loss = 0.3373110890388489, acc = 0.892578125\n",
      "Batch 120: loss = 0.31297796964645386, acc = 0.90234375\n",
      "Batch 121: loss = 0.3871930241584778, acc = 0.8759765625\n",
      "Batch 122: loss = 0.3124505877494812, acc = 0.8876953125\n",
      "Batch 123: loss = 0.3496602475643158, acc = 0.8876953125\n",
      "Batch 124: loss = 0.35494348406791687, acc = 0.8701171875\n",
      "Batch 125: loss = 0.38194525241851807, acc = 0.8759765625\n",
      "Batch 126: loss = 0.36204200983047485, acc = 0.8876953125\n",
      "\n",
      "Epoch 60/100\n",
      "Batch 1: loss = 0.5108358263969421, acc = 0.8564453125\n",
      "Batch 2: loss = 0.3811333179473877, acc = 0.8828125\n",
      "Batch 3: loss = 0.3716903328895569, acc = 0.8779296875\n",
      "Batch 4: loss = 0.36599570512771606, acc = 0.8818359375\n",
      "Batch 5: loss = 0.3391951024532318, acc = 0.8974609375\n",
      "Batch 6: loss = 0.38665056228637695, acc = 0.8779296875\n",
      "Batch 7: loss = 0.37806814908981323, acc = 0.880859375\n",
      "Batch 8: loss = 0.34560415148735046, acc = 0.8857421875\n",
      "Batch 9: loss = 0.34233179688453674, acc = 0.8876953125\n",
      "Batch 10: loss = 0.28118860721588135, acc = 0.90234375\n",
      "Batch 11: loss = 0.36057060956954956, acc = 0.876953125\n",
      "Batch 12: loss = 0.3628920614719391, acc = 0.87890625\n",
      "Batch 13: loss = 0.36569780111312866, acc = 0.876953125\n",
      "Batch 14: loss = 0.3754597008228302, acc = 0.876953125\n",
      "Batch 15: loss = 0.32909098267555237, acc = 0.89453125\n",
      "Batch 16: loss = 0.34439408779144287, acc = 0.890625\n",
      "Batch 17: loss = 0.35181933641433716, acc = 0.8740234375\n",
      "Batch 18: loss = 0.3812633454799652, acc = 0.8818359375\n",
      "Batch 19: loss = 0.3591671586036682, acc = 0.89453125\n",
      "Batch 20: loss = 0.3317934274673462, acc = 0.8984375\n",
      "Batch 21: loss = 0.4247829020023346, acc = 0.8583984375\n",
      "Batch 22: loss = 0.3931662440299988, acc = 0.8740234375\n",
      "Batch 23: loss = 0.38861170411109924, acc = 0.873046875\n",
      "Batch 24: loss = 0.3516519069671631, acc = 0.8876953125\n",
      "Batch 25: loss = 0.30744653940200806, acc = 0.9033203125\n",
      "Batch 26: loss = 0.3428287208080292, acc = 0.8857421875\n",
      "Batch 27: loss = 0.413594126701355, acc = 0.857421875\n",
      "Batch 28: loss = 0.4105297327041626, acc = 0.876953125\n",
      "Batch 29: loss = 0.41295507550239563, acc = 0.8662109375\n",
      "Batch 30: loss = 0.37551066279411316, acc = 0.8701171875\n",
      "Batch 31: loss = 0.38187599182128906, acc = 0.8681640625\n",
      "Batch 32: loss = 0.42694953083992004, acc = 0.8544921875\n",
      "Batch 33: loss = 0.32900363206863403, acc = 0.8935546875\n",
      "Batch 34: loss = 0.3913553059101105, acc = 0.859375\n",
      "Batch 35: loss = 0.37013179063796997, acc = 0.8740234375\n",
      "Batch 36: loss = 0.3496190309524536, acc = 0.8916015625\n",
      "Batch 37: loss = 0.338992714881897, acc = 0.880859375\n",
      "Batch 38: loss = 0.35212403535842896, acc = 0.890625\n",
      "Batch 39: loss = 0.31864407658576965, acc = 0.890625\n",
      "Batch 40: loss = 0.3575047254562378, acc = 0.8671875\n",
      "Batch 41: loss = 0.2962229251861572, acc = 0.8896484375\n",
      "Batch 42: loss = 0.3420661985874176, acc = 0.87890625\n",
      "Batch 43: loss = 0.4017188251018524, acc = 0.857421875\n",
      "Batch 44: loss = 0.352367639541626, acc = 0.8857421875\n",
      "Batch 45: loss = 0.3233669698238373, acc = 0.896484375\n",
      "Batch 46: loss = 0.35744568705558777, acc = 0.884765625\n",
      "Batch 47: loss = 0.33328673243522644, acc = 0.888671875\n",
      "Batch 48: loss = 0.3650745749473572, acc = 0.87109375\n",
      "Batch 49: loss = 0.3332598805427551, acc = 0.8935546875\n",
      "Batch 50: loss = 0.33721107244491577, acc = 0.890625\n",
      "Batch 51: loss = 0.3458734154701233, acc = 0.8857421875\n",
      "Batch 52: loss = 0.3594277799129486, acc = 0.88671875\n",
      "Batch 53: loss = 0.34222495555877686, acc = 0.8916015625\n",
      "Batch 54: loss = 0.3176538050174713, acc = 0.890625\n",
      "Batch 55: loss = 0.32913336157798767, acc = 0.8837890625\n",
      "Batch 56: loss = 0.3741627335548401, acc = 0.8642578125\n",
      "Batch 57: loss = 0.36479297280311584, acc = 0.884765625\n",
      "Batch 58: loss = 0.3964901268482208, acc = 0.857421875\n",
      "Batch 59: loss = 0.2857581377029419, acc = 0.9091796875\n",
      "Batch 60: loss = 0.33567944169044495, acc = 0.890625\n",
      "Batch 61: loss = 0.3580508232116699, acc = 0.884765625\n",
      "Batch 62: loss = 0.41008812189102173, acc = 0.85546875\n",
      "Batch 63: loss = 0.3378802239894867, acc = 0.8916015625\n",
      "Batch 64: loss = 0.32819393277168274, acc = 0.8916015625\n",
      "Batch 65: loss = 0.3909224569797516, acc = 0.873046875\n",
      "Batch 66: loss = 0.34646734595298767, acc = 0.8798828125\n",
      "Batch 67: loss = 0.3538871705532074, acc = 0.875\n",
      "Batch 68: loss = 0.35093194246292114, acc = 0.8857421875\n",
      "Batch 69: loss = 0.32710957527160645, acc = 0.90234375\n",
      "Batch 70: loss = 0.39923518896102905, acc = 0.861328125\n",
      "Batch 71: loss = 0.3637359142303467, acc = 0.8681640625\n",
      "Batch 72: loss = 0.32936275005340576, acc = 0.8994140625\n",
      "Batch 73: loss = 0.4003121256828308, acc = 0.8671875\n",
      "Batch 74: loss = 0.3658677935600281, acc = 0.875\n",
      "Batch 75: loss = 0.42729148268699646, acc = 0.859375\n",
      "Batch 76: loss = 0.4099631607532501, acc = 0.8603515625\n",
      "Batch 77: loss = 0.3458006978034973, acc = 0.8779296875\n",
      "Batch 78: loss = 0.38154345750808716, acc = 0.8720703125\n",
      "Batch 79: loss = 0.3621816635131836, acc = 0.876953125\n",
      "Batch 80: loss = 0.3194814920425415, acc = 0.89453125\n",
      "Batch 81: loss = 0.36776497960090637, acc = 0.87109375\n",
      "Batch 82: loss = 0.348991334438324, acc = 0.88671875\n",
      "Batch 83: loss = 0.3577614426612854, acc = 0.87890625\n",
      "Batch 84: loss = 0.364053875207901, acc = 0.875\n",
      "Batch 85: loss = 0.36909377574920654, acc = 0.87890625\n",
      "Batch 86: loss = 0.35768407583236694, acc = 0.875\n",
      "Batch 87: loss = 0.3665640354156494, acc = 0.8740234375\n",
      "Batch 88: loss = 0.42899513244628906, acc = 0.8525390625\n",
      "Batch 89: loss = 0.3732748031616211, acc = 0.8681640625\n",
      "Batch 90: loss = 0.37125164270401, acc = 0.8779296875\n",
      "Batch 91: loss = 0.39057064056396484, acc = 0.8740234375\n",
      "Batch 92: loss = 0.36877918243408203, acc = 0.873046875\n",
      "Batch 93: loss = 0.34473010897636414, acc = 0.8857421875\n",
      "Batch 94: loss = 0.3491559624671936, acc = 0.8837890625\n",
      "Batch 95: loss = 0.330798864364624, acc = 0.896484375\n",
      "Batch 96: loss = 0.37774544954299927, acc = 0.8759765625\n",
      "Batch 97: loss = 0.3572046458721161, acc = 0.880859375\n",
      "Batch 98: loss = 0.3749752342700958, acc = 0.8740234375\n",
      "Batch 99: loss = 0.36082905530929565, acc = 0.8779296875\n",
      "Batch 100: loss = 0.36530065536499023, acc = 0.8759765625\n",
      "Batch 101: loss = 0.3717615008354187, acc = 0.8798828125\n",
      "Batch 102: loss = 0.3632636070251465, acc = 0.880859375\n",
      "Batch 103: loss = 0.35566776990890503, acc = 0.892578125\n",
      "Batch 104: loss = 0.33291834592819214, acc = 0.8876953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 105: loss = 0.34409981966018677, acc = 0.880859375\n",
      "Batch 106: loss = 0.3374571204185486, acc = 0.8818359375\n",
      "Batch 107: loss = 0.3568042516708374, acc = 0.892578125\n",
      "Batch 108: loss = 0.3597876727581024, acc = 0.8759765625\n",
      "Batch 109: loss = 0.3355065584182739, acc = 0.880859375\n",
      "Batch 110: loss = 0.3461226224899292, acc = 0.8798828125\n",
      "Batch 111: loss = 0.36012405157089233, acc = 0.875\n",
      "Batch 112: loss = 0.3445587456226349, acc = 0.8857421875\n",
      "Batch 113: loss = 0.3629395365715027, acc = 0.8837890625\n",
      "Batch 114: loss = 0.3474624752998352, acc = 0.880859375\n",
      "Batch 115: loss = 0.365070104598999, acc = 0.875\n",
      "Batch 116: loss = 0.382172554731369, acc = 0.8701171875\n",
      "Batch 117: loss = 0.3524983525276184, acc = 0.890625\n",
      "Batch 118: loss = 0.31695273518562317, acc = 0.888671875\n",
      "Batch 119: loss = 0.33501875400543213, acc = 0.8916015625\n",
      "Batch 120: loss = 0.3176973760128021, acc = 0.90234375\n",
      "Batch 121: loss = 0.35672345757484436, acc = 0.8759765625\n",
      "Batch 122: loss = 0.3270367383956909, acc = 0.8876953125\n",
      "Batch 123: loss = 0.3628894090652466, acc = 0.8828125\n",
      "Batch 124: loss = 0.3907735049724579, acc = 0.853515625\n",
      "Batch 125: loss = 0.4011532664299011, acc = 0.8701171875\n",
      "Batch 126: loss = 0.3555490970611572, acc = 0.8935546875\n",
      "Saved checkpoint to weights.60.h5\n",
      "\n",
      "Epoch 61/100\n",
      "Batch 1: loss = 0.5091067552566528, acc = 0.8505859375\n",
      "Batch 2: loss = 0.41668397188186646, acc = 0.861328125\n",
      "Batch 3: loss = 0.3553854823112488, acc = 0.8798828125\n",
      "Batch 4: loss = 0.36630845069885254, acc = 0.8935546875\n",
      "Batch 5: loss = 0.3552066683769226, acc = 0.8818359375\n",
      "Batch 6: loss = 0.4169531762599945, acc = 0.865234375\n",
      "Batch 7: loss = 0.3603758215904236, acc = 0.8837890625\n",
      "Batch 8: loss = 0.3506859540939331, acc = 0.8818359375\n",
      "Batch 9: loss = 0.34788089990615845, acc = 0.892578125\n",
      "Batch 10: loss = 0.3130922317504883, acc = 0.890625\n",
      "Batch 11: loss = 0.34590452909469604, acc = 0.8779296875\n",
      "Batch 12: loss = 0.34579235315322876, acc = 0.8779296875\n",
      "Batch 13: loss = 0.3572377562522888, acc = 0.8916015625\n",
      "Batch 14: loss = 0.3304503560066223, acc = 0.888671875\n",
      "Batch 15: loss = 0.3586553931236267, acc = 0.869140625\n",
      "Batch 16: loss = 0.34745898842811584, acc = 0.8896484375\n",
      "Batch 17: loss = 0.3625320792198181, acc = 0.876953125\n",
      "Batch 18: loss = 0.3359019160270691, acc = 0.8896484375\n",
      "Batch 19: loss = 0.33994704484939575, acc = 0.884765625\n",
      "Batch 20: loss = 0.3602161407470703, acc = 0.8759765625\n",
      "Batch 21: loss = 0.3627801835536957, acc = 0.8740234375\n",
      "Batch 22: loss = 0.3670816719532013, acc = 0.880859375\n",
      "Batch 23: loss = 0.3831270933151245, acc = 0.87109375\n",
      "Batch 24: loss = 0.3823193907737732, acc = 0.8740234375\n",
      "Batch 25: loss = 0.322775661945343, acc = 0.8916015625\n",
      "Batch 26: loss = 0.35852962732315063, acc = 0.8701171875\n",
      "Batch 27: loss = 0.4151143431663513, acc = 0.8583984375\n",
      "Batch 28: loss = 0.36482661962509155, acc = 0.869140625\n",
      "Batch 29: loss = 0.3979186415672302, acc = 0.8623046875\n",
      "Batch 30: loss = 0.38348865509033203, acc = 0.8720703125\n",
      "Batch 31: loss = 0.35772931575775146, acc = 0.890625\n",
      "Batch 32: loss = 0.39629852771759033, acc = 0.873046875\n",
      "Batch 33: loss = 0.3561171889305115, acc = 0.880859375\n",
      "Batch 34: loss = 0.39204439520835876, acc = 0.8701171875\n",
      "Batch 35: loss = 0.37287208437919617, acc = 0.8837890625\n",
      "Batch 36: loss = 0.3074180483818054, acc = 0.89453125\n",
      "Batch 37: loss = 0.3184906840324402, acc = 0.8984375\n",
      "Batch 38: loss = 0.3322446942329407, acc = 0.8857421875\n",
      "Batch 39: loss = 0.31892144680023193, acc = 0.8955078125\n",
      "Batch 40: loss = 0.37471461296081543, acc = 0.8828125\n",
      "Batch 41: loss = 0.32432809472084045, acc = 0.88671875\n",
      "Batch 42: loss = 0.36354324221611023, acc = 0.8720703125\n",
      "Batch 43: loss = 0.3875322937965393, acc = 0.8818359375\n",
      "Batch 44: loss = 0.3548036813735962, acc = 0.8955078125\n",
      "Batch 45: loss = 0.30778616666793823, acc = 0.9013671875\n",
      "Batch 46: loss = 0.3200685679912567, acc = 0.8916015625\n",
      "Batch 47: loss = 0.3599242866039276, acc = 0.8828125\n",
      "Batch 48: loss = 0.34973907470703125, acc = 0.8720703125\n",
      "Batch 49: loss = 0.3124784231185913, acc = 0.8955078125\n",
      "Batch 50: loss = 0.3188818395137787, acc = 0.8935546875\n",
      "Batch 51: loss = 0.3637804090976715, acc = 0.875\n",
      "Batch 52: loss = 0.35309281945228577, acc = 0.8798828125\n",
      "Batch 53: loss = 0.36991479992866516, acc = 0.8818359375\n",
      "Batch 54: loss = 0.29700830578804016, acc = 0.8984375\n",
      "Batch 55: loss = 0.3218767046928406, acc = 0.8984375\n",
      "Batch 56: loss = 0.35376524925231934, acc = 0.880859375\n",
      "Batch 57: loss = 0.3987744450569153, acc = 0.859375\n",
      "Batch 58: loss = 0.3894829750061035, acc = 0.8740234375\n",
      "Batch 59: loss = 0.30574941635131836, acc = 0.90625\n",
      "Batch 60: loss = 0.3733246922492981, acc = 0.87890625\n",
      "Batch 61: loss = 0.31160300970077515, acc = 0.900390625\n",
      "Batch 62: loss = 0.42490410804748535, acc = 0.8544921875\n",
      "Batch 63: loss = 0.3739970624446869, acc = 0.8798828125\n",
      "Batch 64: loss = 0.34002143144607544, acc = 0.8837890625\n",
      "Batch 65: loss = 0.3494325578212738, acc = 0.884765625\n",
      "Batch 66: loss = 0.31948721408843994, acc = 0.8974609375\n",
      "Batch 67: loss = 0.37034887075424194, acc = 0.87890625\n",
      "Batch 68: loss = 0.3637304902076721, acc = 0.880859375\n",
      "Batch 69: loss = 0.3498038947582245, acc = 0.888671875\n",
      "Batch 70: loss = 0.3921250104904175, acc = 0.8720703125\n",
      "Batch 71: loss = 0.3443867564201355, acc = 0.888671875\n",
      "Batch 72: loss = 0.3101539611816406, acc = 0.9072265625\n",
      "Batch 73: loss = 0.39943522214889526, acc = 0.8681640625\n",
      "Batch 74: loss = 0.3856886029243469, acc = 0.859375\n",
      "Batch 75: loss = 0.4215391278266907, acc = 0.85546875\n",
      "Batch 76: loss = 0.37566936016082764, acc = 0.875\n",
      "Batch 77: loss = 0.33308789134025574, acc = 0.8818359375\n",
      "Batch 78: loss = 0.3476651906967163, acc = 0.888671875\n",
      "Batch 79: loss = 0.33226916193962097, acc = 0.89453125\n",
      "Batch 80: loss = 0.31314167380332947, acc = 0.88671875\n",
      "Batch 81: loss = 0.3646736145019531, acc = 0.876953125\n",
      "Batch 82: loss = 0.3130338788032532, acc = 0.8994140625\n",
      "Batch 83: loss = 0.34623873233795166, acc = 0.8818359375\n",
      "Batch 84: loss = 0.323803186416626, acc = 0.888671875\n",
      "Batch 85: loss = 0.3776127099990845, acc = 0.8720703125\n",
      "Batch 86: loss = 0.3587154448032379, acc = 0.8798828125\n",
      "Batch 87: loss = 0.3378615081310272, acc = 0.88671875\n",
      "Batch 88: loss = 0.41744667291641235, acc = 0.859375\n",
      "Batch 89: loss = 0.34179526567459106, acc = 0.884765625\n",
      "Batch 90: loss = 0.3462131917476654, acc = 0.8837890625\n",
      "Batch 91: loss = 0.3738945722579956, acc = 0.875\n",
      "Batch 92: loss = 0.4051080346107483, acc = 0.86328125\n",
      "Batch 93: loss = 0.3293135464191437, acc = 0.8857421875\n",
      "Batch 94: loss = 0.32662245631217957, acc = 0.8955078125\n",
      "Batch 95: loss = 0.28718775510787964, acc = 0.8935546875\n",
      "Batch 96: loss = 0.3870214819908142, acc = 0.8681640625\n",
      "Batch 97: loss = 0.36424481868743896, acc = 0.8857421875\n",
      "Batch 98: loss = 0.341788113117218, acc = 0.8876953125\n",
      "Batch 99: loss = 0.3672351837158203, acc = 0.8798828125\n",
      "Batch 100: loss = 0.37289297580718994, acc = 0.8720703125\n",
      "Batch 101: loss = 0.35287341475486755, acc = 0.8720703125\n",
      "Batch 102: loss = 0.3658371865749359, acc = 0.87890625\n",
      "Batch 103: loss = 0.3883897662162781, acc = 0.8662109375\n",
      "Batch 104: loss = 0.30774185061454773, acc = 0.900390625\n",
      "Batch 105: loss = 0.33983325958251953, acc = 0.8955078125\n",
      "Batch 106: loss = 0.3311074376106262, acc = 0.8857421875\n",
      "Batch 107: loss = 0.3541960120201111, acc = 0.876953125\n",
      "Batch 108: loss = 0.3152042031288147, acc = 0.8916015625\n",
      "Batch 109: loss = 0.31335514783859253, acc = 0.89453125\n",
      "Batch 110: loss = 0.3146904408931732, acc = 0.9033203125\n",
      "Batch 111: loss = 0.32805585861206055, acc = 0.8828125\n",
      "Batch 112: loss = 0.353130966424942, acc = 0.892578125\n",
      "Batch 113: loss = 0.3560928702354431, acc = 0.8837890625\n",
      "Batch 114: loss = 0.3461397886276245, acc = 0.8916015625\n",
      "Batch 115: loss = 0.37134742736816406, acc = 0.876953125\n",
      "Batch 116: loss = 0.3742985725402832, acc = 0.876953125\n",
      "Batch 117: loss = 0.3874933421611786, acc = 0.87890625\n",
      "Batch 118: loss = 0.3057786226272583, acc = 0.8935546875\n",
      "Batch 119: loss = 0.36956995725631714, acc = 0.8798828125\n",
      "Batch 120: loss = 0.30186623334884644, acc = 0.8935546875\n",
      "Batch 121: loss = 0.3784642219543457, acc = 0.8642578125\n",
      "Batch 122: loss = 0.33289822936058044, acc = 0.8837890625\n",
      "Batch 123: loss = 0.33758318424224854, acc = 0.8857421875\n",
      "Batch 124: loss = 0.37590378522872925, acc = 0.869140625\n",
      "Batch 125: loss = 0.38337403535842896, acc = 0.8759765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 126: loss = 0.38117313385009766, acc = 0.869140625\n",
      "\n",
      "Epoch 62/100\n",
      "Batch 1: loss = 0.5021188259124756, acc = 0.85546875\n",
      "Batch 2: loss = 0.3897380828857422, acc = 0.875\n",
      "Batch 3: loss = 0.334661602973938, acc = 0.8974609375\n",
      "Batch 4: loss = 0.31942135095596313, acc = 0.9013671875\n",
      "Batch 5: loss = 0.3367595672607422, acc = 0.884765625\n",
      "Batch 6: loss = 0.3871545195579529, acc = 0.8701171875\n",
      "Batch 7: loss = 0.36923813819885254, acc = 0.88671875\n",
      "Batch 8: loss = 0.3741464912891388, acc = 0.884765625\n",
      "Batch 9: loss = 0.3332163691520691, acc = 0.8935546875\n",
      "Batch 10: loss = 0.2996639013290405, acc = 0.9013671875\n",
      "Batch 11: loss = 0.3833024203777313, acc = 0.8779296875\n",
      "Batch 12: loss = 0.33817559480667114, acc = 0.8837890625\n",
      "Batch 13: loss = 0.3211075961589813, acc = 0.888671875\n",
      "Batch 14: loss = 0.35243427753448486, acc = 0.884765625\n",
      "Batch 15: loss = 0.31142470240592957, acc = 0.8916015625\n",
      "Batch 16: loss = 0.34100353717803955, acc = 0.892578125\n",
      "Batch 17: loss = 0.3318023085594177, acc = 0.888671875\n",
      "Batch 18: loss = 0.3522849977016449, acc = 0.880859375\n",
      "Batch 19: loss = 0.33879774808883667, acc = 0.88671875\n",
      "Batch 20: loss = 0.35611337423324585, acc = 0.8779296875\n",
      "Batch 21: loss = 0.40166401863098145, acc = 0.8564453125\n",
      "Batch 22: loss = 0.3919353485107422, acc = 0.876953125\n",
      "Batch 23: loss = 0.37020885944366455, acc = 0.8642578125\n",
      "Batch 24: loss = 0.3356572687625885, acc = 0.88671875\n",
      "Batch 25: loss = 0.33816438913345337, acc = 0.8935546875\n",
      "Batch 26: loss = 0.34674569964408875, acc = 0.8720703125\n",
      "Batch 27: loss = 0.39977043867111206, acc = 0.8662109375\n",
      "Batch 28: loss = 0.3676585257053375, acc = 0.876953125\n",
      "Batch 29: loss = 0.38965752720832825, acc = 0.876953125\n",
      "Batch 30: loss = 0.3521052598953247, acc = 0.888671875\n",
      "Batch 31: loss = 0.3603482246398926, acc = 0.8779296875\n",
      "Batch 32: loss = 0.4045720100402832, acc = 0.87109375\n",
      "Batch 33: loss = 0.350984126329422, acc = 0.8828125\n",
      "Batch 34: loss = 0.37052592635154724, acc = 0.8671875\n",
      "Batch 35: loss = 0.37633877992630005, acc = 0.8740234375\n",
      "Batch 36: loss = 0.33643803000450134, acc = 0.8828125\n",
      "Batch 37: loss = 0.307005375623703, acc = 0.8984375\n",
      "Batch 38: loss = 0.33833709359169006, acc = 0.88671875\n",
      "Batch 39: loss = 0.3201920986175537, acc = 0.8955078125\n",
      "Batch 40: loss = 0.3354606032371521, acc = 0.8994140625\n",
      "Batch 41: loss = 0.31291723251342773, acc = 0.8876953125\n",
      "Batch 42: loss = 0.33607009053230286, acc = 0.8876953125\n",
      "Batch 43: loss = 0.3757809102535248, acc = 0.869140625\n",
      "Batch 44: loss = 0.3114464282989502, acc = 0.8994140625\n",
      "Batch 45: loss = 0.31390947103500366, acc = 0.8876953125\n",
      "Batch 46: loss = 0.32062360644340515, acc = 0.890625\n",
      "Batch 47: loss = 0.37493467330932617, acc = 0.87890625\n",
      "Batch 48: loss = 0.347899466753006, acc = 0.88671875\n",
      "Batch 49: loss = 0.3194614052772522, acc = 0.8955078125\n",
      "Batch 50: loss = 0.31644633412361145, acc = 0.8955078125\n",
      "Batch 51: loss = 0.29990196228027344, acc = 0.900390625\n",
      "Batch 52: loss = 0.36213648319244385, acc = 0.880859375\n",
      "Batch 53: loss = 0.3514726758003235, acc = 0.8857421875\n",
      "Batch 54: loss = 0.2940911054611206, acc = 0.900390625\n",
      "Batch 55: loss = 0.2742752134799957, acc = 0.91015625\n",
      "Batch 56: loss = 0.3367447853088379, acc = 0.8876953125\n",
      "Batch 57: loss = 0.3712470531463623, acc = 0.8671875\n",
      "Batch 58: loss = 0.4233520030975342, acc = 0.857421875\n",
      "Batch 59: loss = 0.29400062561035156, acc = 0.9052734375\n",
      "Batch 60: loss = 0.37360918521881104, acc = 0.875\n",
      "Batch 61: loss = 0.3435351848602295, acc = 0.888671875\n",
      "Batch 62: loss = 0.39065390825271606, acc = 0.86328125\n",
      "Batch 63: loss = 0.3104174733161926, acc = 0.89453125\n",
      "Batch 64: loss = 0.29382216930389404, acc = 0.90625\n",
      "Batch 65: loss = 0.3405126631259918, acc = 0.8876953125\n",
      "Batch 66: loss = 0.37450727820396423, acc = 0.884765625\n",
      "Batch 67: loss = 0.34091436862945557, acc = 0.890625\n",
      "Batch 68: loss = 0.3183579444885254, acc = 0.8896484375\n",
      "Batch 69: loss = 0.3267363905906677, acc = 0.896484375\n",
      "Batch 70: loss = 0.37139713764190674, acc = 0.8779296875\n",
      "Batch 71: loss = 0.37308332324028015, acc = 0.8701171875\n",
      "Batch 72: loss = 0.3300151228904724, acc = 0.8994140625\n",
      "Batch 73: loss = 0.3727406859397888, acc = 0.87109375\n",
      "Batch 74: loss = 0.35884889960289, acc = 0.875\n",
      "Batch 75: loss = 0.4051057696342468, acc = 0.859375\n",
      "Batch 76: loss = 0.3447980582714081, acc = 0.8798828125\n",
      "Batch 77: loss = 0.32693448662757874, acc = 0.884765625\n",
      "Batch 78: loss = 0.362104594707489, acc = 0.89453125\n",
      "Batch 79: loss = 0.31751182675361633, acc = 0.896484375\n",
      "Batch 80: loss = 0.33860012888908386, acc = 0.8798828125\n",
      "Batch 81: loss = 0.32419446110725403, acc = 0.8935546875\n",
      "Batch 82: loss = 0.3321846127510071, acc = 0.8837890625\n",
      "Batch 83: loss = 0.33846768736839294, acc = 0.8837890625\n",
      "Batch 84: loss = 0.33591991662979126, acc = 0.8779296875\n",
      "Batch 85: loss = 0.40279221534729004, acc = 0.8662109375\n",
      "Batch 86: loss = 0.3586808741092682, acc = 0.8896484375\n",
      "Batch 87: loss = 0.3638680577278137, acc = 0.8818359375\n",
      "Batch 88: loss = 0.38088560104370117, acc = 0.876953125\n",
      "Batch 89: loss = 0.30696403980255127, acc = 0.900390625\n",
      "Batch 90: loss = 0.353481650352478, acc = 0.8837890625\n",
      "Batch 91: loss = 0.38227611780166626, acc = 0.8828125\n",
      "Batch 92: loss = 0.3701484799385071, acc = 0.865234375\n",
      "Batch 93: loss = 0.302264928817749, acc = 0.8935546875\n",
      "Batch 94: loss = 0.3201369643211365, acc = 0.8916015625\n",
      "Batch 95: loss = 0.32041192054748535, acc = 0.8955078125\n",
      "Batch 96: loss = 0.36993134021759033, acc = 0.8671875\n",
      "Batch 97: loss = 0.36829474568367004, acc = 0.8876953125\n",
      "Batch 98: loss = 0.3545258045196533, acc = 0.875\n",
      "Batch 99: loss = 0.3709285259246826, acc = 0.87109375\n",
      "Batch 100: loss = 0.3225075602531433, acc = 0.8759765625\n",
      "Batch 101: loss = 0.35435950756073, acc = 0.869140625\n",
      "Batch 102: loss = 0.36791521310806274, acc = 0.869140625\n",
      "Batch 103: loss = 0.33592838048934937, acc = 0.8955078125\n",
      "Batch 104: loss = 0.3048752546310425, acc = 0.90234375\n",
      "Batch 105: loss = 0.3121880888938904, acc = 0.8896484375\n",
      "Batch 106: loss = 0.3320618271827698, acc = 0.884765625\n",
      "Batch 107: loss = 0.36517566442489624, acc = 0.8779296875\n",
      "Batch 108: loss = 0.32920587062835693, acc = 0.8798828125\n",
      "Batch 109: loss = 0.3511349558830261, acc = 0.8798828125\n",
      "Batch 110: loss = 0.3552888333797455, acc = 0.8837890625\n",
      "Batch 111: loss = 0.3561573922634125, acc = 0.880859375\n",
      "Batch 112: loss = 0.37006205320358276, acc = 0.8798828125\n",
      "Batch 113: loss = 0.3475368320941925, acc = 0.87890625\n",
      "Batch 114: loss = 0.35716819763183594, acc = 0.876953125\n",
      "Batch 115: loss = 0.3195393681526184, acc = 0.90625\n",
      "Batch 116: loss = 0.3743319511413574, acc = 0.8681640625\n",
      "Batch 117: loss = 0.33187416195869446, acc = 0.89453125\n",
      "Batch 118: loss = 0.30456697940826416, acc = 0.9013671875\n",
      "Batch 119: loss = 0.32942330837249756, acc = 0.890625\n",
      "Batch 120: loss = 0.3255816698074341, acc = 0.89453125\n",
      "Batch 121: loss = 0.3592877686023712, acc = 0.873046875\n",
      "Batch 122: loss = 0.30508801341056824, acc = 0.9052734375\n",
      "Batch 123: loss = 0.3268239498138428, acc = 0.892578125\n",
      "Batch 124: loss = 0.38195592164993286, acc = 0.875\n",
      "Batch 125: loss = 0.3616257309913635, acc = 0.87890625\n",
      "Batch 126: loss = 0.37609347701072693, acc = 0.869140625\n",
      "\n",
      "Epoch 63/100\n",
      "Batch 1: loss = 0.5122184753417969, acc = 0.8583984375\n",
      "Batch 2: loss = 0.3648655414581299, acc = 0.8798828125\n",
      "Batch 3: loss = 0.3535078167915344, acc = 0.8896484375\n",
      "Batch 4: loss = 0.36127400398254395, acc = 0.8779296875\n",
      "Batch 5: loss = 0.34262174367904663, acc = 0.8837890625\n",
      "Batch 6: loss = 0.35329577326774597, acc = 0.8837890625\n",
      "Batch 7: loss = 0.32934287190437317, acc = 0.88671875\n",
      "Batch 8: loss = 0.365678608417511, acc = 0.8759765625\n",
      "Batch 9: loss = 0.32762718200683594, acc = 0.900390625\n",
      "Batch 10: loss = 0.3042437732219696, acc = 0.9013671875\n",
      "Batch 11: loss = 0.35138893127441406, acc = 0.8837890625\n",
      "Batch 12: loss = 0.34162503480911255, acc = 0.8837890625\n",
      "Batch 13: loss = 0.34007763862609863, acc = 0.8974609375\n",
      "Batch 14: loss = 0.3610973358154297, acc = 0.88671875\n",
      "Batch 15: loss = 0.37214046716690063, acc = 0.8828125\n",
      "Batch 16: loss = 0.33846938610076904, acc = 0.8896484375\n",
      "Batch 17: loss = 0.322482168674469, acc = 0.892578125\n",
      "Batch 18: loss = 0.38601088523864746, acc = 0.87109375\n",
      "Batch 19: loss = 0.36598777770996094, acc = 0.8720703125\n",
      "Batch 20: loss = 0.35606828331947327, acc = 0.87890625\n",
      "Batch 21: loss = 0.3468203544616699, acc = 0.880859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 22: loss = 0.37514710426330566, acc = 0.8701171875\n",
      "Batch 23: loss = 0.3549847900867462, acc = 0.8759765625\n",
      "Batch 24: loss = 0.32770153880119324, acc = 0.8916015625\n",
      "Batch 25: loss = 0.36161333322525024, acc = 0.8828125\n",
      "Batch 26: loss = 0.3323192000389099, acc = 0.8798828125\n",
      "Batch 27: loss = 0.3500400483608246, acc = 0.8818359375\n",
      "Batch 28: loss = 0.4080849587917328, acc = 0.857421875\n",
      "Batch 29: loss = 0.38153383135795593, acc = 0.8798828125\n",
      "Batch 30: loss = 0.3504302203655243, acc = 0.87890625\n",
      "Batch 31: loss = 0.36519280076026917, acc = 0.88671875\n",
      "Batch 32: loss = 0.393961101770401, acc = 0.8662109375\n",
      "Batch 33: loss = 0.3068350553512573, acc = 0.8994140625\n",
      "Batch 34: loss = 0.3546407222747803, acc = 0.869140625\n",
      "Batch 35: loss = 0.35880395770072937, acc = 0.8857421875\n",
      "Batch 36: loss = 0.3492167592048645, acc = 0.8759765625\n",
      "Batch 37: loss = 0.3062882125377655, acc = 0.9033203125\n",
      "Batch 38: loss = 0.3718385696411133, acc = 0.8837890625\n",
      "Batch 39: loss = 0.3083078861236572, acc = 0.8955078125\n",
      "Batch 40: loss = 0.3367343544960022, acc = 0.8857421875\n",
      "Batch 41: loss = 0.3073343336582184, acc = 0.8916015625\n",
      "Batch 42: loss = 0.341499924659729, acc = 0.8876953125\n",
      "Batch 43: loss = 0.3787037134170532, acc = 0.873046875\n",
      "Batch 44: loss = 0.34880656003952026, acc = 0.8876953125\n",
      "Batch 45: loss = 0.31402260065078735, acc = 0.8984375\n",
      "Batch 46: loss = 0.27721965312957764, acc = 0.908203125\n",
      "Batch 47: loss = 0.329842209815979, acc = 0.904296875\n",
      "Batch 48: loss = 0.3256244659423828, acc = 0.888671875\n",
      "Batch 49: loss = 0.3153223991394043, acc = 0.896484375\n",
      "Batch 50: loss = 0.3053455054759979, acc = 0.9013671875\n",
      "Batch 51: loss = 0.34634706377983093, acc = 0.888671875\n",
      "Batch 52: loss = 0.30909401178359985, acc = 0.8974609375\n",
      "Batch 53: loss = 0.34508347511291504, acc = 0.8779296875\n",
      "Batch 54: loss = 0.2829059958457947, acc = 0.91015625\n",
      "Batch 55: loss = 0.28398749232292175, acc = 0.90234375\n",
      "Batch 56: loss = 0.3825618028640747, acc = 0.8759765625\n",
      "Batch 57: loss = 0.3388064503669739, acc = 0.873046875\n",
      "Batch 58: loss = 0.3649691343307495, acc = 0.873046875\n",
      "Batch 59: loss = 0.2678673267364502, acc = 0.9091796875\n",
      "Batch 60: loss = 0.3707456588745117, acc = 0.888671875\n",
      "Batch 61: loss = 0.33927345275878906, acc = 0.8876953125\n",
      "Batch 62: loss = 0.3714030385017395, acc = 0.8671875\n",
      "Batch 63: loss = 0.35300588607788086, acc = 0.890625\n",
      "Batch 64: loss = 0.3226459324359894, acc = 0.89453125\n",
      "Batch 65: loss = 0.3578057289123535, acc = 0.880859375\n",
      "Batch 66: loss = 0.34703636169433594, acc = 0.876953125\n",
      "Batch 67: loss = 0.35496148467063904, acc = 0.8837890625\n",
      "Batch 68: loss = 0.36246171593666077, acc = 0.8720703125\n",
      "Batch 69: loss = 0.3315690755844116, acc = 0.8896484375\n",
      "Batch 70: loss = 0.3572407364845276, acc = 0.8740234375\n",
      "Batch 71: loss = 0.33935514092445374, acc = 0.880859375\n",
      "Batch 72: loss = 0.3383960425853729, acc = 0.8828125\n",
      "Batch 73: loss = 0.3633776903152466, acc = 0.8876953125\n",
      "Batch 74: loss = 0.38303494453430176, acc = 0.876953125\n",
      "Batch 75: loss = 0.42041510343551636, acc = 0.861328125\n",
      "Batch 76: loss = 0.36727190017700195, acc = 0.880859375\n",
      "Batch 77: loss = 0.36340412497520447, acc = 0.8740234375\n",
      "Batch 78: loss = 0.38275957107543945, acc = 0.8720703125\n",
      "Batch 79: loss = 0.3184314966201782, acc = 0.896484375\n",
      "Batch 80: loss = 0.34319359064102173, acc = 0.880859375\n",
      "Batch 81: loss = 0.35343995690345764, acc = 0.8759765625\n",
      "Batch 82: loss = 0.36092233657836914, acc = 0.8798828125\n",
      "Batch 83: loss = 0.3461783528327942, acc = 0.8857421875\n",
      "Batch 84: loss = 0.3440318703651428, acc = 0.8701171875\n",
      "Batch 85: loss = 0.36481720209121704, acc = 0.87109375\n",
      "Batch 86: loss = 0.35219520330429077, acc = 0.87890625\n",
      "Batch 87: loss = 0.37171053886413574, acc = 0.8798828125\n",
      "Batch 88: loss = 0.41281044483184814, acc = 0.865234375\n",
      "Batch 89: loss = 0.3098447322845459, acc = 0.8857421875\n",
      "Batch 90: loss = 0.3510362505912781, acc = 0.869140625\n",
      "Batch 91: loss = 0.3863028883934021, acc = 0.87109375\n",
      "Batch 92: loss = 0.34548988938331604, acc = 0.8896484375\n",
      "Batch 93: loss = 0.3172905743122101, acc = 0.89453125\n",
      "Batch 94: loss = 0.33034050464630127, acc = 0.8857421875\n",
      "Batch 95: loss = 0.3168158531188965, acc = 0.9033203125\n",
      "Batch 96: loss = 0.37960284948349, acc = 0.859375\n",
      "Batch 97: loss = 0.3567976951599121, acc = 0.884765625\n",
      "Batch 98: loss = 0.32290923595428467, acc = 0.8935546875\n",
      "Batch 99: loss = 0.3642643094062805, acc = 0.87890625\n",
      "Batch 100: loss = 0.32584095001220703, acc = 0.8935546875\n",
      "Batch 101: loss = 0.3394663333892822, acc = 0.873046875\n",
      "Batch 102: loss = 0.3795400857925415, acc = 0.8623046875\n",
      "Batch 103: loss = 0.33820655941963196, acc = 0.89453125\n",
      "Batch 104: loss = 0.3317625820636749, acc = 0.890625\n",
      "Batch 105: loss = 0.32022520899772644, acc = 0.8896484375\n",
      "Batch 106: loss = 0.32288455963134766, acc = 0.8896484375\n",
      "Batch 107: loss = 0.33902183175086975, acc = 0.87890625\n",
      "Batch 108: loss = 0.332472026348114, acc = 0.892578125\n",
      "Batch 109: loss = 0.34450653195381165, acc = 0.8857421875\n",
      "Batch 110: loss = 0.32858526706695557, acc = 0.888671875\n",
      "Batch 111: loss = 0.35121122002601624, acc = 0.8798828125\n",
      "Batch 112: loss = 0.3740214407444, acc = 0.8779296875\n",
      "Batch 113: loss = 0.3338279128074646, acc = 0.888671875\n",
      "Batch 114: loss = 0.3326878845691681, acc = 0.884765625\n",
      "Batch 115: loss = 0.3971782326698303, acc = 0.8623046875\n",
      "Batch 116: loss = 0.3966723084449768, acc = 0.8603515625\n",
      "Batch 117: loss = 0.3553777039051056, acc = 0.87890625\n",
      "Batch 118: loss = 0.29817336797714233, acc = 0.90234375\n",
      "Batch 119: loss = 0.32362622022628784, acc = 0.892578125\n",
      "Batch 120: loss = 0.3212224841117859, acc = 0.888671875\n",
      "Batch 121: loss = 0.3493000268936157, acc = 0.8828125\n",
      "Batch 122: loss = 0.3053959310054779, acc = 0.88671875\n",
      "Batch 123: loss = 0.337077796459198, acc = 0.890625\n",
      "Batch 124: loss = 0.34129419922828674, acc = 0.880859375\n",
      "Batch 125: loss = 0.39681077003479004, acc = 0.8662109375\n",
      "Batch 126: loss = 0.38580527901649475, acc = 0.87109375\n",
      "\n",
      "Epoch 64/100\n",
      "Batch 1: loss = 0.4756152033805847, acc = 0.869140625\n",
      "Batch 2: loss = 0.35113808512687683, acc = 0.8798828125\n",
      "Batch 3: loss = 0.3516587018966675, acc = 0.8857421875\n",
      "Batch 4: loss = 0.3315199911594391, acc = 0.8955078125\n",
      "Batch 5: loss = 0.35843175649642944, acc = 0.8779296875\n",
      "Batch 6: loss = 0.3567715585231781, acc = 0.88671875\n",
      "Batch 7: loss = 0.32517147064208984, acc = 0.900390625\n",
      "Batch 8: loss = 0.33147406578063965, acc = 0.88671875\n",
      "Batch 9: loss = 0.31675735116004944, acc = 0.888671875\n",
      "Batch 10: loss = 0.2917473614215851, acc = 0.896484375\n",
      "Batch 11: loss = 0.3133310079574585, acc = 0.888671875\n",
      "Batch 12: loss = 0.33855143189430237, acc = 0.8779296875\n",
      "Batch 13: loss = 0.2929653227329254, acc = 0.900390625\n",
      "Batch 14: loss = 0.34217822551727295, acc = 0.8974609375\n",
      "Batch 15: loss = 0.30474960803985596, acc = 0.8994140625\n",
      "Batch 16: loss = 0.340484082698822, acc = 0.8798828125\n",
      "Batch 17: loss = 0.3396760821342468, acc = 0.884765625\n",
      "Batch 18: loss = 0.3638678193092346, acc = 0.8837890625\n",
      "Batch 19: loss = 0.33570176362991333, acc = 0.8955078125\n",
      "Batch 20: loss = 0.3354039490222931, acc = 0.8818359375\n",
      "Batch 21: loss = 0.4061011075973511, acc = 0.869140625\n",
      "Batch 22: loss = 0.3243030607700348, acc = 0.8916015625\n",
      "Batch 23: loss = 0.3470940589904785, acc = 0.89453125\n",
      "Batch 24: loss = 0.3315269351005554, acc = 0.8916015625\n",
      "Batch 25: loss = 0.3195720314979553, acc = 0.8984375\n",
      "Batch 26: loss = 0.33920085430145264, acc = 0.884765625\n",
      "Batch 27: loss = 0.40656208992004395, acc = 0.8505859375\n",
      "Batch 28: loss = 0.35460197925567627, acc = 0.884765625\n",
      "Batch 29: loss = 0.3510725796222687, acc = 0.8740234375\n",
      "Batch 30: loss = 0.3615368902683258, acc = 0.8857421875\n",
      "Batch 31: loss = 0.33927327394485474, acc = 0.8935546875\n",
      "Batch 32: loss = 0.3982331156730652, acc = 0.8681640625\n",
      "Batch 33: loss = 0.3234524726867676, acc = 0.900390625\n",
      "Batch 34: loss = 0.33031731843948364, acc = 0.8955078125\n",
      "Batch 35: loss = 0.3708830177783966, acc = 0.875\n",
      "Batch 36: loss = 0.31272977590560913, acc = 0.8896484375\n",
      "Batch 37: loss = 0.2931958734989166, acc = 0.8984375\n",
      "Batch 38: loss = 0.32239335775375366, acc = 0.8984375\n",
      "Batch 39: loss = 0.29384946823120117, acc = 0.916015625\n",
      "Batch 40: loss = 0.33890342712402344, acc = 0.8837890625\n",
      "Batch 41: loss = 0.3109332025051117, acc = 0.8818359375\n",
      "Batch 42: loss = 0.340130478143692, acc = 0.8857421875\n",
      "Batch 43: loss = 0.3581109642982483, acc = 0.8720703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 44: loss = 0.3074303865432739, acc = 0.900390625\n",
      "Batch 45: loss = 0.3386259377002716, acc = 0.8798828125\n",
      "Batch 46: loss = 0.2843948006629944, acc = 0.8994140625\n",
      "Batch 47: loss = 0.32836633920669556, acc = 0.8984375\n",
      "Batch 48: loss = 0.3456871211528778, acc = 0.88671875\n",
      "Batch 49: loss = 0.3325522541999817, acc = 0.8759765625\n",
      "Batch 50: loss = 0.3085993826389313, acc = 0.8935546875\n",
      "Batch 51: loss = 0.3291853666305542, acc = 0.8994140625\n",
      "Batch 52: loss = 0.3314038813114166, acc = 0.8876953125\n",
      "Batch 53: loss = 0.35303330421447754, acc = 0.8779296875\n",
      "Batch 54: loss = 0.285494327545166, acc = 0.8974609375\n",
      "Batch 55: loss = 0.3160674571990967, acc = 0.8994140625\n",
      "Batch 56: loss = 0.34065255522727966, acc = 0.8759765625\n",
      "Batch 57: loss = 0.35630151629447937, acc = 0.87890625\n",
      "Batch 58: loss = 0.36881956458091736, acc = 0.873046875\n",
      "Batch 59: loss = 0.26899242401123047, acc = 0.90625\n",
      "Batch 60: loss = 0.35549288988113403, acc = 0.87890625\n",
      "Batch 61: loss = 0.2968224287033081, acc = 0.9150390625\n",
      "Batch 62: loss = 0.4009648561477661, acc = 0.873046875\n",
      "Batch 63: loss = 0.36070460081100464, acc = 0.8779296875\n",
      "Batch 64: loss = 0.3090429902076721, acc = 0.8984375\n",
      "Batch 65: loss = 0.37633273005485535, acc = 0.8701171875\n",
      "Batch 66: loss = 0.3402943015098572, acc = 0.8876953125\n",
      "Batch 67: loss = 0.32682374119758606, acc = 0.8857421875\n",
      "Batch 68: loss = 0.3298954367637634, acc = 0.880859375\n",
      "Batch 69: loss = 0.3034147024154663, acc = 0.8955078125\n",
      "Batch 70: loss = 0.3699583411216736, acc = 0.8818359375\n",
      "Batch 71: loss = 0.3494483232498169, acc = 0.8857421875\n",
      "Batch 72: loss = 0.3235982358455658, acc = 0.8916015625\n",
      "Batch 73: loss = 0.3307352662086487, acc = 0.8818359375\n",
      "Batch 74: loss = 0.34555408358573914, acc = 0.8857421875\n",
      "Batch 75: loss = 0.4200529456138611, acc = 0.85546875\n",
      "Batch 76: loss = 0.3783732056617737, acc = 0.8779296875\n",
      "Batch 77: loss = 0.32621049880981445, acc = 0.890625\n",
      "Batch 78: loss = 0.34520846605300903, acc = 0.8935546875\n",
      "Batch 79: loss = 0.3038502037525177, acc = 0.8994140625\n",
      "Batch 80: loss = 0.31033116579055786, acc = 0.8974609375\n",
      "Batch 81: loss = 0.34995901584625244, acc = 0.8857421875\n",
      "Batch 82: loss = 0.3656437397003174, acc = 0.8740234375\n",
      "Batch 83: loss = 0.348548948764801, acc = 0.87890625\n",
      "Batch 84: loss = 0.3359268605709076, acc = 0.88671875\n",
      "Batch 85: loss = 0.3712640106678009, acc = 0.8681640625\n",
      "Batch 86: loss = 0.33226877450942993, acc = 0.8876953125\n",
      "Batch 87: loss = 0.3750836253166199, acc = 0.8740234375\n",
      "Batch 88: loss = 0.4054732322692871, acc = 0.865234375\n",
      "Batch 89: loss = 0.3520472049713135, acc = 0.8896484375\n",
      "Batch 90: loss = 0.35335320234298706, acc = 0.890625\n",
      "Batch 91: loss = 0.35070616006851196, acc = 0.8779296875\n",
      "Batch 92: loss = 0.3875091075897217, acc = 0.8798828125\n",
      "Batch 93: loss = 0.3294600546360016, acc = 0.880859375\n",
      "Batch 94: loss = 0.3173083961009979, acc = 0.8974609375\n",
      "Batch 95: loss = 0.32324671745300293, acc = 0.8876953125\n",
      "Batch 96: loss = 0.3689241409301758, acc = 0.876953125\n",
      "Batch 97: loss = 0.36113816499710083, acc = 0.8818359375\n",
      "Batch 98: loss = 0.37507104873657227, acc = 0.8759765625\n",
      "Batch 99: loss = 0.3322490453720093, acc = 0.8857421875\n",
      "Batch 100: loss = 0.36748993396759033, acc = 0.8740234375\n",
      "Batch 101: loss = 0.3298459053039551, acc = 0.88671875\n",
      "Batch 102: loss = 0.36446213722229004, acc = 0.876953125\n",
      "Batch 103: loss = 0.3621335029602051, acc = 0.8837890625\n",
      "Batch 104: loss = 0.31554511189460754, acc = 0.8974609375\n",
      "Batch 105: loss = 0.33445924520492554, acc = 0.89453125\n",
      "Batch 106: loss = 0.35375118255615234, acc = 0.884765625\n",
      "Batch 107: loss = 0.3214288055896759, acc = 0.892578125\n",
      "Batch 108: loss = 0.32701751589775085, acc = 0.8935546875\n",
      "Batch 109: loss = 0.34057462215423584, acc = 0.8857421875\n",
      "Batch 110: loss = 0.32571494579315186, acc = 0.896484375\n",
      "Batch 111: loss = 0.31416815519332886, acc = 0.8916015625\n",
      "Batch 112: loss = 0.3744899034500122, acc = 0.8720703125\n",
      "Batch 113: loss = 0.3563805818557739, acc = 0.8828125\n",
      "Batch 114: loss = 0.3385823369026184, acc = 0.8916015625\n",
      "Batch 115: loss = 0.3474537134170532, acc = 0.892578125\n",
      "Batch 116: loss = 0.34774714708328247, acc = 0.8876953125\n",
      "Batch 117: loss = 0.3530920147895813, acc = 0.8671875\n",
      "Batch 118: loss = 0.3415222764015198, acc = 0.8896484375\n",
      "Batch 119: loss = 0.3328399658203125, acc = 0.8974609375\n",
      "Batch 120: loss = 0.3140552341938019, acc = 0.89453125\n",
      "Batch 121: loss = 0.32872167229652405, acc = 0.8916015625\n",
      "Batch 122: loss = 0.31579238176345825, acc = 0.88671875\n",
      "Batch 123: loss = 0.3305818736553192, acc = 0.87890625\n",
      "Batch 124: loss = 0.34011560678482056, acc = 0.8798828125\n",
      "Batch 125: loss = 0.32431232929229736, acc = 0.8935546875\n",
      "Batch 126: loss = 0.34686464071273804, acc = 0.884765625\n",
      "\n",
      "Epoch 65/100\n",
      "Batch 1: loss = 0.4767342209815979, acc = 0.8701171875\n",
      "Batch 2: loss = 0.35294318199157715, acc = 0.8916015625\n",
      "Batch 3: loss = 0.3320784270763397, acc = 0.90234375\n",
      "Batch 4: loss = 0.32633447647094727, acc = 0.9033203125\n",
      "Batch 5: loss = 0.361309677362442, acc = 0.8779296875\n",
      "Batch 6: loss = 0.3514263927936554, acc = 0.888671875\n",
      "Batch 7: loss = 0.3322915732860565, acc = 0.890625\n",
      "Batch 8: loss = 0.33001798391342163, acc = 0.8974609375\n",
      "Batch 9: loss = 0.316558837890625, acc = 0.8935546875\n",
      "Batch 10: loss = 0.28228759765625, acc = 0.90234375\n",
      "Batch 11: loss = 0.31541621685028076, acc = 0.896484375\n",
      "Batch 12: loss = 0.33935028314590454, acc = 0.880859375\n",
      "Batch 13: loss = 0.3343820571899414, acc = 0.896484375\n",
      "Batch 14: loss = 0.31949353218078613, acc = 0.904296875\n",
      "Batch 15: loss = 0.3101232051849365, acc = 0.8984375\n",
      "Batch 16: loss = 0.32900381088256836, acc = 0.892578125\n",
      "Batch 17: loss = 0.29678428173065186, acc = 0.91015625\n",
      "Batch 18: loss = 0.3694150149822235, acc = 0.8759765625\n",
      "Batch 19: loss = 0.34932848811149597, acc = 0.8701171875\n",
      "Batch 20: loss = 0.3250083327293396, acc = 0.8857421875\n",
      "Batch 21: loss = 0.3458417057991028, acc = 0.876953125\n",
      "Batch 22: loss = 0.323767751455307, acc = 0.8818359375\n",
      "Batch 23: loss = 0.34750422835350037, acc = 0.880859375\n",
      "Batch 24: loss = 0.3219929337501526, acc = 0.8896484375\n",
      "Batch 25: loss = 0.33727002143859863, acc = 0.8818359375\n",
      "Batch 26: loss = 0.33454233407974243, acc = 0.880859375\n",
      "Batch 27: loss = 0.3755371570587158, acc = 0.865234375\n",
      "Batch 28: loss = 0.3642902076244354, acc = 0.8828125\n",
      "Batch 29: loss = 0.37921446561813354, acc = 0.880859375\n",
      "Batch 30: loss = 0.31642651557922363, acc = 0.8994140625\n",
      "Batch 31: loss = 0.3748629093170166, acc = 0.8759765625\n",
      "Batch 32: loss = 0.3568422198295593, acc = 0.8779296875\n",
      "Batch 33: loss = 0.3234158158302307, acc = 0.8828125\n",
      "Batch 34: loss = 0.32134634256362915, acc = 0.8876953125\n",
      "Batch 35: loss = 0.3396078646183014, acc = 0.884765625\n",
      "Batch 36: loss = 0.3234233260154724, acc = 0.89453125\n",
      "Batch 37: loss = 0.31382977962493896, acc = 0.88671875\n",
      "Batch 38: loss = 0.3499600887298584, acc = 0.8876953125\n",
      "Batch 39: loss = 0.3103582262992859, acc = 0.8974609375\n",
      "Batch 40: loss = 0.34511837363243103, acc = 0.8916015625\n",
      "Batch 41: loss = 0.2983207106590271, acc = 0.9013671875\n",
      "Batch 42: loss = 0.3272448480129242, acc = 0.88671875\n",
      "Batch 43: loss = 0.3368886709213257, acc = 0.890625\n",
      "Batch 44: loss = 0.32098492980003357, acc = 0.8955078125\n",
      "Batch 45: loss = 0.3119698464870453, acc = 0.896484375\n",
      "Batch 46: loss = 0.29255449771881104, acc = 0.9033203125\n",
      "Batch 47: loss = 0.30983373522758484, acc = 0.900390625\n",
      "Batch 48: loss = 0.3162241280078888, acc = 0.890625\n",
      "Batch 49: loss = 0.3009531497955322, acc = 0.90234375\n",
      "Batch 50: loss = 0.2951849102973938, acc = 0.90234375\n",
      "Batch 51: loss = 0.32565081119537354, acc = 0.8955078125\n",
      "Batch 52: loss = 0.31490087509155273, acc = 0.900390625\n",
      "Batch 53: loss = 0.33615583181381226, acc = 0.8876953125\n",
      "Batch 54: loss = 0.27017897367477417, acc = 0.9140625\n",
      "Batch 55: loss = 0.29128676652908325, acc = 0.908203125\n",
      "Batch 56: loss = 0.3238648772239685, acc = 0.8896484375\n",
      "Batch 57: loss = 0.3480494022369385, acc = 0.87890625\n",
      "Batch 58: loss = 0.3556182384490967, acc = 0.8701171875\n",
      "Batch 59: loss = 0.2646405100822449, acc = 0.9111328125\n",
      "Batch 60: loss = 0.34541448950767517, acc = 0.8876953125\n",
      "Batch 61: loss = 0.3119071125984192, acc = 0.90234375\n",
      "Batch 62: loss = 0.35518646240234375, acc = 0.87890625\n",
      "Batch 63: loss = 0.33834969997406006, acc = 0.884765625\n",
      "Batch 64: loss = 0.2937423288822174, acc = 0.9111328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 65: loss = 0.3207951784133911, acc = 0.896484375\n",
      "Batch 66: loss = 0.32684633135795593, acc = 0.880859375\n",
      "Batch 67: loss = 0.3478890061378479, acc = 0.88671875\n",
      "Batch 68: loss = 0.33205288648605347, acc = 0.8955078125\n",
      "Batch 69: loss = 0.3272522985935211, acc = 0.8935546875\n",
      "Batch 70: loss = 0.34670278429985046, acc = 0.8896484375\n",
      "Batch 71: loss = 0.3246951401233673, acc = 0.890625\n",
      "Batch 72: loss = 0.3137718141078949, acc = 0.8994140625\n",
      "Batch 73: loss = 0.35120636224746704, acc = 0.8759765625\n",
      "Batch 74: loss = 0.3479865491390228, acc = 0.880859375\n",
      "Batch 75: loss = 0.3887402415275574, acc = 0.8681640625\n",
      "Batch 76: loss = 0.35166019201278687, acc = 0.8720703125\n",
      "Batch 77: loss = 0.3302364945411682, acc = 0.8857421875\n",
      "Batch 78: loss = 0.33374130725860596, acc = 0.890625\n",
      "Batch 79: loss = 0.29241228103637695, acc = 0.90234375\n",
      "Batch 80: loss = 0.31709209084510803, acc = 0.888671875\n",
      "Batch 81: loss = 0.31397759914398193, acc = 0.90234375\n",
      "Batch 82: loss = 0.31170058250427246, acc = 0.9013671875\n",
      "Batch 83: loss = 0.3401036262512207, acc = 0.88671875\n",
      "Batch 84: loss = 0.3301132619380951, acc = 0.88671875\n",
      "Batch 85: loss = 0.37117353081703186, acc = 0.8740234375\n",
      "Batch 86: loss = 0.3644089698791504, acc = 0.873046875\n",
      "Batch 87: loss = 0.3147246837615967, acc = 0.8994140625\n",
      "Batch 88: loss = 0.3853732943534851, acc = 0.8671875\n",
      "Batch 89: loss = 0.3373602032661438, acc = 0.8955078125\n",
      "Batch 90: loss = 0.3558611273765564, acc = 0.8759765625\n",
      "Batch 91: loss = 0.3812987804412842, acc = 0.880859375\n",
      "Batch 92: loss = 0.3673523962497711, acc = 0.8828125\n",
      "Batch 93: loss = 0.3143243193626404, acc = 0.8935546875\n",
      "Batch 94: loss = 0.31707531213760376, acc = 0.8955078125\n",
      "Batch 95: loss = 0.2554686665534973, acc = 0.91796875\n",
      "Batch 96: loss = 0.3844781219959259, acc = 0.8642578125\n",
      "Batch 97: loss = 0.33654409646987915, acc = 0.8798828125\n",
      "Batch 98: loss = 0.3200429081916809, acc = 0.8876953125\n",
      "Batch 99: loss = 0.33148667216300964, acc = 0.8798828125\n",
      "Batch 100: loss = 0.3383371829986572, acc = 0.884765625\n",
      "Batch 101: loss = 0.32944563031196594, acc = 0.8876953125\n",
      "Batch 102: loss = 0.37493571639060974, acc = 0.87109375\n",
      "Batch 103: loss = 0.3369293212890625, acc = 0.888671875\n",
      "Batch 104: loss = 0.30908745527267456, acc = 0.8994140625\n",
      "Batch 105: loss = 0.28876757621765137, acc = 0.9072265625\n",
      "Batch 106: loss = 0.32204559445381165, acc = 0.888671875\n",
      "Batch 107: loss = 0.3188878893852234, acc = 0.8935546875\n",
      "Batch 108: loss = 0.3117460608482361, acc = 0.896484375\n",
      "Batch 109: loss = 0.3017522990703583, acc = 0.8974609375\n",
      "Batch 110: loss = 0.3217453360557556, acc = 0.884765625\n",
      "Batch 111: loss = 0.34846824407577515, acc = 0.892578125\n",
      "Batch 112: loss = 0.30737006664276123, acc = 0.892578125\n",
      "Batch 113: loss = 0.3367522358894348, acc = 0.884765625\n",
      "Batch 114: loss = 0.34100258350372314, acc = 0.9013671875\n",
      "Batch 115: loss = 0.3729449510574341, acc = 0.873046875\n",
      "Batch 116: loss = 0.38820651173591614, acc = 0.876953125\n",
      "Batch 117: loss = 0.3441673517227173, acc = 0.890625\n",
      "Batch 118: loss = 0.27299293875694275, acc = 0.912109375\n",
      "Batch 119: loss = 0.3250616788864136, acc = 0.8935546875\n",
      "Batch 120: loss = 0.3070717751979828, acc = 0.900390625\n",
      "Batch 121: loss = 0.3381594121456146, acc = 0.8828125\n",
      "Batch 122: loss = 0.32119154930114746, acc = 0.888671875\n",
      "Batch 123: loss = 0.3171462118625641, acc = 0.8837890625\n",
      "Batch 124: loss = 0.33467453718185425, acc = 0.888671875\n",
      "Batch 125: loss = 0.34854984283447266, acc = 0.89453125\n",
      "Batch 126: loss = 0.35221004486083984, acc = 0.8837890625\n",
      "\n",
      "Epoch 66/100\n",
      "Batch 1: loss = 0.44591420888900757, acc = 0.865234375\n",
      "Batch 2: loss = 0.34522053599357605, acc = 0.892578125\n",
      "Batch 3: loss = 0.3685276508331299, acc = 0.8779296875\n",
      "Batch 4: loss = 0.29266834259033203, acc = 0.9033203125\n",
      "Batch 5: loss = 0.33540117740631104, acc = 0.88671875\n",
      "Batch 6: loss = 0.36280328035354614, acc = 0.8857421875\n",
      "Batch 7: loss = 0.33777621388435364, acc = 0.8994140625\n",
      "Batch 8: loss = 0.3273411691188812, acc = 0.8857421875\n",
      "Batch 9: loss = 0.3120262026786804, acc = 0.9052734375\n",
      "Batch 10: loss = 0.27286040782928467, acc = 0.916015625\n",
      "Batch 11: loss = 0.33314013481140137, acc = 0.8984375\n",
      "Batch 12: loss = 0.3301326036453247, acc = 0.8896484375\n",
      "Batch 13: loss = 0.3242999017238617, acc = 0.890625\n",
      "Batch 14: loss = 0.32168319821357727, acc = 0.8935546875\n",
      "Batch 15: loss = 0.2882452607154846, acc = 0.91796875\n",
      "Batch 16: loss = 0.32756489515304565, acc = 0.8857421875\n",
      "Batch 17: loss = 0.3478635847568512, acc = 0.8837890625\n",
      "Batch 18: loss = 0.34400495886802673, acc = 0.888671875\n",
      "Batch 19: loss = 0.3393317461013794, acc = 0.896484375\n",
      "Batch 20: loss = 0.31501305103302, acc = 0.880859375\n",
      "Batch 21: loss = 0.35990777611732483, acc = 0.8837890625\n",
      "Batch 22: loss = 0.30898261070251465, acc = 0.89453125\n",
      "Batch 23: loss = 0.3542290925979614, acc = 0.875\n",
      "Batch 24: loss = 0.31348997354507446, acc = 0.892578125\n",
      "Batch 25: loss = 0.323577880859375, acc = 0.88671875\n",
      "Batch 26: loss = 0.30166101455688477, acc = 0.908203125\n",
      "Batch 27: loss = 0.3579603433609009, acc = 0.8671875\n",
      "Batch 28: loss = 0.38005709648132324, acc = 0.875\n",
      "Batch 29: loss = 0.3489170968532562, acc = 0.8896484375\n",
      "Batch 30: loss = 0.3437343239784241, acc = 0.890625\n",
      "Batch 31: loss = 0.347852885723114, acc = 0.8818359375\n",
      "Batch 32: loss = 0.3889240026473999, acc = 0.8701171875\n",
      "Batch 33: loss = 0.3228583037853241, acc = 0.90234375\n",
      "Batch 34: loss = 0.3149036765098572, acc = 0.8935546875\n",
      "Batch 35: loss = 0.36066555976867676, acc = 0.8779296875\n",
      "Batch 36: loss = 0.2792878746986389, acc = 0.904296875\n",
      "Batch 37: loss = 0.2694621980190277, acc = 0.916015625\n",
      "Batch 38: loss = 0.33794111013412476, acc = 0.8916015625\n",
      "Batch 39: loss = 0.3435659408569336, acc = 0.892578125\n",
      "Batch 40: loss = 0.3472025990486145, acc = 0.890625\n",
      "Batch 41: loss = 0.2782065272331238, acc = 0.9013671875\n",
      "Batch 42: loss = 0.32712146639823914, acc = 0.8876953125\n",
      "Batch 43: loss = 0.3527964949607849, acc = 0.8818359375\n",
      "Batch 44: loss = 0.308624804019928, acc = 0.900390625\n",
      "Batch 45: loss = 0.306462824344635, acc = 0.89453125\n",
      "Batch 46: loss = 0.2943990230560303, acc = 0.9033203125\n",
      "Batch 47: loss = 0.3086990416049957, acc = 0.9072265625\n",
      "Batch 48: loss = 0.3122939467430115, acc = 0.8984375\n",
      "Batch 49: loss = 0.29762643575668335, acc = 0.8974609375\n",
      "Batch 50: loss = 0.31940507888793945, acc = 0.9033203125\n",
      "Batch 51: loss = 0.3001331388950348, acc = 0.900390625\n",
      "Batch 52: loss = 0.35027557611465454, acc = 0.8828125\n",
      "Batch 53: loss = 0.34447842836380005, acc = 0.8876953125\n",
      "Batch 54: loss = 0.28698816895484924, acc = 0.9033203125\n",
      "Batch 55: loss = 0.3087114691734314, acc = 0.9013671875\n",
      "Batch 56: loss = 0.338779091835022, acc = 0.8798828125\n",
      "Batch 57: loss = 0.32420530915260315, acc = 0.896484375\n",
      "Batch 58: loss = 0.38677942752838135, acc = 0.8671875\n",
      "Batch 59: loss = 0.2694934010505676, acc = 0.91796875\n",
      "Batch 60: loss = 0.32861149311065674, acc = 0.89453125\n",
      "Batch 61: loss = 0.30750882625579834, acc = 0.8994140625\n",
      "Batch 62: loss = 0.35520118474960327, acc = 0.880859375\n",
      "Batch 63: loss = 0.3683387041091919, acc = 0.888671875\n",
      "Batch 64: loss = 0.32681214809417725, acc = 0.8857421875\n",
      "Batch 65: loss = 0.31402772665023804, acc = 0.8935546875\n",
      "Batch 66: loss = 0.32713252305984497, acc = 0.8896484375\n",
      "Batch 67: loss = 0.3022468090057373, acc = 0.8974609375\n",
      "Batch 68: loss = 0.35324037075042725, acc = 0.8798828125\n",
      "Batch 69: loss = 0.3273468613624573, acc = 0.8974609375\n",
      "Batch 70: loss = 0.3627355694770813, acc = 0.8720703125\n",
      "Batch 71: loss = 0.3419773280620575, acc = 0.876953125\n",
      "Batch 72: loss = 0.3374350666999817, acc = 0.89453125\n",
      "Batch 73: loss = 0.3502456843852997, acc = 0.8857421875\n",
      "Batch 74: loss = 0.3655201494693756, acc = 0.87109375\n",
      "Batch 75: loss = 0.3926037549972534, acc = 0.853515625\n",
      "Batch 76: loss = 0.35296687483787537, acc = 0.8779296875\n",
      "Batch 77: loss = 0.35422635078430176, acc = 0.8671875\n",
      "Batch 78: loss = 0.3651469945907593, acc = 0.8779296875\n",
      "Batch 79: loss = 0.32054001092910767, acc = 0.8916015625\n",
      "Batch 80: loss = 0.3165832757949829, acc = 0.8798828125\n",
      "Batch 81: loss = 0.35662105679512024, acc = 0.8828125\n",
      "Batch 82: loss = 0.30630046129226685, acc = 0.904296875\n",
      "Batch 83: loss = 0.31435346603393555, acc = 0.892578125\n",
      "Batch 84: loss = 0.3504583239555359, acc = 0.8798828125\n",
      "Batch 85: loss = 0.3753972351551056, acc = 0.876953125\n",
      "Batch 86: loss = 0.3501579761505127, acc = 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 87: loss = 0.3220282196998596, acc = 0.892578125\n",
      "Batch 88: loss = 0.37587299942970276, acc = 0.8779296875\n",
      "Batch 89: loss = 0.29473912715911865, acc = 0.90625\n",
      "Batch 90: loss = 0.33187901973724365, acc = 0.8818359375\n",
      "Batch 91: loss = 0.36174386739730835, acc = 0.875\n",
      "Batch 92: loss = 0.3690539598464966, acc = 0.869140625\n",
      "Batch 93: loss = 0.29287266731262207, acc = 0.9052734375\n",
      "Batch 94: loss = 0.30638620257377625, acc = 0.890625\n",
      "Batch 95: loss = 0.324734091758728, acc = 0.9013671875\n",
      "Batch 96: loss = 0.33184152841567993, acc = 0.8857421875\n",
      "Batch 97: loss = 0.339009165763855, acc = 0.88671875\n",
      "Batch 98: loss = 0.3304339647293091, acc = 0.8876953125\n",
      "Batch 99: loss = 0.32301992177963257, acc = 0.892578125\n",
      "Batch 100: loss = 0.34445419907569885, acc = 0.87890625\n",
      "Batch 101: loss = 0.3277949392795563, acc = 0.8837890625\n",
      "Batch 102: loss = 0.3156821131706238, acc = 0.896484375\n",
      "Batch 103: loss = 0.33129221200942993, acc = 0.890625\n",
      "Batch 104: loss = 0.30971235036849976, acc = 0.8984375\n",
      "Batch 105: loss = 0.29613208770751953, acc = 0.908203125\n",
      "Batch 106: loss = 0.30582255125045776, acc = 0.884765625\n",
      "Batch 107: loss = 0.3645542860031128, acc = 0.8701171875\n",
      "Batch 108: loss = 0.3202994763851166, acc = 0.89453125\n",
      "Batch 109: loss = 0.2827768325805664, acc = 0.9140625\n",
      "Batch 110: loss = 0.2838720679283142, acc = 0.9091796875\n",
      "Batch 111: loss = 0.33169007301330566, acc = 0.888671875\n",
      "Batch 112: loss = 0.29438817501068115, acc = 0.90234375\n",
      "Batch 113: loss = 0.32716795802116394, acc = 0.892578125\n",
      "Batch 114: loss = 0.3370063900947571, acc = 0.8876953125\n",
      "Batch 115: loss = 0.3040144741535187, acc = 0.904296875\n",
      "Batch 116: loss = 0.33277109265327454, acc = 0.890625\n",
      "Batch 117: loss = 0.316047340631485, acc = 0.8876953125\n",
      "Batch 118: loss = 0.2831924557685852, acc = 0.900390625\n",
      "Batch 119: loss = 0.31205230951309204, acc = 0.908203125\n",
      "Batch 120: loss = 0.28940480947494507, acc = 0.90234375\n",
      "Batch 121: loss = 0.33390122652053833, acc = 0.884765625\n",
      "Batch 122: loss = 0.296261727809906, acc = 0.9013671875\n",
      "Batch 123: loss = 0.3209380507469177, acc = 0.900390625\n",
      "Batch 124: loss = 0.3720818758010864, acc = 0.875\n",
      "Batch 125: loss = 0.3669278025627136, acc = 0.8798828125\n",
      "Batch 126: loss = 0.3355199992656708, acc = 0.896484375\n",
      "\n",
      "Epoch 67/100\n",
      "Batch 1: loss = 0.47744911909103394, acc = 0.8564453125\n",
      "Batch 2: loss = 0.34636610746383667, acc = 0.8935546875\n",
      "Batch 3: loss = 0.3525454103946686, acc = 0.8935546875\n",
      "Batch 4: loss = 0.3412727117538452, acc = 0.8955078125\n",
      "Batch 5: loss = 0.357708215713501, acc = 0.888671875\n",
      "Batch 6: loss = 0.3164011240005493, acc = 0.904296875\n",
      "Batch 7: loss = 0.3302488327026367, acc = 0.8876953125\n",
      "Batch 8: loss = 0.3406703770160675, acc = 0.892578125\n",
      "Batch 9: loss = 0.34372419118881226, acc = 0.8984375\n",
      "Batch 10: loss = 0.27534979581832886, acc = 0.908203125\n",
      "Batch 11: loss = 0.32313525676727295, acc = 0.8955078125\n",
      "Batch 12: loss = 0.3106350302696228, acc = 0.8994140625\n",
      "Batch 13: loss = 0.3077234923839569, acc = 0.8955078125\n",
      "Batch 14: loss = 0.3444195091724396, acc = 0.8876953125\n",
      "Batch 15: loss = 0.31509825587272644, acc = 0.8896484375\n",
      "Batch 16: loss = 0.2987361550331116, acc = 0.90234375\n",
      "Batch 17: loss = 0.33181917667388916, acc = 0.888671875\n",
      "Batch 18: loss = 0.33391186594963074, acc = 0.8857421875\n",
      "Batch 19: loss = 0.3528154194355011, acc = 0.8837890625\n",
      "Batch 20: loss = 0.30032896995544434, acc = 0.89453125\n",
      "Batch 21: loss = 0.36163529753685, acc = 0.876953125\n",
      "Batch 22: loss = 0.3501976728439331, acc = 0.880859375\n",
      "Batch 23: loss = 0.3576870560646057, acc = 0.87890625\n",
      "Batch 24: loss = 0.3192424774169922, acc = 0.890625\n",
      "Batch 25: loss = 0.32637447118759155, acc = 0.8935546875\n",
      "Batch 26: loss = 0.3055275082588196, acc = 0.8955078125\n",
      "Batch 27: loss = 0.3482324481010437, acc = 0.8857421875\n",
      "Batch 28: loss = 0.3669309616088867, acc = 0.8681640625\n",
      "Batch 29: loss = 0.37639230489730835, acc = 0.873046875\n",
      "Batch 30: loss = 0.3335629999637604, acc = 0.8876953125\n",
      "Batch 31: loss = 0.335294246673584, acc = 0.8916015625\n",
      "Batch 32: loss = 0.3635180592536926, acc = 0.8828125\n",
      "Batch 33: loss = 0.3170921206474304, acc = 0.9033203125\n",
      "Batch 34: loss = 0.3679102659225464, acc = 0.880859375\n",
      "Batch 35: loss = 0.3441612124443054, acc = 0.884765625\n",
      "Batch 36: loss = 0.30994540452957153, acc = 0.900390625\n",
      "Batch 37: loss = 0.28780898451805115, acc = 0.9052734375\n",
      "Batch 38: loss = 0.3235127627849579, acc = 0.8984375\n",
      "Batch 39: loss = 0.30328094959259033, acc = 0.8984375\n",
      "Batch 40: loss = 0.34806621074676514, acc = 0.88671875\n",
      "Batch 41: loss = 0.29875028133392334, acc = 0.90234375\n",
      "Batch 42: loss = 0.3495749235153198, acc = 0.890625\n",
      "Batch 43: loss = 0.3414580225944519, acc = 0.8876953125\n",
      "Batch 44: loss = 0.3438761234283447, acc = 0.8857421875\n",
      "Batch 45: loss = 0.3038786053657532, acc = 0.896484375\n",
      "Batch 46: loss = 0.27384668588638306, acc = 0.9140625\n",
      "Batch 47: loss = 0.3013981580734253, acc = 0.892578125\n",
      "Batch 48: loss = 0.3327375650405884, acc = 0.8798828125\n",
      "Batch 49: loss = 0.27118024230003357, acc = 0.9140625\n",
      "Batch 50: loss = 0.28550487756729126, acc = 0.908203125\n",
      "Batch 51: loss = 0.30437371134757996, acc = 0.89453125\n",
      "Batch 52: loss = 0.30596494674682617, acc = 0.892578125\n",
      "Batch 53: loss = 0.3252750635147095, acc = 0.8857421875\n",
      "Batch 54: loss = 0.2754920423030853, acc = 0.9169921875\n",
      "Batch 55: loss = 0.283137708902359, acc = 0.9150390625\n",
      "Batch 56: loss = 0.3154687285423279, acc = 0.890625\n",
      "Batch 57: loss = 0.34568166732788086, acc = 0.8818359375\n",
      "Batch 58: loss = 0.3471669852733612, acc = 0.8857421875\n",
      "Batch 59: loss = 0.2804664373397827, acc = 0.916015625\n",
      "Batch 60: loss = 0.3226558566093445, acc = 0.8896484375\n",
      "Batch 61: loss = 0.2896149754524231, acc = 0.908203125\n",
      "Batch 62: loss = 0.36489540338516235, acc = 0.8779296875\n",
      "Batch 63: loss = 0.331258624792099, acc = 0.8935546875\n",
      "Batch 64: loss = 0.30151814222335815, acc = 0.8974609375\n",
      "Batch 65: loss = 0.3563178777694702, acc = 0.8818359375\n",
      "Batch 66: loss = 0.32792460918426514, acc = 0.8896484375\n",
      "Batch 67: loss = 0.31087690591812134, acc = 0.8876953125\n",
      "Batch 68: loss = 0.34627243876457214, acc = 0.8955078125\n",
      "Batch 69: loss = 0.27830034494400024, acc = 0.9130859375\n",
      "Batch 70: loss = 0.34778597950935364, acc = 0.87890625\n",
      "Batch 71: loss = 0.3046240210533142, acc = 0.892578125\n",
      "Batch 72: loss = 0.30992960929870605, acc = 0.8935546875\n",
      "Batch 73: loss = 0.3296276330947876, acc = 0.890625\n",
      "Batch 74: loss = 0.3572738766670227, acc = 0.888671875\n",
      "Batch 75: loss = 0.3916764259338379, acc = 0.8642578125\n",
      "Batch 76: loss = 0.3380051851272583, acc = 0.8798828125\n",
      "Batch 77: loss = 0.33206409215927124, acc = 0.890625\n",
      "Batch 78: loss = 0.3286638557910919, acc = 0.8955078125\n",
      "Batch 79: loss = 0.2998706102371216, acc = 0.8984375\n",
      "Batch 80: loss = 0.2858438789844513, acc = 0.896484375\n",
      "Batch 81: loss = 0.3216772675514221, acc = 0.8896484375\n",
      "Batch 82: loss = 0.34324395656585693, acc = 0.8896484375\n",
      "Batch 83: loss = 0.31700438261032104, acc = 0.892578125\n",
      "Batch 84: loss = 0.32096028327941895, acc = 0.890625\n",
      "Batch 85: loss = 0.353695809841156, acc = 0.8779296875\n",
      "Batch 86: loss = 0.30945390462875366, acc = 0.89453125\n",
      "Batch 87: loss = 0.32581382989883423, acc = 0.8818359375\n",
      "Batch 88: loss = 0.3891642391681671, acc = 0.87109375\n",
      "Batch 89: loss = 0.2838631868362427, acc = 0.908203125\n",
      "Batch 90: loss = 0.311440110206604, acc = 0.89453125\n",
      "Batch 91: loss = 0.3137925863265991, acc = 0.89453125\n",
      "Batch 92: loss = 0.34355711936950684, acc = 0.88671875\n",
      "Batch 93: loss = 0.29181429743766785, acc = 0.90234375\n",
      "Batch 94: loss = 0.3328581750392914, acc = 0.8828125\n",
      "Batch 95: loss = 0.26748234033584595, acc = 0.912109375\n",
      "Batch 96: loss = 0.32872456312179565, acc = 0.8818359375\n",
      "Batch 97: loss = 0.34109193086624146, acc = 0.884765625\n",
      "Batch 98: loss = 0.3529530167579651, acc = 0.88671875\n",
      "Batch 99: loss = 0.2986416816711426, acc = 0.90234375\n",
      "Batch 100: loss = 0.31838342547416687, acc = 0.89453125\n",
      "Batch 101: loss = 0.31116223335266113, acc = 0.896484375\n",
      "Batch 102: loss = 0.3359966576099396, acc = 0.8837890625\n",
      "Batch 103: loss = 0.3027854263782501, acc = 0.9013671875\n",
      "Batch 104: loss = 0.33703720569610596, acc = 0.888671875\n",
      "Batch 105: loss = 0.2949755787849426, acc = 0.9013671875\n",
      "Batch 106: loss = 0.3371003270149231, acc = 0.8876953125\n",
      "Batch 107: loss = 0.32853972911834717, acc = 0.8984375\n",
      "Batch 108: loss = 0.3151126801967621, acc = 0.8984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 109: loss = 0.30690890550613403, acc = 0.8916015625\n",
      "Batch 110: loss = 0.33759185671806335, acc = 0.8916015625\n",
      "Batch 111: loss = 0.34974852204322815, acc = 0.87890625\n",
      "Batch 112: loss = 0.30305445194244385, acc = 0.9150390625\n",
      "Batch 113: loss = 0.3040430247783661, acc = 0.8955078125\n",
      "Batch 114: loss = 0.33661434054374695, acc = 0.892578125\n",
      "Batch 115: loss = 0.34440261125564575, acc = 0.8828125\n",
      "Batch 116: loss = 0.3371089696884155, acc = 0.8984375\n",
      "Batch 117: loss = 0.32962748408317566, acc = 0.896484375\n",
      "Batch 118: loss = 0.2696300446987152, acc = 0.9130859375\n",
      "Batch 119: loss = 0.28910738229751587, acc = 0.9150390625\n",
      "Batch 120: loss = 0.3099156320095062, acc = 0.896484375\n",
      "Batch 121: loss = 0.336660772562027, acc = 0.8818359375\n",
      "Batch 122: loss = 0.31421342492103577, acc = 0.888671875\n",
      "Batch 123: loss = 0.2907525599002838, acc = 0.9052734375\n",
      "Batch 124: loss = 0.33671945333480835, acc = 0.87890625\n",
      "Batch 125: loss = 0.3510870337486267, acc = 0.8857421875\n",
      "Batch 126: loss = 0.37958580255508423, acc = 0.8798828125\n",
      "\n",
      "Epoch 68/100\n",
      "Batch 1: loss = 0.46924084424972534, acc = 0.865234375\n",
      "Batch 2: loss = 0.3485175371170044, acc = 0.8818359375\n",
      "Batch 3: loss = 0.32757341861724854, acc = 0.896484375\n",
      "Batch 4: loss = 0.3551245331764221, acc = 0.8994140625\n",
      "Batch 5: loss = 0.32564812898635864, acc = 0.8916015625\n",
      "Batch 6: loss = 0.33769524097442627, acc = 0.8857421875\n",
      "Batch 7: loss = 0.37100929021835327, acc = 0.8857421875\n",
      "Batch 8: loss = 0.31860166788101196, acc = 0.8935546875\n",
      "Batch 9: loss = 0.3227062225341797, acc = 0.892578125\n",
      "Batch 10: loss = 0.2863263189792633, acc = 0.91796875\n",
      "Batch 11: loss = 0.3276514410972595, acc = 0.8896484375\n",
      "Batch 12: loss = 0.3197624087333679, acc = 0.8916015625\n",
      "Batch 13: loss = 0.29976463317871094, acc = 0.904296875\n",
      "Batch 14: loss = 0.3208296298980713, acc = 0.9052734375\n",
      "Batch 15: loss = 0.2725496292114258, acc = 0.9072265625\n",
      "Batch 16: loss = 0.30499041080474854, acc = 0.900390625\n",
      "Batch 17: loss = 0.2963719964027405, acc = 0.9033203125\n",
      "Batch 18: loss = 0.29760992527008057, acc = 0.904296875\n",
      "Batch 19: loss = 0.3081061840057373, acc = 0.900390625\n",
      "Batch 20: loss = 0.3104040026664734, acc = 0.888671875\n",
      "Batch 21: loss = 0.33636265993118286, acc = 0.8876953125\n",
      "Batch 22: loss = 0.3632468581199646, acc = 0.8818359375\n",
      "Batch 23: loss = 0.3540811538696289, acc = 0.8857421875\n",
      "Batch 24: loss = 0.29314929246902466, acc = 0.892578125\n",
      "Batch 25: loss = 0.31142324209213257, acc = 0.89453125\n",
      "Batch 26: loss = 0.3056759238243103, acc = 0.896484375\n",
      "Batch 27: loss = 0.3732788562774658, acc = 0.8759765625\n",
      "Batch 28: loss = 0.3587976098060608, acc = 0.8759765625\n",
      "Batch 29: loss = 0.35785847902297974, acc = 0.8896484375\n",
      "Batch 30: loss = 0.36121729016304016, acc = 0.8876953125\n",
      "Batch 31: loss = 0.34128081798553467, acc = 0.8857421875\n",
      "Batch 32: loss = 0.35591787099838257, acc = 0.884765625\n",
      "Batch 33: loss = 0.30042535066604614, acc = 0.896484375\n",
      "Batch 34: loss = 0.35298746824264526, acc = 0.87890625\n",
      "Batch 35: loss = 0.318603515625, acc = 0.890625\n",
      "Batch 36: loss = 0.27594485878944397, acc = 0.90625\n",
      "Batch 37: loss = 0.2788289487361908, acc = 0.9091796875\n",
      "Batch 38: loss = 0.31035158038139343, acc = 0.89453125\n",
      "Batch 39: loss = 0.3027801811695099, acc = 0.9052734375\n",
      "Batch 40: loss = 0.3099762797355652, acc = 0.888671875\n",
      "Batch 41: loss = 0.2712792754173279, acc = 0.90234375\n",
      "Batch 42: loss = 0.31901416182518005, acc = 0.8916015625\n",
      "Batch 43: loss = 0.31667381525039673, acc = 0.884765625\n",
      "Batch 44: loss = 0.31740304827690125, acc = 0.90625\n",
      "Batch 45: loss = 0.2792743742465973, acc = 0.9072265625\n",
      "Batch 46: loss = 0.3014315962791443, acc = 0.8984375\n",
      "Batch 47: loss = 0.31275486946105957, acc = 0.896484375\n",
      "Batch 48: loss = 0.2960093021392822, acc = 0.8984375\n",
      "Batch 49: loss = 0.2937350869178772, acc = 0.9033203125\n",
      "Batch 50: loss = 0.2902371883392334, acc = 0.912109375\n",
      "Batch 51: loss = 0.3131570816040039, acc = 0.8955078125\n",
      "Batch 52: loss = 0.30066990852355957, acc = 0.89453125\n",
      "Batch 53: loss = 0.3306306004524231, acc = 0.890625\n",
      "Batch 54: loss = 0.2717702388763428, acc = 0.904296875\n",
      "Batch 55: loss = 0.29750603437423706, acc = 0.9013671875\n",
      "Batch 56: loss = 0.30856871604919434, acc = 0.90625\n",
      "Batch 57: loss = 0.3337007164955139, acc = 0.8837890625\n",
      "Batch 58: loss = 0.3337534964084625, acc = 0.8837890625\n",
      "Batch 59: loss = 0.2816038131713867, acc = 0.9169921875\n",
      "Batch 60: loss = 0.30128028988838196, acc = 0.90625\n",
      "Batch 61: loss = 0.28632012009620667, acc = 0.912109375\n",
      "Batch 62: loss = 0.35683274269104004, acc = 0.880859375\n",
      "Batch 63: loss = 0.31799939274787903, acc = 0.892578125\n",
      "Batch 64: loss = 0.29496508836746216, acc = 0.8994140625\n",
      "Batch 65: loss = 0.31726303696632385, acc = 0.8984375\n",
      "Batch 66: loss = 0.30183789134025574, acc = 0.90234375\n",
      "Batch 67: loss = 0.3368380069732666, acc = 0.88671875\n",
      "Batch 68: loss = 0.3581872582435608, acc = 0.8759765625\n",
      "Batch 69: loss = 0.29504233598709106, acc = 0.900390625\n",
      "Batch 70: loss = 0.34842008352279663, acc = 0.876953125\n",
      "Batch 71: loss = 0.3059486746788025, acc = 0.8984375\n",
      "Batch 72: loss = 0.31990841031074524, acc = 0.8955078125\n",
      "Batch 73: loss = 0.35168465971946716, acc = 0.8759765625\n",
      "Batch 74: loss = 0.3383573591709137, acc = 0.8876953125\n",
      "Batch 75: loss = 0.37847456336021423, acc = 0.86328125\n",
      "Batch 76: loss = 0.33948588371276855, acc = 0.888671875\n",
      "Batch 77: loss = 0.31926482915878296, acc = 0.88671875\n",
      "Batch 78: loss = 0.34419816732406616, acc = 0.8916015625\n",
      "Batch 79: loss = 0.3258865177631378, acc = 0.880859375\n",
      "Batch 80: loss = 0.28888261318206787, acc = 0.90234375\n",
      "Batch 81: loss = 0.2958410978317261, acc = 0.8916015625\n",
      "Batch 82: loss = 0.314923495054245, acc = 0.8994140625\n",
      "Batch 83: loss = 0.3210110068321228, acc = 0.88671875\n",
      "Batch 84: loss = 0.3367551565170288, acc = 0.8798828125\n",
      "Batch 85: loss = 0.3654961884021759, acc = 0.8671875\n",
      "Batch 86: loss = 0.3217969536781311, acc = 0.8916015625\n",
      "Batch 87: loss = 0.30585533380508423, acc = 0.896484375\n",
      "Batch 88: loss = 0.37610936164855957, acc = 0.8740234375\n",
      "Batch 89: loss = 0.32602569460868835, acc = 0.8955078125\n",
      "Batch 90: loss = 0.2861366271972656, acc = 0.9033203125\n",
      "Batch 91: loss = 0.3632941246032715, acc = 0.88671875\n",
      "Batch 92: loss = 0.3473623991012573, acc = 0.8955078125\n",
      "Batch 93: loss = 0.30190181732177734, acc = 0.90234375\n",
      "Batch 94: loss = 0.30582261085510254, acc = 0.8994140625\n",
      "Batch 95: loss = 0.27367448806762695, acc = 0.90234375\n",
      "Batch 96: loss = 0.3330662250518799, acc = 0.890625\n",
      "Batch 97: loss = 0.2928791642189026, acc = 0.9072265625\n",
      "Batch 98: loss = 0.3251759707927704, acc = 0.8984375\n",
      "Batch 99: loss = 0.35045117139816284, acc = 0.87890625\n",
      "Batch 100: loss = 0.3490089178085327, acc = 0.8798828125\n",
      "Batch 101: loss = 0.31447023153305054, acc = 0.88671875\n",
      "Batch 102: loss = 0.3276820182800293, acc = 0.8896484375\n",
      "Batch 103: loss = 0.3635936975479126, acc = 0.8857421875\n",
      "Batch 104: loss = 0.30595749616622925, acc = 0.8935546875\n",
      "Batch 105: loss = 0.29887646436691284, acc = 0.8916015625\n",
      "Batch 106: loss = 0.33078697323799133, acc = 0.8916015625\n",
      "Batch 107: loss = 0.3029748797416687, acc = 0.904296875\n",
      "Batch 108: loss = 0.29795342683792114, acc = 0.91015625\n",
      "Batch 109: loss = 0.3142213225364685, acc = 0.8974609375\n",
      "Batch 110: loss = 0.31665515899658203, acc = 0.90234375\n",
      "Batch 111: loss = 0.32545727491378784, acc = 0.8935546875\n",
      "Batch 112: loss = 0.2981913089752197, acc = 0.900390625\n",
      "Batch 113: loss = 0.30974316596984863, acc = 0.900390625\n",
      "Batch 114: loss = 0.3287637233734131, acc = 0.8828125\n",
      "Batch 115: loss = 0.32665473222732544, acc = 0.892578125\n",
      "Batch 116: loss = 0.35441723465919495, acc = 0.875\n",
      "Batch 117: loss = 0.32788828015327454, acc = 0.904296875\n",
      "Batch 118: loss = 0.2989407181739807, acc = 0.8994140625\n",
      "Batch 119: loss = 0.27831342816352844, acc = 0.9072265625\n",
      "Batch 120: loss = 0.29614782333374023, acc = 0.8994140625\n",
      "Batch 121: loss = 0.3016413152217865, acc = 0.90234375\n",
      "Batch 122: loss = 0.31510108709335327, acc = 0.8916015625\n",
      "Batch 123: loss = 0.33629387617111206, acc = 0.8896484375\n",
      "Batch 124: loss = 0.3334936201572418, acc = 0.8876953125\n",
      "Batch 125: loss = 0.32503724098205566, acc = 0.900390625\n",
      "Batch 126: loss = 0.34870365262031555, acc = 0.8837890625\n",
      "\n",
      "Epoch 69/100\n",
      "Batch 1: loss = 0.46526971459388733, acc = 0.859375\n",
      "Batch 2: loss = 0.3213963508605957, acc = 0.896484375\n",
      "Batch 3: loss = 0.2881733477115631, acc = 0.90234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4: loss = 0.3502306342124939, acc = 0.87890625\n",
      "Batch 5: loss = 0.36863040924072266, acc = 0.87890625\n",
      "Batch 6: loss = 0.34204381704330444, acc = 0.892578125\n",
      "Batch 7: loss = 0.32751238346099854, acc = 0.8955078125\n",
      "Batch 8: loss = 0.33805200457572937, acc = 0.8857421875\n",
      "Batch 9: loss = 0.3339507579803467, acc = 0.88671875\n",
      "Batch 10: loss = 0.2830130457878113, acc = 0.90234375\n",
      "Batch 11: loss = 0.325041800737381, acc = 0.89453125\n",
      "Batch 12: loss = 0.31396234035491943, acc = 0.89453125\n",
      "Batch 13: loss = 0.27581316232681274, acc = 0.90625\n",
      "Batch 14: loss = 0.30208587646484375, acc = 0.8984375\n",
      "Batch 15: loss = 0.28659242391586304, acc = 0.904296875\n",
      "Batch 16: loss = 0.3282925486564636, acc = 0.890625\n",
      "Batch 17: loss = 0.3511340916156769, acc = 0.8818359375\n",
      "Batch 18: loss = 0.31281226873397827, acc = 0.892578125\n",
      "Batch 19: loss = 0.31870952248573303, acc = 0.8955078125\n",
      "Batch 20: loss = 0.2883969843387604, acc = 0.9013671875\n",
      "Batch 21: loss = 0.32179689407348633, acc = 0.8935546875\n",
      "Batch 22: loss = 0.3399145007133484, acc = 0.8818359375\n",
      "Batch 23: loss = 0.3422055244445801, acc = 0.8896484375\n",
      "Batch 24: loss = 0.3256646394729614, acc = 0.8837890625\n",
      "Batch 25: loss = 0.30506831407546997, acc = 0.9033203125\n",
      "Batch 26: loss = 0.31348299980163574, acc = 0.892578125\n",
      "Batch 27: loss = 0.32436811923980713, acc = 0.8896484375\n",
      "Batch 28: loss = 0.3575383424758911, acc = 0.8818359375\n",
      "Batch 29: loss = 0.3551027178764343, acc = 0.8779296875\n",
      "Batch 30: loss = 0.32033950090408325, acc = 0.90234375\n",
      "Batch 31: loss = 0.35322797298431396, acc = 0.8837890625\n",
      "Batch 32: loss = 0.31856948137283325, acc = 0.89453125\n",
      "Batch 33: loss = 0.3137795329093933, acc = 0.8955078125\n",
      "Batch 34: loss = 0.3397011458873749, acc = 0.8876953125\n",
      "Batch 35: loss = 0.318409264087677, acc = 0.890625\n",
      "Batch 36: loss = 0.31518563628196716, acc = 0.8935546875\n",
      "Batch 37: loss = 0.3030560612678528, acc = 0.8994140625\n",
      "Batch 38: loss = 0.3149946630001068, acc = 0.8837890625\n",
      "Batch 39: loss = 0.27564680576324463, acc = 0.9033203125\n",
      "Batch 40: loss = 0.3534175753593445, acc = 0.8818359375\n",
      "Batch 41: loss = 0.2961347699165344, acc = 0.8974609375\n",
      "Batch 42: loss = 0.32649847865104675, acc = 0.8876953125\n",
      "Batch 43: loss = 0.3422902226448059, acc = 0.888671875\n",
      "Batch 44: loss = 0.31488099694252014, acc = 0.9013671875\n",
      "Batch 45: loss = 0.3002469539642334, acc = 0.8935546875\n",
      "Batch 46: loss = 0.2926263213157654, acc = 0.912109375\n",
      "Batch 47: loss = 0.3039683699607849, acc = 0.904296875\n",
      "Batch 48: loss = 0.3135523498058319, acc = 0.8994140625\n",
      "Batch 49: loss = 0.2813887298107147, acc = 0.900390625\n",
      "Batch 50: loss = 0.2774975895881653, acc = 0.90625\n",
      "Batch 51: loss = 0.3147549331188202, acc = 0.890625\n",
      "Batch 52: loss = 0.2882690131664276, acc = 0.904296875\n",
      "Batch 53: loss = 0.32208365201950073, acc = 0.8935546875\n",
      "Batch 54: loss = 0.2716263234615326, acc = 0.91015625\n",
      "Batch 55: loss = 0.28443998098373413, acc = 0.9091796875\n",
      "Batch 56: loss = 0.3277778625488281, acc = 0.87890625\n",
      "Batch 57: loss = 0.34838950634002686, acc = 0.8798828125\n",
      "Batch 58: loss = 0.3163102865219116, acc = 0.890625\n",
      "Batch 59: loss = 0.2567808926105499, acc = 0.9150390625\n",
      "Batch 60: loss = 0.3285693824291229, acc = 0.8955078125\n",
      "Batch 61: loss = 0.30253463983535767, acc = 0.892578125\n",
      "Batch 62: loss = 0.3812105655670166, acc = 0.8720703125\n",
      "Batch 63: loss = 0.2641770541667938, acc = 0.9150390625\n",
      "Batch 64: loss = 0.29467612504959106, acc = 0.900390625\n",
      "Batch 65: loss = 0.294270396232605, acc = 0.904296875\n",
      "Batch 66: loss = 0.3124195635318756, acc = 0.8974609375\n",
      "Batch 67: loss = 0.30786097049713135, acc = 0.8994140625\n",
      "Batch 68: loss = 0.29325398802757263, acc = 0.904296875\n",
      "Batch 69: loss = 0.28829431533813477, acc = 0.8984375\n",
      "Batch 70: loss = 0.3327590823173523, acc = 0.89453125\n",
      "Batch 71: loss = 0.3329616189002991, acc = 0.8916015625\n",
      "Batch 72: loss = 0.2907540798187256, acc = 0.8974609375\n",
      "Batch 73: loss = 0.3593520224094391, acc = 0.8740234375\n",
      "Batch 74: loss = 0.35516244173049927, acc = 0.8740234375\n",
      "Batch 75: loss = 0.36534541845321655, acc = 0.8701171875\n",
      "Batch 76: loss = 0.30397462844848633, acc = 0.89453125\n",
      "Batch 77: loss = 0.32194602489471436, acc = 0.892578125\n",
      "Batch 78: loss = 0.34515321254730225, acc = 0.888671875\n",
      "Batch 79: loss = 0.27511081099510193, acc = 0.9072265625\n",
      "Batch 80: loss = 0.27575308084487915, acc = 0.908203125\n",
      "Batch 81: loss = 0.30640292167663574, acc = 0.88671875\n",
      "Batch 82: loss = 0.28127941489219666, acc = 0.90625\n",
      "Batch 83: loss = 0.29404890537261963, acc = 0.90625\n",
      "Batch 84: loss = 0.2935011088848114, acc = 0.896484375\n",
      "Batch 85: loss = 0.3242623209953308, acc = 0.8994140625\n",
      "Batch 86: loss = 0.3256548047065735, acc = 0.8798828125\n",
      "Batch 87: loss = 0.32494091987609863, acc = 0.8955078125\n",
      "Batch 88: loss = 0.3358997106552124, acc = 0.8896484375\n",
      "Batch 89: loss = 0.28522878885269165, acc = 0.8984375\n",
      "Batch 90: loss = 0.3306174874305725, acc = 0.8896484375\n",
      "Batch 91: loss = 0.3278045654296875, acc = 0.888671875\n",
      "Batch 92: loss = 0.3735778033733368, acc = 0.8681640625\n",
      "Batch 93: loss = 0.29980066418647766, acc = 0.9052734375\n",
      "Batch 94: loss = 0.29461222887039185, acc = 0.8994140625\n",
      "Batch 95: loss = 0.28163039684295654, acc = 0.9072265625\n",
      "Batch 96: loss = 0.34074151515960693, acc = 0.880859375\n",
      "Batch 97: loss = 0.3139685392379761, acc = 0.8974609375\n",
      "Batch 98: loss = 0.33208662271499634, acc = 0.890625\n",
      "Batch 99: loss = 0.3537049889564514, acc = 0.888671875\n",
      "Batch 100: loss = 0.30119460821151733, acc = 0.904296875\n",
      "Batch 101: loss = 0.28911587595939636, acc = 0.8984375\n",
      "Batch 102: loss = 0.3111724257469177, acc = 0.896484375\n",
      "Batch 103: loss = 0.3251510262489319, acc = 0.896484375\n",
      "Batch 104: loss = 0.26460835337638855, acc = 0.91015625\n",
      "Batch 105: loss = 0.3210815191268921, acc = 0.8896484375\n",
      "Batch 106: loss = 0.31263139843940735, acc = 0.876953125\n",
      "Batch 107: loss = 0.28175169229507446, acc = 0.91796875\n",
      "Batch 108: loss = 0.28893107175827026, acc = 0.888671875\n",
      "Batch 109: loss = 0.2929390072822571, acc = 0.90234375\n",
      "Batch 110: loss = 0.3369043469429016, acc = 0.8935546875\n",
      "Batch 111: loss = 0.3023295998573303, acc = 0.8994140625\n",
      "Batch 112: loss = 0.3260228633880615, acc = 0.8935546875\n",
      "Batch 113: loss = 0.29485493898391724, acc = 0.9052734375\n",
      "Batch 114: loss = 0.3228216767311096, acc = 0.900390625\n",
      "Batch 115: loss = 0.33434098958969116, acc = 0.88671875\n",
      "Batch 116: loss = 0.33590468764305115, acc = 0.8876953125\n",
      "Batch 117: loss = 0.34294626116752625, acc = 0.88671875\n",
      "Batch 118: loss = 0.28353869915008545, acc = 0.890625\n",
      "Batch 119: loss = 0.3101955056190491, acc = 0.890625\n",
      "Batch 120: loss = 0.2837754189968109, acc = 0.9111328125\n",
      "Batch 121: loss = 0.31746745109558105, acc = 0.8916015625\n",
      "Batch 122: loss = 0.32366615533828735, acc = 0.8935546875\n",
      "Batch 123: loss = 0.30144765973091125, acc = 0.8955078125\n",
      "Batch 124: loss = 0.3070720434188843, acc = 0.896484375\n",
      "Batch 125: loss = 0.3433249592781067, acc = 0.8896484375\n",
      "Batch 126: loss = 0.3187825679779053, acc = 0.8955078125\n",
      "\n",
      "Epoch 70/100\n",
      "Batch 1: loss = 0.4452901780605316, acc = 0.8623046875\n",
      "Batch 2: loss = 0.3156476616859436, acc = 0.892578125\n",
      "Batch 3: loss = 0.35635095834732056, acc = 0.8818359375\n",
      "Batch 4: loss = 0.328643798828125, acc = 0.9013671875\n",
      "Batch 5: loss = 0.34050607681274414, acc = 0.890625\n",
      "Batch 6: loss = 0.36596712470054626, acc = 0.8828125\n",
      "Batch 7: loss = 0.32083043456077576, acc = 0.89453125\n",
      "Batch 8: loss = 0.3660981357097626, acc = 0.8876953125\n",
      "Batch 9: loss = 0.3309915065765381, acc = 0.8876953125\n",
      "Batch 10: loss = 0.27512627840042114, acc = 0.9072265625\n",
      "Batch 11: loss = 0.3174780011177063, acc = 0.8935546875\n",
      "Batch 12: loss = 0.2874945104122162, acc = 0.9013671875\n",
      "Batch 13: loss = 0.3093438148498535, acc = 0.8994140625\n",
      "Batch 14: loss = 0.32337456941604614, acc = 0.896484375\n",
      "Batch 15: loss = 0.2965797185897827, acc = 0.8984375\n",
      "Batch 16: loss = 0.2761000096797943, acc = 0.904296875\n",
      "Batch 17: loss = 0.3299626410007477, acc = 0.8935546875\n",
      "Batch 18: loss = 0.305655300617218, acc = 0.900390625\n",
      "Batch 19: loss = 0.32084205746650696, acc = 0.8935546875\n",
      "Batch 20: loss = 0.31265637278556824, acc = 0.8916015625\n",
      "Batch 21: loss = 0.3377370834350586, acc = 0.8896484375\n",
      "Batch 22: loss = 0.34312230348587036, acc = 0.888671875\n",
      "Batch 23: loss = 0.3061453402042389, acc = 0.9013671875\n",
      "Batch 24: loss = 0.2844425439834595, acc = 0.8916015625\n",
      "Batch 25: loss = 0.28498566150665283, acc = 0.91015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 26: loss = 0.2809837758541107, acc = 0.892578125\n",
      "Batch 27: loss = 0.30547595024108887, acc = 0.89453125\n",
      "Batch 28: loss = 0.3546937108039856, acc = 0.8779296875\n",
      "Batch 29: loss = 0.3637416660785675, acc = 0.8828125\n",
      "Batch 30: loss = 0.33012616634368896, acc = 0.896484375\n",
      "Batch 31: loss = 0.3317945599555969, acc = 0.896484375\n",
      "Batch 32: loss = 0.32832616567611694, acc = 0.8916015625\n",
      "Batch 33: loss = 0.30851614475250244, acc = 0.890625\n",
      "Batch 34: loss = 0.34293413162231445, acc = 0.8876953125\n",
      "Batch 35: loss = 0.3328540325164795, acc = 0.8857421875\n",
      "Batch 36: loss = 0.3022709786891937, acc = 0.896484375\n",
      "Batch 37: loss = 0.292205810546875, acc = 0.90625\n",
      "Batch 38: loss = 0.31732094287872314, acc = 0.890625\n",
      "Batch 39: loss = 0.3154757022857666, acc = 0.900390625\n",
      "Batch 40: loss = 0.319566547870636, acc = 0.8837890625\n",
      "Batch 41: loss = 0.2682246267795563, acc = 0.91015625\n",
      "Batch 42: loss = 0.29371023178100586, acc = 0.9052734375\n",
      "Batch 43: loss = 0.30147334933280945, acc = 0.8994140625\n",
      "Batch 44: loss = 0.28025558590888977, acc = 0.91015625\n",
      "Batch 45: loss = 0.28402525186538696, acc = 0.9052734375\n",
      "Batch 46: loss = 0.29516398906707764, acc = 0.8974609375\n",
      "Batch 47: loss = 0.28257495164871216, acc = 0.9013671875\n",
      "Batch 48: loss = 0.30991148948669434, acc = 0.884765625\n",
      "Batch 49: loss = 0.2964635491371155, acc = 0.90625\n",
      "Batch 50: loss = 0.27600356936454773, acc = 0.908203125\n",
      "Batch 51: loss = 0.33727705478668213, acc = 0.8779296875\n",
      "Batch 52: loss = 0.3046535849571228, acc = 0.8955078125\n",
      "Batch 53: loss = 0.34647583961486816, acc = 0.8798828125\n",
      "Batch 54: loss = 0.24664418399333954, acc = 0.9140625\n",
      "Batch 55: loss = 0.2492174506187439, acc = 0.9150390625\n",
      "Batch 56: loss = 0.3319735527038574, acc = 0.8896484375\n",
      "Batch 57: loss = 0.3596208691596985, acc = 0.8681640625\n",
      "Batch 58: loss = 0.33259475231170654, acc = 0.900390625\n",
      "Batch 59: loss = 0.2872755527496338, acc = 0.9072265625\n",
      "Batch 60: loss = 0.3363640308380127, acc = 0.8935546875\n",
      "Batch 61: loss = 0.2518174648284912, acc = 0.9111328125\n",
      "Batch 62: loss = 0.3545432388782501, acc = 0.8857421875\n",
      "Batch 63: loss = 0.28081583976745605, acc = 0.90625\n",
      "Batch 64: loss = 0.2784203886985779, acc = 0.9091796875\n",
      "Batch 65: loss = 0.31369316577911377, acc = 0.9033203125\n",
      "Batch 66: loss = 0.3176514804363251, acc = 0.896484375\n",
      "Batch 67: loss = 0.3054100275039673, acc = 0.8994140625\n",
      "Batch 68: loss = 0.3063413202762604, acc = 0.8935546875\n",
      "Batch 69: loss = 0.3093578517436981, acc = 0.8974609375\n",
      "Batch 70: loss = 0.30935466289520264, acc = 0.88671875\n",
      "Batch 71: loss = 0.2903727889060974, acc = 0.90234375\n",
      "Batch 72: loss = 0.2990354895591736, acc = 0.9013671875\n",
      "Batch 73: loss = 0.3376691937446594, acc = 0.89453125\n",
      "Batch 74: loss = 0.3184521198272705, acc = 0.8876953125\n",
      "Batch 75: loss = 0.38015449047088623, acc = 0.87109375\n",
      "Batch 76: loss = 0.3156217932701111, acc = 0.890625\n",
      "Batch 77: loss = 0.3087031841278076, acc = 0.890625\n",
      "Batch 78: loss = 0.3316860496997833, acc = 0.89453125\n",
      "Batch 79: loss = 0.2953871488571167, acc = 0.8955078125\n",
      "Batch 80: loss = 0.2746138572692871, acc = 0.9130859375\n",
      "Batch 81: loss = 0.3053942918777466, acc = 0.896484375\n",
      "Batch 82: loss = 0.3244178891181946, acc = 0.8876953125\n",
      "Batch 83: loss = 0.2951434850692749, acc = 0.90625\n",
      "Batch 84: loss = 0.354536235332489, acc = 0.8671875\n",
      "Batch 85: loss = 0.33135029673576355, acc = 0.8857421875\n",
      "Batch 86: loss = 0.3111090660095215, acc = 0.8994140625\n",
      "Batch 87: loss = 0.29351574182510376, acc = 0.9091796875\n",
      "Batch 88: loss = 0.36001282930374146, acc = 0.8818359375\n",
      "Batch 89: loss = 0.3183978199958801, acc = 0.8974609375\n",
      "Batch 90: loss = 0.3159617781639099, acc = 0.8955078125\n",
      "Batch 91: loss = 0.3342055678367615, acc = 0.8818359375\n",
      "Batch 92: loss = 0.34359413385391235, acc = 0.8828125\n",
      "Batch 93: loss = 0.2929511070251465, acc = 0.896484375\n",
      "Batch 94: loss = 0.3224019706249237, acc = 0.8974609375\n",
      "Batch 95: loss = 0.27612850069999695, acc = 0.9130859375\n",
      "Batch 96: loss = 0.3169611096382141, acc = 0.89453125\n",
      "Batch 97: loss = 0.32440608739852905, acc = 0.896484375\n",
      "Batch 98: loss = 0.3039688766002655, acc = 0.89453125\n",
      "Batch 99: loss = 0.33074814081192017, acc = 0.8876953125\n",
      "Batch 100: loss = 0.3195279836654663, acc = 0.8798828125\n",
      "Batch 101: loss = 0.3022577464580536, acc = 0.9013671875\n",
      "Batch 102: loss = 0.32586869597435, acc = 0.8876953125\n",
      "Batch 103: loss = 0.34383440017700195, acc = 0.888671875\n",
      "Batch 104: loss = 0.2874623239040375, acc = 0.8974609375\n",
      "Batch 105: loss = 0.2641814053058624, acc = 0.908203125\n",
      "Batch 106: loss = 0.2980528175830841, acc = 0.8984375\n",
      "Batch 107: loss = 0.2965277433395386, acc = 0.9033203125\n",
      "Batch 108: loss = 0.30252552032470703, acc = 0.8984375\n",
      "Batch 109: loss = 0.2940470278263092, acc = 0.90625\n",
      "Batch 110: loss = 0.30508071184158325, acc = 0.9072265625\n",
      "Batch 111: loss = 0.31143343448638916, acc = 0.9013671875\n",
      "Batch 112: loss = 0.2891601622104645, acc = 0.9140625\n",
      "Batch 113: loss = 0.2813910245895386, acc = 0.8955078125\n",
      "Batch 114: loss = 0.3113929331302643, acc = 0.892578125\n",
      "Batch 115: loss = 0.2925448417663574, acc = 0.9150390625\n",
      "Batch 116: loss = 0.3322872519493103, acc = 0.892578125\n",
      "Batch 117: loss = 0.29801467061042786, acc = 0.9072265625\n",
      "Batch 118: loss = 0.2863394618034363, acc = 0.9052734375\n",
      "Batch 119: loss = 0.2736962139606476, acc = 0.9150390625\n",
      "Batch 120: loss = 0.2833794951438904, acc = 0.9130859375\n",
      "Batch 121: loss = 0.348446249961853, acc = 0.87890625\n",
      "Batch 122: loss = 0.29689064621925354, acc = 0.8955078125\n",
      "Batch 123: loss = 0.3338300883769989, acc = 0.876953125\n",
      "Batch 124: loss = 0.3298656642436981, acc = 0.89453125\n",
      "Batch 125: loss = 0.32668349146842957, acc = 0.890625\n",
      "Batch 126: loss = 0.34310317039489746, acc = 0.8857421875\n",
      "Saved checkpoint to weights.70.h5\n",
      "\n",
      "Epoch 71/100\n",
      "Batch 1: loss = 0.4278267025947571, acc = 0.8798828125\n",
      "Batch 2: loss = 0.3064658045768738, acc = 0.9013671875\n",
      "Batch 3: loss = 0.33487260341644287, acc = 0.8984375\n",
      "Batch 4: loss = 0.3067783713340759, acc = 0.892578125\n",
      "Batch 5: loss = 0.31444063782691956, acc = 0.8984375\n",
      "Batch 6: loss = 0.3363976776599884, acc = 0.892578125\n",
      "Batch 7: loss = 0.33368217945098877, acc = 0.8974609375\n",
      "Batch 8: loss = 0.3202088475227356, acc = 0.890625\n",
      "Batch 9: loss = 0.26837170124053955, acc = 0.9072265625\n",
      "Batch 10: loss = 0.27446413040161133, acc = 0.90625\n",
      "Batch 11: loss = 0.2999594211578369, acc = 0.8974609375\n",
      "Batch 12: loss = 0.3108466863632202, acc = 0.8955078125\n",
      "Batch 13: loss = 0.28874844312667847, acc = 0.90234375\n",
      "Batch 14: loss = 0.32205790281295776, acc = 0.89453125\n",
      "Batch 15: loss = 0.2839619517326355, acc = 0.9130859375\n",
      "Batch 16: loss = 0.2848716080188751, acc = 0.9130859375\n",
      "Batch 17: loss = 0.3183565139770508, acc = 0.8916015625\n",
      "Batch 18: loss = 0.3020738363265991, acc = 0.8984375\n",
      "Batch 19: loss = 0.3081810176372528, acc = 0.8974609375\n",
      "Batch 20: loss = 0.28534600138664246, acc = 0.90234375\n",
      "Batch 21: loss = 0.3447772264480591, acc = 0.8818359375\n",
      "Batch 22: loss = 0.34552979469299316, acc = 0.8876953125\n",
      "Batch 23: loss = 0.32981544733047485, acc = 0.896484375\n",
      "Batch 24: loss = 0.31230807304382324, acc = 0.9033203125\n",
      "Batch 25: loss = 0.31431710720062256, acc = 0.900390625\n",
      "Batch 26: loss = 0.2715834975242615, acc = 0.9130859375\n",
      "Batch 27: loss = 0.3357688784599304, acc = 0.892578125\n",
      "Batch 28: loss = 0.3061133623123169, acc = 0.8984375\n",
      "Batch 29: loss = 0.3371797204017639, acc = 0.8837890625\n",
      "Batch 30: loss = 0.30095282196998596, acc = 0.8994140625\n",
      "Batch 31: loss = 0.32294130325317383, acc = 0.8896484375\n",
      "Batch 32: loss = 0.3286578059196472, acc = 0.876953125\n",
      "Batch 33: loss = 0.2908148169517517, acc = 0.900390625\n",
      "Batch 34: loss = 0.30993637442588806, acc = 0.8984375\n",
      "Batch 35: loss = 0.2939876317977905, acc = 0.9033203125\n",
      "Batch 36: loss = 0.30531367659568787, acc = 0.900390625\n",
      "Batch 37: loss = 0.28779399394989014, acc = 0.9072265625\n",
      "Batch 38: loss = 0.31459569931030273, acc = 0.8916015625\n",
      "Batch 39: loss = 0.25904953479766846, acc = 0.9208984375\n",
      "Batch 40: loss = 0.3148621618747711, acc = 0.890625\n",
      "Batch 41: loss = 0.3020581007003784, acc = 0.90234375\n",
      "Batch 42: loss = 0.33474844694137573, acc = 0.890625\n",
      "Batch 43: loss = 0.34082043170928955, acc = 0.88671875\n",
      "Batch 44: loss = 0.27172714471817017, acc = 0.9208984375\n",
      "Batch 45: loss = 0.25510871410369873, acc = 0.9169921875\n",
      "Batch 46: loss = 0.2690466642379761, acc = 0.9072265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 47: loss = 0.28016743063926697, acc = 0.9111328125\n",
      "Batch 48: loss = 0.2582254409790039, acc = 0.923828125\n",
      "Batch 49: loss = 0.2744382619857788, acc = 0.9150390625\n",
      "Batch 50: loss = 0.2825527489185333, acc = 0.91015625\n",
      "Batch 51: loss = 0.2954469323158264, acc = 0.8994140625\n",
      "Batch 52: loss = 0.263525128364563, acc = 0.9140625\n",
      "Batch 53: loss = 0.29881027340888977, acc = 0.896484375\n",
      "Batch 54: loss = 0.2675623893737793, acc = 0.9052734375\n",
      "Batch 55: loss = 0.2778882086277008, acc = 0.9130859375\n",
      "Batch 56: loss = 0.3064032793045044, acc = 0.892578125\n",
      "Batch 57: loss = 0.33561211824417114, acc = 0.8779296875\n",
      "Batch 58: loss = 0.36237961053848267, acc = 0.8759765625\n",
      "Batch 59: loss = 0.2701480984687805, acc = 0.904296875\n",
      "Batch 60: loss = 0.32732799649238586, acc = 0.892578125\n",
      "Batch 61: loss = 0.2875846028327942, acc = 0.9052734375\n",
      "Batch 62: loss = 0.35347142815589905, acc = 0.8740234375\n",
      "Batch 63: loss = 0.3294699490070343, acc = 0.890625\n",
      "Batch 64: loss = 0.27400001883506775, acc = 0.908203125\n",
      "Batch 65: loss = 0.2958904206752777, acc = 0.8974609375\n",
      "Batch 66: loss = 0.3180835247039795, acc = 0.9013671875\n",
      "Batch 67: loss = 0.31039178371429443, acc = 0.892578125\n",
      "Batch 68: loss = 0.2999003827571869, acc = 0.9072265625\n",
      "Batch 69: loss = 0.27363455295562744, acc = 0.90234375\n",
      "Batch 70: loss = 0.30840274691581726, acc = 0.9013671875\n",
      "Batch 71: loss = 0.287004679441452, acc = 0.904296875\n",
      "Batch 72: loss = 0.3013465404510498, acc = 0.90234375\n",
      "Batch 73: loss = 0.32701361179351807, acc = 0.8876953125\n",
      "Batch 74: loss = 0.33967065811157227, acc = 0.87890625\n",
      "Batch 75: loss = 0.3411904573440552, acc = 0.8857421875\n",
      "Batch 76: loss = 0.3143913745880127, acc = 0.8994140625\n",
      "Batch 77: loss = 0.27098721265792847, acc = 0.9130859375\n",
      "Batch 78: loss = 0.31953027844429016, acc = 0.8955078125\n",
      "Batch 79: loss = 0.276894748210907, acc = 0.9111328125\n",
      "Batch 80: loss = 0.2846824526786804, acc = 0.90625\n",
      "Batch 81: loss = 0.2945488691329956, acc = 0.9013671875\n",
      "Batch 82: loss = 0.3151058554649353, acc = 0.892578125\n",
      "Batch 83: loss = 0.30343562364578247, acc = 0.9033203125\n",
      "Batch 84: loss = 0.3049105405807495, acc = 0.8974609375\n",
      "Batch 85: loss = 0.343986451625824, acc = 0.875\n",
      "Batch 86: loss = 0.36220160126686096, acc = 0.8779296875\n",
      "Batch 87: loss = 0.3107445240020752, acc = 0.9013671875\n",
      "Batch 88: loss = 0.32050269842147827, acc = 0.884765625\n",
      "Batch 89: loss = 0.29473236203193665, acc = 0.9091796875\n",
      "Batch 90: loss = 0.31270211935043335, acc = 0.900390625\n",
      "Batch 91: loss = 0.3130825161933899, acc = 0.892578125\n",
      "Batch 92: loss = 0.31904345750808716, acc = 0.90234375\n",
      "Batch 93: loss = 0.2920253276824951, acc = 0.908203125\n",
      "Batch 94: loss = 0.28047338128089905, acc = 0.9130859375\n",
      "Batch 95: loss = 0.27643293142318726, acc = 0.9091796875\n",
      "Batch 96: loss = 0.3335410952568054, acc = 0.8876953125\n",
      "Batch 97: loss = 0.3191688060760498, acc = 0.888671875\n",
      "Batch 98: loss = 0.33986568450927734, acc = 0.88671875\n",
      "Batch 99: loss = 0.29972442984580994, acc = 0.8994140625\n",
      "Batch 100: loss = 0.3161272704601288, acc = 0.8984375\n",
      "Batch 101: loss = 0.2953364849090576, acc = 0.9033203125\n",
      "Batch 102: loss = 0.3153451383113861, acc = 0.8994140625\n",
      "Batch 103: loss = 0.3308180868625641, acc = 0.88671875\n",
      "Batch 104: loss = 0.27720391750335693, acc = 0.9150390625\n",
      "Batch 105: loss = 0.29823899269104004, acc = 0.8955078125\n",
      "Batch 106: loss = 0.30919119715690613, acc = 0.90234375\n",
      "Batch 107: loss = 0.3398756980895996, acc = 0.8798828125\n",
      "Batch 108: loss = 0.32113415002822876, acc = 0.8935546875\n",
      "Batch 109: loss = 0.28661680221557617, acc = 0.9052734375\n",
      "Batch 110: loss = 0.30147814750671387, acc = 0.9013671875\n",
      "Batch 111: loss = 0.32922863960266113, acc = 0.8837890625\n",
      "Batch 112: loss = 0.30789482593536377, acc = 0.896484375\n",
      "Batch 113: loss = 0.27974411845207214, acc = 0.9072265625\n",
      "Batch 114: loss = 0.33300623297691345, acc = 0.8994140625\n",
      "Batch 115: loss = 0.3464096188545227, acc = 0.8857421875\n",
      "Batch 116: loss = 0.3090803325176239, acc = 0.90234375\n",
      "Batch 117: loss = 0.34228503704071045, acc = 0.88671875\n",
      "Batch 118: loss = 0.2632827162742615, acc = 0.9072265625\n",
      "Batch 119: loss = 0.30799442529678345, acc = 0.8935546875\n",
      "Batch 120: loss = 0.2676151990890503, acc = 0.91015625\n",
      "Batch 121: loss = 0.3219043016433716, acc = 0.8935546875\n",
      "Batch 122: loss = 0.2984533905982971, acc = 0.9013671875\n",
      "Batch 123: loss = 0.32789814472198486, acc = 0.884765625\n",
      "Batch 124: loss = 0.32460492849349976, acc = 0.890625\n",
      "Batch 125: loss = 0.30207347869873047, acc = 0.8916015625\n",
      "Batch 126: loss = 0.3293686807155609, acc = 0.89453125\n",
      "\n",
      "Epoch 72/100\n",
      "Batch 1: loss = 0.43750298023223877, acc = 0.8642578125\n",
      "Batch 2: loss = 0.3401886820793152, acc = 0.8935546875\n",
      "Batch 3: loss = 0.34154218435287476, acc = 0.8974609375\n",
      "Batch 4: loss = 0.30678290128707886, acc = 0.90234375\n",
      "Batch 5: loss = 0.31447291374206543, acc = 0.896484375\n",
      "Batch 6: loss = 0.3185439109802246, acc = 0.8994140625\n",
      "Batch 7: loss = 0.32892102003097534, acc = 0.8916015625\n",
      "Batch 8: loss = 0.33071213960647583, acc = 0.8974609375\n",
      "Batch 9: loss = 0.2972104251384735, acc = 0.8994140625\n",
      "Batch 10: loss = 0.29290175437927246, acc = 0.9091796875\n",
      "Batch 11: loss = 0.27909019589424133, acc = 0.90625\n",
      "Batch 12: loss = 0.331045538187027, acc = 0.8828125\n",
      "Batch 13: loss = 0.3120279014110565, acc = 0.89453125\n",
      "Batch 14: loss = 0.3173098564147949, acc = 0.8984375\n",
      "Batch 15: loss = 0.26985618472099304, acc = 0.9140625\n",
      "Batch 16: loss = 0.2977322041988373, acc = 0.892578125\n",
      "Batch 17: loss = 0.3122413754463196, acc = 0.896484375\n",
      "Batch 18: loss = 0.3104533553123474, acc = 0.896484375\n",
      "Batch 19: loss = 0.3278641104698181, acc = 0.8984375\n",
      "Batch 20: loss = 0.3040354251861572, acc = 0.900390625\n",
      "Batch 21: loss = 0.326852023601532, acc = 0.8876953125\n",
      "Batch 22: loss = 0.3755842447280884, acc = 0.87890625\n",
      "Batch 23: loss = 0.31596559286117554, acc = 0.8955078125\n",
      "Batch 24: loss = 0.3062451481819153, acc = 0.900390625\n",
      "Batch 25: loss = 0.31565603613853455, acc = 0.8974609375\n",
      "Batch 26: loss = 0.2829305827617645, acc = 0.9111328125\n",
      "Batch 27: loss = 0.3421418070793152, acc = 0.8818359375\n",
      "Batch 28: loss = 0.32518479228019714, acc = 0.8896484375\n",
      "Batch 29: loss = 0.32558929920196533, acc = 0.8935546875\n",
      "Batch 30: loss = 0.329841285943985, acc = 0.888671875\n",
      "Batch 31: loss = 0.3257024884223938, acc = 0.8974609375\n",
      "Batch 32: loss = 0.3310072720050812, acc = 0.888671875\n",
      "Batch 33: loss = 0.28704822063446045, acc = 0.8994140625\n",
      "Batch 34: loss = 0.33294469118118286, acc = 0.884765625\n",
      "Batch 35: loss = 0.31975412368774414, acc = 0.8896484375\n",
      "Batch 36: loss = 0.29475677013397217, acc = 0.904296875\n",
      "Batch 37: loss = 0.28321751952171326, acc = 0.91015625\n",
      "Batch 38: loss = 0.320244163274765, acc = 0.89453125\n",
      "Batch 39: loss = 0.26922255754470825, acc = 0.9052734375\n",
      "Batch 40: loss = 0.32044553756713867, acc = 0.890625\n",
      "Batch 41: loss = 0.2849999666213989, acc = 0.904296875\n",
      "Batch 42: loss = 0.30485379695892334, acc = 0.9052734375\n",
      "Batch 43: loss = 0.3052405118942261, acc = 0.8896484375\n",
      "Batch 44: loss = 0.28813648223876953, acc = 0.908203125\n",
      "Batch 45: loss = 0.2966609001159668, acc = 0.9013671875\n",
      "Batch 46: loss = 0.28360068798065186, acc = 0.9072265625\n",
      "Batch 47: loss = 0.3144438862800598, acc = 0.9052734375\n",
      "Batch 48: loss = 0.28272712230682373, acc = 0.9072265625\n",
      "Batch 49: loss = 0.2918870151042938, acc = 0.9052734375\n",
      "Batch 50: loss = 0.2758655250072479, acc = 0.9111328125\n",
      "Batch 51: loss = 0.3239138722419739, acc = 0.8916015625\n",
      "Batch 52: loss = 0.26601168513298035, acc = 0.9169921875\n",
      "Batch 53: loss = 0.2557266056537628, acc = 0.919921875\n",
      "Batch 54: loss = 0.2604716420173645, acc = 0.921875\n",
      "Batch 55: loss = 0.251737117767334, acc = 0.9130859375\n",
      "Batch 56: loss = 0.29340940713882446, acc = 0.89453125\n",
      "Batch 57: loss = 0.3395945429801941, acc = 0.884765625\n",
      "Batch 58: loss = 0.3372584879398346, acc = 0.8828125\n",
      "Batch 59: loss = 0.22335469722747803, acc = 0.927734375\n",
      "Batch 60: loss = 0.3049973249435425, acc = 0.8984375\n",
      "Batch 61: loss = 0.26690399646759033, acc = 0.9169921875\n",
      "Batch 62: loss = 0.3774482011795044, acc = 0.859375\n",
      "Batch 63: loss = 0.29250457882881165, acc = 0.900390625\n",
      "Batch 64: loss = 0.2647041380405426, acc = 0.921875\n",
      "Batch 65: loss = 0.29496246576309204, acc = 0.904296875\n",
      "Batch 66: loss = 0.3236425817012787, acc = 0.8916015625\n",
      "Batch 67: loss = 0.3149104714393616, acc = 0.8818359375\n",
      "Batch 68: loss = 0.28938180208206177, acc = 0.9052734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 69: loss = 0.267184853553772, acc = 0.9130859375\n",
      "Batch 70: loss = 0.30250075459480286, acc = 0.892578125\n",
      "Batch 71: loss = 0.3039582073688507, acc = 0.900390625\n",
      "Batch 72: loss = 0.30463606119155884, acc = 0.900390625\n",
      "Batch 73: loss = 0.2955349087715149, acc = 0.8994140625\n",
      "Batch 74: loss = 0.33562707901000977, acc = 0.880859375\n",
      "Batch 75: loss = 0.37822070717811584, acc = 0.8759765625\n",
      "Batch 76: loss = 0.32215380668640137, acc = 0.896484375\n",
      "Batch 77: loss = 0.2930071949958801, acc = 0.904296875\n",
      "Batch 78: loss = 0.33198079466819763, acc = 0.880859375\n",
      "Batch 79: loss = 0.2652123272418976, acc = 0.91015625\n",
      "Batch 80: loss = 0.26172858476638794, acc = 0.90625\n",
      "Batch 81: loss = 0.3109776973724365, acc = 0.8935546875\n",
      "Batch 82: loss = 0.2808196246623993, acc = 0.90234375\n",
      "Batch 83: loss = 0.29360902309417725, acc = 0.90234375\n",
      "Batch 84: loss = 0.31783464550971985, acc = 0.8994140625\n",
      "Batch 85: loss = 0.2995968461036682, acc = 0.896484375\n",
      "Batch 86: loss = 0.2932452857494354, acc = 0.8994140625\n",
      "Batch 87: loss = 0.30116909742355347, acc = 0.900390625\n",
      "Batch 88: loss = 0.36207014322280884, acc = 0.8857421875\n",
      "Batch 89: loss = 0.2705802917480469, acc = 0.919921875\n",
      "Batch 90: loss = 0.31993597745895386, acc = 0.892578125\n",
      "Batch 91: loss = 0.31657594442367554, acc = 0.8974609375\n",
      "Batch 92: loss = 0.3563876152038574, acc = 0.88671875\n",
      "Batch 93: loss = 0.2715873718261719, acc = 0.9072265625\n",
      "Batch 94: loss = 0.2782505750656128, acc = 0.9052734375\n",
      "Batch 95: loss = 0.2581894099712372, acc = 0.9150390625\n",
      "Batch 96: loss = 0.34691447019577026, acc = 0.8779296875\n",
      "Batch 97: loss = 0.31087666749954224, acc = 0.90234375\n",
      "Batch 98: loss = 0.299282431602478, acc = 0.91015625\n",
      "Batch 99: loss = 0.31963682174682617, acc = 0.904296875\n",
      "Batch 100: loss = 0.282722145318985, acc = 0.9033203125\n",
      "Batch 101: loss = 0.30599695444107056, acc = 0.888671875\n",
      "Batch 102: loss = 0.31782475113868713, acc = 0.892578125\n",
      "Batch 103: loss = 0.3406561613082886, acc = 0.8935546875\n",
      "Batch 104: loss = 0.3034381866455078, acc = 0.90234375\n",
      "Batch 105: loss = 0.29007333517074585, acc = 0.90234375\n",
      "Batch 106: loss = 0.2631288170814514, acc = 0.9111328125\n",
      "Batch 107: loss = 0.28900954127311707, acc = 0.9013671875\n",
      "Batch 108: loss = 0.28171104192733765, acc = 0.91015625\n",
      "Batch 109: loss = 0.33392444252967834, acc = 0.892578125\n",
      "Batch 110: loss = 0.3098490238189697, acc = 0.9013671875\n",
      "Batch 111: loss = 0.2937333285808563, acc = 0.9072265625\n",
      "Batch 112: loss = 0.28436610102653503, acc = 0.8994140625\n",
      "Batch 113: loss = 0.2815108299255371, acc = 0.904296875\n",
      "Batch 114: loss = 0.31718915700912476, acc = 0.8984375\n",
      "Batch 115: loss = 0.3013344705104828, acc = 0.8974609375\n",
      "Batch 116: loss = 0.30527716875076294, acc = 0.884765625\n",
      "Batch 117: loss = 0.2904963791370392, acc = 0.896484375\n",
      "Batch 118: loss = 0.26398766040802, acc = 0.9111328125\n",
      "Batch 119: loss = 0.28908485174179077, acc = 0.908203125\n",
      "Batch 120: loss = 0.27495986223220825, acc = 0.908203125\n",
      "Batch 121: loss = 0.33497801423072815, acc = 0.88671875\n",
      "Batch 122: loss = 0.26281145215034485, acc = 0.9052734375\n",
      "Batch 123: loss = 0.3265196681022644, acc = 0.880859375\n",
      "Batch 124: loss = 0.34535714983940125, acc = 0.87890625\n",
      "Batch 125: loss = 0.35078978538513184, acc = 0.8798828125\n",
      "Batch 126: loss = 0.32930225133895874, acc = 0.8828125\n",
      "\n",
      "Epoch 73/100\n",
      "Batch 1: loss = 0.43098706007003784, acc = 0.8779296875\n",
      "Batch 2: loss = 0.32016831636428833, acc = 0.8876953125\n",
      "Batch 3: loss = 0.3421570062637329, acc = 0.88671875\n",
      "Batch 4: loss = 0.2722005248069763, acc = 0.912109375\n",
      "Batch 5: loss = 0.289896160364151, acc = 0.892578125\n",
      "Batch 6: loss = 0.3103911280632019, acc = 0.8974609375\n",
      "Batch 7: loss = 0.33254045248031616, acc = 0.89453125\n",
      "Batch 8: loss = 0.325123131275177, acc = 0.8916015625\n",
      "Batch 9: loss = 0.24567672610282898, acc = 0.92578125\n",
      "Batch 10: loss = 0.2723020911216736, acc = 0.9130859375\n",
      "Batch 11: loss = 0.3022344708442688, acc = 0.8974609375\n",
      "Batch 12: loss = 0.2771379351615906, acc = 0.90234375\n",
      "Batch 13: loss = 0.27948981523513794, acc = 0.8984375\n",
      "Batch 14: loss = 0.2684580087661743, acc = 0.9130859375\n",
      "Batch 15: loss = 0.2995578646659851, acc = 0.8994140625\n",
      "Batch 16: loss = 0.30735719203948975, acc = 0.89453125\n",
      "Batch 17: loss = 0.29332929849624634, acc = 0.8984375\n",
      "Batch 18: loss = 0.2899942994117737, acc = 0.90625\n",
      "Batch 19: loss = 0.3159221410751343, acc = 0.900390625\n",
      "Batch 20: loss = 0.29271942377090454, acc = 0.89453125\n",
      "Batch 21: loss = 0.2949226498603821, acc = 0.90625\n",
      "Batch 22: loss = 0.32239797711372375, acc = 0.8935546875\n",
      "Batch 23: loss = 0.328888475894928, acc = 0.8955078125\n",
      "Batch 24: loss = 0.27230560779571533, acc = 0.91015625\n",
      "Batch 25: loss = 0.29859694838523865, acc = 0.8984375\n",
      "Batch 26: loss = 0.3028115928173065, acc = 0.890625\n",
      "Batch 27: loss = 0.2866821885108948, acc = 0.8935546875\n",
      "Batch 28: loss = 0.35353511571884155, acc = 0.876953125\n",
      "Batch 29: loss = 0.30095773935317993, acc = 0.908203125\n",
      "Batch 30: loss = 0.3223913908004761, acc = 0.8974609375\n",
      "Batch 31: loss = 0.34304821491241455, acc = 0.890625\n",
      "Batch 32: loss = 0.3365352153778076, acc = 0.8935546875\n",
      "Batch 33: loss = 0.2933551073074341, acc = 0.9013671875\n",
      "Batch 34: loss = 0.2965322434902191, acc = 0.9013671875\n",
      "Batch 35: loss = 0.32550814747810364, acc = 0.8935546875\n",
      "Batch 36: loss = 0.26649224758148193, acc = 0.9130859375\n",
      "Batch 37: loss = 0.27405205368995667, acc = 0.9111328125\n",
      "Batch 38: loss = 0.2968387007713318, acc = 0.8984375\n",
      "Batch 39: loss = 0.2959098517894745, acc = 0.9052734375\n",
      "Batch 40: loss = 0.31315019726753235, acc = 0.900390625\n",
      "Batch 41: loss = 0.3157044053077698, acc = 0.88671875\n",
      "Batch 42: loss = 0.34328407049179077, acc = 0.880859375\n",
      "Batch 43: loss = 0.30922988057136536, acc = 0.8974609375\n",
      "Batch 44: loss = 0.29163891077041626, acc = 0.8994140625\n",
      "Batch 45: loss = 0.27708616852760315, acc = 0.9052734375\n",
      "Batch 46: loss = 0.29148784279823303, acc = 0.900390625\n",
      "Batch 47: loss = 0.27363449335098267, acc = 0.91015625\n",
      "Batch 48: loss = 0.2929559350013733, acc = 0.9052734375\n",
      "Batch 49: loss = 0.2734631896018982, acc = 0.908203125\n",
      "Batch 50: loss = 0.27418482303619385, acc = 0.9150390625\n",
      "Batch 51: loss = 0.28244441747665405, acc = 0.916015625\n",
      "Batch 52: loss = 0.27779901027679443, acc = 0.904296875\n",
      "Batch 53: loss = 0.3059212863445282, acc = 0.90234375\n",
      "Batch 54: loss = 0.27515172958374023, acc = 0.9033203125\n",
      "Batch 55: loss = 0.22535397112369537, acc = 0.9345703125\n",
      "Batch 56: loss = 0.3240508437156677, acc = 0.8837890625\n",
      "Batch 57: loss = 0.28289350867271423, acc = 0.9091796875\n",
      "Batch 58: loss = 0.34127315878868103, acc = 0.8857421875\n",
      "Batch 59: loss = 0.2508907616138458, acc = 0.9091796875\n",
      "Batch 60: loss = 0.3318355083465576, acc = 0.8935546875\n",
      "Batch 61: loss = 0.3030087649822235, acc = 0.91015625\n",
      "Batch 62: loss = 0.32937192916870117, acc = 0.8876953125\n",
      "Batch 63: loss = 0.2994382381439209, acc = 0.8984375\n",
      "Batch 64: loss = 0.26906704902648926, acc = 0.9091796875\n",
      "Batch 65: loss = 0.3140835165977478, acc = 0.89453125\n",
      "Batch 66: loss = 0.318505197763443, acc = 0.8974609375\n",
      "Batch 67: loss = 0.2964487671852112, acc = 0.892578125\n",
      "Batch 68: loss = 0.3126401901245117, acc = 0.9013671875\n",
      "Batch 69: loss = 0.27527308464050293, acc = 0.904296875\n",
      "Batch 70: loss = 0.3129793405532837, acc = 0.89453125\n",
      "Batch 71: loss = 0.3330456614494324, acc = 0.88671875\n",
      "Batch 72: loss = 0.28030288219451904, acc = 0.908203125\n",
      "Batch 73: loss = 0.3014022707939148, acc = 0.8935546875\n",
      "Batch 74: loss = 0.3074328899383545, acc = 0.896484375\n",
      "Batch 75: loss = 0.3132092356681824, acc = 0.888671875\n",
      "Batch 76: loss = 0.27970439195632935, acc = 0.9111328125\n",
      "Batch 77: loss = 0.3027569055557251, acc = 0.8974609375\n",
      "Batch 78: loss = 0.31660032272338867, acc = 0.89453125\n",
      "Batch 79: loss = 0.3055964708328247, acc = 0.9033203125\n",
      "Batch 80: loss = 0.27753153443336487, acc = 0.9072265625\n",
      "Batch 81: loss = 0.28451186418533325, acc = 0.912109375\n",
      "Batch 82: loss = 0.3130175769329071, acc = 0.8984375\n",
      "Batch 83: loss = 0.2897336184978485, acc = 0.89453125\n",
      "Batch 84: loss = 0.3146113157272339, acc = 0.8994140625\n",
      "Batch 85: loss = 0.3306894898414612, acc = 0.880859375\n",
      "Batch 86: loss = 0.28714147210121155, acc = 0.904296875\n",
      "Batch 87: loss = 0.29877686500549316, acc = 0.90234375\n",
      "Batch 88: loss = 0.3354591131210327, acc = 0.888671875\n",
      "Batch 89: loss = 0.2916366159915924, acc = 0.9072265625\n",
      "Batch 90: loss = 0.30227455496788025, acc = 0.8935546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 91: loss = 0.3346317410469055, acc = 0.88671875\n",
      "Batch 92: loss = 0.3459669351577759, acc = 0.8837890625\n",
      "Batch 93: loss = 0.2632743716239929, acc = 0.9130859375\n",
      "Batch 94: loss = 0.2798316776752472, acc = 0.9052734375\n",
      "Batch 95: loss = 0.2812746465206146, acc = 0.900390625\n",
      "Batch 96: loss = 0.31321483850479126, acc = 0.892578125\n",
      "Batch 97: loss = 0.28395864367485046, acc = 0.912109375\n",
      "Batch 98: loss = 0.31252631545066833, acc = 0.8876953125\n",
      "Batch 99: loss = 0.32073140144348145, acc = 0.8828125\n",
      "Batch 100: loss = 0.30807799100875854, acc = 0.8828125\n",
      "Batch 101: loss = 0.31125181913375854, acc = 0.8876953125\n",
      "Batch 102: loss = 0.30862075090408325, acc = 0.8994140625\n",
      "Batch 103: loss = 0.30048668384552, acc = 0.8994140625\n",
      "Batch 104: loss = 0.2983055114746094, acc = 0.8994140625\n",
      "Batch 105: loss = 0.27330052852630615, acc = 0.9111328125\n",
      "Batch 106: loss = 0.2579311728477478, acc = 0.916015625\n",
      "Batch 107: loss = 0.3155420422554016, acc = 0.896484375\n",
      "Batch 108: loss = 0.2988157868385315, acc = 0.8974609375\n",
      "Batch 109: loss = 0.3153773546218872, acc = 0.892578125\n",
      "Batch 110: loss = 0.29193270206451416, acc = 0.900390625\n",
      "Batch 111: loss = 0.30327337980270386, acc = 0.896484375\n",
      "Batch 112: loss = 0.28724032640457153, acc = 0.9033203125\n",
      "Batch 113: loss = 0.30291280150413513, acc = 0.90625\n",
      "Batch 114: loss = 0.2944898307323456, acc = 0.9072265625\n",
      "Batch 115: loss = 0.3147103786468506, acc = 0.8935546875\n",
      "Batch 116: loss = 0.3213500380516052, acc = 0.8974609375\n",
      "Batch 117: loss = 0.3132805824279785, acc = 0.8876953125\n",
      "Batch 118: loss = 0.2720116376876831, acc = 0.9033203125\n",
      "Batch 119: loss = 0.28056252002716064, acc = 0.90625\n",
      "Batch 120: loss = 0.24568238854408264, acc = 0.9189453125\n",
      "Batch 121: loss = 0.29864010214805603, acc = 0.89453125\n",
      "Batch 122: loss = 0.25927066802978516, acc = 0.91015625\n",
      "Batch 123: loss = 0.3026120960712433, acc = 0.896484375\n",
      "Batch 124: loss = 0.299643337726593, acc = 0.896484375\n",
      "Batch 125: loss = 0.3327520787715912, acc = 0.8974609375\n",
      "Batch 126: loss = 0.3150753676891327, acc = 0.9013671875\n",
      "\n",
      "Epoch 74/100\n",
      "Batch 1: loss = 0.428372859954834, acc = 0.8779296875\n",
      "Batch 2: loss = 0.3117850720882416, acc = 0.892578125\n",
      "Batch 3: loss = 0.3148616552352905, acc = 0.8955078125\n",
      "Batch 4: loss = 0.2929757535457611, acc = 0.91015625\n",
      "Batch 5: loss = 0.31124699115753174, acc = 0.9072265625\n",
      "Batch 6: loss = 0.3254263401031494, acc = 0.8994140625\n",
      "Batch 7: loss = 0.31955695152282715, acc = 0.8955078125\n",
      "Batch 8: loss = 0.340637743473053, acc = 0.8818359375\n",
      "Batch 9: loss = 0.29234543442726135, acc = 0.9013671875\n",
      "Batch 10: loss = 0.2563945949077606, acc = 0.916015625\n",
      "Batch 11: loss = 0.2952245771884918, acc = 0.904296875\n",
      "Batch 12: loss = 0.30874085426330566, acc = 0.892578125\n",
      "Batch 13: loss = 0.2934298515319824, acc = 0.9052734375\n",
      "Batch 14: loss = 0.2903345823287964, acc = 0.90625\n",
      "Batch 15: loss = 0.2645416259765625, acc = 0.9091796875\n",
      "Batch 16: loss = 0.2885226309299469, acc = 0.8974609375\n",
      "Batch 17: loss = 0.32494720816612244, acc = 0.888671875\n",
      "Batch 18: loss = 0.2731446623802185, acc = 0.9033203125\n",
      "Batch 19: loss = 0.29402366280555725, acc = 0.91015625\n",
      "Batch 20: loss = 0.2807302176952362, acc = 0.91015625\n",
      "Batch 21: loss = 0.31313443183898926, acc = 0.8935546875\n",
      "Batch 22: loss = 0.29277944564819336, acc = 0.90234375\n",
      "Batch 23: loss = 0.3240271806716919, acc = 0.890625\n",
      "Batch 24: loss = 0.2558334469795227, acc = 0.919921875\n",
      "Batch 25: loss = 0.31519240140914917, acc = 0.8955078125\n",
      "Batch 26: loss = 0.2959204912185669, acc = 0.8916015625\n",
      "Batch 27: loss = 0.3078729510307312, acc = 0.8984375\n",
      "Batch 28: loss = 0.320184588432312, acc = 0.884765625\n",
      "Batch 29: loss = 0.34435421228408813, acc = 0.8818359375\n",
      "Batch 30: loss = 0.3217838704586029, acc = 0.8916015625\n",
      "Batch 31: loss = 0.31377357244491577, acc = 0.89453125\n",
      "Batch 32: loss = 0.33507832884788513, acc = 0.8828125\n",
      "Batch 33: loss = 0.2838355302810669, acc = 0.9091796875\n",
      "Batch 34: loss = 0.3241920471191406, acc = 0.888671875\n",
      "Batch 35: loss = 0.3435209095478058, acc = 0.884765625\n",
      "Batch 36: loss = 0.30424928665161133, acc = 0.89453125\n",
      "Batch 37: loss = 0.2850784361362457, acc = 0.908203125\n",
      "Batch 38: loss = 0.2897469997406006, acc = 0.91015625\n",
      "Batch 39: loss = 0.29051443934440613, acc = 0.904296875\n",
      "Batch 40: loss = 0.326379656791687, acc = 0.89453125\n",
      "Batch 41: loss = 0.2839239835739136, acc = 0.90234375\n",
      "Batch 42: loss = 0.28652966022491455, acc = 0.892578125\n",
      "Batch 43: loss = 0.31144553422927856, acc = 0.88671875\n",
      "Batch 44: loss = 0.30342763662338257, acc = 0.9013671875\n",
      "Batch 45: loss = 0.30024009943008423, acc = 0.88671875\n",
      "Batch 46: loss = 0.2526126503944397, acc = 0.91796875\n",
      "Batch 47: loss = 0.29058176279067993, acc = 0.8994140625\n",
      "Batch 48: loss = 0.2696561813354492, acc = 0.9150390625\n",
      "Batch 49: loss = 0.26512858271598816, acc = 0.9228515625\n",
      "Batch 50: loss = 0.3001519441604614, acc = 0.908203125\n",
      "Batch 51: loss = 0.2960105538368225, acc = 0.8955078125\n",
      "Batch 52: loss = 0.2969309687614441, acc = 0.900390625\n",
      "Batch 53: loss = 0.25503110885620117, acc = 0.9189453125\n",
      "Batch 54: loss = 0.2488444745540619, acc = 0.9189453125\n",
      "Batch 55: loss = 0.27265310287475586, acc = 0.9150390625\n",
      "Batch 56: loss = 0.29534804821014404, acc = 0.8974609375\n",
      "Batch 57: loss = 0.3334245979785919, acc = 0.8916015625\n",
      "Batch 58: loss = 0.32183581590652466, acc = 0.896484375\n",
      "Batch 59: loss = 0.2509229779243469, acc = 0.9228515625\n",
      "Batch 60: loss = 0.2960703372955322, acc = 0.900390625\n",
      "Batch 61: loss = 0.2979763448238373, acc = 0.9072265625\n",
      "Batch 62: loss = 0.32995331287384033, acc = 0.890625\n",
      "Batch 63: loss = 0.2775629460811615, acc = 0.9052734375\n",
      "Batch 64: loss = 0.2461339384317398, acc = 0.916015625\n",
      "Batch 65: loss = 0.297834187746048, acc = 0.8984375\n",
      "Batch 66: loss = 0.2922486364841461, acc = 0.9140625\n",
      "Batch 67: loss = 0.28217142820358276, acc = 0.9091796875\n",
      "Batch 68: loss = 0.3061802089214325, acc = 0.8935546875\n",
      "Batch 69: loss = 0.29228079319000244, acc = 0.9033203125\n",
      "Batch 70: loss = 0.3089965581893921, acc = 0.8955078125\n",
      "Batch 71: loss = 0.3118727505207062, acc = 0.8916015625\n",
      "Batch 72: loss = 0.2728976011276245, acc = 0.9130859375\n",
      "Batch 73: loss = 0.33400243520736694, acc = 0.89453125\n",
      "Batch 74: loss = 0.3127506375312805, acc = 0.8935546875\n",
      "Batch 75: loss = 0.32385164499282837, acc = 0.8818359375\n",
      "Batch 76: loss = 0.3029317259788513, acc = 0.8955078125\n",
      "Batch 77: loss = 0.2888137698173523, acc = 0.9013671875\n",
      "Batch 78: loss = 0.26992055773735046, acc = 0.916015625\n",
      "Batch 79: loss = 0.2956165671348572, acc = 0.892578125\n",
      "Batch 80: loss = 0.2928178608417511, acc = 0.90234375\n",
      "Batch 81: loss = 0.3014514446258545, acc = 0.8955078125\n",
      "Batch 82: loss = 0.30923905968666077, acc = 0.89453125\n",
      "Batch 83: loss = 0.30171865224838257, acc = 0.8974609375\n",
      "Batch 84: loss = 0.3412441313266754, acc = 0.8828125\n",
      "Batch 85: loss = 0.32130494713783264, acc = 0.888671875\n",
      "Batch 86: loss = 0.2784959673881531, acc = 0.9052734375\n",
      "Batch 87: loss = 0.3187941908836365, acc = 0.900390625\n",
      "Batch 88: loss = 0.34491419792175293, acc = 0.890625\n",
      "Batch 89: loss = 0.3116510510444641, acc = 0.912109375\n",
      "Batch 90: loss = 0.2878926992416382, acc = 0.904296875\n",
      "Batch 91: loss = 0.31146544218063354, acc = 0.89453125\n",
      "Batch 92: loss = 0.34731829166412354, acc = 0.888671875\n",
      "Batch 93: loss = 0.2809140682220459, acc = 0.8984375\n",
      "Batch 94: loss = 0.25909215211868286, acc = 0.921875\n",
      "Batch 95: loss = 0.2558547854423523, acc = 0.9189453125\n",
      "Batch 96: loss = 0.339555561542511, acc = 0.87890625\n",
      "Batch 97: loss = 0.3244444727897644, acc = 0.8857421875\n",
      "Batch 98: loss = 0.29640626907348633, acc = 0.9052734375\n",
      "Batch 99: loss = 0.31263259053230286, acc = 0.892578125\n",
      "Batch 100: loss = 0.3128305673599243, acc = 0.89453125\n",
      "Batch 101: loss = 0.2838815748691559, acc = 0.904296875\n",
      "Batch 102: loss = 0.32283496856689453, acc = 0.9033203125\n",
      "Batch 103: loss = 0.30046212673187256, acc = 0.90625\n",
      "Batch 104: loss = 0.25785067677497864, acc = 0.9111328125\n",
      "Batch 105: loss = 0.3219498097896576, acc = 0.89453125\n",
      "Batch 106: loss = 0.29527246952056885, acc = 0.90234375\n",
      "Batch 107: loss = 0.2698197662830353, acc = 0.9130859375\n",
      "Batch 108: loss = 0.27301621437072754, acc = 0.9033203125\n",
      "Batch 109: loss = 0.3040602505207062, acc = 0.8935546875\n",
      "Batch 110: loss = 0.2844746708869934, acc = 0.90625\n",
      "Batch 111: loss = 0.3149396777153015, acc = 0.904296875\n",
      "Batch 112: loss = 0.3241320252418518, acc = 0.8974609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 113: loss = 0.29790884256362915, acc = 0.8974609375\n",
      "Batch 114: loss = 0.30390650033950806, acc = 0.9072265625\n",
      "Batch 115: loss = 0.30982714891433716, acc = 0.8994140625\n",
      "Batch 116: loss = 0.31830501556396484, acc = 0.896484375\n",
      "Batch 117: loss = 0.3044466972351074, acc = 0.892578125\n",
      "Batch 118: loss = 0.2640032172203064, acc = 0.912109375\n",
      "Batch 119: loss = 0.298420250415802, acc = 0.890625\n",
      "Batch 120: loss = 0.25642186403274536, acc = 0.91796875\n",
      "Batch 121: loss = 0.2988414764404297, acc = 0.892578125\n",
      "Batch 122: loss = 0.3005634546279907, acc = 0.8955078125\n",
      "Batch 123: loss = 0.30964237451553345, acc = 0.8916015625\n",
      "Batch 124: loss = 0.3261559307575226, acc = 0.90234375\n",
      "Batch 125: loss = 0.3298749029636383, acc = 0.8857421875\n",
      "Batch 126: loss = 0.3233013153076172, acc = 0.8974609375\n",
      "\n",
      "Epoch 75/100\n",
      "Batch 1: loss = 0.41912728548049927, acc = 0.8759765625\n",
      "Batch 2: loss = 0.29452794790267944, acc = 0.8955078125\n",
      "Batch 3: loss = 0.3250889182090759, acc = 0.890625\n",
      "Batch 4: loss = 0.2967417240142822, acc = 0.9111328125\n",
      "Batch 5: loss = 0.3120253086090088, acc = 0.8994140625\n",
      "Batch 6: loss = 0.3085395097732544, acc = 0.9013671875\n",
      "Batch 7: loss = 0.33941301703453064, acc = 0.884765625\n",
      "Batch 8: loss = 0.3215283155441284, acc = 0.8916015625\n",
      "Batch 9: loss = 0.2665099501609802, acc = 0.912109375\n",
      "Batch 10: loss = 0.25304415822029114, acc = 0.912109375\n",
      "Batch 11: loss = 0.28480273485183716, acc = 0.900390625\n",
      "Batch 12: loss = 0.31521445512771606, acc = 0.890625\n",
      "Batch 13: loss = 0.3047376275062561, acc = 0.8984375\n",
      "Batch 14: loss = 0.28477370738983154, acc = 0.9140625\n",
      "Batch 15: loss = 0.2865101099014282, acc = 0.9169921875\n",
      "Batch 16: loss = 0.30473047494888306, acc = 0.9072265625\n",
      "Batch 17: loss = 0.2882566452026367, acc = 0.90234375\n",
      "Batch 18: loss = 0.29649150371551514, acc = 0.8916015625\n",
      "Batch 19: loss = 0.3257733881473541, acc = 0.89453125\n",
      "Batch 20: loss = 0.2796878218650818, acc = 0.896484375\n",
      "Batch 21: loss = 0.34461086988449097, acc = 0.87890625\n",
      "Batch 22: loss = 0.3341090679168701, acc = 0.8935546875\n",
      "Batch 23: loss = 0.30046504735946655, acc = 0.8984375\n",
      "Batch 24: loss = 0.3075498342514038, acc = 0.8994140625\n",
      "Batch 25: loss = 0.30647093057632446, acc = 0.8974609375\n",
      "Batch 26: loss = 0.30735427141189575, acc = 0.908203125\n",
      "Batch 27: loss = 0.317876935005188, acc = 0.900390625\n",
      "Batch 28: loss = 0.3095763325691223, acc = 0.8828125\n",
      "Batch 29: loss = 0.31547632813453674, acc = 0.8876953125\n",
      "Batch 30: loss = 0.30543044209480286, acc = 0.8876953125\n",
      "Batch 31: loss = 0.29548293352127075, acc = 0.90234375\n",
      "Batch 32: loss = 0.3294242024421692, acc = 0.8955078125\n",
      "Batch 33: loss = 0.27662259340286255, acc = 0.9091796875\n",
      "Batch 34: loss = 0.2997259795665741, acc = 0.9072265625\n",
      "Batch 35: loss = 0.3054433763027191, acc = 0.908203125\n",
      "Batch 36: loss = 0.27641674876213074, acc = 0.8984375\n",
      "Batch 37: loss = 0.27701130509376526, acc = 0.90625\n",
      "Batch 38: loss = 0.2997579872608185, acc = 0.900390625\n",
      "Batch 39: loss = 0.2654186487197876, acc = 0.908203125\n",
      "Batch 40: loss = 0.29906824231147766, acc = 0.90234375\n",
      "Batch 41: loss = 0.28764939308166504, acc = 0.900390625\n",
      "Batch 42: loss = 0.30995434522628784, acc = 0.8876953125\n",
      "Batch 43: loss = 0.3098152279853821, acc = 0.8916015625\n",
      "Batch 44: loss = 0.2699113190174103, acc = 0.9169921875\n",
      "Batch 45: loss = 0.2714041769504547, acc = 0.90625\n",
      "Batch 46: loss = 0.2699669599533081, acc = 0.9111328125\n",
      "Batch 47: loss = 0.28075140714645386, acc = 0.9091796875\n",
      "Batch 48: loss = 0.2845333218574524, acc = 0.9033203125\n",
      "Batch 49: loss = 0.27925509214401245, acc = 0.9033203125\n",
      "Batch 50: loss = 0.2409655749797821, acc = 0.9248046875\n",
      "Batch 51: loss = 0.2776798605918884, acc = 0.9033203125\n",
      "Batch 52: loss = 0.2627667784690857, acc = 0.9033203125\n",
      "Batch 53: loss = 0.2780440151691437, acc = 0.9150390625\n",
      "Batch 54: loss = 0.24867939949035645, acc = 0.9111328125\n",
      "Batch 55: loss = 0.23695698380470276, acc = 0.931640625\n",
      "Batch 56: loss = 0.31791168451309204, acc = 0.892578125\n",
      "Batch 57: loss = 0.2959297299385071, acc = 0.884765625\n",
      "Batch 58: loss = 0.34925001859664917, acc = 0.89453125\n",
      "Batch 59: loss = 0.265491783618927, acc = 0.9072265625\n",
      "Batch 60: loss = 0.2924560010433197, acc = 0.9072265625\n",
      "Batch 61: loss = 0.2727871835231781, acc = 0.91015625\n",
      "Batch 62: loss = 0.33231306076049805, acc = 0.880859375\n",
      "Batch 63: loss = 0.2959388196468353, acc = 0.9150390625\n",
      "Batch 64: loss = 0.26959896087646484, acc = 0.90625\n",
      "Batch 65: loss = 0.31023433804512024, acc = 0.888671875\n",
      "Batch 66: loss = 0.3242059648036957, acc = 0.8974609375\n",
      "Batch 67: loss = 0.29865550994873047, acc = 0.8896484375\n",
      "Batch 68: loss = 0.30031469464302063, acc = 0.900390625\n",
      "Batch 69: loss = 0.2773260474205017, acc = 0.908203125\n",
      "Batch 70: loss = 0.3627367317676544, acc = 0.875\n",
      "Batch 71: loss = 0.29551881551742554, acc = 0.892578125\n",
      "Batch 72: loss = 0.3029499650001526, acc = 0.90234375\n",
      "Batch 73: loss = 0.32216155529022217, acc = 0.8994140625\n",
      "Batch 74: loss = 0.3483678996562958, acc = 0.8779296875\n",
      "Batch 75: loss = 0.32936644554138184, acc = 0.8935546875\n",
      "Batch 76: loss = 0.31449055671691895, acc = 0.9033203125\n",
      "Batch 77: loss = 0.30274030566215515, acc = 0.8994140625\n",
      "Batch 78: loss = 0.3206979036331177, acc = 0.8896484375\n",
      "Batch 79: loss = 0.2802789509296417, acc = 0.9091796875\n",
      "Batch 80: loss = 0.29948490858078003, acc = 0.896484375\n",
      "Batch 81: loss = 0.28938794136047363, acc = 0.9013671875\n",
      "Batch 82: loss = 0.3181418776512146, acc = 0.89453125\n",
      "Batch 83: loss = 0.28450867533683777, acc = 0.8994140625\n",
      "Batch 84: loss = 0.30600130558013916, acc = 0.8916015625\n",
      "Batch 85: loss = 0.31883448362350464, acc = 0.884765625\n",
      "Batch 86: loss = 0.3121298551559448, acc = 0.892578125\n",
      "Batch 87: loss = 0.2804662883281708, acc = 0.9033203125\n",
      "Batch 88: loss = 0.33781465888023376, acc = 0.8857421875\n",
      "Batch 89: loss = 0.3021562099456787, acc = 0.8974609375\n",
      "Batch 90: loss = 0.29159438610076904, acc = 0.904296875\n",
      "Batch 91: loss = 0.33382076025009155, acc = 0.8857421875\n",
      "Batch 92: loss = 0.3443751931190491, acc = 0.884765625\n",
      "Batch 93: loss = 0.2689822018146515, acc = 0.90625\n",
      "Batch 94: loss = 0.25681471824645996, acc = 0.9130859375\n",
      "Batch 95: loss = 0.29031550884246826, acc = 0.9052734375\n",
      "Batch 96: loss = 0.28473925590515137, acc = 0.892578125\n",
      "Batch 97: loss = 0.3245833218097687, acc = 0.892578125\n",
      "Batch 98: loss = 0.2874295711517334, acc = 0.9033203125\n",
      "Batch 99: loss = 0.31619903445243835, acc = 0.8818359375\n",
      "Batch 100: loss = 0.3074103593826294, acc = 0.8857421875\n",
      "Batch 101: loss = 0.28624963760375977, acc = 0.8935546875\n",
      "Batch 102: loss = 0.3192812204360962, acc = 0.8935546875\n",
      "Batch 103: loss = 0.28578534722328186, acc = 0.9033203125\n",
      "Batch 104: loss = 0.311021625995636, acc = 0.892578125\n",
      "Batch 105: loss = 0.2731086015701294, acc = 0.912109375\n",
      "Batch 106: loss = 0.2758631408214569, acc = 0.90234375\n",
      "Batch 107: loss = 0.2605327069759369, acc = 0.91796875\n",
      "Batch 108: loss = 0.2685830593109131, acc = 0.900390625\n",
      "Batch 109: loss = 0.2732049226760864, acc = 0.91015625\n",
      "Batch 110: loss = 0.2731761336326599, acc = 0.91796875\n",
      "Batch 111: loss = 0.3010638654232025, acc = 0.9033203125\n",
      "Batch 112: loss = 0.2849717140197754, acc = 0.9052734375\n",
      "Batch 113: loss = 0.31241071224212646, acc = 0.896484375\n",
      "Batch 114: loss = 0.3389817476272583, acc = 0.890625\n",
      "Batch 115: loss = 0.3138797879219055, acc = 0.90234375\n",
      "Batch 116: loss = 0.3274756073951721, acc = 0.888671875\n",
      "Batch 117: loss = 0.3004639148712158, acc = 0.8984375\n",
      "Batch 118: loss = 0.2569578289985657, acc = 0.9140625\n",
      "Batch 119: loss = 0.30505260825157166, acc = 0.8984375\n",
      "Batch 120: loss = 0.25683921575546265, acc = 0.9111328125\n",
      "Batch 121: loss = 0.3012344241142273, acc = 0.8974609375\n",
      "Batch 122: loss = 0.2651958167552948, acc = 0.9111328125\n",
      "Batch 123: loss = 0.28077223896980286, acc = 0.9072265625\n",
      "Batch 124: loss = 0.3071347773075104, acc = 0.8916015625\n",
      "Batch 125: loss = 0.339026540517807, acc = 0.8818359375\n",
      "Batch 126: loss = 0.319485068321228, acc = 0.8984375\n",
      "\n",
      "Epoch 76/100\n",
      "Batch 1: loss = 0.4119681119918823, acc = 0.87890625\n",
      "Batch 2: loss = 0.30536678433418274, acc = 0.8974609375\n",
      "Batch 3: loss = 0.27836158871650696, acc = 0.9130859375\n",
      "Batch 4: loss = 0.3172428011894226, acc = 0.8994140625\n",
      "Batch 5: loss = 0.3241119980812073, acc = 0.888671875\n",
      "Batch 6: loss = 0.3364996910095215, acc = 0.884765625\n",
      "Batch 7: loss = 0.26666224002838135, acc = 0.9091796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8: loss = 0.29887425899505615, acc = 0.90234375\n",
      "Batch 9: loss = 0.28625860810279846, acc = 0.8994140625\n",
      "Batch 10: loss = 0.2881222665309906, acc = 0.9091796875\n",
      "Batch 11: loss = 0.2745780348777771, acc = 0.91015625\n",
      "Batch 12: loss = 0.3217717409133911, acc = 0.8837890625\n",
      "Batch 13: loss = 0.2830297350883484, acc = 0.90234375\n",
      "Batch 14: loss = 0.28309202194213867, acc = 0.921875\n",
      "Batch 15: loss = 0.30018481612205505, acc = 0.8994140625\n",
      "Batch 16: loss = 0.30097341537475586, acc = 0.908203125\n",
      "Batch 17: loss = 0.2890494167804718, acc = 0.9091796875\n",
      "Batch 18: loss = 0.278067022562027, acc = 0.9052734375\n",
      "Batch 19: loss = 0.29742130637168884, acc = 0.900390625\n",
      "Batch 20: loss = 0.28786033391952515, acc = 0.8974609375\n",
      "Batch 21: loss = 0.3236796259880066, acc = 0.8994140625\n",
      "Batch 22: loss = 0.32670295238494873, acc = 0.8896484375\n",
      "Batch 23: loss = 0.29521578550338745, acc = 0.896484375\n",
      "Batch 24: loss = 0.27168118953704834, acc = 0.9013671875\n",
      "Batch 25: loss = 0.29796838760375977, acc = 0.908203125\n",
      "Batch 26: loss = 0.28433680534362793, acc = 0.90234375\n",
      "Batch 27: loss = 0.31138384342193604, acc = 0.8916015625\n",
      "Batch 28: loss = 0.30187109112739563, acc = 0.8984375\n",
      "Batch 29: loss = 0.3352534770965576, acc = 0.8779296875\n",
      "Batch 30: loss = 0.2989380359649658, acc = 0.9052734375\n",
      "Batch 31: loss = 0.33233338594436646, acc = 0.892578125\n",
      "Batch 32: loss = 0.31845933198928833, acc = 0.88671875\n",
      "Batch 33: loss = 0.25467976927757263, acc = 0.9013671875\n",
      "Batch 34: loss = 0.35061997175216675, acc = 0.88671875\n",
      "Batch 35: loss = 0.31154248118400574, acc = 0.8955078125\n",
      "Batch 36: loss = 0.2364622801542282, acc = 0.9228515625\n",
      "Batch 37: loss = 0.2656697928905487, acc = 0.9091796875\n",
      "Batch 38: loss = 0.2942647337913513, acc = 0.8974609375\n",
      "Batch 39: loss = 0.2615297734737396, acc = 0.916015625\n",
      "Batch 40: loss = 0.31624263525009155, acc = 0.890625\n",
      "Batch 41: loss = 0.2768230438232422, acc = 0.91796875\n",
      "Batch 42: loss = 0.28811150789260864, acc = 0.9111328125\n",
      "Batch 43: loss = 0.3206114172935486, acc = 0.8955078125\n",
      "Batch 44: loss = 0.3303472101688385, acc = 0.8994140625\n",
      "Batch 45: loss = 0.25999921560287476, acc = 0.9169921875\n",
      "Batch 46: loss = 0.2518279552459717, acc = 0.9111328125\n",
      "Batch 47: loss = 0.2609136700630188, acc = 0.9248046875\n",
      "Batch 48: loss = 0.27271920442581177, acc = 0.9091796875\n",
      "Batch 49: loss = 0.29297488927841187, acc = 0.9052734375\n",
      "Batch 50: loss = 0.2682892680168152, acc = 0.9033203125\n",
      "Batch 51: loss = 0.2962082624435425, acc = 0.90234375\n",
      "Batch 52: loss = 0.27571171522140503, acc = 0.912109375\n",
      "Batch 53: loss = 0.32995569705963135, acc = 0.8916015625\n",
      "Batch 54: loss = 0.23430606722831726, acc = 0.919921875\n",
      "Batch 55: loss = 0.2707194983959198, acc = 0.9130859375\n",
      "Batch 56: loss = 0.2832927703857422, acc = 0.8974609375\n",
      "Batch 57: loss = 0.2921673059463501, acc = 0.8818359375\n",
      "Batch 58: loss = 0.3263285160064697, acc = 0.8994140625\n",
      "Batch 59: loss = 0.23604151606559753, acc = 0.9248046875\n",
      "Batch 60: loss = 0.3034053444862366, acc = 0.900390625\n",
      "Batch 61: loss = 0.26812833547592163, acc = 0.908203125\n",
      "Batch 62: loss = 0.3465953469276428, acc = 0.8896484375\n",
      "Batch 63: loss = 0.28494584560394287, acc = 0.9072265625\n",
      "Batch 64: loss = 0.28545504808425903, acc = 0.9072265625\n",
      "Batch 65: loss = 0.2943834662437439, acc = 0.9130859375\n",
      "Batch 66: loss = 0.29533499479293823, acc = 0.89453125\n",
      "Batch 67: loss = 0.3045574426651001, acc = 0.8994140625\n",
      "Batch 68: loss = 0.2883114516735077, acc = 0.9013671875\n",
      "Batch 69: loss = 0.2657136917114258, acc = 0.9150390625\n",
      "Batch 70: loss = 0.31736916303634644, acc = 0.8916015625\n",
      "Batch 71: loss = 0.29012972116470337, acc = 0.9033203125\n",
      "Batch 72: loss = 0.29503515362739563, acc = 0.9013671875\n",
      "Batch 73: loss = 0.3240054249763489, acc = 0.892578125\n",
      "Batch 74: loss = 0.31178218126296997, acc = 0.892578125\n",
      "Batch 75: loss = 0.328302800655365, acc = 0.87890625\n",
      "Batch 76: loss = 0.29165565967559814, acc = 0.8994140625\n",
      "Batch 77: loss = 0.30058932304382324, acc = 0.900390625\n",
      "Batch 78: loss = 0.3324974775314331, acc = 0.8857421875\n",
      "Batch 79: loss = 0.25153857469558716, acc = 0.923828125\n",
      "Batch 80: loss = 0.27111753821372986, acc = 0.908203125\n",
      "Batch 81: loss = 0.2930305600166321, acc = 0.8984375\n",
      "Batch 82: loss = 0.3081541955471039, acc = 0.8955078125\n",
      "Batch 83: loss = 0.314003050327301, acc = 0.8974609375\n",
      "Batch 84: loss = 0.29137158393859863, acc = 0.9072265625\n",
      "Batch 85: loss = 0.31068354845046997, acc = 0.884765625\n",
      "Batch 86: loss = 0.30731284618377686, acc = 0.896484375\n",
      "Batch 87: loss = 0.2818964719772339, acc = 0.90234375\n",
      "Batch 88: loss = 0.3289329409599304, acc = 0.8876953125\n",
      "Batch 89: loss = 0.2891061305999756, acc = 0.9091796875\n",
      "Batch 90: loss = 0.3446959853172302, acc = 0.875\n",
      "Batch 91: loss = 0.31532955169677734, acc = 0.90234375\n",
      "Batch 92: loss = 0.3027721643447876, acc = 0.890625\n",
      "Batch 93: loss = 0.27339407801628113, acc = 0.9052734375\n",
      "Batch 94: loss = 0.28244930505752563, acc = 0.8994140625\n",
      "Batch 95: loss = 0.2632790803909302, acc = 0.9072265625\n",
      "Batch 96: loss = 0.3012373745441437, acc = 0.9013671875\n",
      "Batch 97: loss = 0.30820634961128235, acc = 0.8994140625\n",
      "Batch 98: loss = 0.2922835052013397, acc = 0.9013671875\n",
      "Batch 99: loss = 0.31590020656585693, acc = 0.8955078125\n",
      "Batch 100: loss = 0.3102867305278778, acc = 0.9033203125\n",
      "Batch 101: loss = 0.2916337251663208, acc = 0.900390625\n",
      "Batch 102: loss = 0.31290680170059204, acc = 0.8974609375\n",
      "Batch 103: loss = 0.3156382441520691, acc = 0.8955078125\n",
      "Batch 104: loss = 0.2822723090648651, acc = 0.90625\n",
      "Batch 105: loss = 0.25928768515586853, acc = 0.9130859375\n",
      "Batch 106: loss = 0.27421027421951294, acc = 0.9033203125\n",
      "Batch 107: loss = 0.28488531708717346, acc = 0.9072265625\n",
      "Batch 108: loss = 0.28436923027038574, acc = 0.90625\n",
      "Batch 109: loss = 0.2605525255203247, acc = 0.916015625\n",
      "Batch 110: loss = 0.28019246459007263, acc = 0.91015625\n",
      "Batch 111: loss = 0.3327210545539856, acc = 0.8935546875\n",
      "Batch 112: loss = 0.2676251232624054, acc = 0.900390625\n",
      "Batch 113: loss = 0.32366886734962463, acc = 0.8984375\n",
      "Batch 114: loss = 0.32634198665618896, acc = 0.89453125\n",
      "Batch 115: loss = 0.3049241602420807, acc = 0.896484375\n",
      "Batch 116: loss = 0.2766944169998169, acc = 0.9091796875\n",
      "Batch 117: loss = 0.3258932828903198, acc = 0.900390625\n",
      "Batch 118: loss = 0.2661767601966858, acc = 0.90625\n",
      "Batch 119: loss = 0.26649922132492065, acc = 0.9169921875\n",
      "Batch 120: loss = 0.25705307722091675, acc = 0.9169921875\n",
      "Batch 121: loss = 0.2713329493999481, acc = 0.9072265625\n",
      "Batch 122: loss = 0.2874044179916382, acc = 0.9013671875\n",
      "Batch 123: loss = 0.28642719984054565, acc = 0.9013671875\n",
      "Batch 124: loss = 0.28607356548309326, acc = 0.900390625\n",
      "Batch 125: loss = 0.30250662565231323, acc = 0.900390625\n",
      "Batch 126: loss = 0.2899155914783478, acc = 0.9052734375\n",
      "\n",
      "Epoch 77/100\n",
      "Batch 1: loss = 0.4446452558040619, acc = 0.8701171875\n",
      "Batch 2: loss = 0.28107404708862305, acc = 0.904296875\n",
      "Batch 3: loss = 0.30332449078559875, acc = 0.900390625\n",
      "Batch 4: loss = 0.2843800485134125, acc = 0.90625\n",
      "Batch 5: loss = 0.29454153776168823, acc = 0.892578125\n",
      "Batch 6: loss = 0.3038676083087921, acc = 0.904296875\n",
      "Batch 7: loss = 0.28582364320755005, acc = 0.8994140625\n",
      "Batch 8: loss = 0.30648452043533325, acc = 0.9033203125\n",
      "Batch 9: loss = 0.3303201198577881, acc = 0.8994140625\n",
      "Batch 10: loss = 0.26733097434043884, acc = 0.912109375\n",
      "Batch 11: loss = 0.2801370620727539, acc = 0.91015625\n",
      "Batch 12: loss = 0.25583234429359436, acc = 0.908203125\n",
      "Batch 13: loss = 0.27735692262649536, acc = 0.9072265625\n",
      "Batch 14: loss = 0.26592227816581726, acc = 0.9130859375\n",
      "Batch 15: loss = 0.2414921522140503, acc = 0.9189453125\n",
      "Batch 16: loss = 0.2731960415840149, acc = 0.9140625\n",
      "Batch 17: loss = 0.3114011883735657, acc = 0.892578125\n",
      "Batch 18: loss = 0.24118363857269287, acc = 0.9296875\n",
      "Batch 19: loss = 0.27189308404922485, acc = 0.912109375\n",
      "Batch 20: loss = 0.29734307527542114, acc = 0.896484375\n",
      "Batch 21: loss = 0.3258287310600281, acc = 0.89453125\n",
      "Batch 22: loss = 0.3233547806739807, acc = 0.892578125\n",
      "Batch 23: loss = 0.2939046025276184, acc = 0.8984375\n",
      "Batch 24: loss = 0.2726631760597229, acc = 0.9111328125\n",
      "Batch 25: loss = 0.2691987156867981, acc = 0.9052734375\n",
      "Batch 26: loss = 0.27514564990997314, acc = 0.9033203125\n",
      "Batch 27: loss = 0.33949601650238037, acc = 0.8876953125\n",
      "Batch 28: loss = 0.310820609331131, acc = 0.892578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 29: loss = 0.29253000020980835, acc = 0.9052734375\n",
      "Batch 30: loss = 0.2678608298301697, acc = 0.9130859375\n",
      "Batch 31: loss = 0.30602139234542847, acc = 0.892578125\n",
      "Batch 32: loss = 0.30700618028640747, acc = 0.896484375\n",
      "Batch 33: loss = 0.2703525722026825, acc = 0.8974609375\n",
      "Batch 34: loss = 0.2976727783679962, acc = 0.896484375\n",
      "Batch 35: loss = 0.29858702421188354, acc = 0.9013671875\n",
      "Batch 36: loss = 0.2774033546447754, acc = 0.9140625\n",
      "Batch 37: loss = 0.2836361229419708, acc = 0.9033203125\n",
      "Batch 38: loss = 0.2790709435939789, acc = 0.9111328125\n",
      "Batch 39: loss = 0.2480275183916092, acc = 0.9111328125\n",
      "Batch 40: loss = 0.26980340480804443, acc = 0.912109375\n",
      "Batch 41: loss = 0.27878087759017944, acc = 0.9052734375\n",
      "Batch 42: loss = 0.3153373599052429, acc = 0.884765625\n",
      "Batch 43: loss = 0.2779187262058258, acc = 0.9140625\n",
      "Batch 44: loss = 0.2969794273376465, acc = 0.9013671875\n",
      "Batch 45: loss = 0.2613939046859741, acc = 0.923828125\n",
      "Batch 46: loss = 0.2602682113647461, acc = 0.9130859375\n",
      "Batch 47: loss = 0.2805786728858948, acc = 0.919921875\n",
      "Batch 48: loss = 0.28570765256881714, acc = 0.90625\n",
      "Batch 49: loss = 0.2719840407371521, acc = 0.9140625\n",
      "Batch 50: loss = 0.2540820837020874, acc = 0.9140625\n",
      "Batch 51: loss = 0.23765544593334198, acc = 0.91796875\n",
      "Batch 52: loss = 0.2990586757659912, acc = 0.9052734375\n",
      "Batch 53: loss = 0.30866163969039917, acc = 0.8994140625\n",
      "Batch 54: loss = 0.24380218982696533, acc = 0.9140625\n",
      "Batch 55: loss = 0.27336499094963074, acc = 0.9130859375\n",
      "Batch 56: loss = 0.2853151261806488, acc = 0.904296875\n",
      "Batch 57: loss = 0.3219066858291626, acc = 0.8798828125\n",
      "Batch 58: loss = 0.32404667139053345, acc = 0.896484375\n",
      "Batch 59: loss = 0.23655670881271362, acc = 0.919921875\n",
      "Batch 60: loss = 0.2743949890136719, acc = 0.91015625\n",
      "Batch 61: loss = 0.27247655391693115, acc = 0.912109375\n",
      "Batch 62: loss = 0.3220542371273041, acc = 0.896484375\n",
      "Batch 63: loss = 0.268541157245636, acc = 0.9111328125\n",
      "Batch 64: loss = 0.2669239044189453, acc = 0.908203125\n",
      "Batch 65: loss = 0.32149672508239746, acc = 0.8916015625\n",
      "Batch 66: loss = 0.27257758378982544, acc = 0.900390625\n",
      "Batch 67: loss = 0.2582688629627228, acc = 0.912109375\n",
      "Batch 68: loss = 0.2749260663986206, acc = 0.91015625\n",
      "Batch 69: loss = 0.24326160550117493, acc = 0.9130859375\n",
      "Batch 70: loss = 0.29530003666877747, acc = 0.9072265625\n",
      "Batch 71: loss = 0.2992873191833496, acc = 0.8955078125\n",
      "Batch 72: loss = 0.23276287317276, acc = 0.9248046875\n",
      "Batch 73: loss = 0.32031452655792236, acc = 0.88671875\n",
      "Batch 74: loss = 0.3309114873409271, acc = 0.892578125\n",
      "Batch 75: loss = 0.3201890289783478, acc = 0.8857421875\n",
      "Batch 76: loss = 0.3345601558685303, acc = 0.888671875\n",
      "Batch 77: loss = 0.3075335621833801, acc = 0.892578125\n",
      "Batch 78: loss = 0.29973018169403076, acc = 0.90234375\n",
      "Batch 79: loss = 0.2922753691673279, acc = 0.9033203125\n",
      "Batch 80: loss = 0.24509364366531372, acc = 0.9150390625\n",
      "Batch 81: loss = 0.2879909873008728, acc = 0.9052734375\n",
      "Batch 82: loss = 0.3099125623703003, acc = 0.890625\n",
      "Batch 83: loss = 0.28477543592453003, acc = 0.912109375\n",
      "Batch 84: loss = 0.2788868844509125, acc = 0.9052734375\n",
      "Batch 85: loss = 0.31260910630226135, acc = 0.8955078125\n",
      "Batch 86: loss = 0.29586106538772583, acc = 0.8994140625\n",
      "Batch 87: loss = 0.2736428678035736, acc = 0.9140625\n",
      "Batch 88: loss = 0.3339334726333618, acc = 0.89453125\n",
      "Batch 89: loss = 0.2617396116256714, acc = 0.916015625\n",
      "Batch 90: loss = 0.3195338249206543, acc = 0.8984375\n",
      "Batch 91: loss = 0.30197930335998535, acc = 0.90625\n",
      "Batch 92: loss = 0.3189755976200104, acc = 0.8974609375\n",
      "Batch 93: loss = 0.2634173631668091, acc = 0.908203125\n",
      "Batch 94: loss = 0.27275317907333374, acc = 0.9150390625\n",
      "Batch 95: loss = 0.29829347133636475, acc = 0.892578125\n",
      "Batch 96: loss = 0.3121926188468933, acc = 0.8837890625\n",
      "Batch 97: loss = 0.2949638366699219, acc = 0.9033203125\n",
      "Batch 98: loss = 0.2944570779800415, acc = 0.9013671875\n",
      "Batch 99: loss = 0.29206225275993347, acc = 0.9013671875\n",
      "Batch 100: loss = 0.305090993642807, acc = 0.8955078125\n",
      "Batch 101: loss = 0.29114675521850586, acc = 0.8974609375\n",
      "Batch 102: loss = 0.30714690685272217, acc = 0.892578125\n",
      "Batch 103: loss = 0.3224438726902008, acc = 0.90234375\n",
      "Batch 104: loss = 0.2569211721420288, acc = 0.9140625\n",
      "Batch 105: loss = 0.2861364781856537, acc = 0.90234375\n",
      "Batch 106: loss = 0.25774240493774414, acc = 0.9091796875\n",
      "Batch 107: loss = 0.279900461435318, acc = 0.9052734375\n",
      "Batch 108: loss = 0.2716366648674011, acc = 0.91015625\n",
      "Batch 109: loss = 0.2915405035018921, acc = 0.912109375\n",
      "Batch 110: loss = 0.300260066986084, acc = 0.8994140625\n",
      "Batch 111: loss = 0.281488835811615, acc = 0.9033203125\n",
      "Batch 112: loss = 0.28559207916259766, acc = 0.8974609375\n",
      "Batch 113: loss = 0.26567524671554565, acc = 0.9091796875\n",
      "Batch 114: loss = 0.2984551191329956, acc = 0.900390625\n",
      "Batch 115: loss = 0.3039727509021759, acc = 0.8916015625\n",
      "Batch 116: loss = 0.307692289352417, acc = 0.9052734375\n",
      "Batch 117: loss = 0.31070613861083984, acc = 0.90234375\n",
      "Batch 118: loss = 0.2639714479446411, acc = 0.9150390625\n",
      "Batch 119: loss = 0.26567575335502625, acc = 0.908203125\n",
      "Batch 120: loss = 0.23696887493133545, acc = 0.919921875\n",
      "Batch 121: loss = 0.29529231786727905, acc = 0.89453125\n",
      "Batch 122: loss = 0.280510812997818, acc = 0.9033203125\n",
      "Batch 123: loss = 0.2693021297454834, acc = 0.9072265625\n",
      "Batch 124: loss = 0.3283036947250366, acc = 0.880859375\n",
      "Batch 125: loss = 0.2972763180732727, acc = 0.9072265625\n",
      "Batch 126: loss = 0.30865415930747986, acc = 0.8955078125\n",
      "\n",
      "Epoch 78/100\n",
      "Batch 1: loss = 0.4378155767917633, acc = 0.8828125\n",
      "Batch 2: loss = 0.3061583638191223, acc = 0.890625\n",
      "Batch 3: loss = 0.30320942401885986, acc = 0.900390625\n",
      "Batch 4: loss = 0.2986164689064026, acc = 0.91015625\n",
      "Batch 5: loss = 0.30395618081092834, acc = 0.8994140625\n",
      "Batch 6: loss = 0.3165157735347748, acc = 0.8916015625\n",
      "Batch 7: loss = 0.2713688611984253, acc = 0.9150390625\n",
      "Batch 8: loss = 0.33403539657592773, acc = 0.8935546875\n",
      "Batch 9: loss = 0.26356905698776245, acc = 0.90625\n",
      "Batch 10: loss = 0.27460354566574097, acc = 0.908203125\n",
      "Batch 11: loss = 0.27264919877052307, acc = 0.9072265625\n",
      "Batch 12: loss = 0.23019379377365112, acc = 0.931640625\n",
      "Batch 13: loss = 0.32257533073425293, acc = 0.8828125\n",
      "Batch 14: loss = 0.30799466371536255, acc = 0.908203125\n",
      "Batch 15: loss = 0.2793193757534027, acc = 0.9091796875\n",
      "Batch 16: loss = 0.2750168442726135, acc = 0.916015625\n",
      "Batch 17: loss = 0.2785874903202057, acc = 0.912109375\n",
      "Batch 18: loss = 0.25438985228538513, acc = 0.908203125\n",
      "Batch 19: loss = 0.3031527101993561, acc = 0.9033203125\n",
      "Batch 20: loss = 0.2795700430870056, acc = 0.9072265625\n",
      "Batch 21: loss = 0.3290519714355469, acc = 0.888671875\n",
      "Batch 22: loss = 0.3066943883895874, acc = 0.89453125\n",
      "Batch 23: loss = 0.29687610268592834, acc = 0.9150390625\n",
      "Batch 24: loss = 0.2736198306083679, acc = 0.91015625\n",
      "Batch 25: loss = 0.27781978249549866, acc = 0.9111328125\n",
      "Batch 26: loss = 0.27605313062667847, acc = 0.9033203125\n",
      "Batch 27: loss = 0.319622278213501, acc = 0.8857421875\n",
      "Batch 28: loss = 0.3076627850532532, acc = 0.8984375\n",
      "Batch 29: loss = 0.2905317544937134, acc = 0.90234375\n",
      "Batch 30: loss = 0.3048419952392578, acc = 0.8916015625\n",
      "Batch 31: loss = 0.3078513443470001, acc = 0.88671875\n",
      "Batch 32: loss = 0.3403709828853607, acc = 0.888671875\n",
      "Batch 33: loss = 0.26953548192977905, acc = 0.9091796875\n",
      "Batch 34: loss = 0.3036907911300659, acc = 0.908203125\n",
      "Batch 35: loss = 0.30885186791419983, acc = 0.896484375\n",
      "Batch 36: loss = 0.23738116025924683, acc = 0.9189453125\n",
      "Batch 37: loss = 0.279840350151062, acc = 0.9130859375\n",
      "Batch 38: loss = 0.2662743926048279, acc = 0.9111328125\n",
      "Batch 39: loss = 0.2560894787311554, acc = 0.9169921875\n",
      "Batch 40: loss = 0.31516456604003906, acc = 0.9013671875\n",
      "Batch 41: loss = 0.2530480623245239, acc = 0.916015625\n",
      "Batch 42: loss = 0.2938298285007477, acc = 0.9052734375\n",
      "Batch 43: loss = 0.31563544273376465, acc = 0.8896484375\n",
      "Batch 44: loss = 0.2924460172653198, acc = 0.91015625\n",
      "Batch 45: loss = 0.24589568376541138, acc = 0.9228515625\n",
      "Batch 46: loss = 0.2607986330986023, acc = 0.9111328125\n",
      "Batch 47: loss = 0.2883787453174591, acc = 0.908203125\n",
      "Batch 48: loss = 0.26637160778045654, acc = 0.9091796875\n",
      "Batch 49: loss = 0.2805711030960083, acc = 0.9091796875\n",
      "Batch 50: loss = 0.25766658782958984, acc = 0.912109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 51: loss = 0.28716734051704407, acc = 0.9013671875\n",
      "Batch 52: loss = 0.2739614248275757, acc = 0.90625\n",
      "Batch 53: loss = 0.2741588056087494, acc = 0.9072265625\n",
      "Batch 54: loss = 0.2753834128379822, acc = 0.91015625\n",
      "Batch 55: loss = 0.26758304238319397, acc = 0.9130859375\n",
      "Batch 56: loss = 0.2738390564918518, acc = 0.9111328125\n",
      "Batch 57: loss = 0.2767423987388611, acc = 0.9111328125\n",
      "Batch 58: loss = 0.2987273335456848, acc = 0.8974609375\n",
      "Batch 59: loss = 0.22631458938121796, acc = 0.9228515625\n",
      "Batch 60: loss = 0.31242835521698, acc = 0.892578125\n",
      "Batch 61: loss = 0.26121458411216736, acc = 0.91796875\n",
      "Batch 62: loss = 0.31899750232696533, acc = 0.8857421875\n",
      "Batch 63: loss = 0.2787576913833618, acc = 0.9140625\n",
      "Batch 64: loss = 0.2742706537246704, acc = 0.9111328125\n",
      "Batch 65: loss = 0.30911391973495483, acc = 0.900390625\n",
      "Batch 66: loss = 0.2875351905822754, acc = 0.90234375\n",
      "Batch 67: loss = 0.2958855926990509, acc = 0.8984375\n",
      "Batch 68: loss = 0.28514283895492554, acc = 0.90625\n",
      "Batch 69: loss = 0.2775286138057709, acc = 0.91015625\n",
      "Batch 70: loss = 0.27193695306777954, acc = 0.9013671875\n",
      "Batch 71: loss = 0.32687270641326904, acc = 0.896484375\n",
      "Batch 72: loss = 0.308161199092865, acc = 0.90234375\n",
      "Batch 73: loss = 0.3225055932998657, acc = 0.8974609375\n",
      "Batch 74: loss = 0.2899078130722046, acc = 0.904296875\n",
      "Batch 75: loss = 0.33359459042549133, acc = 0.8828125\n",
      "Batch 76: loss = 0.31136900186538696, acc = 0.888671875\n",
      "Batch 77: loss = 0.2985879182815552, acc = 0.9072265625\n",
      "Batch 78: loss = 0.30226194858551025, acc = 0.9033203125\n",
      "Batch 79: loss = 0.27300822734832764, acc = 0.90234375\n",
      "Batch 80: loss = 0.2629929780960083, acc = 0.90625\n",
      "Batch 81: loss = 0.2900078296661377, acc = 0.8974609375\n",
      "Batch 82: loss = 0.32168638706207275, acc = 0.890625\n",
      "Batch 83: loss = 0.27887970209121704, acc = 0.9130859375\n",
      "Batch 84: loss = 0.2810383439064026, acc = 0.9033203125\n",
      "Batch 85: loss = 0.27943506836891174, acc = 0.9052734375\n",
      "Batch 86: loss = 0.2903449535369873, acc = 0.8994140625\n",
      "Batch 87: loss = 0.2966253459453583, acc = 0.8984375\n",
      "Batch 88: loss = 0.33464300632476807, acc = 0.89453125\n",
      "Batch 89: loss = 0.301174134016037, acc = 0.900390625\n",
      "Batch 90: loss = 0.2998952269554138, acc = 0.892578125\n",
      "Batch 91: loss = 0.31292545795440674, acc = 0.8935546875\n",
      "Batch 92: loss = 0.35972875356674194, acc = 0.87890625\n",
      "Batch 93: loss = 0.23451778292655945, acc = 0.919921875\n",
      "Batch 94: loss = 0.2587798535823822, acc = 0.91015625\n",
      "Batch 95: loss = 0.2510780096054077, acc = 0.921875\n",
      "Batch 96: loss = 0.3371313810348511, acc = 0.8828125\n",
      "Batch 97: loss = 0.29018789529800415, acc = 0.912109375\n",
      "Batch 98: loss = 0.2835264205932617, acc = 0.9052734375\n",
      "Batch 99: loss = 0.33876168727874756, acc = 0.880859375\n",
      "Batch 100: loss = 0.280403733253479, acc = 0.9052734375\n",
      "Batch 101: loss = 0.23653191328048706, acc = 0.92578125\n",
      "Batch 102: loss = 0.30552318692207336, acc = 0.8994140625\n",
      "Batch 103: loss = 0.31244975328445435, acc = 0.8935546875\n",
      "Batch 104: loss = 0.2607432007789612, acc = 0.90625\n",
      "Batch 105: loss = 0.3018629550933838, acc = 0.900390625\n",
      "Batch 106: loss = 0.2728334665298462, acc = 0.908203125\n",
      "Batch 107: loss = 0.26763179898262024, acc = 0.9150390625\n",
      "Batch 108: loss = 0.2865368127822876, acc = 0.9111328125\n",
      "Batch 109: loss = 0.2923772931098938, acc = 0.9091796875\n",
      "Batch 110: loss = 0.28324878215789795, acc = 0.908203125\n",
      "Batch 111: loss = 0.26618558168411255, acc = 0.9072265625\n",
      "Batch 112: loss = 0.2783178985118866, acc = 0.9208984375\n",
      "Batch 113: loss = 0.31201934814453125, acc = 0.890625\n",
      "Batch 114: loss = 0.2747068405151367, acc = 0.916015625\n",
      "Batch 115: loss = 0.3179904818534851, acc = 0.904296875\n",
      "Batch 116: loss = 0.3163646459579468, acc = 0.8955078125\n",
      "Batch 117: loss = 0.3212045431137085, acc = 0.8935546875\n",
      "Batch 118: loss = 0.24076510965824127, acc = 0.9111328125\n",
      "Batch 119: loss = 0.2468624711036682, acc = 0.916015625\n",
      "Batch 120: loss = 0.25630584359169006, acc = 0.9169921875\n",
      "Batch 121: loss = 0.28755414485931396, acc = 0.8984375\n",
      "Batch 122: loss = 0.25246065855026245, acc = 0.9052734375\n",
      "Batch 123: loss = 0.2842777967453003, acc = 0.908203125\n",
      "Batch 124: loss = 0.2992485761642456, acc = 0.8955078125\n",
      "Batch 125: loss = 0.3061189651489258, acc = 0.896484375\n",
      "Batch 126: loss = 0.31571778655052185, acc = 0.8935546875\n",
      "\n",
      "Epoch 79/100\n",
      "Batch 1: loss = 0.42824339866638184, acc = 0.880859375\n",
      "Batch 2: loss = 0.2839074730873108, acc = 0.900390625\n",
      "Batch 3: loss = 0.30803415179252625, acc = 0.8994140625\n",
      "Batch 4: loss = 0.29700571298599243, acc = 0.900390625\n",
      "Batch 5: loss = 0.26679715514183044, acc = 0.9052734375\n",
      "Batch 6: loss = 0.3143480122089386, acc = 0.896484375\n",
      "Batch 7: loss = 0.30009669065475464, acc = 0.9052734375\n",
      "Batch 8: loss = 0.34286168217658997, acc = 0.8876953125\n",
      "Batch 9: loss = 0.3076678514480591, acc = 0.904296875\n",
      "Batch 10: loss = 0.25997060537338257, acc = 0.9140625\n",
      "Batch 11: loss = 0.2838628590106964, acc = 0.90625\n",
      "Batch 12: loss = 0.29911935329437256, acc = 0.8896484375\n",
      "Batch 13: loss = 0.3061858117580414, acc = 0.892578125\n",
      "Batch 14: loss = 0.29540249705314636, acc = 0.8955078125\n",
      "Batch 15: loss = 0.29250162839889526, acc = 0.900390625\n",
      "Batch 16: loss = 0.2742106020450592, acc = 0.9111328125\n",
      "Batch 17: loss = 0.26821252703666687, acc = 0.9150390625\n",
      "Batch 18: loss = 0.25839805603027344, acc = 0.9189453125\n",
      "Batch 19: loss = 0.2996242940425873, acc = 0.8916015625\n",
      "Batch 20: loss = 0.28138983249664307, acc = 0.89453125\n",
      "Batch 21: loss = 0.32586073875427246, acc = 0.890625\n",
      "Batch 22: loss = 0.315655916929245, acc = 0.892578125\n",
      "Batch 23: loss = 0.3119809627532959, acc = 0.8974609375\n",
      "Batch 24: loss = 0.26310795545578003, acc = 0.9208984375\n",
      "Batch 25: loss = 0.2850389778614044, acc = 0.9169921875\n",
      "Batch 26: loss = 0.2487669736146927, acc = 0.9140625\n",
      "Batch 27: loss = 0.3168291449546814, acc = 0.896484375\n",
      "Batch 28: loss = 0.28994953632354736, acc = 0.892578125\n",
      "Batch 29: loss = 0.3017756938934326, acc = 0.8955078125\n",
      "Batch 30: loss = 0.28103238344192505, acc = 0.9091796875\n",
      "Batch 31: loss = 0.30028071999549866, acc = 0.8994140625\n",
      "Batch 32: loss = 0.2967435419559479, acc = 0.8984375\n",
      "Batch 33: loss = 0.2706811726093292, acc = 0.9072265625\n",
      "Batch 34: loss = 0.2758409380912781, acc = 0.9072265625\n",
      "Batch 35: loss = 0.2808363735675812, acc = 0.912109375\n",
      "Batch 36: loss = 0.23564378917217255, acc = 0.923828125\n",
      "Batch 37: loss = 0.2463451474905014, acc = 0.9130859375\n",
      "Batch 38: loss = 0.2764495611190796, acc = 0.9091796875\n",
      "Batch 39: loss = 0.23150788247585297, acc = 0.9248046875\n",
      "Batch 40: loss = 0.30020102858543396, acc = 0.9072265625\n",
      "Batch 41: loss = 0.25623124837875366, acc = 0.91796875\n",
      "Batch 42: loss = 0.2846927344799042, acc = 0.904296875\n",
      "Batch 43: loss = 0.2992176413536072, acc = 0.8984375\n",
      "Batch 44: loss = 0.30205675959587097, acc = 0.8994140625\n",
      "Batch 45: loss = 0.24882853031158447, acc = 0.91015625\n",
      "Batch 46: loss = 0.2448234260082245, acc = 0.9150390625\n",
      "Batch 47: loss = 0.26524004340171814, acc = 0.91015625\n",
      "Batch 48: loss = 0.28366273641586304, acc = 0.9091796875\n",
      "Batch 49: loss = 0.2683570384979248, acc = 0.916015625\n",
      "Batch 50: loss = 0.29715806245803833, acc = 0.90625\n",
      "Batch 51: loss = 0.26250094175338745, acc = 0.9169921875\n",
      "Batch 52: loss = 0.31834980845451355, acc = 0.892578125\n",
      "Batch 53: loss = 0.29155629873275757, acc = 0.89453125\n",
      "Batch 54: loss = 0.24624353647232056, acc = 0.912109375\n",
      "Batch 55: loss = 0.28577423095703125, acc = 0.90625\n",
      "Batch 56: loss = 0.261045902967453, acc = 0.91015625\n",
      "Batch 57: loss = 0.2995723485946655, acc = 0.8857421875\n",
      "Batch 58: loss = 0.33447644114494324, acc = 0.884765625\n",
      "Batch 59: loss = 0.2506513297557831, acc = 0.9189453125\n",
      "Batch 60: loss = 0.2891191244125366, acc = 0.90234375\n",
      "Batch 61: loss = 0.272499144077301, acc = 0.9111328125\n",
      "Batch 62: loss = 0.29163503646850586, acc = 0.9013671875\n",
      "Batch 63: loss = 0.2624446749687195, acc = 0.9169921875\n",
      "Batch 64: loss = 0.26154839992523193, acc = 0.916015625\n",
      "Batch 65: loss = 0.2947859764099121, acc = 0.90625\n",
      "Batch 66: loss = 0.28040218353271484, acc = 0.9111328125\n",
      "Batch 67: loss = 0.27892178297042847, acc = 0.900390625\n",
      "Batch 68: loss = 0.3066871464252472, acc = 0.8955078125\n",
      "Batch 69: loss = 0.2792177200317383, acc = 0.90625\n",
      "Batch 70: loss = 0.321449339389801, acc = 0.8876953125\n",
      "Batch 71: loss = 0.28652772307395935, acc = 0.91015625\n",
      "Batch 72: loss = 0.2884224057197571, acc = 0.9033203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 73: loss = 0.3038262128829956, acc = 0.9052734375\n",
      "Batch 74: loss = 0.28765374422073364, acc = 0.89453125\n",
      "Batch 75: loss = 0.31269383430480957, acc = 0.8916015625\n",
      "Batch 76: loss = 0.2883005738258362, acc = 0.900390625\n",
      "Batch 77: loss = 0.27157771587371826, acc = 0.9091796875\n",
      "Batch 78: loss = 0.2874014973640442, acc = 0.91015625\n",
      "Batch 79: loss = 0.26575782895088196, acc = 0.91015625\n",
      "Batch 80: loss = 0.27525269985198975, acc = 0.9052734375\n",
      "Batch 81: loss = 0.28890371322631836, acc = 0.9052734375\n",
      "Batch 82: loss = 0.29117727279663086, acc = 0.9052734375\n",
      "Batch 83: loss = 0.29935693740844727, acc = 0.9111328125\n",
      "Batch 84: loss = 0.26123228669166565, acc = 0.9169921875\n",
      "Batch 85: loss = 0.2652079463005066, acc = 0.90625\n",
      "Batch 86: loss = 0.29311269521713257, acc = 0.9013671875\n",
      "Batch 87: loss = 0.2960124909877777, acc = 0.896484375\n",
      "Batch 88: loss = 0.31524673104286194, acc = 0.88671875\n",
      "Batch 89: loss = 0.2602321207523346, acc = 0.912109375\n",
      "Batch 90: loss = 0.336126446723938, acc = 0.88671875\n",
      "Batch 91: loss = 0.3271932303905487, acc = 0.892578125\n",
      "Batch 92: loss = 0.31734809279441833, acc = 0.8994140625\n",
      "Batch 93: loss = 0.2710278630256653, acc = 0.900390625\n",
      "Batch 94: loss = 0.2597501873970032, acc = 0.9072265625\n",
      "Batch 95: loss = 0.2546793818473816, acc = 0.91796875\n",
      "Batch 96: loss = 0.3097276985645294, acc = 0.896484375\n",
      "Batch 97: loss = 0.2908326983451843, acc = 0.9150390625\n",
      "Batch 98: loss = 0.2747814655303955, acc = 0.9033203125\n",
      "Batch 99: loss = 0.28743690252304077, acc = 0.9140625\n",
      "Batch 100: loss = 0.28328680992126465, acc = 0.9013671875\n",
      "Batch 101: loss = 0.27111488580703735, acc = 0.9052734375\n",
      "Batch 102: loss = 0.2869597375392914, acc = 0.90234375\n",
      "Batch 103: loss = 0.3142285943031311, acc = 0.89453125\n",
      "Batch 104: loss = 0.24588589370250702, acc = 0.91796875\n",
      "Batch 105: loss = 0.28749364614486694, acc = 0.9130859375\n",
      "Batch 106: loss = 0.23645097017288208, acc = 0.9296875\n",
      "Batch 107: loss = 0.29537433385849, acc = 0.90234375\n",
      "Batch 108: loss = 0.27746909856796265, acc = 0.9052734375\n",
      "Batch 109: loss = 0.28830134868621826, acc = 0.8994140625\n",
      "Batch 110: loss = 0.2510359585285187, acc = 0.919921875\n",
      "Batch 111: loss = 0.29181355237960815, acc = 0.9033203125\n",
      "Batch 112: loss = 0.28145408630371094, acc = 0.904296875\n",
      "Batch 113: loss = 0.28424152731895447, acc = 0.9072265625\n",
      "Batch 114: loss = 0.2733005881309509, acc = 0.91015625\n",
      "Batch 115: loss = 0.26317209005355835, acc = 0.908203125\n",
      "Batch 116: loss = 0.31720268726348877, acc = 0.9013671875\n",
      "Batch 117: loss = 0.3234979510307312, acc = 0.908203125\n",
      "Batch 118: loss = 0.2736662030220032, acc = 0.908203125\n",
      "Batch 119: loss = 0.2527458667755127, acc = 0.9287109375\n",
      "Batch 120: loss = 0.21874868869781494, acc = 0.9248046875\n",
      "Batch 121: loss = 0.2953270971775055, acc = 0.8955078125\n",
      "Batch 122: loss = 0.24852611124515533, acc = 0.91015625\n",
      "Batch 123: loss = 0.2819347679615021, acc = 0.90625\n",
      "Batch 124: loss = 0.2925701141357422, acc = 0.9013671875\n",
      "Batch 125: loss = 0.33635956048965454, acc = 0.884765625\n",
      "Batch 126: loss = 0.27720916271209717, acc = 0.91015625\n",
      "\n",
      "Epoch 80/100\n",
      "Batch 1: loss = 0.3916128873825073, acc = 0.8916015625\n",
      "Batch 2: loss = 0.2933444380760193, acc = 0.8974609375\n",
      "Batch 3: loss = 0.3127704858779907, acc = 0.8896484375\n",
      "Batch 4: loss = 0.28788623213768005, acc = 0.912109375\n",
      "Batch 5: loss = 0.293861448764801, acc = 0.89453125\n",
      "Batch 6: loss = 0.341371089220047, acc = 0.884765625\n",
      "Batch 7: loss = 0.29713624715805054, acc = 0.8984375\n",
      "Batch 8: loss = 0.2454988956451416, acc = 0.921875\n",
      "Batch 9: loss = 0.26919859647750854, acc = 0.9130859375\n",
      "Batch 10: loss = 0.27460917830467224, acc = 0.904296875\n",
      "Batch 11: loss = 0.29966115951538086, acc = 0.90234375\n",
      "Batch 12: loss = 0.24400801956653595, acc = 0.916015625\n",
      "Batch 13: loss = 0.2807577848434448, acc = 0.8994140625\n",
      "Batch 14: loss = 0.28473377227783203, acc = 0.90625\n",
      "Batch 15: loss = 0.2884242534637451, acc = 0.900390625\n",
      "Batch 16: loss = 0.2700861990451813, acc = 0.9091796875\n",
      "Batch 17: loss = 0.30012452602386475, acc = 0.9052734375\n",
      "Batch 18: loss = 0.30170345306396484, acc = 0.9033203125\n",
      "Batch 19: loss = 0.3107220530509949, acc = 0.8984375\n",
      "Batch 20: loss = 0.2871241867542267, acc = 0.89453125\n",
      "Batch 21: loss = 0.28977441787719727, acc = 0.900390625\n",
      "Batch 22: loss = 0.28105634450912476, acc = 0.9111328125\n",
      "Batch 23: loss = 0.27715158462524414, acc = 0.91015625\n",
      "Batch 24: loss = 0.25787919759750366, acc = 0.90234375\n",
      "Batch 25: loss = 0.2864110767841339, acc = 0.908203125\n",
      "Batch 26: loss = 0.2990143299102783, acc = 0.8935546875\n",
      "Batch 27: loss = 0.2822837233543396, acc = 0.9072265625\n",
      "Batch 28: loss = 0.3401584327220917, acc = 0.880859375\n",
      "Batch 29: loss = 0.3113393485546112, acc = 0.8984375\n",
      "Batch 30: loss = 0.27696123719215393, acc = 0.9150390625\n",
      "Batch 31: loss = 0.30159884691238403, acc = 0.904296875\n",
      "Batch 32: loss = 0.30403757095336914, acc = 0.8955078125\n",
      "Batch 33: loss = 0.23293834924697876, acc = 0.923828125\n",
      "Batch 34: loss = 0.3499772846698761, acc = 0.8837890625\n",
      "Batch 35: loss = 0.2708033621311188, acc = 0.916015625\n",
      "Batch 36: loss = 0.29912346601486206, acc = 0.9033203125\n",
      "Batch 37: loss = 0.2599022388458252, acc = 0.9111328125\n",
      "Batch 38: loss = 0.24739223718643188, acc = 0.9169921875\n",
      "Batch 39: loss = 0.29094505310058594, acc = 0.9111328125\n",
      "Batch 40: loss = 0.30285537242889404, acc = 0.904296875\n",
      "Batch 41: loss = 0.24525924026966095, acc = 0.919921875\n",
      "Batch 42: loss = 0.26797550916671753, acc = 0.9140625\n",
      "Batch 43: loss = 0.3029283285140991, acc = 0.89453125\n",
      "Batch 44: loss = 0.24767795205116272, acc = 0.9267578125\n",
      "Batch 45: loss = 0.286382257938385, acc = 0.912109375\n",
      "Batch 46: loss = 0.25888222455978394, acc = 0.9072265625\n",
      "Batch 47: loss = 0.2774243652820587, acc = 0.90625\n",
      "Batch 48: loss = 0.2787139415740967, acc = 0.9052734375\n",
      "Batch 49: loss = 0.26405858993530273, acc = 0.919921875\n",
      "Batch 50: loss = 0.28000974655151367, acc = 0.9111328125\n",
      "Batch 51: loss = 0.29076677560806274, acc = 0.8955078125\n",
      "Batch 52: loss = 0.28697454929351807, acc = 0.9013671875\n",
      "Batch 53: loss = 0.2718174457550049, acc = 0.9140625\n",
      "Batch 54: loss = 0.27195826172828674, acc = 0.9033203125\n",
      "Batch 55: loss = 0.25978171825408936, acc = 0.9130859375\n",
      "Batch 56: loss = 0.26595044136047363, acc = 0.9091796875\n",
      "Batch 57: loss = 0.2990621328353882, acc = 0.89453125\n",
      "Batch 58: loss = 0.3390774130821228, acc = 0.8818359375\n",
      "Batch 59: loss = 0.23035591840744019, acc = 0.923828125\n",
      "Batch 60: loss = 0.266359806060791, acc = 0.9091796875\n",
      "Batch 61: loss = 0.2812448740005493, acc = 0.9072265625\n",
      "Batch 62: loss = 0.3420513868331909, acc = 0.892578125\n",
      "Batch 63: loss = 0.3061586618423462, acc = 0.8974609375\n",
      "Batch 64: loss = 0.24096925556659698, acc = 0.91796875\n",
      "Batch 65: loss = 0.3152552843093872, acc = 0.8935546875\n",
      "Batch 66: loss = 0.2911597788333893, acc = 0.9052734375\n",
      "Batch 67: loss = 0.28496772050857544, acc = 0.8935546875\n",
      "Batch 68: loss = 0.2990899384021759, acc = 0.90625\n",
      "Batch 69: loss = 0.2630567252635956, acc = 0.9111328125\n",
      "Batch 70: loss = 0.25485503673553467, acc = 0.9208984375\n",
      "Batch 71: loss = 0.2906554341316223, acc = 0.900390625\n",
      "Batch 72: loss = 0.25122225284576416, acc = 0.9140625\n",
      "Batch 73: loss = 0.32346993684768677, acc = 0.890625\n",
      "Batch 74: loss = 0.2936740219593048, acc = 0.8955078125\n",
      "Batch 75: loss = 0.32804763317108154, acc = 0.8759765625\n",
      "Batch 76: loss = 0.2833210229873657, acc = 0.896484375\n",
      "Batch 77: loss = 0.29334118962287903, acc = 0.9052734375\n",
      "Batch 78: loss = 0.28696200251579285, acc = 0.912109375\n",
      "Batch 79: loss = 0.23913568258285522, acc = 0.9189453125\n",
      "Batch 80: loss = 0.2849203944206238, acc = 0.8974609375\n",
      "Batch 81: loss = 0.27640825510025024, acc = 0.91015625\n",
      "Batch 82: loss = 0.30071890354156494, acc = 0.8974609375\n",
      "Batch 83: loss = 0.2547709345817566, acc = 0.91796875\n",
      "Batch 84: loss = 0.266360878944397, acc = 0.908203125\n",
      "Batch 85: loss = 0.27642613649368286, acc = 0.9072265625\n",
      "Batch 86: loss = 0.28176194429397583, acc = 0.912109375\n",
      "Batch 87: loss = 0.29499906301498413, acc = 0.908203125\n",
      "Batch 88: loss = 0.3476295471191406, acc = 0.8857421875\n",
      "Batch 89: loss = 0.3166884779930115, acc = 0.8984375\n",
      "Batch 90: loss = 0.2943849265575409, acc = 0.900390625\n",
      "Batch 91: loss = 0.308932363986969, acc = 0.8916015625\n",
      "Batch 92: loss = 0.2719314694404602, acc = 0.90625\n",
      "Batch 93: loss = 0.2820795774459839, acc = 0.9033203125\n",
      "Batch 94: loss = 0.2884818911552429, acc = 0.900390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 95: loss = 0.24631671607494354, acc = 0.923828125\n",
      "Batch 96: loss = 0.2675853669643402, acc = 0.9169921875\n",
      "Batch 97: loss = 0.26767587661743164, acc = 0.9130859375\n",
      "Batch 98: loss = 0.2776605188846588, acc = 0.91015625\n",
      "Batch 99: loss = 0.29079824686050415, acc = 0.9052734375\n",
      "Batch 100: loss = 0.269307941198349, acc = 0.90234375\n",
      "Batch 101: loss = 0.2713164687156677, acc = 0.9013671875\n",
      "Batch 102: loss = 0.2967521548271179, acc = 0.89453125\n",
      "Batch 103: loss = 0.2846979796886444, acc = 0.90625\n",
      "Batch 104: loss = 0.26661068201065063, acc = 0.921875\n",
      "Batch 105: loss = 0.2311454713344574, acc = 0.9287109375\n",
      "Batch 106: loss = 0.27754122018814087, acc = 0.8974609375\n",
      "Batch 107: loss = 0.2817321717739105, acc = 0.9013671875\n",
      "Batch 108: loss = 0.303741991519928, acc = 0.8916015625\n",
      "Batch 109: loss = 0.2617793679237366, acc = 0.9072265625\n",
      "Batch 110: loss = 0.28065192699432373, acc = 0.9228515625\n",
      "Batch 111: loss = 0.28239721059799194, acc = 0.8984375\n",
      "Batch 112: loss = 0.29073190689086914, acc = 0.908203125\n",
      "Batch 113: loss = 0.28411078453063965, acc = 0.904296875\n",
      "Batch 114: loss = 0.2945117950439453, acc = 0.9072265625\n",
      "Batch 115: loss = 0.29282212257385254, acc = 0.90234375\n",
      "Batch 116: loss = 0.30556368827819824, acc = 0.9013671875\n",
      "Batch 117: loss = 0.2953477203845978, acc = 0.9033203125\n",
      "Batch 118: loss = 0.2585121989250183, acc = 0.90625\n",
      "Batch 119: loss = 0.26809796690940857, acc = 0.90625\n",
      "Batch 120: loss = 0.25667405128479004, acc = 0.9111328125\n",
      "Batch 121: loss = 0.3091908395290375, acc = 0.90234375\n",
      "Batch 122: loss = 0.2898319959640503, acc = 0.9033203125\n",
      "Batch 123: loss = 0.26265591382980347, acc = 0.9130859375\n",
      "Batch 124: loss = 0.26528722047805786, acc = 0.9091796875\n",
      "Batch 125: loss = 0.3319712281227112, acc = 0.8876953125\n",
      "Batch 126: loss = 0.2851191759109497, acc = 0.91015625\n",
      "Saved checkpoint to weights.80.h5\n",
      "\n",
      "Epoch 81/100\n",
      "Batch 1: loss = 0.34270012378692627, acc = 0.8974609375\n",
      "Batch 2: loss = 0.2781482934951782, acc = 0.90234375\n",
      "Batch 3: loss = 0.3224436640739441, acc = 0.896484375\n",
      "Batch 4: loss = 0.2889293134212494, acc = 0.908203125\n",
      "Batch 5: loss = 0.3000457286834717, acc = 0.912109375\n",
      "Batch 6: loss = 0.3120616674423218, acc = 0.9052734375\n",
      "Batch 7: loss = 0.2775411307811737, acc = 0.912109375\n",
      "Batch 8: loss = 0.25461411476135254, acc = 0.9169921875\n",
      "Batch 9: loss = 0.27482688426971436, acc = 0.90625\n",
      "Batch 10: loss = 0.24071060121059418, acc = 0.9228515625\n",
      "Batch 11: loss = 0.25397393107414246, acc = 0.9169921875\n",
      "Batch 12: loss = 0.295393705368042, acc = 0.884765625\n",
      "Batch 13: loss = 0.25991716980934143, acc = 0.908203125\n",
      "Batch 14: loss = 0.29865044355392456, acc = 0.9052734375\n",
      "Batch 15: loss = 0.2762237787246704, acc = 0.916015625\n",
      "Batch 16: loss = 0.2931469678878784, acc = 0.9013671875\n",
      "Batch 17: loss = 0.27809280157089233, acc = 0.9111328125\n",
      "Batch 18: loss = 0.2570562958717346, acc = 0.912109375\n",
      "Batch 19: loss = 0.2629774808883667, acc = 0.9072265625\n",
      "Batch 20: loss = 0.2614997923374176, acc = 0.9150390625\n",
      "Batch 21: loss = 0.2978229522705078, acc = 0.9052734375\n",
      "Batch 22: loss = 0.29504236578941345, acc = 0.9033203125\n",
      "Batch 23: loss = 0.2728945314884186, acc = 0.90625\n",
      "Batch 24: loss = 0.2788408696651459, acc = 0.9052734375\n",
      "Batch 25: loss = 0.2626212239265442, acc = 0.916015625\n",
      "Batch 26: loss = 0.2664157748222351, acc = 0.9150390625\n",
      "Batch 27: loss = 0.33252036571502686, acc = 0.8798828125\n",
      "Batch 28: loss = 0.295928955078125, acc = 0.89453125\n",
      "Batch 29: loss = 0.2832767367362976, acc = 0.9091796875\n",
      "Batch 30: loss = 0.2758220136165619, acc = 0.9150390625\n",
      "Batch 31: loss = 0.2971135377883911, acc = 0.9013671875\n",
      "Batch 32: loss = 0.2898936867713928, acc = 0.90234375\n",
      "Batch 33: loss = 0.24471740424633026, acc = 0.91796875\n",
      "Batch 34: loss = 0.3043607473373413, acc = 0.8984375\n",
      "Batch 35: loss = 0.28080588579177856, acc = 0.908203125\n",
      "Batch 36: loss = 0.2747769355773926, acc = 0.9072265625\n",
      "Batch 37: loss = 0.2689865231513977, acc = 0.919921875\n",
      "Batch 38: loss = 0.26325929164886475, acc = 0.9130859375\n",
      "Batch 39: loss = 0.24277904629707336, acc = 0.921875\n",
      "Batch 40: loss = 0.2714945077896118, acc = 0.912109375\n",
      "Batch 41: loss = 0.2690916657447815, acc = 0.9111328125\n",
      "Batch 42: loss = 0.2759908437728882, acc = 0.9091796875\n",
      "Batch 43: loss = 0.28661414980888367, acc = 0.90625\n",
      "Batch 44: loss = 0.26485177874565125, acc = 0.9169921875\n",
      "Batch 45: loss = 0.2444334775209427, acc = 0.908203125\n",
      "Batch 46: loss = 0.2605377435684204, acc = 0.90234375\n",
      "Batch 47: loss = 0.2697165608406067, acc = 0.916015625\n",
      "Batch 48: loss = 0.2742883563041687, acc = 0.90625\n",
      "Batch 49: loss = 0.2627737522125244, acc = 0.9091796875\n",
      "Batch 50: loss = 0.2700095772743225, acc = 0.912109375\n",
      "Batch 51: loss = 0.2893216013908386, acc = 0.9013671875\n",
      "Batch 52: loss = 0.24711236357688904, acc = 0.9189453125\n",
      "Batch 53: loss = 0.30038827657699585, acc = 0.8955078125\n",
      "Batch 54: loss = 0.24008987843990326, acc = 0.921875\n",
      "Batch 55: loss = 0.2711142897605896, acc = 0.9140625\n",
      "Batch 56: loss = 0.2792878746986389, acc = 0.90625\n",
      "Batch 57: loss = 0.32792946696281433, acc = 0.8916015625\n",
      "Batch 58: loss = 0.2892071306705475, acc = 0.896484375\n",
      "Batch 59: loss = 0.2437768280506134, acc = 0.916015625\n",
      "Batch 60: loss = 0.2983549237251282, acc = 0.9013671875\n",
      "Batch 61: loss = 0.2691064774990082, acc = 0.8984375\n",
      "Batch 62: loss = 0.27772969007492065, acc = 0.904296875\n",
      "Batch 63: loss = 0.2672298550605774, acc = 0.916015625\n",
      "Batch 64: loss = 0.25925180315971375, acc = 0.9072265625\n",
      "Batch 65: loss = 0.28236767649650574, acc = 0.9140625\n",
      "Batch 66: loss = 0.2701480984687805, acc = 0.908203125\n",
      "Batch 67: loss = 0.2761276364326477, acc = 0.904296875\n",
      "Batch 68: loss = 0.2735167443752289, acc = 0.908203125\n",
      "Batch 69: loss = 0.24936597049236298, acc = 0.916015625\n",
      "Batch 70: loss = 0.3072066903114319, acc = 0.89453125\n",
      "Batch 71: loss = 0.2539052963256836, acc = 0.912109375\n",
      "Batch 72: loss = 0.2653358578681946, acc = 0.90625\n",
      "Batch 73: loss = 0.27861693501472473, acc = 0.8974609375\n",
      "Batch 74: loss = 0.2898716926574707, acc = 0.908203125\n",
      "Batch 75: loss = 0.31562572717666626, acc = 0.90625\n",
      "Batch 76: loss = 0.2897838354110718, acc = 0.900390625\n",
      "Batch 77: loss = 0.288902223110199, acc = 0.8935546875\n",
      "Batch 78: loss = 0.32191190123558044, acc = 0.890625\n",
      "Batch 79: loss = 0.24991729855537415, acc = 0.912109375\n",
      "Batch 80: loss = 0.24583007395267487, acc = 0.916015625\n",
      "Batch 81: loss = 0.3222884237766266, acc = 0.8974609375\n",
      "Batch 82: loss = 0.30021750926971436, acc = 0.8974609375\n",
      "Batch 83: loss = 0.27837109565734863, acc = 0.8994140625\n",
      "Batch 84: loss = 0.28852057456970215, acc = 0.900390625\n",
      "Batch 85: loss = 0.29885104298591614, acc = 0.8916015625\n",
      "Batch 86: loss = 0.28730446100234985, acc = 0.9033203125\n",
      "Batch 87: loss = 0.2958260774612427, acc = 0.9013671875\n",
      "Batch 88: loss = 0.34536615014076233, acc = 0.8837890625\n",
      "Batch 89: loss = 0.2507905960083008, acc = 0.919921875\n",
      "Batch 90: loss = 0.2776752710342407, acc = 0.9013671875\n",
      "Batch 91: loss = 0.3048756420612335, acc = 0.892578125\n",
      "Batch 92: loss = 0.29080063104629517, acc = 0.9033203125\n",
      "Batch 93: loss = 0.2659290134906769, acc = 0.912109375\n",
      "Batch 94: loss = 0.27708810567855835, acc = 0.90234375\n",
      "Batch 95: loss = 0.26015859842300415, acc = 0.9111328125\n",
      "Batch 96: loss = 0.2705979645252228, acc = 0.9150390625\n",
      "Batch 97: loss = 0.2763703763484955, acc = 0.9091796875\n",
      "Batch 98: loss = 0.3100764751434326, acc = 0.9013671875\n",
      "Batch 99: loss = 0.2771109342575073, acc = 0.9189453125\n",
      "Batch 100: loss = 0.27453380823135376, acc = 0.908203125\n",
      "Batch 101: loss = 0.26834768056869507, acc = 0.9091796875\n",
      "Batch 102: loss = 0.30763179063796997, acc = 0.8876953125\n",
      "Batch 103: loss = 0.29474174976348877, acc = 0.90625\n",
      "Batch 104: loss = 0.25109273195266724, acc = 0.9228515625\n",
      "Batch 105: loss = 0.2702826261520386, acc = 0.904296875\n",
      "Batch 106: loss = 0.266995906829834, acc = 0.921875\n",
      "Batch 107: loss = 0.2600313425064087, acc = 0.9169921875\n",
      "Batch 108: loss = 0.2595110535621643, acc = 0.9140625\n",
      "Batch 109: loss = 0.24015994369983673, acc = 0.9208984375\n",
      "Batch 110: loss = 0.29961127042770386, acc = 0.904296875\n",
      "Batch 111: loss = 0.2686668038368225, acc = 0.9013671875\n",
      "Batch 112: loss = 0.2730998992919922, acc = 0.908203125\n",
      "Batch 113: loss = 0.2869740128517151, acc = 0.90234375\n",
      "Batch 114: loss = 0.27679118514060974, acc = 0.90625\n",
      "Batch 115: loss = 0.2968178391456604, acc = 0.896484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 116: loss = 0.30192244052886963, acc = 0.8974609375\n",
      "Batch 117: loss = 0.2855604887008667, acc = 0.904296875\n",
      "Batch 118: loss = 0.24611060321331024, acc = 0.9150390625\n",
      "Batch 119: loss = 0.22770336270332336, acc = 0.923828125\n",
      "Batch 120: loss = 0.27046117186546326, acc = 0.9130859375\n",
      "Batch 121: loss = 0.26203054189682007, acc = 0.9150390625\n",
      "Batch 122: loss = 0.27546459436416626, acc = 0.900390625\n",
      "Batch 123: loss = 0.2681886851787567, acc = 0.9091796875\n",
      "Batch 124: loss = 0.30222105979919434, acc = 0.8994140625\n",
      "Batch 125: loss = 0.3005834221839905, acc = 0.8916015625\n",
      "Batch 126: loss = 0.2921912968158722, acc = 0.9013671875\n",
      "\n",
      "Epoch 82/100\n",
      "Batch 1: loss = 0.4223910868167877, acc = 0.87109375\n",
      "Batch 2: loss = 0.276297390460968, acc = 0.912109375\n",
      "Batch 3: loss = 0.311445027589798, acc = 0.9013671875\n",
      "Batch 4: loss = 0.29205238819122314, acc = 0.908203125\n",
      "Batch 5: loss = 0.29296380281448364, acc = 0.892578125\n",
      "Batch 6: loss = 0.28288477659225464, acc = 0.908203125\n",
      "Batch 7: loss = 0.31230470538139343, acc = 0.8974609375\n",
      "Batch 8: loss = 0.3113459050655365, acc = 0.8994140625\n",
      "Batch 9: loss = 0.25533196330070496, acc = 0.9140625\n",
      "Batch 10: loss = 0.24602872133255005, acc = 0.91796875\n",
      "Batch 11: loss = 0.2682175934314728, acc = 0.919921875\n",
      "Batch 12: loss = 0.2790779769420624, acc = 0.9052734375\n",
      "Batch 13: loss = 0.27759215235710144, acc = 0.912109375\n",
      "Batch 14: loss = 0.2510989308357239, acc = 0.9140625\n",
      "Batch 15: loss = 0.2649695873260498, acc = 0.9072265625\n",
      "Batch 16: loss = 0.2656650245189667, acc = 0.9130859375\n",
      "Batch 17: loss = 0.26450422406196594, acc = 0.9072265625\n",
      "Batch 18: loss = 0.2784390151500702, acc = 0.908203125\n",
      "Batch 19: loss = 0.28777623176574707, acc = 0.90234375\n",
      "Batch 20: loss = 0.24592390656471252, acc = 0.904296875\n",
      "Batch 21: loss = 0.3040921092033386, acc = 0.9052734375\n",
      "Batch 22: loss = 0.290475070476532, acc = 0.8974609375\n",
      "Batch 23: loss = 0.28869765996932983, acc = 0.90625\n",
      "Batch 24: loss = 0.25925910472869873, acc = 0.91796875\n",
      "Batch 25: loss = 0.30281251668930054, acc = 0.8974609375\n",
      "Batch 26: loss = 0.2883814573287964, acc = 0.9111328125\n",
      "Batch 27: loss = 0.27459877729415894, acc = 0.9052734375\n",
      "Batch 28: loss = 0.2717718482017517, acc = 0.8984375\n",
      "Batch 29: loss = 0.2967411279678345, acc = 0.908203125\n",
      "Batch 30: loss = 0.26257726550102234, acc = 0.91796875\n",
      "Batch 31: loss = 0.27036190032958984, acc = 0.9052734375\n",
      "Batch 32: loss = 0.31294554471969604, acc = 0.8955078125\n",
      "Batch 33: loss = 0.2631330192089081, acc = 0.91015625\n",
      "Batch 34: loss = 0.32523924112319946, acc = 0.8984375\n",
      "Batch 35: loss = 0.30659279227256775, acc = 0.9072265625\n",
      "Batch 36: loss = 0.2562320828437805, acc = 0.91015625\n",
      "Batch 37: loss = 0.26131460070610046, acc = 0.912109375\n",
      "Batch 38: loss = 0.26518678665161133, acc = 0.9111328125\n",
      "Batch 39: loss = 0.2674563527107239, acc = 0.91015625\n",
      "Batch 40: loss = 0.29262393712997437, acc = 0.9013671875\n",
      "Batch 41: loss = 0.249452143907547, acc = 0.9140625\n",
      "Batch 42: loss = 0.30709248781204224, acc = 0.90234375\n",
      "Batch 43: loss = 0.3064928650856018, acc = 0.9033203125\n",
      "Batch 44: loss = 0.26582926511764526, acc = 0.921875\n",
      "Batch 45: loss = 0.258657306432724, acc = 0.908203125\n",
      "Batch 46: loss = 0.22719553112983704, acc = 0.9287109375\n",
      "Batch 47: loss = 0.26277828216552734, acc = 0.916015625\n",
      "Batch 48: loss = 0.25682395696640015, acc = 0.9091796875\n",
      "Batch 49: loss = 0.25281423330307007, acc = 0.919921875\n",
      "Batch 50: loss = 0.24803116917610168, acc = 0.912109375\n",
      "Batch 51: loss = 0.2758859395980835, acc = 0.9130859375\n",
      "Batch 52: loss = 0.2516341209411621, acc = 0.90625\n",
      "Batch 53: loss = 0.2871127724647522, acc = 0.9033203125\n",
      "Batch 54: loss = 0.24376726150512695, acc = 0.9150390625\n",
      "Batch 55: loss = 0.23491722345352173, acc = 0.9228515625\n",
      "Batch 56: loss = 0.2654763162136078, acc = 0.916015625\n",
      "Batch 57: loss = 0.28402918577194214, acc = 0.9111328125\n",
      "Batch 58: loss = 0.35651344060897827, acc = 0.880859375\n",
      "Batch 59: loss = 0.23662437498569489, acc = 0.916015625\n",
      "Batch 60: loss = 0.2732897698879242, acc = 0.900390625\n",
      "Batch 61: loss = 0.24461376667022705, acc = 0.9267578125\n",
      "Batch 62: loss = 0.28495198488235474, acc = 0.892578125\n",
      "Batch 63: loss = 0.25356924533843994, acc = 0.91796875\n",
      "Batch 64: loss = 0.2512999176979065, acc = 0.9072265625\n",
      "Batch 65: loss = 0.27408888936042786, acc = 0.908203125\n",
      "Batch 66: loss = 0.29726797342300415, acc = 0.9130859375\n",
      "Batch 67: loss = 0.2586122155189514, acc = 0.9130859375\n",
      "Batch 68: loss = 0.27334660291671753, acc = 0.91015625\n",
      "Batch 69: loss = 0.2627893090248108, acc = 0.916015625\n",
      "Batch 70: loss = 0.26595279574394226, acc = 0.91015625\n",
      "Batch 71: loss = 0.3016514480113983, acc = 0.89453125\n",
      "Batch 72: loss = 0.2990051507949829, acc = 0.9013671875\n",
      "Batch 73: loss = 0.2796682119369507, acc = 0.9150390625\n",
      "Batch 74: loss = 0.29579102993011475, acc = 0.9013671875\n",
      "Batch 75: loss = 0.3003664016723633, acc = 0.8896484375\n",
      "Batch 76: loss = 0.2514403760433197, acc = 0.908203125\n",
      "Batch 77: loss = 0.25725147128105164, acc = 0.90234375\n",
      "Batch 78: loss = 0.2983652949333191, acc = 0.9072265625\n",
      "Batch 79: loss = 0.26933014392852783, acc = 0.91015625\n",
      "Batch 80: loss = 0.2471395879983902, acc = 0.9130859375\n",
      "Batch 81: loss = 0.2522938847541809, acc = 0.9169921875\n",
      "Batch 82: loss = 0.2648725211620331, acc = 0.912109375\n",
      "Batch 83: loss = 0.27719801664352417, acc = 0.8994140625\n",
      "Batch 84: loss = 0.26724526286125183, acc = 0.9091796875\n",
      "Batch 85: loss = 0.28389686346054077, acc = 0.8994140625\n",
      "Batch 86: loss = 0.2680123746395111, acc = 0.896484375\n",
      "Batch 87: loss = 0.2749837636947632, acc = 0.9130859375\n",
      "Batch 88: loss = 0.317100465297699, acc = 0.892578125\n",
      "Batch 89: loss = 0.2587696313858032, acc = 0.9228515625\n",
      "Batch 90: loss = 0.29620856046676636, acc = 0.90234375\n",
      "Batch 91: loss = 0.2851455807685852, acc = 0.90234375\n",
      "Batch 92: loss = 0.2805405855178833, acc = 0.90625\n",
      "Batch 93: loss = 0.29465362429618835, acc = 0.90625\n",
      "Batch 94: loss = 0.24889147281646729, acc = 0.919921875\n",
      "Batch 95: loss = 0.28027769923210144, acc = 0.904296875\n",
      "Batch 96: loss = 0.28102046251296997, acc = 0.90234375\n",
      "Batch 97: loss = 0.315117746591568, acc = 0.9033203125\n",
      "Batch 98: loss = 0.2956739068031311, acc = 0.8994140625\n",
      "Batch 99: loss = 0.3109239339828491, acc = 0.8984375\n",
      "Batch 100: loss = 0.27865391969680786, acc = 0.904296875\n",
      "Batch 101: loss = 0.3214089274406433, acc = 0.8818359375\n",
      "Batch 102: loss = 0.3116909861564636, acc = 0.8974609375\n",
      "Batch 103: loss = 0.28974902629852295, acc = 0.9052734375\n",
      "Batch 104: loss = 0.24959541857242584, acc = 0.9130859375\n",
      "Batch 105: loss = 0.26462996006011963, acc = 0.908203125\n",
      "Batch 106: loss = 0.2657291889190674, acc = 0.9072265625\n",
      "Batch 107: loss = 0.3003431558609009, acc = 0.9033203125\n",
      "Batch 108: loss = 0.28709566593170166, acc = 0.9033203125\n",
      "Batch 109: loss = 0.2541462779045105, acc = 0.9150390625\n",
      "Batch 110: loss = 0.2487705796957016, acc = 0.916015625\n",
      "Batch 111: loss = 0.2838272452354431, acc = 0.90234375\n",
      "Batch 112: loss = 0.24473543465137482, acc = 0.9130859375\n",
      "Batch 113: loss = 0.2745739221572876, acc = 0.9091796875\n",
      "Batch 114: loss = 0.29530441761016846, acc = 0.91015625\n",
      "Batch 115: loss = 0.2920021414756775, acc = 0.8984375\n",
      "Batch 116: loss = 0.3025704026222229, acc = 0.8974609375\n",
      "Batch 117: loss = 0.2822030782699585, acc = 0.9052734375\n",
      "Batch 118: loss = 0.23798158764839172, acc = 0.9150390625\n",
      "Batch 119: loss = 0.26046034693717957, acc = 0.908203125\n",
      "Batch 120: loss = 0.2246590107679367, acc = 0.9365234375\n",
      "Batch 121: loss = 0.2781364917755127, acc = 0.9072265625\n",
      "Batch 122: loss = 0.28213435411453247, acc = 0.904296875\n",
      "Batch 123: loss = 0.28486168384552, acc = 0.896484375\n",
      "Batch 124: loss = 0.2872200608253479, acc = 0.904296875\n",
      "Batch 125: loss = 0.2796325385570526, acc = 0.8994140625\n",
      "Batch 126: loss = 0.2768074572086334, acc = 0.9052734375\n",
      "\n",
      "Epoch 83/100\n",
      "Batch 1: loss = 0.40438371896743774, acc = 0.8837890625\n",
      "Batch 2: loss = 0.2784861922264099, acc = 0.9169921875\n",
      "Batch 3: loss = 0.29985010623931885, acc = 0.9091796875\n",
      "Batch 4: loss = 0.2609895169734955, acc = 0.9208984375\n",
      "Batch 5: loss = 0.27819913625717163, acc = 0.9091796875\n",
      "Batch 6: loss = 0.29382675886154175, acc = 0.908203125\n",
      "Batch 7: loss = 0.278809130191803, acc = 0.90625\n",
      "Batch 8: loss = 0.2867148220539093, acc = 0.908203125\n",
      "Batch 9: loss = 0.2576321065425873, acc = 0.9130859375\n",
      "Batch 10: loss = 0.2522704303264618, acc = 0.9150390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11: loss = 0.22728323936462402, acc = 0.9248046875\n",
      "Batch 12: loss = 0.2540647089481354, acc = 0.91015625\n",
      "Batch 13: loss = 0.23439183831214905, acc = 0.923828125\n",
      "Batch 14: loss = 0.2608101963996887, acc = 0.9091796875\n",
      "Batch 15: loss = 0.23514777421951294, acc = 0.912109375\n",
      "Batch 16: loss = 0.29183274507522583, acc = 0.8994140625\n",
      "Batch 17: loss = 0.2637776732444763, acc = 0.9091796875\n",
      "Batch 18: loss = 0.28637513518333435, acc = 0.908203125\n",
      "Batch 19: loss = 0.29185929894447327, acc = 0.9150390625\n",
      "Batch 20: loss = 0.23500779271125793, acc = 0.9130859375\n",
      "Batch 21: loss = 0.30433908104896545, acc = 0.90234375\n",
      "Batch 22: loss = 0.27768898010253906, acc = 0.9130859375\n",
      "Batch 23: loss = 0.2956449091434479, acc = 0.8974609375\n",
      "Batch 24: loss = 0.26505911350250244, acc = 0.908203125\n",
      "Batch 25: loss = 0.291056752204895, acc = 0.908203125\n",
      "Batch 26: loss = 0.2518184781074524, acc = 0.9150390625\n",
      "Batch 27: loss = 0.2985086441040039, acc = 0.9033203125\n",
      "Batch 28: loss = 0.3195497393608093, acc = 0.8955078125\n",
      "Batch 29: loss = 0.27726393938064575, acc = 0.90234375\n",
      "Batch 30: loss = 0.26626086235046387, acc = 0.9189453125\n",
      "Batch 31: loss = 0.28400856256484985, acc = 0.890625\n",
      "Batch 32: loss = 0.31344151496887207, acc = 0.8984375\n",
      "Batch 33: loss = 0.24539607763290405, acc = 0.923828125\n",
      "Batch 34: loss = 0.273997038602829, acc = 0.9052734375\n",
      "Batch 35: loss = 0.27955806255340576, acc = 0.8994140625\n",
      "Batch 36: loss = 0.2722077965736389, acc = 0.90625\n",
      "Batch 37: loss = 0.25153809785842896, acc = 0.916015625\n",
      "Batch 38: loss = 0.24934150278568268, acc = 0.919921875\n",
      "Batch 39: loss = 0.25358080863952637, acc = 0.9111328125\n",
      "Batch 40: loss = 0.284518837928772, acc = 0.9072265625\n",
      "Batch 41: loss = 0.26118600368499756, acc = 0.9033203125\n",
      "Batch 42: loss = 0.26804327964782715, acc = 0.91015625\n",
      "Batch 43: loss = 0.2945918142795563, acc = 0.8984375\n",
      "Batch 44: loss = 0.2440684288740158, acc = 0.9150390625\n",
      "Batch 45: loss = 0.22176320850849152, acc = 0.919921875\n",
      "Batch 46: loss = 0.2413594275712967, acc = 0.91796875\n",
      "Batch 47: loss = 0.23853467404842377, acc = 0.927734375\n",
      "Batch 48: loss = 0.28939780592918396, acc = 0.912109375\n",
      "Batch 49: loss = 0.2777409553527832, acc = 0.90625\n",
      "Batch 50: loss = 0.24680498242378235, acc = 0.916015625\n",
      "Batch 51: loss = 0.2676228880882263, acc = 0.9111328125\n",
      "Batch 52: loss = 0.26341700553894043, acc = 0.908203125\n",
      "Batch 53: loss = 0.2784741520881653, acc = 0.9072265625\n",
      "Batch 54: loss = 0.20929330587387085, acc = 0.9375\n",
      "Batch 55: loss = 0.2149372547864914, acc = 0.9306640625\n",
      "Batch 56: loss = 0.27294591069221497, acc = 0.9052734375\n",
      "Batch 57: loss = 0.2735804319381714, acc = 0.916015625\n",
      "Batch 58: loss = 0.27849024534225464, acc = 0.90234375\n",
      "Batch 59: loss = 0.22466856241226196, acc = 0.927734375\n",
      "Batch 60: loss = 0.25986969470977783, acc = 0.912109375\n",
      "Batch 61: loss = 0.2486792802810669, acc = 0.9228515625\n",
      "Batch 62: loss = 0.29109716415405273, acc = 0.9072265625\n",
      "Batch 63: loss = 0.2618885040283203, acc = 0.9140625\n",
      "Batch 64: loss = 0.2340662032365799, acc = 0.9208984375\n",
      "Batch 65: loss = 0.2801651954650879, acc = 0.9091796875\n",
      "Batch 66: loss = 0.2796049118041992, acc = 0.9013671875\n",
      "Batch 67: loss = 0.26009052991867065, acc = 0.912109375\n",
      "Batch 68: loss = 0.262722909450531, acc = 0.9189453125\n",
      "Batch 69: loss = 0.23251968622207642, acc = 0.9267578125\n",
      "Batch 70: loss = 0.2751390337944031, acc = 0.9091796875\n",
      "Batch 71: loss = 0.2559164762496948, acc = 0.90234375\n",
      "Batch 72: loss = 0.26202189922332764, acc = 0.9111328125\n",
      "Batch 73: loss = 0.2733169496059418, acc = 0.912109375\n",
      "Batch 74: loss = 0.30055803060531616, acc = 0.900390625\n",
      "Batch 75: loss = 0.3559172451496124, acc = 0.8779296875\n",
      "Batch 76: loss = 0.30189192295074463, acc = 0.904296875\n",
      "Batch 77: loss = 0.28765201568603516, acc = 0.9013671875\n",
      "Batch 78: loss = 0.2709362506866455, acc = 0.91015625\n",
      "Batch 79: loss = 0.2661507725715637, acc = 0.904296875\n",
      "Batch 80: loss = 0.25684964656829834, acc = 0.9111328125\n",
      "Batch 81: loss = 0.27343881130218506, acc = 0.90234375\n",
      "Batch 82: loss = 0.29384908080101013, acc = 0.9033203125\n",
      "Batch 83: loss = 0.29617035388946533, acc = 0.904296875\n",
      "Batch 84: loss = 0.30302155017852783, acc = 0.8935546875\n",
      "Batch 85: loss = 0.27950701117515564, acc = 0.90625\n",
      "Batch 86: loss = 0.25791341066360474, acc = 0.9248046875\n",
      "Batch 87: loss = 0.2769840657711029, acc = 0.9140625\n",
      "Batch 88: loss = 0.317625492811203, acc = 0.89453125\n",
      "Batch 89: loss = 0.27731412649154663, acc = 0.9111328125\n",
      "Batch 90: loss = 0.2835766077041626, acc = 0.8974609375\n",
      "Batch 91: loss = 0.28634199500083923, acc = 0.9072265625\n",
      "Batch 92: loss = 0.2972199022769928, acc = 0.900390625\n",
      "Batch 93: loss = 0.24523329734802246, acc = 0.92578125\n",
      "Batch 94: loss = 0.27615904808044434, acc = 0.9091796875\n",
      "Batch 95: loss = 0.25091445446014404, acc = 0.9169921875\n",
      "Batch 96: loss = 0.2731938064098358, acc = 0.912109375\n",
      "Batch 97: loss = 0.3016723692417145, acc = 0.8916015625\n",
      "Batch 98: loss = 0.29367855191230774, acc = 0.9013671875\n",
      "Batch 99: loss = 0.31374943256378174, acc = 0.8974609375\n",
      "Batch 100: loss = 0.2804076671600342, acc = 0.8916015625\n",
      "Batch 101: loss = 0.25788334012031555, acc = 0.91015625\n",
      "Batch 102: loss = 0.2871186137199402, acc = 0.896484375\n",
      "Batch 103: loss = 0.3120081424713135, acc = 0.8984375\n",
      "Batch 104: loss = 0.2563211917877197, acc = 0.9111328125\n",
      "Batch 105: loss = 0.2565196454524994, acc = 0.919921875\n",
      "Batch 106: loss = 0.25087955594062805, acc = 0.91015625\n",
      "Batch 107: loss = 0.26328569650650024, acc = 0.91015625\n",
      "Batch 108: loss = 0.2671954035758972, acc = 0.90234375\n",
      "Batch 109: loss = 0.26391535997390747, acc = 0.9150390625\n",
      "Batch 110: loss = 0.23369815945625305, acc = 0.91796875\n",
      "Batch 111: loss = 0.28246259689331055, acc = 0.8994140625\n",
      "Batch 112: loss = 0.2627933621406555, acc = 0.9140625\n",
      "Batch 113: loss = 0.25689613819122314, acc = 0.9130859375\n",
      "Batch 114: loss = 0.28337594866752625, acc = 0.9033203125\n",
      "Batch 115: loss = 0.26152053475379944, acc = 0.912109375\n",
      "Batch 116: loss = 0.2526625990867615, acc = 0.921875\n",
      "Batch 117: loss = 0.3022882342338562, acc = 0.9052734375\n",
      "Batch 118: loss = 0.2677578330039978, acc = 0.908203125\n",
      "Batch 119: loss = 0.26023411750793457, acc = 0.9072265625\n",
      "Batch 120: loss = 0.25322625041007996, acc = 0.916015625\n",
      "Batch 121: loss = 0.25028735399246216, acc = 0.91015625\n",
      "Batch 122: loss = 0.2920606732368469, acc = 0.8974609375\n",
      "Batch 123: loss = 0.2640407681465149, acc = 0.912109375\n",
      "Batch 124: loss = 0.26625895500183105, acc = 0.912109375\n",
      "Batch 125: loss = 0.2743753492832184, acc = 0.9150390625\n",
      "Batch 126: loss = 0.26862651109695435, acc = 0.9208984375\n",
      "\n",
      "Epoch 84/100\n",
      "Batch 1: loss = 0.4270513355731964, acc = 0.880859375\n",
      "Batch 2: loss = 0.2834663987159729, acc = 0.9052734375\n",
      "Batch 3: loss = 0.28931617736816406, acc = 0.9033203125\n",
      "Batch 4: loss = 0.31409525871276855, acc = 0.90234375\n",
      "Batch 5: loss = 0.273700475692749, acc = 0.8994140625\n",
      "Batch 6: loss = 0.31226998567581177, acc = 0.8994140625\n",
      "Batch 7: loss = 0.28224408626556396, acc = 0.8955078125\n",
      "Batch 8: loss = 0.247589111328125, acc = 0.92578125\n",
      "Batch 9: loss = 0.27390822768211365, acc = 0.912109375\n",
      "Batch 10: loss = 0.25504595041275024, acc = 0.9140625\n",
      "Batch 11: loss = 0.25357383489608765, acc = 0.9130859375\n",
      "Batch 12: loss = 0.24867317080497742, acc = 0.9072265625\n",
      "Batch 13: loss = 0.25647953152656555, acc = 0.916015625\n",
      "Batch 14: loss = 0.29255980253219604, acc = 0.9130859375\n",
      "Batch 15: loss = 0.23989205062389374, acc = 0.9208984375\n",
      "Batch 16: loss = 0.2616559863090515, acc = 0.9169921875\n",
      "Batch 17: loss = 0.26848772168159485, acc = 0.908203125\n",
      "Batch 18: loss = 0.2745857536792755, acc = 0.91015625\n",
      "Batch 19: loss = 0.31104719638824463, acc = 0.8984375\n",
      "Batch 20: loss = 0.29876255989074707, acc = 0.88671875\n",
      "Batch 21: loss = 0.3110251724720001, acc = 0.8935546875\n",
      "Batch 22: loss = 0.2944132089614868, acc = 0.8974609375\n",
      "Batch 23: loss = 0.29854702949523926, acc = 0.900390625\n",
      "Batch 24: loss = 0.22234275937080383, acc = 0.9267578125\n",
      "Batch 25: loss = 0.2720899283885956, acc = 0.908203125\n",
      "Batch 26: loss = 0.26591622829437256, acc = 0.9052734375\n",
      "Batch 27: loss = 0.29047074913978577, acc = 0.9013671875\n",
      "Batch 28: loss = 0.28982260823249817, acc = 0.8994140625\n",
      "Batch 29: loss = 0.3244985044002533, acc = 0.888671875\n",
      "Batch 30: loss = 0.28434765338897705, acc = 0.9072265625\n",
      "Batch 31: loss = 0.2780885398387909, acc = 0.8935546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 32: loss = 0.2643956243991852, acc = 0.916015625\n",
      "Batch 33: loss = 0.28276127576828003, acc = 0.9111328125\n",
      "Batch 34: loss = 0.27086320519447327, acc = 0.912109375\n",
      "Batch 35: loss = 0.2540634870529175, acc = 0.9169921875\n",
      "Batch 36: loss = 0.2579076886177063, acc = 0.916015625\n",
      "Batch 37: loss = 0.2577781081199646, acc = 0.91796875\n",
      "Batch 38: loss = 0.27087530493736267, acc = 0.921875\n",
      "Batch 39: loss = 0.2522448003292084, acc = 0.919921875\n",
      "Batch 40: loss = 0.29348257184028625, acc = 0.904296875\n",
      "Batch 41: loss = 0.22902679443359375, acc = 0.9248046875\n",
      "Batch 42: loss = 0.2805541455745697, acc = 0.91015625\n",
      "Batch 43: loss = 0.31330597400665283, acc = 0.8955078125\n",
      "Batch 44: loss = 0.2632332444190979, acc = 0.923828125\n",
      "Batch 45: loss = 0.24190080165863037, acc = 0.919921875\n",
      "Batch 46: loss = 0.23873873054981232, acc = 0.919921875\n",
      "Batch 47: loss = 0.2686471939086914, acc = 0.908203125\n",
      "Batch 48: loss = 0.25194022059440613, acc = 0.9140625\n",
      "Batch 49: loss = 0.22941216826438904, acc = 0.92578125\n",
      "Batch 50: loss = 0.2435494065284729, acc = 0.9169921875\n",
      "Batch 51: loss = 0.26502925157546997, acc = 0.9072265625\n",
      "Batch 52: loss = 0.273569256067276, acc = 0.9033203125\n",
      "Batch 53: loss = 0.2567712664604187, acc = 0.919921875\n",
      "Batch 54: loss = 0.22855082154273987, acc = 0.916015625\n",
      "Batch 55: loss = 0.2389383316040039, acc = 0.9189453125\n",
      "Batch 56: loss = 0.24547278881072998, acc = 0.9140625\n",
      "Batch 57: loss = 0.29293763637542725, acc = 0.892578125\n",
      "Batch 58: loss = 0.31825727224349976, acc = 0.900390625\n",
      "Batch 59: loss = 0.2572173774242401, acc = 0.908203125\n",
      "Batch 60: loss = 0.26232391595840454, acc = 0.9130859375\n",
      "Batch 61: loss = 0.2616889178752899, acc = 0.9111328125\n",
      "Batch 62: loss = 0.2754612863063812, acc = 0.9013671875\n",
      "Batch 63: loss = 0.2385328710079193, acc = 0.9228515625\n",
      "Batch 64: loss = 0.21618980169296265, acc = 0.92578125\n",
      "Batch 65: loss = 0.25298872590065, acc = 0.9169921875\n",
      "Batch 66: loss = 0.2610400915145874, acc = 0.9091796875\n",
      "Batch 67: loss = 0.24785704910755157, acc = 0.9189453125\n",
      "Batch 68: loss = 0.27741461992263794, acc = 0.9130859375\n",
      "Batch 69: loss = 0.261420875787735, acc = 0.9140625\n",
      "Batch 70: loss = 0.28171586990356445, acc = 0.900390625\n",
      "Batch 71: loss = 0.2901862561702728, acc = 0.9072265625\n",
      "Batch 72: loss = 0.2782440781593323, acc = 0.8994140625\n",
      "Batch 73: loss = 0.2754793167114258, acc = 0.9072265625\n",
      "Batch 74: loss = 0.31326597929000854, acc = 0.884765625\n",
      "Batch 75: loss = 0.3380466103553772, acc = 0.888671875\n",
      "Batch 76: loss = 0.2913442850112915, acc = 0.892578125\n",
      "Batch 77: loss = 0.2713432312011719, acc = 0.9072265625\n",
      "Batch 78: loss = 0.3056459426879883, acc = 0.8984375\n",
      "Batch 79: loss = 0.25706011056900024, acc = 0.9130859375\n",
      "Batch 80: loss = 0.246507465839386, acc = 0.9091796875\n",
      "Batch 81: loss = 0.2634291648864746, acc = 0.9140625\n",
      "Batch 82: loss = 0.2730560302734375, acc = 0.9111328125\n",
      "Batch 83: loss = 0.26222556829452515, acc = 0.90625\n",
      "Batch 84: loss = 0.2892637252807617, acc = 0.908203125\n",
      "Batch 85: loss = 0.28031790256500244, acc = 0.90234375\n",
      "Batch 86: loss = 0.27380484342575073, acc = 0.9033203125\n",
      "Batch 87: loss = 0.28180262446403503, acc = 0.9013671875\n",
      "Batch 88: loss = 0.3329201340675354, acc = 0.8984375\n",
      "Batch 89: loss = 0.25174209475517273, acc = 0.9189453125\n",
      "Batch 90: loss = 0.2528688907623291, acc = 0.9150390625\n",
      "Batch 91: loss = 0.25225210189819336, acc = 0.9140625\n",
      "Batch 92: loss = 0.2863253951072693, acc = 0.91015625\n",
      "Batch 93: loss = 0.25196632742881775, acc = 0.919921875\n",
      "Batch 94: loss = 0.25722968578338623, acc = 0.9140625\n",
      "Batch 95: loss = 0.2649826407432556, acc = 0.908203125\n",
      "Batch 96: loss = 0.2677314281463623, acc = 0.9013671875\n",
      "Batch 97: loss = 0.30882737040519714, acc = 0.9052734375\n",
      "Batch 98: loss = 0.2701892852783203, acc = 0.9072265625\n",
      "Batch 99: loss = 0.27610695362091064, acc = 0.90234375\n",
      "Batch 100: loss = 0.29650065302848816, acc = 0.9013671875\n",
      "Batch 101: loss = 0.2827199101448059, acc = 0.900390625\n",
      "Batch 102: loss = 0.2963547110557556, acc = 0.904296875\n",
      "Batch 103: loss = 0.2857230007648468, acc = 0.9072265625\n",
      "Batch 104: loss = 0.2584035098552704, acc = 0.912109375\n",
      "Batch 105: loss = 0.25662535429000854, acc = 0.9150390625\n",
      "Batch 106: loss = 0.2729015052318573, acc = 0.904296875\n",
      "Batch 107: loss = 0.2677123248577118, acc = 0.9150390625\n",
      "Batch 108: loss = 0.25544747710227966, acc = 0.9111328125\n",
      "Batch 109: loss = 0.2675188183784485, acc = 0.908203125\n",
      "Batch 110: loss = 0.27817875146865845, acc = 0.916015625\n",
      "Batch 111: loss = 0.2687733471393585, acc = 0.912109375\n",
      "Batch 112: loss = 0.24064350128173828, acc = 0.919921875\n",
      "Batch 113: loss = 0.28293299674987793, acc = 0.9072265625\n",
      "Batch 114: loss = 0.27657002210617065, acc = 0.9111328125\n",
      "Batch 115: loss = 0.2733546197414398, acc = 0.9052734375\n",
      "Batch 116: loss = 0.2948536276817322, acc = 0.896484375\n",
      "Batch 117: loss = 0.2790253460407257, acc = 0.8994140625\n",
      "Batch 118: loss = 0.24250170588493347, acc = 0.9267578125\n",
      "Batch 119: loss = 0.2563864290714264, acc = 0.9052734375\n",
      "Batch 120: loss = 0.24373096227645874, acc = 0.90625\n",
      "Batch 121: loss = 0.27490296959877014, acc = 0.9013671875\n",
      "Batch 122: loss = 0.28026658296585083, acc = 0.896484375\n",
      "Batch 123: loss = 0.2700490355491638, acc = 0.9091796875\n",
      "Batch 124: loss = 0.29681599140167236, acc = 0.890625\n",
      "Batch 125: loss = 0.2835496664047241, acc = 0.9052734375\n",
      "Batch 126: loss = 0.2711162567138672, acc = 0.9091796875\n",
      "\n",
      "Epoch 85/100\n",
      "Batch 1: loss = 0.4115757942199707, acc = 0.88671875\n",
      "Batch 2: loss = 0.25888001918792725, acc = 0.912109375\n",
      "Batch 3: loss = 0.2707620859146118, acc = 0.9140625\n",
      "Batch 4: loss = 0.3076056241989136, acc = 0.9091796875\n",
      "Batch 5: loss = 0.25670474767684937, acc = 0.9169921875\n",
      "Batch 6: loss = 0.3246000409126282, acc = 0.892578125\n",
      "Batch 7: loss = 0.24911415576934814, acc = 0.9150390625\n",
      "Batch 8: loss = 0.3374646306037903, acc = 0.892578125\n",
      "Batch 9: loss = 0.28003737330436707, acc = 0.9033203125\n",
      "Batch 10: loss = 0.2380269318819046, acc = 0.916015625\n",
      "Batch 11: loss = 0.27896052598953247, acc = 0.9052734375\n",
      "Batch 12: loss = 0.23672173917293549, acc = 0.923828125\n",
      "Batch 13: loss = 0.2625155448913574, acc = 0.9091796875\n",
      "Batch 14: loss = 0.25211024284362793, acc = 0.927734375\n",
      "Batch 15: loss = 0.25598472356796265, acc = 0.916015625\n",
      "Batch 16: loss = 0.25245723128318787, acc = 0.9150390625\n",
      "Batch 17: loss = 0.2730376422405243, acc = 0.9169921875\n",
      "Batch 18: loss = 0.2854044437408447, acc = 0.9052734375\n",
      "Batch 19: loss = 0.24715451896190643, acc = 0.9208984375\n",
      "Batch 20: loss = 0.26460346579551697, acc = 0.90234375\n",
      "Batch 21: loss = 0.28188884258270264, acc = 0.9189453125\n",
      "Batch 22: loss = 0.26945987343788147, acc = 0.9072265625\n",
      "Batch 23: loss = 0.2762157917022705, acc = 0.9130859375\n",
      "Batch 24: loss = 0.26045066118240356, acc = 0.9140625\n",
      "Batch 25: loss = 0.27845674753189087, acc = 0.90625\n",
      "Batch 26: loss = 0.23876197636127472, acc = 0.9189453125\n",
      "Batch 27: loss = 0.27169233560562134, acc = 0.908203125\n",
      "Batch 28: loss = 0.2858227491378784, acc = 0.904296875\n",
      "Batch 29: loss = 0.307776540517807, acc = 0.900390625\n",
      "Batch 30: loss = 0.28102630376815796, acc = 0.9013671875\n",
      "Batch 31: loss = 0.2735450267791748, acc = 0.9130859375\n",
      "Batch 32: loss = 0.3212752640247345, acc = 0.8896484375\n",
      "Batch 33: loss = 0.24491526186466217, acc = 0.9130859375\n",
      "Batch 34: loss = 0.26668694615364075, acc = 0.91796875\n",
      "Batch 35: loss = 0.2686263918876648, acc = 0.908203125\n",
      "Batch 36: loss = 0.24083703756332397, acc = 0.9189453125\n",
      "Batch 37: loss = 0.26002636551856995, acc = 0.908203125\n",
      "Batch 38: loss = 0.24445509910583496, acc = 0.9208984375\n",
      "Batch 39: loss = 0.23941907286643982, acc = 0.92578125\n",
      "Batch 40: loss = 0.2740338444709778, acc = 0.908203125\n",
      "Batch 41: loss = 0.23294192552566528, acc = 0.9091796875\n",
      "Batch 42: loss = 0.25476503372192383, acc = 0.916015625\n",
      "Batch 43: loss = 0.280994713306427, acc = 0.91015625\n",
      "Batch 44: loss = 0.2525777816772461, acc = 0.91015625\n",
      "Batch 45: loss = 0.2594353258609772, acc = 0.912109375\n",
      "Batch 46: loss = 0.26012203097343445, acc = 0.9150390625\n",
      "Batch 47: loss = 0.24370671808719635, acc = 0.9189453125\n",
      "Batch 48: loss = 0.2431568205356598, acc = 0.9208984375\n",
      "Batch 49: loss = 0.20493289828300476, acc = 0.9365234375\n",
      "Batch 50: loss = 0.24176755547523499, acc = 0.9140625\n",
      "Batch 51: loss = 0.2855214774608612, acc = 0.904296875\n",
      "Batch 52: loss = 0.23724886775016785, acc = 0.919921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 53: loss = 0.26870226860046387, acc = 0.9111328125\n",
      "Batch 54: loss = 0.22646775841712952, acc = 0.923828125\n",
      "Batch 55: loss = 0.2634690999984741, acc = 0.9111328125\n",
      "Batch 56: loss = 0.2641827464103699, acc = 0.9052734375\n",
      "Batch 57: loss = 0.285825252532959, acc = 0.90234375\n",
      "Batch 58: loss = 0.31185099482536316, acc = 0.8984375\n",
      "Batch 59: loss = 0.2137758582830429, acc = 0.9326171875\n",
      "Batch 60: loss = 0.2777688503265381, acc = 0.9150390625\n",
      "Batch 61: loss = 0.26480984687805176, acc = 0.9072265625\n",
      "Batch 62: loss = 0.30592960119247437, acc = 0.8955078125\n",
      "Batch 63: loss = 0.24576599895954132, acc = 0.9150390625\n",
      "Batch 64: loss = 0.24450740218162537, acc = 0.9111328125\n",
      "Batch 65: loss = 0.2710583806037903, acc = 0.9140625\n",
      "Batch 66: loss = 0.2998000383377075, acc = 0.896484375\n",
      "Batch 67: loss = 0.25972020626068115, acc = 0.9150390625\n",
      "Batch 68: loss = 0.28752660751342773, acc = 0.9033203125\n",
      "Batch 69: loss = 0.24476808309555054, acc = 0.919921875\n",
      "Batch 70: loss = 0.2872067391872406, acc = 0.8955078125\n",
      "Batch 71: loss = 0.2665571868419647, acc = 0.9052734375\n",
      "Batch 72: loss = 0.2526283264160156, acc = 0.9130859375\n",
      "Batch 73: loss = 0.3134651780128479, acc = 0.8994140625\n",
      "Batch 74: loss = 0.30833834409713745, acc = 0.8916015625\n",
      "Batch 75: loss = 0.2738684415817261, acc = 0.908203125\n",
      "Batch 76: loss = 0.30600616335868835, acc = 0.904296875\n",
      "Batch 77: loss = 0.28927046060562134, acc = 0.904296875\n",
      "Batch 78: loss = 0.2725170850753784, acc = 0.912109375\n",
      "Batch 79: loss = 0.23296770453453064, acc = 0.9208984375\n",
      "Batch 80: loss = 0.24034768342971802, acc = 0.921875\n",
      "Batch 81: loss = 0.25364959239959717, acc = 0.9189453125\n",
      "Batch 82: loss = 0.26772117614746094, acc = 0.916015625\n",
      "Batch 83: loss = 0.2565614581108093, acc = 0.916015625\n",
      "Batch 84: loss = 0.2728095054626465, acc = 0.9208984375\n",
      "Batch 85: loss = 0.2623663544654846, acc = 0.91015625\n",
      "Batch 86: loss = 0.2720126509666443, acc = 0.9140625\n",
      "Batch 87: loss = 0.28218552470207214, acc = 0.90234375\n",
      "Batch 88: loss = 0.2893419861793518, acc = 0.91015625\n",
      "Batch 89: loss = 0.24971577525138855, acc = 0.9111328125\n",
      "Batch 90: loss = 0.2764548659324646, acc = 0.9091796875\n",
      "Batch 91: loss = 0.24336865544319153, acc = 0.919921875\n",
      "Batch 92: loss = 0.2900879383087158, acc = 0.8974609375\n",
      "Batch 93: loss = 0.24398531019687653, acc = 0.9111328125\n",
      "Batch 94: loss = 0.2407909631729126, acc = 0.9208984375\n",
      "Batch 95: loss = 0.2660222053527832, acc = 0.9111328125\n",
      "Batch 96: loss = 0.31922465562820435, acc = 0.8935546875\n",
      "Batch 97: loss = 0.2878137230873108, acc = 0.9033203125\n",
      "Batch 98: loss = 0.26843881607055664, acc = 0.91015625\n",
      "Batch 99: loss = 0.29814690351486206, acc = 0.90234375\n",
      "Batch 100: loss = 0.2628248631954193, acc = 0.90625\n",
      "Batch 101: loss = 0.29781633615493774, acc = 0.8916015625\n",
      "Batch 102: loss = 0.3002629280090332, acc = 0.90625\n",
      "Batch 103: loss = 0.28427302837371826, acc = 0.91015625\n",
      "Batch 104: loss = 0.24472853541374207, acc = 0.923828125\n",
      "Batch 105: loss = 0.2100425362586975, acc = 0.927734375\n",
      "Batch 106: loss = 0.2541869282722473, acc = 0.91015625\n",
      "Batch 107: loss = 0.24502158164978027, acc = 0.916015625\n",
      "Batch 108: loss = 0.2524699568748474, acc = 0.9130859375\n",
      "Batch 109: loss = 0.25813883543014526, acc = 0.91015625\n",
      "Batch 110: loss = 0.2758713662624359, acc = 0.9111328125\n",
      "Batch 111: loss = 0.24915394186973572, acc = 0.9189453125\n",
      "Batch 112: loss = 0.28514111042022705, acc = 0.908203125\n",
      "Batch 113: loss = 0.26649540662765503, acc = 0.9189453125\n",
      "Batch 114: loss = 0.2788280248641968, acc = 0.908203125\n",
      "Batch 115: loss = 0.3017447292804718, acc = 0.8994140625\n",
      "Batch 116: loss = 0.2616066634654999, acc = 0.91015625\n",
      "Batch 117: loss = 0.28927940130233765, acc = 0.9072265625\n",
      "Batch 118: loss = 0.2371271252632141, acc = 0.9150390625\n",
      "Batch 119: loss = 0.24621781706809998, acc = 0.921875\n",
      "Batch 120: loss = 0.24966518580913544, acc = 0.9228515625\n",
      "Batch 121: loss = 0.2393900752067566, acc = 0.916015625\n",
      "Batch 122: loss = 0.23489172756671906, acc = 0.919921875\n",
      "Batch 123: loss = 0.24949988722801208, acc = 0.923828125\n",
      "Batch 124: loss = 0.2809697091579437, acc = 0.8935546875\n",
      "Batch 125: loss = 0.2851077914237976, acc = 0.89453125\n",
      "Batch 126: loss = 0.27479124069213867, acc = 0.9111328125\n",
      "\n",
      "Epoch 86/100\n",
      "Batch 1: loss = 0.3853045105934143, acc = 0.890625\n",
      "Batch 2: loss = 0.280272901058197, acc = 0.9091796875\n",
      "Batch 3: loss = 0.2655854821205139, acc = 0.9140625\n",
      "Batch 4: loss = 0.2945353388786316, acc = 0.908203125\n",
      "Batch 5: loss = 0.26767000555992126, acc = 0.9140625\n",
      "Batch 6: loss = 0.31163710355758667, acc = 0.9052734375\n",
      "Batch 7: loss = 0.261627197265625, acc = 0.9072265625\n",
      "Batch 8: loss = 0.3022152781486511, acc = 0.908203125\n",
      "Batch 9: loss = 0.2720281183719635, acc = 0.9072265625\n",
      "Batch 10: loss = 0.23789609968662262, acc = 0.9169921875\n",
      "Batch 11: loss = 0.28666484355926514, acc = 0.8994140625\n",
      "Batch 12: loss = 0.24544981122016907, acc = 0.9130859375\n",
      "Batch 13: loss = 0.26548445224761963, acc = 0.912109375\n",
      "Batch 14: loss = 0.24915656447410583, acc = 0.91796875\n",
      "Batch 15: loss = 0.2616313099861145, acc = 0.919921875\n",
      "Batch 16: loss = 0.2690170407295227, acc = 0.9091796875\n",
      "Batch 17: loss = 0.261513352394104, acc = 0.91015625\n",
      "Batch 18: loss = 0.24909375607967377, acc = 0.912109375\n",
      "Batch 19: loss = 0.2524789571762085, acc = 0.9228515625\n",
      "Batch 20: loss = 0.2594573199748993, acc = 0.9140625\n",
      "Batch 21: loss = 0.2961239814758301, acc = 0.908203125\n",
      "Batch 22: loss = 0.272968590259552, acc = 0.9111328125\n",
      "Batch 23: loss = 0.3003995418548584, acc = 0.9091796875\n",
      "Batch 24: loss = 0.26417553424835205, acc = 0.9150390625\n",
      "Batch 25: loss = 0.24404765665531158, acc = 0.9228515625\n",
      "Batch 26: loss = 0.24718835949897766, acc = 0.9130859375\n",
      "Batch 27: loss = 0.2643510103225708, acc = 0.9150390625\n",
      "Batch 28: loss = 0.28241562843322754, acc = 0.9033203125\n",
      "Batch 29: loss = 0.285125732421875, acc = 0.9091796875\n",
      "Batch 30: loss = 0.26621532440185547, acc = 0.9130859375\n",
      "Batch 31: loss = 0.30671703815460205, acc = 0.8994140625\n",
      "Batch 32: loss = 0.30621227622032166, acc = 0.8955078125\n",
      "Batch 33: loss = 0.24295778572559357, acc = 0.9150390625\n",
      "Batch 34: loss = 0.2891390919685364, acc = 0.896484375\n",
      "Batch 35: loss = 0.2523883581161499, acc = 0.9150390625\n",
      "Batch 36: loss = 0.2761119306087494, acc = 0.91015625\n",
      "Batch 37: loss = 0.26452842354774475, acc = 0.9033203125\n",
      "Batch 38: loss = 0.24526691436767578, acc = 0.916015625\n",
      "Batch 39: loss = 0.2512029707431793, acc = 0.91015625\n",
      "Batch 40: loss = 0.2727982997894287, acc = 0.9140625\n",
      "Batch 41: loss = 0.23238898813724518, acc = 0.9208984375\n",
      "Batch 42: loss = 0.2719424068927765, acc = 0.9072265625\n",
      "Batch 43: loss = 0.2956392765045166, acc = 0.9013671875\n",
      "Batch 44: loss = 0.2937389016151428, acc = 0.9052734375\n",
      "Batch 45: loss = 0.26281172037124634, acc = 0.916015625\n",
      "Batch 46: loss = 0.22826480865478516, acc = 0.92578125\n",
      "Batch 47: loss = 0.2536025643348694, acc = 0.9287109375\n",
      "Batch 48: loss = 0.25433337688446045, acc = 0.916015625\n",
      "Batch 49: loss = 0.21936115622520447, acc = 0.927734375\n",
      "Batch 50: loss = 0.24562402069568634, acc = 0.9169921875\n",
      "Batch 51: loss = 0.27967119216918945, acc = 0.9111328125\n",
      "Batch 52: loss = 0.2870369255542755, acc = 0.90234375\n",
      "Batch 53: loss = 0.2611222267150879, acc = 0.912109375\n",
      "Batch 54: loss = 0.22117114067077637, acc = 0.9306640625\n",
      "Batch 55: loss = 0.24261251091957092, acc = 0.9150390625\n",
      "Batch 56: loss = 0.3141273260116577, acc = 0.8935546875\n",
      "Batch 57: loss = 0.2659875154495239, acc = 0.90234375\n",
      "Batch 58: loss = 0.34539908170700073, acc = 0.890625\n",
      "Batch 59: loss = 0.23162254691123962, acc = 0.9248046875\n",
      "Batch 60: loss = 0.2859708070755005, acc = 0.8974609375\n",
      "Batch 61: loss = 0.25105416774749756, acc = 0.9189453125\n",
      "Batch 62: loss = 0.28167569637298584, acc = 0.9052734375\n",
      "Batch 63: loss = 0.25098150968551636, acc = 0.9228515625\n",
      "Batch 64: loss = 0.22472618520259857, acc = 0.9228515625\n",
      "Batch 65: loss = 0.2842913866043091, acc = 0.908203125\n",
      "Batch 66: loss = 0.26084738969802856, acc = 0.91015625\n",
      "Batch 67: loss = 0.2438172698020935, acc = 0.9111328125\n",
      "Batch 68: loss = 0.24493232369422913, acc = 0.9189453125\n",
      "Batch 69: loss = 0.23447269201278687, acc = 0.9189453125\n",
      "Batch 70: loss = 0.2769668400287628, acc = 0.8974609375\n",
      "Batch 71: loss = 0.25212782621383667, acc = 0.9052734375\n",
      "Batch 72: loss = 0.2576296925544739, acc = 0.9111328125\n",
      "Batch 73: loss = 0.31255728006362915, acc = 0.89453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 74: loss = 0.2703550159931183, acc = 0.8984375\n",
      "Batch 75: loss = 0.304915189743042, acc = 0.8896484375\n",
      "Batch 76: loss = 0.3021891415119171, acc = 0.8837890625\n",
      "Batch 77: loss = 0.2558031678199768, acc = 0.9130859375\n",
      "Batch 78: loss = 0.24739393591880798, acc = 0.919921875\n",
      "Batch 79: loss = 0.23241253197193146, acc = 0.9189453125\n",
      "Batch 80: loss = 0.23408061265945435, acc = 0.912109375\n",
      "Batch 81: loss = 0.2649599611759186, acc = 0.900390625\n",
      "Batch 82: loss = 0.2690092921257019, acc = 0.9091796875\n",
      "Batch 83: loss = 0.270564466714859, acc = 0.900390625\n",
      "Batch 84: loss = 0.26100778579711914, acc = 0.9228515625\n",
      "Batch 85: loss = 0.28908127546310425, acc = 0.88671875\n",
      "Batch 86: loss = 0.2711237370967865, acc = 0.9072265625\n",
      "Batch 87: loss = 0.2639892101287842, acc = 0.9130859375\n",
      "Batch 88: loss = 0.30938780307769775, acc = 0.890625\n",
      "Batch 89: loss = 0.2715745270252228, acc = 0.9111328125\n",
      "Batch 90: loss = 0.2689799964427948, acc = 0.908203125\n",
      "Batch 91: loss = 0.267871230840683, acc = 0.912109375\n",
      "Batch 92: loss = 0.29584765434265137, acc = 0.900390625\n",
      "Batch 93: loss = 0.3098098039627075, acc = 0.890625\n",
      "Batch 94: loss = 0.24163520336151123, acc = 0.919921875\n",
      "Batch 95: loss = 0.234724760055542, acc = 0.919921875\n",
      "Batch 96: loss = 0.29641956090927124, acc = 0.8935546875\n",
      "Batch 97: loss = 0.2771158218383789, acc = 0.9052734375\n",
      "Batch 98: loss = 0.280049204826355, acc = 0.9072265625\n",
      "Batch 99: loss = 0.27500635385513306, acc = 0.9130859375\n",
      "Batch 100: loss = 0.27011141180992126, acc = 0.8994140625\n",
      "Batch 101: loss = 0.2601437568664551, acc = 0.9169921875\n",
      "Batch 102: loss = 0.27118176221847534, acc = 0.912109375\n",
      "Batch 103: loss = 0.2663254141807556, acc = 0.9111328125\n",
      "Batch 104: loss = 0.23344764113426208, acc = 0.921875\n",
      "Batch 105: loss = 0.2395092397928238, acc = 0.9326171875\n",
      "Batch 106: loss = 0.23890241980552673, acc = 0.919921875\n",
      "Batch 107: loss = 0.25440865755081177, acc = 0.908203125\n",
      "Batch 108: loss = 0.28843429684638977, acc = 0.9091796875\n",
      "Batch 109: loss = 0.2621312141418457, acc = 0.912109375\n",
      "Batch 110: loss = 0.23707644641399384, acc = 0.9306640625\n",
      "Batch 111: loss = 0.2635592818260193, acc = 0.9013671875\n",
      "Batch 112: loss = 0.27063679695129395, acc = 0.9052734375\n",
      "Batch 113: loss = 0.2701984643936157, acc = 0.91015625\n",
      "Batch 114: loss = 0.2593483626842499, acc = 0.90625\n",
      "Batch 115: loss = 0.2828862965106964, acc = 0.90625\n",
      "Batch 116: loss = 0.2729938328266144, acc = 0.9111328125\n",
      "Batch 117: loss = 0.26365944743156433, acc = 0.9111328125\n",
      "Batch 118: loss = 0.2476186901330948, acc = 0.9111328125\n",
      "Batch 119: loss = 0.22198210656642914, acc = 0.916015625\n",
      "Batch 120: loss = 0.23225603997707367, acc = 0.9189453125\n",
      "Batch 121: loss = 0.2681597173213959, acc = 0.9072265625\n",
      "Batch 122: loss = 0.2454569786787033, acc = 0.91796875\n",
      "Batch 123: loss = 0.27137649059295654, acc = 0.9111328125\n",
      "Batch 124: loss = 0.2765195071697235, acc = 0.908203125\n",
      "Batch 125: loss = 0.25544655323028564, acc = 0.9189453125\n",
      "Batch 126: loss = 0.28468048572540283, acc = 0.90625\n",
      "\n",
      "Epoch 87/100\n",
      "Batch 1: loss = 0.42134228348731995, acc = 0.87890625\n",
      "Batch 2: loss = 0.2628682851791382, acc = 0.9140625\n",
      "Batch 3: loss = 0.2864372134208679, acc = 0.908203125\n",
      "Batch 4: loss = 0.2427656352519989, acc = 0.9267578125\n",
      "Batch 5: loss = 0.2845990061759949, acc = 0.9111328125\n",
      "Batch 6: loss = 0.3232993483543396, acc = 0.8984375\n",
      "Batch 7: loss = 0.28551268577575684, acc = 0.8994140625\n",
      "Batch 8: loss = 0.2968544363975525, acc = 0.8984375\n",
      "Batch 9: loss = 0.2779235243797302, acc = 0.90234375\n",
      "Batch 10: loss = 0.25389182567596436, acc = 0.9130859375\n",
      "Batch 11: loss = 0.2812098264694214, acc = 0.90625\n",
      "Batch 12: loss = 0.22350266575813293, acc = 0.923828125\n",
      "Batch 13: loss = 0.2896695137023926, acc = 0.90234375\n",
      "Batch 14: loss = 0.22050458192825317, acc = 0.9345703125\n",
      "Batch 15: loss = 0.22914832830429077, acc = 0.923828125\n",
      "Batch 16: loss = 0.23013466596603394, acc = 0.923828125\n",
      "Batch 17: loss = 0.27749550342559814, acc = 0.9052734375\n",
      "Batch 18: loss = 0.23945529758930206, acc = 0.9296875\n",
      "Batch 19: loss = 0.2686203122138977, acc = 0.9140625\n",
      "Batch 20: loss = 0.2787826657295227, acc = 0.9013671875\n",
      "Batch 21: loss = 0.31958824396133423, acc = 0.890625\n",
      "Batch 22: loss = 0.2699715495109558, acc = 0.904296875\n",
      "Batch 23: loss = 0.28380855917930603, acc = 0.90234375\n",
      "Batch 24: loss = 0.23782989382743835, acc = 0.9248046875\n",
      "Batch 25: loss = 0.27344274520874023, acc = 0.9072265625\n",
      "Batch 26: loss = 0.2645893096923828, acc = 0.91015625\n",
      "Batch 27: loss = 0.2727833688259125, acc = 0.9033203125\n",
      "Batch 28: loss = 0.279376357793808, acc = 0.91015625\n",
      "Batch 29: loss = 0.31157854199409485, acc = 0.892578125\n",
      "Batch 30: loss = 0.2846284508705139, acc = 0.9091796875\n",
      "Batch 31: loss = 0.29159995913505554, acc = 0.89453125\n",
      "Batch 32: loss = 0.3092803657054901, acc = 0.8955078125\n",
      "Batch 33: loss = 0.2304217368364334, acc = 0.9267578125\n",
      "Batch 34: loss = 0.27692341804504395, acc = 0.904296875\n",
      "Batch 35: loss = 0.2756088674068451, acc = 0.9111328125\n",
      "Batch 36: loss = 0.22138458490371704, acc = 0.9267578125\n",
      "Batch 37: loss = 0.2072622925043106, acc = 0.927734375\n",
      "Batch 38: loss = 0.25996652245521545, acc = 0.9189453125\n",
      "Batch 39: loss = 0.24074429273605347, acc = 0.9208984375\n",
      "Batch 40: loss = 0.28311455249786377, acc = 0.8994140625\n",
      "Batch 41: loss = 0.2668182849884033, acc = 0.904296875\n",
      "Batch 42: loss = 0.24611815810203552, acc = 0.923828125\n",
      "Batch 43: loss = 0.26839128136634827, acc = 0.91015625\n",
      "Batch 44: loss = 0.23459859192371368, acc = 0.9248046875\n",
      "Batch 45: loss = 0.22364655137062073, acc = 0.9248046875\n",
      "Batch 46: loss = 0.22159871459007263, acc = 0.9248046875\n",
      "Batch 47: loss = 0.2651698589324951, acc = 0.9150390625\n",
      "Batch 48: loss = 0.2496800571680069, acc = 0.9189453125\n",
      "Batch 49: loss = 0.23104742169380188, acc = 0.9365234375\n",
      "Batch 50: loss = 0.2261812686920166, acc = 0.923828125\n",
      "Batch 51: loss = 0.2627701759338379, acc = 0.91796875\n",
      "Batch 52: loss = 0.2538231611251831, acc = 0.9091796875\n",
      "Batch 53: loss = 0.25010761618614197, acc = 0.9140625\n",
      "Batch 54: loss = 0.2436991035938263, acc = 0.916015625\n",
      "Batch 55: loss = 0.23323750495910645, acc = 0.9296875\n",
      "Batch 56: loss = 0.27179425954818726, acc = 0.9013671875\n",
      "Batch 57: loss = 0.2778821289539337, acc = 0.9072265625\n",
      "Batch 58: loss = 0.2899407148361206, acc = 0.8984375\n",
      "Batch 59: loss = 0.234333798289299, acc = 0.91796875\n",
      "Batch 60: loss = 0.28898686170578003, acc = 0.8984375\n",
      "Batch 61: loss = 0.22968457639217377, acc = 0.921875\n",
      "Batch 62: loss = 0.26901674270629883, acc = 0.9091796875\n",
      "Batch 63: loss = 0.22364027798175812, acc = 0.9287109375\n",
      "Batch 64: loss = 0.24162927269935608, acc = 0.908203125\n",
      "Batch 65: loss = 0.27293825149536133, acc = 0.904296875\n",
      "Batch 66: loss = 0.28222936391830444, acc = 0.9033203125\n",
      "Batch 67: loss = 0.2570698857307434, acc = 0.9169921875\n",
      "Batch 68: loss = 0.2906523048877716, acc = 0.904296875\n",
      "Batch 69: loss = 0.21174287796020508, acc = 0.9345703125\n",
      "Batch 70: loss = 0.28259921073913574, acc = 0.8984375\n",
      "Batch 71: loss = 0.27785032987594604, acc = 0.9072265625\n",
      "Batch 72: loss = 0.27125537395477295, acc = 0.9130859375\n",
      "Batch 73: loss = 0.2741292119026184, acc = 0.9111328125\n",
      "Batch 74: loss = 0.25905606150627136, acc = 0.9169921875\n",
      "Batch 75: loss = 0.31110814213752747, acc = 0.8974609375\n",
      "Batch 76: loss = 0.28516334295272827, acc = 0.908203125\n",
      "Batch 77: loss = 0.27606841921806335, acc = 0.91015625\n",
      "Batch 78: loss = 0.2776470184326172, acc = 0.9091796875\n",
      "Batch 79: loss = 0.25783777236938477, acc = 0.9150390625\n",
      "Batch 80: loss = 0.21988169848918915, acc = 0.9248046875\n",
      "Batch 81: loss = 0.28165701031684875, acc = 0.900390625\n",
      "Batch 82: loss = 0.28640174865722656, acc = 0.9072265625\n",
      "Batch 83: loss = 0.28731587529182434, acc = 0.90234375\n",
      "Batch 84: loss = 0.25871244072914124, acc = 0.9052734375\n",
      "Batch 85: loss = 0.2717934846878052, acc = 0.908203125\n",
      "Batch 86: loss = 0.27330487966537476, acc = 0.9013671875\n",
      "Batch 87: loss = 0.266533762216568, acc = 0.9150390625\n",
      "Batch 88: loss = 0.28097277879714966, acc = 0.9111328125\n",
      "Batch 89: loss = 0.24058225750923157, acc = 0.92578125\n",
      "Batch 90: loss = 0.2870085537433624, acc = 0.900390625\n",
      "Batch 91: loss = 0.27600017189979553, acc = 0.912109375\n",
      "Batch 92: loss = 0.2792854905128479, acc = 0.91015625\n",
      "Batch 93: loss = 0.2761063277721405, acc = 0.9072265625\n",
      "Batch 94: loss = 0.2477414608001709, acc = 0.9189453125\n",
      "Batch 95: loss = 0.21943368017673492, acc = 0.9384765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 96: loss = 0.27904295921325684, acc = 0.900390625\n",
      "Batch 97: loss = 0.29974180459976196, acc = 0.8955078125\n",
      "Batch 98: loss = 0.29067277908325195, acc = 0.9013671875\n",
      "Batch 99: loss = 0.2939061224460602, acc = 0.904296875\n",
      "Batch 100: loss = 0.2685961127281189, acc = 0.9072265625\n",
      "Batch 101: loss = 0.23375225067138672, acc = 0.912109375\n",
      "Batch 102: loss = 0.28928375244140625, acc = 0.890625\n",
      "Batch 103: loss = 0.26748132705688477, acc = 0.904296875\n",
      "Batch 104: loss = 0.2500564157962799, acc = 0.9130859375\n",
      "Batch 105: loss = 0.2634865939617157, acc = 0.908203125\n",
      "Batch 106: loss = 0.23140154778957367, acc = 0.9267578125\n",
      "Batch 107: loss = 0.2683662176132202, acc = 0.91015625\n",
      "Batch 108: loss = 0.2708093523979187, acc = 0.9072265625\n",
      "Batch 109: loss = 0.23317360877990723, acc = 0.923828125\n",
      "Batch 110: loss = 0.25276219844818115, acc = 0.9228515625\n",
      "Batch 111: loss = 0.23547019064426422, acc = 0.92578125\n",
      "Batch 112: loss = 0.2552763819694519, acc = 0.91015625\n",
      "Batch 113: loss = 0.25782907009124756, acc = 0.912109375\n",
      "Batch 114: loss = 0.26325300335884094, acc = 0.9150390625\n",
      "Batch 115: loss = 0.26943546533584595, acc = 0.9169921875\n",
      "Batch 116: loss = 0.27860188484191895, acc = 0.908203125\n",
      "Batch 117: loss = 0.2849568724632263, acc = 0.9091796875\n",
      "Batch 118: loss = 0.25263312458992004, acc = 0.9130859375\n",
      "Batch 119: loss = 0.263767808675766, acc = 0.9140625\n",
      "Batch 120: loss = 0.2362576574087143, acc = 0.921875\n",
      "Batch 121: loss = 0.25029993057250977, acc = 0.91796875\n",
      "Batch 122: loss = 0.23576948046684265, acc = 0.91796875\n",
      "Batch 123: loss = 0.26908767223358154, acc = 0.9150390625\n",
      "Batch 124: loss = 0.2775256633758545, acc = 0.9052734375\n",
      "Batch 125: loss = 0.29180943965911865, acc = 0.90234375\n",
      "Batch 126: loss = 0.24593952298164368, acc = 0.923828125\n",
      "\n",
      "Epoch 88/100\n",
      "Batch 1: loss = 0.395378053188324, acc = 0.8837890625\n",
      "Batch 2: loss = 0.3009544014930725, acc = 0.896484375\n",
      "Batch 3: loss = 0.2875526547431946, acc = 0.900390625\n",
      "Batch 4: loss = 0.27491289377212524, acc = 0.904296875\n",
      "Batch 5: loss = 0.2676360011100769, acc = 0.9072265625\n",
      "Batch 6: loss = 0.280447781085968, acc = 0.90234375\n",
      "Batch 7: loss = 0.2626103162765503, acc = 0.904296875\n",
      "Batch 8: loss = 0.27651864290237427, acc = 0.9072265625\n",
      "Batch 9: loss = 0.24780674278736115, acc = 0.9150390625\n",
      "Batch 10: loss = 0.22779962420463562, acc = 0.921875\n",
      "Batch 11: loss = 0.25971996784210205, acc = 0.91015625\n",
      "Batch 12: loss = 0.244241863489151, acc = 0.9208984375\n",
      "Batch 13: loss = 0.26916128396987915, acc = 0.912109375\n",
      "Batch 14: loss = 0.29167884588241577, acc = 0.908203125\n",
      "Batch 15: loss = 0.2531716525554657, acc = 0.9130859375\n",
      "Batch 16: loss = 0.24509567022323608, acc = 0.912109375\n",
      "Batch 17: loss = 0.25187739729881287, acc = 0.9189453125\n",
      "Batch 18: loss = 0.2598998248577118, acc = 0.912109375\n",
      "Batch 19: loss = 0.2889748811721802, acc = 0.904296875\n",
      "Batch 20: loss = 0.2722412049770355, acc = 0.90625\n",
      "Batch 21: loss = 0.30130600929260254, acc = 0.896484375\n",
      "Batch 22: loss = 0.28453388810157776, acc = 0.9091796875\n",
      "Batch 23: loss = 0.2780458331108093, acc = 0.916015625\n",
      "Batch 24: loss = 0.26334452629089355, acc = 0.9091796875\n",
      "Batch 25: loss = 0.2582138180732727, acc = 0.9140625\n",
      "Batch 26: loss = 0.23193517327308655, acc = 0.91796875\n",
      "Batch 27: loss = 0.2376471906900406, acc = 0.9208984375\n",
      "Batch 28: loss = 0.2380741834640503, acc = 0.9208984375\n",
      "Batch 29: loss = 0.2960957884788513, acc = 0.8994140625\n",
      "Batch 30: loss = 0.2543860971927643, acc = 0.916015625\n",
      "Batch 31: loss = 0.26888516545295715, acc = 0.9140625\n",
      "Batch 32: loss = 0.26835131645202637, acc = 0.91015625\n",
      "Batch 33: loss = 0.2561676502227783, acc = 0.91796875\n",
      "Batch 34: loss = 0.24952545762062073, acc = 0.916015625\n",
      "Batch 35: loss = 0.2846010625362396, acc = 0.9169921875\n",
      "Batch 36: loss = 0.2750106155872345, acc = 0.8994140625\n",
      "Batch 37: loss = 0.2313610166311264, acc = 0.921875\n",
      "Batch 38: loss = 0.2706860899925232, acc = 0.908203125\n",
      "Batch 39: loss = 0.22680802643299103, acc = 0.9326171875\n",
      "Batch 40: loss = 0.28988105058670044, acc = 0.90625\n",
      "Batch 41: loss = 0.272743821144104, acc = 0.900390625\n",
      "Batch 42: loss = 0.26408684253692627, acc = 0.9150390625\n",
      "Batch 43: loss = 0.2818549871444702, acc = 0.90234375\n",
      "Batch 44: loss = 0.24177980422973633, acc = 0.9169921875\n",
      "Batch 45: loss = 0.2634057104587555, acc = 0.9169921875\n",
      "Batch 46: loss = 0.255784273147583, acc = 0.912109375\n",
      "Batch 47: loss = 0.2727240324020386, acc = 0.9033203125\n",
      "Batch 48: loss = 0.2519650459289551, acc = 0.9208984375\n",
      "Batch 49: loss = 0.22588613629341125, acc = 0.923828125\n",
      "Batch 50: loss = 0.2307768017053604, acc = 0.916015625\n",
      "Batch 51: loss = 0.24340204894542694, acc = 0.919921875\n",
      "Batch 52: loss = 0.24376794695854187, acc = 0.9150390625\n",
      "Batch 53: loss = 0.27910465002059937, acc = 0.90625\n",
      "Batch 54: loss = 0.23805908858776093, acc = 0.91015625\n",
      "Batch 55: loss = 0.23864571750164032, acc = 0.927734375\n",
      "Batch 56: loss = 0.25861063599586487, acc = 0.90625\n",
      "Batch 57: loss = 0.25652623176574707, acc = 0.90625\n",
      "Batch 58: loss = 0.28181883692741394, acc = 0.90625\n",
      "Batch 59: loss = 0.20413807034492493, acc = 0.9287109375\n",
      "Batch 60: loss = 0.2775891125202179, acc = 0.9091796875\n",
      "Batch 61: loss = 0.2340461164712906, acc = 0.9267578125\n",
      "Batch 62: loss = 0.25339385867118835, acc = 0.9140625\n",
      "Batch 63: loss = 0.2873879671096802, acc = 0.9091796875\n",
      "Batch 64: loss = 0.24152639508247375, acc = 0.9140625\n",
      "Batch 65: loss = 0.2515999674797058, acc = 0.9130859375\n",
      "Batch 66: loss = 0.2987439036369324, acc = 0.9052734375\n",
      "Batch 67: loss = 0.254935085773468, acc = 0.908203125\n",
      "Batch 68: loss = 0.27891668677330017, acc = 0.90625\n",
      "Batch 69: loss = 0.26528358459472656, acc = 0.91796875\n",
      "Batch 70: loss = 0.2795681953430176, acc = 0.9150390625\n",
      "Batch 71: loss = 0.26909762620925903, acc = 0.9130859375\n",
      "Batch 72: loss = 0.24313011765480042, acc = 0.921875\n",
      "Batch 73: loss = 0.27183404564857483, acc = 0.904296875\n",
      "Batch 74: loss = 0.28099703788757324, acc = 0.9072265625\n",
      "Batch 75: loss = 0.2884012460708618, acc = 0.8955078125\n",
      "Batch 76: loss = 0.2744012773036957, acc = 0.900390625\n",
      "Batch 77: loss = 0.24586129188537598, acc = 0.9091796875\n",
      "Batch 78: loss = 0.24276050925254822, acc = 0.9130859375\n",
      "Batch 79: loss = 0.24020341038703918, acc = 0.923828125\n",
      "Batch 80: loss = 0.23095101118087769, acc = 0.9150390625\n",
      "Batch 81: loss = 0.2631797790527344, acc = 0.912109375\n",
      "Batch 82: loss = 0.27573642134666443, acc = 0.9052734375\n",
      "Batch 83: loss = 0.2611960768699646, acc = 0.91015625\n",
      "Batch 84: loss = 0.286251962184906, acc = 0.90234375\n",
      "Batch 85: loss = 0.2483164668083191, acc = 0.9140625\n",
      "Batch 86: loss = 0.2404029369354248, acc = 0.9228515625\n",
      "Batch 87: loss = 0.2696912884712219, acc = 0.9169921875\n",
      "Batch 88: loss = 0.31173378229141235, acc = 0.8984375\n",
      "Batch 89: loss = 0.27673766016960144, acc = 0.9140625\n",
      "Batch 90: loss = 0.26068538427352905, acc = 0.9033203125\n",
      "Batch 91: loss = 0.2759177088737488, acc = 0.9072265625\n",
      "Batch 92: loss = 0.3050485849380493, acc = 0.8955078125\n",
      "Batch 93: loss = 0.23106294870376587, acc = 0.916015625\n",
      "Batch 94: loss = 0.23563826084136963, acc = 0.9228515625\n",
      "Batch 95: loss = 0.22284188866615295, acc = 0.9208984375\n",
      "Batch 96: loss = 0.2954874634742737, acc = 0.8994140625\n",
      "Batch 97: loss = 0.2877451479434967, acc = 0.900390625\n",
      "Batch 98: loss = 0.24746888875961304, acc = 0.9150390625\n",
      "Batch 99: loss = 0.2711125612258911, acc = 0.9072265625\n",
      "Batch 100: loss = 0.24929729104042053, acc = 0.9130859375\n",
      "Batch 101: loss = 0.25584185123443604, acc = 0.9130859375\n",
      "Batch 102: loss = 0.2747070789337158, acc = 0.90234375\n",
      "Batch 103: loss = 0.3064557909965515, acc = 0.8896484375\n",
      "Batch 104: loss = 0.251849889755249, acc = 0.916015625\n",
      "Batch 105: loss = 0.24176885187625885, acc = 0.919921875\n",
      "Batch 106: loss = 0.24342045187950134, acc = 0.919921875\n",
      "Batch 107: loss = 0.21709051728248596, acc = 0.9306640625\n",
      "Batch 108: loss = 0.2655360698699951, acc = 0.9130859375\n",
      "Batch 109: loss = 0.2726103663444519, acc = 0.916015625\n",
      "Batch 110: loss = 0.26946038007736206, acc = 0.9140625\n",
      "Batch 111: loss = 0.23645731806755066, acc = 0.9208984375\n",
      "Batch 112: loss = 0.2427910566329956, acc = 0.9208984375\n",
      "Batch 113: loss = 0.24776770174503326, acc = 0.9130859375\n",
      "Batch 114: loss = 0.28188276290893555, acc = 0.9052734375\n",
      "Batch 115: loss = 0.27161747217178345, acc = 0.9140625\n",
      "Batch 116: loss = 0.2657228112220764, acc = 0.916015625\n",
      "Batch 117: loss = 0.2619503140449524, acc = 0.9091796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 118: loss = 0.2287348061800003, acc = 0.9140625\n",
      "Batch 119: loss = 0.23362740874290466, acc = 0.9208984375\n",
      "Batch 120: loss = 0.22537089884281158, acc = 0.921875\n",
      "Batch 121: loss = 0.23219086229801178, acc = 0.916015625\n",
      "Batch 122: loss = 0.2529650330543518, acc = 0.916015625\n",
      "Batch 123: loss = 0.26410597562789917, acc = 0.921875\n",
      "Batch 124: loss = 0.2621996998786926, acc = 0.908203125\n",
      "Batch 125: loss = 0.2672000527381897, acc = 0.9111328125\n",
      "Batch 126: loss = 0.281141996383667, acc = 0.9072265625\n",
      "\n",
      "Epoch 89/100\n",
      "Batch 1: loss = 0.3591761589050293, acc = 0.9033203125\n",
      "Batch 2: loss = 0.27293068170547485, acc = 0.9033203125\n",
      "Batch 3: loss = 0.27732032537460327, acc = 0.9150390625\n",
      "Batch 4: loss = 0.24746179580688477, acc = 0.92578125\n",
      "Batch 5: loss = 0.2538941502571106, acc = 0.921875\n",
      "Batch 6: loss = 0.2749217748641968, acc = 0.9072265625\n",
      "Batch 7: loss = 0.2999931275844574, acc = 0.8955078125\n",
      "Batch 8: loss = 0.2548621892929077, acc = 0.9140625\n",
      "Batch 9: loss = 0.2588788866996765, acc = 0.908203125\n",
      "Batch 10: loss = 0.21070393919944763, acc = 0.931640625\n",
      "Batch 11: loss = 0.25138330459594727, acc = 0.9111328125\n",
      "Batch 12: loss = 0.24532470107078552, acc = 0.91015625\n",
      "Batch 13: loss = 0.2200963795185089, acc = 0.921875\n",
      "Batch 14: loss = 0.2552192509174347, acc = 0.91796875\n",
      "Batch 15: loss = 0.25203558802604675, acc = 0.9072265625\n",
      "Batch 16: loss = 0.24723774194717407, acc = 0.9091796875\n",
      "Batch 17: loss = 0.2625129818916321, acc = 0.9150390625\n",
      "Batch 18: loss = 0.2713860869407654, acc = 0.90625\n",
      "Batch 19: loss = 0.26189589500427246, acc = 0.919921875\n",
      "Batch 20: loss = 0.2816869616508484, acc = 0.9072265625\n",
      "Batch 21: loss = 0.26477447152137756, acc = 0.91015625\n",
      "Batch 22: loss = 0.24855464696884155, acc = 0.91796875\n",
      "Batch 23: loss = 0.30877673625946045, acc = 0.896484375\n",
      "Batch 24: loss = 0.27503669261932373, acc = 0.9072265625\n",
      "Batch 25: loss = 0.2563279867172241, acc = 0.9140625\n",
      "Batch 26: loss = 0.24880731105804443, acc = 0.91796875\n",
      "Batch 27: loss = 0.2546374201774597, acc = 0.9140625\n",
      "Batch 28: loss = 0.26839107275009155, acc = 0.904296875\n",
      "Batch 29: loss = 0.27511340379714966, acc = 0.9052734375\n",
      "Batch 30: loss = 0.2628350257873535, acc = 0.9111328125\n",
      "Batch 31: loss = 0.27362576127052307, acc = 0.912109375\n",
      "Batch 32: loss = 0.26571184396743774, acc = 0.91796875\n",
      "Batch 33: loss = 0.2418021857738495, acc = 0.9189453125\n",
      "Batch 34: loss = 0.2558078467845917, acc = 0.9052734375\n",
      "Batch 35: loss = 0.27239587903022766, acc = 0.9072265625\n",
      "Batch 36: loss = 0.25563761591911316, acc = 0.9169921875\n",
      "Batch 37: loss = 0.2357468605041504, acc = 0.9228515625\n",
      "Batch 38: loss = 0.24352623522281647, acc = 0.9208984375\n",
      "Batch 39: loss = 0.2644219398498535, acc = 0.9169921875\n",
      "Batch 40: loss = 0.25194770097732544, acc = 0.916015625\n",
      "Batch 41: loss = 0.22568821907043457, acc = 0.9306640625\n",
      "Batch 42: loss = 0.2638435363769531, acc = 0.9091796875\n",
      "Batch 43: loss = 0.2939308285713196, acc = 0.892578125\n",
      "Batch 44: loss = 0.2615985870361328, acc = 0.9130859375\n",
      "Batch 45: loss = 0.25799286365509033, acc = 0.912109375\n",
      "Batch 46: loss = 0.2255030870437622, acc = 0.92578125\n",
      "Batch 47: loss = 0.25671499967575073, acc = 0.9140625\n",
      "Batch 48: loss = 0.2540379762649536, acc = 0.9189453125\n",
      "Batch 49: loss = 0.21611288189888, acc = 0.9306640625\n",
      "Batch 50: loss = 0.24000795185565948, acc = 0.912109375\n",
      "Batch 51: loss = 0.2576974928379059, acc = 0.91015625\n",
      "Batch 52: loss = 0.2454722672700882, acc = 0.912109375\n",
      "Batch 53: loss = 0.27546513080596924, acc = 0.9111328125\n",
      "Batch 54: loss = 0.2397688329219818, acc = 0.92578125\n",
      "Batch 55: loss = 0.2354031205177307, acc = 0.916015625\n",
      "Batch 56: loss = 0.26364922523498535, acc = 0.9091796875\n",
      "Batch 57: loss = 0.24155350029468536, acc = 0.91796875\n",
      "Batch 58: loss = 0.2982192635536194, acc = 0.9072265625\n",
      "Batch 59: loss = 0.23284704983234406, acc = 0.9228515625\n",
      "Batch 60: loss = 0.27586567401885986, acc = 0.9111328125\n",
      "Batch 61: loss = 0.2556919455528259, acc = 0.916015625\n",
      "Batch 62: loss = 0.2913499176502228, acc = 0.9052734375\n",
      "Batch 63: loss = 0.23148681223392487, acc = 0.919921875\n",
      "Batch 64: loss = 0.24218089878559113, acc = 0.919921875\n",
      "Batch 65: loss = 0.26650065183639526, acc = 0.9208984375\n",
      "Batch 66: loss = 0.24537590146064758, acc = 0.923828125\n",
      "Batch 67: loss = 0.2621598243713379, acc = 0.904296875\n",
      "Batch 68: loss = 0.26074886322021484, acc = 0.9140625\n",
      "Batch 69: loss = 0.23325115442276, acc = 0.9248046875\n",
      "Batch 70: loss = 0.28467434644699097, acc = 0.892578125\n",
      "Batch 71: loss = 0.25447893142700195, acc = 0.91796875\n",
      "Batch 72: loss = 0.24769370257854462, acc = 0.9150390625\n",
      "Batch 73: loss = 0.29032739996910095, acc = 0.90234375\n",
      "Batch 74: loss = 0.29688018560409546, acc = 0.90234375\n",
      "Batch 75: loss = 0.2999149560928345, acc = 0.892578125\n",
      "Batch 76: loss = 0.2589558959007263, acc = 0.9140625\n",
      "Batch 77: loss = 0.2597520053386688, acc = 0.9052734375\n",
      "Batch 78: loss = 0.27749770879745483, acc = 0.90625\n",
      "Batch 79: loss = 0.25972867012023926, acc = 0.9140625\n",
      "Batch 80: loss = 0.2533007860183716, acc = 0.912109375\n",
      "Batch 81: loss = 0.25837528705596924, acc = 0.9091796875\n",
      "Batch 82: loss = 0.2678425908088684, acc = 0.91796875\n",
      "Batch 83: loss = 0.2696400284767151, acc = 0.9091796875\n",
      "Batch 84: loss = 0.24688658118247986, acc = 0.908203125\n",
      "Batch 85: loss = 0.26239633560180664, acc = 0.9072265625\n",
      "Batch 86: loss = 0.26745718717575073, acc = 0.9072265625\n",
      "Batch 87: loss = 0.2675284147262573, acc = 0.9091796875\n",
      "Batch 88: loss = 0.3149409294128418, acc = 0.8857421875\n",
      "Batch 89: loss = 0.28466296195983887, acc = 0.9072265625\n",
      "Batch 90: loss = 0.2698709964752197, acc = 0.9091796875\n",
      "Batch 91: loss = 0.24157676100730896, acc = 0.91796875\n",
      "Batch 92: loss = 0.2893664240837097, acc = 0.8984375\n",
      "Batch 93: loss = 0.2450314164161682, acc = 0.919921875\n",
      "Batch 94: loss = 0.23375430703163147, acc = 0.9287109375\n",
      "Batch 95: loss = 0.2185717076063156, acc = 0.9287109375\n",
      "Batch 96: loss = 0.2742553651332855, acc = 0.9130859375\n",
      "Batch 97: loss = 0.30835938453674316, acc = 0.90234375\n",
      "Batch 98: loss = 0.2536175847053528, acc = 0.916015625\n",
      "Batch 99: loss = 0.2590923309326172, acc = 0.912109375\n",
      "Batch 100: loss = 0.234818235039711, acc = 0.921875\n",
      "Batch 101: loss = 0.23030707240104675, acc = 0.923828125\n",
      "Batch 102: loss = 0.3029671907424927, acc = 0.892578125\n",
      "Batch 103: loss = 0.27442261576652527, acc = 0.9091796875\n",
      "Batch 104: loss = 0.263428270816803, acc = 0.9072265625\n",
      "Batch 105: loss = 0.2674292325973511, acc = 0.904296875\n",
      "Batch 106: loss = 0.24602839350700378, acc = 0.9150390625\n",
      "Batch 107: loss = 0.2588137090206146, acc = 0.9169921875\n",
      "Batch 108: loss = 0.2833530306816101, acc = 0.90625\n",
      "Batch 109: loss = 0.2327353060245514, acc = 0.927734375\n",
      "Batch 110: loss = 0.2587091326713562, acc = 0.9072265625\n",
      "Batch 111: loss = 0.2901315689086914, acc = 0.8974609375\n",
      "Batch 112: loss = 0.27112823724746704, acc = 0.90234375\n",
      "Batch 113: loss = 0.2784598767757416, acc = 0.8974609375\n",
      "Batch 114: loss = 0.25544410943984985, acc = 0.9169921875\n",
      "Batch 115: loss = 0.2583214044570923, acc = 0.9208984375\n",
      "Batch 116: loss = 0.24404343962669373, acc = 0.9111328125\n",
      "Batch 117: loss = 0.2680032253265381, acc = 0.916015625\n",
      "Batch 118: loss = 0.2459942102432251, acc = 0.9169921875\n",
      "Batch 119: loss = 0.2358739674091339, acc = 0.9287109375\n",
      "Batch 120: loss = 0.2585303783416748, acc = 0.9140625\n",
      "Batch 121: loss = 0.22648537158966064, acc = 0.921875\n",
      "Batch 122: loss = 0.2386631965637207, acc = 0.9140625\n",
      "Batch 123: loss = 0.2447355091571808, acc = 0.9189453125\n",
      "Batch 124: loss = 0.2913692891597748, acc = 0.896484375\n",
      "Batch 125: loss = 0.30968284606933594, acc = 0.8955078125\n",
      "Batch 126: loss = 0.27366793155670166, acc = 0.916015625\n",
      "\n",
      "Epoch 90/100\n",
      "Batch 1: loss = 0.3788425326347351, acc = 0.890625\n",
      "Batch 2: loss = 0.29837822914123535, acc = 0.9033203125\n",
      "Batch 3: loss = 0.3267292082309723, acc = 0.890625\n",
      "Batch 4: loss = 0.2751375138759613, acc = 0.921875\n",
      "Batch 5: loss = 0.28846001625061035, acc = 0.9072265625\n",
      "Batch 6: loss = 0.3035445213317871, acc = 0.9091796875\n",
      "Batch 7: loss = 0.2635687589645386, acc = 0.9248046875\n",
      "Batch 8: loss = 0.30401644110679626, acc = 0.90625\n",
      "Batch 9: loss = 0.2420991212129593, acc = 0.91015625\n",
      "Batch 10: loss = 0.2184808850288391, acc = 0.92578125\n",
      "Batch 11: loss = 0.2554436922073364, acc = 0.912109375\n",
      "Batch 12: loss = 0.24186021089553833, acc = 0.927734375\n",
      "Batch 13: loss = 0.2192142903804779, acc = 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14: loss = 0.2506992518901825, acc = 0.9228515625\n",
      "Batch 15: loss = 0.2412365823984146, acc = 0.921875\n",
      "Batch 16: loss = 0.26329755783081055, acc = 0.9130859375\n",
      "Batch 17: loss = 0.2432083636522293, acc = 0.9169921875\n",
      "Batch 18: loss = 0.23456978797912598, acc = 0.9150390625\n",
      "Batch 19: loss = 0.2505326271057129, acc = 0.923828125\n",
      "Batch 20: loss = 0.2377699911594391, acc = 0.9150390625\n",
      "Batch 21: loss = 0.30308517813682556, acc = 0.8974609375\n",
      "Batch 22: loss = 0.30845263600349426, acc = 0.8974609375\n",
      "Batch 23: loss = 0.3024018108844757, acc = 0.908203125\n",
      "Batch 24: loss = 0.25752294063568115, acc = 0.9111328125\n",
      "Batch 25: loss = 0.25181278586387634, acc = 0.912109375\n",
      "Batch 26: loss = 0.2767561376094818, acc = 0.9033203125\n",
      "Batch 27: loss = 0.2652170956134796, acc = 0.9169921875\n",
      "Batch 28: loss = 0.24763287603855133, acc = 0.9150390625\n",
      "Batch 29: loss = 0.24951694905757904, acc = 0.916015625\n",
      "Batch 30: loss = 0.26134252548217773, acc = 0.9033203125\n",
      "Batch 31: loss = 0.25758519768714905, acc = 0.9033203125\n",
      "Batch 32: loss = 0.27279478311538696, acc = 0.8994140625\n",
      "Batch 33: loss = 0.2591918110847473, acc = 0.912109375\n",
      "Batch 34: loss = 0.2667989134788513, acc = 0.9033203125\n",
      "Batch 35: loss = 0.26693278551101685, acc = 0.9130859375\n",
      "Batch 36: loss = 0.23572631180286407, acc = 0.9306640625\n",
      "Batch 37: loss = 0.23582759499549866, acc = 0.9189453125\n",
      "Batch 38: loss = 0.23400847613811493, acc = 0.9208984375\n",
      "Batch 39: loss = 0.21236032247543335, acc = 0.93359375\n",
      "Batch 40: loss = 0.26325881481170654, acc = 0.9091796875\n",
      "Batch 41: loss = 0.27156761288642883, acc = 0.90234375\n",
      "Batch 42: loss = 0.2383444905281067, acc = 0.9169921875\n",
      "Batch 43: loss = 0.2802031934261322, acc = 0.9033203125\n",
      "Batch 44: loss = 0.23121465742588043, acc = 0.923828125\n",
      "Batch 45: loss = 0.2612285017967224, acc = 0.9150390625\n",
      "Batch 46: loss = 0.24044851958751678, acc = 0.9248046875\n",
      "Batch 47: loss = 0.23920942842960358, acc = 0.9208984375\n",
      "Batch 48: loss = 0.19586573541164398, acc = 0.9404296875\n",
      "Batch 49: loss = 0.2578063905239105, acc = 0.919921875\n",
      "Batch 50: loss = 0.24303323030471802, acc = 0.9228515625\n",
      "Batch 51: loss = 0.2517051696777344, acc = 0.9189453125\n",
      "Batch 52: loss = 0.24406951665878296, acc = 0.9091796875\n",
      "Batch 53: loss = 0.24940262734889984, acc = 0.9267578125\n",
      "Batch 54: loss = 0.207449808716774, acc = 0.935546875\n",
      "Batch 55: loss = 0.2498466819524765, acc = 0.9169921875\n",
      "Batch 56: loss = 0.23970888555049896, acc = 0.9140625\n",
      "Batch 57: loss = 0.301300585269928, acc = 0.890625\n",
      "Batch 58: loss = 0.2800455689430237, acc = 0.9072265625\n",
      "Batch 59: loss = 0.2215615212917328, acc = 0.9267578125\n",
      "Batch 60: loss = 0.29352933168411255, acc = 0.90625\n",
      "Batch 61: loss = 0.23187297582626343, acc = 0.923828125\n",
      "Batch 62: loss = 0.2560569643974304, acc = 0.9169921875\n",
      "Batch 63: loss = 0.22090300917625427, acc = 0.9248046875\n",
      "Batch 64: loss = 0.2535287141799927, acc = 0.921875\n",
      "Batch 65: loss = 0.25340092182159424, acc = 0.908203125\n",
      "Batch 66: loss = 0.2687067687511444, acc = 0.908203125\n",
      "Batch 67: loss = 0.23588237166404724, acc = 0.921875\n",
      "Batch 68: loss = 0.28183507919311523, acc = 0.9013671875\n",
      "Batch 69: loss = 0.2149219661951065, acc = 0.931640625\n",
      "Batch 70: loss = 0.24818162620067596, acc = 0.9150390625\n",
      "Batch 71: loss = 0.2544710040092468, acc = 0.9052734375\n",
      "Batch 72: loss = 0.2541741132736206, acc = 0.916015625\n",
      "Batch 73: loss = 0.30395567417144775, acc = 0.8994140625\n",
      "Batch 74: loss = 0.280740886926651, acc = 0.90234375\n",
      "Batch 75: loss = 0.27968326210975647, acc = 0.9052734375\n",
      "Batch 76: loss = 0.259970486164093, acc = 0.9169921875\n",
      "Batch 77: loss = 0.25782865285873413, acc = 0.91796875\n",
      "Batch 78: loss = 0.28052008152008057, acc = 0.9111328125\n",
      "Batch 79: loss = 0.23123720288276672, acc = 0.9296875\n",
      "Batch 80: loss = 0.2609853744506836, acc = 0.9111328125\n",
      "Batch 81: loss = 0.2426486611366272, acc = 0.923828125\n",
      "Batch 82: loss = 0.2553224265575409, acc = 0.91796875\n",
      "Batch 83: loss = 0.23642653226852417, acc = 0.91796875\n",
      "Batch 84: loss = 0.24099302291870117, acc = 0.921875\n",
      "Batch 85: loss = 0.27625149488449097, acc = 0.9091796875\n",
      "Batch 86: loss = 0.2504393458366394, acc = 0.9140625\n",
      "Batch 87: loss = 0.2534427046775818, acc = 0.91015625\n",
      "Batch 88: loss = 0.30857205390930176, acc = 0.89453125\n",
      "Batch 89: loss = 0.2575162649154663, acc = 0.91796875\n",
      "Batch 90: loss = 0.26048988103866577, acc = 0.908203125\n",
      "Batch 91: loss = 0.2637324929237366, acc = 0.9150390625\n",
      "Batch 92: loss = 0.2751728594303131, acc = 0.9091796875\n",
      "Batch 93: loss = 0.2494962066411972, acc = 0.923828125\n",
      "Batch 94: loss = 0.25432437658309937, acc = 0.919921875\n",
      "Batch 95: loss = 0.23831066489219666, acc = 0.9267578125\n",
      "Batch 96: loss = 0.267008513212204, acc = 0.9140625\n",
      "Batch 97: loss = 0.25433260202407837, acc = 0.912109375\n",
      "Batch 98: loss = 0.23893891274929047, acc = 0.9169921875\n",
      "Batch 99: loss = 0.3062424063682556, acc = 0.896484375\n",
      "Batch 100: loss = 0.26404869556427, acc = 0.912109375\n",
      "Batch 101: loss = 0.2640736699104309, acc = 0.91015625\n",
      "Batch 102: loss = 0.27473264932632446, acc = 0.9111328125\n",
      "Batch 103: loss = 0.296655535697937, acc = 0.896484375\n",
      "Batch 104: loss = 0.23604485392570496, acc = 0.9140625\n",
      "Batch 105: loss = 0.24006660282611847, acc = 0.9169921875\n",
      "Batch 106: loss = 0.23593969643115997, acc = 0.9169921875\n",
      "Batch 107: loss = 0.2489556074142456, acc = 0.9228515625\n",
      "Batch 108: loss = 0.237068772315979, acc = 0.931640625\n",
      "Batch 109: loss = 0.27450984716415405, acc = 0.9091796875\n",
      "Batch 110: loss = 0.2576277256011963, acc = 0.9189453125\n",
      "Batch 111: loss = 0.27524492144584656, acc = 0.9111328125\n",
      "Batch 112: loss = 0.267674058675766, acc = 0.9033203125\n",
      "Batch 113: loss = 0.26503947377204895, acc = 0.919921875\n",
      "Batch 114: loss = 0.23655027151107788, acc = 0.9140625\n",
      "Batch 115: loss = 0.2681517004966736, acc = 0.916015625\n",
      "Batch 116: loss = 0.24116891622543335, acc = 0.9189453125\n",
      "Batch 117: loss = 0.25957077741622925, acc = 0.9130859375\n",
      "Batch 118: loss = 0.23130419850349426, acc = 0.9189453125\n",
      "Batch 119: loss = 0.24105355143547058, acc = 0.9228515625\n",
      "Batch 120: loss = 0.2337515950202942, acc = 0.9169921875\n",
      "Batch 121: loss = 0.2587950825691223, acc = 0.90234375\n",
      "Batch 122: loss = 0.2553262710571289, acc = 0.908203125\n",
      "Batch 123: loss = 0.2686959505081177, acc = 0.9091796875\n",
      "Batch 124: loss = 0.2589462399482727, acc = 0.9072265625\n",
      "Batch 125: loss = 0.2626723051071167, acc = 0.9052734375\n",
      "Batch 126: loss = 0.2859181761741638, acc = 0.8994140625\n",
      "Saved checkpoint to weights.90.h5\n",
      "\n",
      "Epoch 91/100\n",
      "Batch 1: loss = 0.39539456367492676, acc = 0.8916015625\n",
      "Batch 2: loss = 0.24565234780311584, acc = 0.912109375\n",
      "Batch 3: loss = 0.28365057706832886, acc = 0.9130859375\n",
      "Batch 4: loss = 0.2706948518753052, acc = 0.9150390625\n",
      "Batch 5: loss = 0.23968729376792908, acc = 0.9267578125\n",
      "Batch 6: loss = 0.2512361407279968, acc = 0.9169921875\n",
      "Batch 7: loss = 0.25735270977020264, acc = 0.912109375\n",
      "Batch 8: loss = 0.2597147822380066, acc = 0.9169921875\n",
      "Batch 9: loss = 0.27151021361351013, acc = 0.9072265625\n",
      "Batch 10: loss = 0.21846932172775269, acc = 0.931640625\n",
      "Batch 11: loss = 0.24028852581977844, acc = 0.92578125\n",
      "Batch 12: loss = 0.23758161067962646, acc = 0.91796875\n",
      "Batch 13: loss = 0.27031341195106506, acc = 0.9140625\n",
      "Batch 14: loss = 0.25509440898895264, acc = 0.9169921875\n",
      "Batch 15: loss = 0.221528559923172, acc = 0.9267578125\n",
      "Batch 16: loss = 0.25825098156929016, acc = 0.9140625\n",
      "Batch 17: loss = 0.2924169898033142, acc = 0.8837890625\n",
      "Batch 18: loss = 0.2738741934299469, acc = 0.90625\n",
      "Batch 19: loss = 0.23916694521903992, acc = 0.9208984375\n",
      "Batch 20: loss = 0.23611271381378174, acc = 0.9130859375\n",
      "Batch 21: loss = 0.3097352981567383, acc = 0.90234375\n",
      "Batch 22: loss = 0.30438438057899475, acc = 0.8935546875\n",
      "Batch 23: loss = 0.29722777009010315, acc = 0.8994140625\n",
      "Batch 24: loss = 0.26442503929138184, acc = 0.9140625\n",
      "Batch 25: loss = 0.2922590374946594, acc = 0.91015625\n",
      "Batch 26: loss = 0.2304765284061432, acc = 0.923828125\n",
      "Batch 27: loss = 0.24286046624183655, acc = 0.9296875\n",
      "Batch 28: loss = 0.2787446975708008, acc = 0.916015625\n",
      "Batch 29: loss = 0.2621115446090698, acc = 0.91796875\n",
      "Batch 30: loss = 0.2608557343482971, acc = 0.9130859375\n",
      "Batch 31: loss = 0.2629427909851074, acc = 0.91796875\n",
      "Batch 32: loss = 0.2901966869831085, acc = 0.904296875\n",
      "Batch 33: loss = 0.2275557667016983, acc = 0.9208984375\n",
      "Batch 34: loss = 0.27017512917518616, acc = 0.9052734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 35: loss = 0.26554161310195923, acc = 0.919921875\n",
      "Batch 36: loss = 0.24617193639278412, acc = 0.921875\n",
      "Batch 37: loss = 0.227186918258667, acc = 0.9267578125\n",
      "Batch 38: loss = 0.2325291931629181, acc = 0.9267578125\n",
      "Batch 39: loss = 0.22415614128112793, acc = 0.923828125\n",
      "Batch 40: loss = 0.26331546902656555, acc = 0.9150390625\n",
      "Batch 41: loss = 0.23808717727661133, acc = 0.91796875\n",
      "Batch 42: loss = 0.25290653109550476, acc = 0.91796875\n",
      "Batch 43: loss = 0.2911849021911621, acc = 0.8974609375\n",
      "Batch 44: loss = 0.29433968663215637, acc = 0.9033203125\n",
      "Batch 45: loss = 0.2897908687591553, acc = 0.91015625\n",
      "Batch 46: loss = 0.23365460336208344, acc = 0.9189453125\n",
      "Batch 47: loss = 0.23720921576023102, acc = 0.9267578125\n",
      "Batch 48: loss = 0.2529965341091156, acc = 0.9150390625\n",
      "Batch 49: loss = 0.21001940965652466, acc = 0.9306640625\n",
      "Batch 50: loss = 0.24734124541282654, acc = 0.91015625\n",
      "Batch 51: loss = 0.2634790241718292, acc = 0.9130859375\n",
      "Batch 52: loss = 0.2172068953514099, acc = 0.9404296875\n",
      "Batch 53: loss = 0.25084179639816284, acc = 0.916015625\n",
      "Batch 54: loss = 0.22440692782402039, acc = 0.927734375\n",
      "Batch 55: loss = 0.2370133399963379, acc = 0.9169921875\n",
      "Batch 56: loss = 0.2621700167655945, acc = 0.921875\n",
      "Batch 57: loss = 0.26044762134552, acc = 0.9208984375\n",
      "Batch 58: loss = 0.27096134424209595, acc = 0.904296875\n",
      "Batch 59: loss = 0.24655993282794952, acc = 0.908203125\n",
      "Batch 60: loss = 0.26376038789749146, acc = 0.9169921875\n",
      "Batch 61: loss = 0.2429671585559845, acc = 0.9169921875\n",
      "Batch 62: loss = 0.3068810701370239, acc = 0.892578125\n",
      "Batch 63: loss = 0.24855798482894897, acc = 0.9150390625\n",
      "Batch 64: loss = 0.23325631022453308, acc = 0.91796875\n",
      "Batch 65: loss = 0.23135808110237122, acc = 0.92578125\n",
      "Batch 66: loss = 0.2309599220752716, acc = 0.9248046875\n",
      "Batch 67: loss = 0.26034221053123474, acc = 0.9072265625\n",
      "Batch 68: loss = 0.2576265037059784, acc = 0.9111328125\n",
      "Batch 69: loss = 0.22075659036636353, acc = 0.9267578125\n",
      "Batch 70: loss = 0.2636564373970032, acc = 0.9150390625\n",
      "Batch 71: loss = 0.2790929973125458, acc = 0.8984375\n",
      "Batch 72: loss = 0.24450767040252686, acc = 0.9208984375\n",
      "Batch 73: loss = 0.28495579957962036, acc = 0.9072265625\n",
      "Batch 74: loss = 0.2503077983856201, acc = 0.91796875\n",
      "Batch 75: loss = 0.308114230632782, acc = 0.8857421875\n",
      "Batch 76: loss = 0.26972344517707825, acc = 0.9169921875\n",
      "Batch 77: loss = 0.2528185248374939, acc = 0.9130859375\n",
      "Batch 78: loss = 0.2795475721359253, acc = 0.9189453125\n",
      "Batch 79: loss = 0.2398059070110321, acc = 0.9267578125\n",
      "Batch 80: loss = 0.23701199889183044, acc = 0.916015625\n",
      "Batch 81: loss = 0.2761523127555847, acc = 0.89453125\n",
      "Batch 82: loss = 0.28190523386001587, acc = 0.904296875\n",
      "Batch 83: loss = 0.23947101831436157, acc = 0.916015625\n",
      "Batch 84: loss = 0.2843191623687744, acc = 0.89453125\n",
      "Batch 85: loss = 0.3048419952392578, acc = 0.8974609375\n",
      "Batch 86: loss = 0.250110924243927, acc = 0.9208984375\n",
      "Batch 87: loss = 0.2835763096809387, acc = 0.91015625\n",
      "Batch 88: loss = 0.28591108322143555, acc = 0.90625\n",
      "Batch 89: loss = 0.23745056986808777, acc = 0.927734375\n",
      "Batch 90: loss = 0.2613917589187622, acc = 0.904296875\n",
      "Batch 91: loss = 0.27079856395721436, acc = 0.9140625\n",
      "Batch 92: loss = 0.2576977014541626, acc = 0.9208984375\n",
      "Batch 93: loss = 0.25999248027801514, acc = 0.9140625\n",
      "Batch 94: loss = 0.24882161617279053, acc = 0.9130859375\n",
      "Batch 95: loss = 0.2107549011707306, acc = 0.9306640625\n",
      "Batch 96: loss = 0.262265145778656, acc = 0.9052734375\n",
      "Batch 97: loss = 0.2760850489139557, acc = 0.908203125\n",
      "Batch 98: loss = 0.2743068337440491, acc = 0.908203125\n",
      "Batch 99: loss = 0.298164963722229, acc = 0.90625\n",
      "Batch 100: loss = 0.25907179713249207, acc = 0.90234375\n",
      "Batch 101: loss = 0.2801780700683594, acc = 0.896484375\n",
      "Batch 102: loss = 0.2919826805591583, acc = 0.90625\n",
      "Batch 103: loss = 0.2930336594581604, acc = 0.90625\n",
      "Batch 104: loss = 0.24700596928596497, acc = 0.916015625\n",
      "Batch 105: loss = 0.2709464430809021, acc = 0.8994140625\n",
      "Batch 106: loss = 0.24066230654716492, acc = 0.9169921875\n",
      "Batch 107: loss = 0.2533705234527588, acc = 0.9228515625\n",
      "Batch 108: loss = 0.24494615197181702, acc = 0.923828125\n",
      "Batch 109: loss = 0.2599193751811981, acc = 0.9189453125\n",
      "Batch 110: loss = 0.24458464980125427, acc = 0.9140625\n",
      "Batch 111: loss = 0.2648688852787018, acc = 0.912109375\n",
      "Batch 112: loss = 0.23184163868427277, acc = 0.9267578125\n",
      "Batch 113: loss = 0.2689441442489624, acc = 0.9130859375\n",
      "Batch 114: loss = 0.2782538831233978, acc = 0.900390625\n",
      "Batch 115: loss = 0.2640683650970459, acc = 0.9169921875\n",
      "Batch 116: loss = 0.2762361764907837, acc = 0.90625\n",
      "Batch 117: loss = 0.24364987015724182, acc = 0.921875\n",
      "Batch 118: loss = 0.24395006895065308, acc = 0.9169921875\n",
      "Batch 119: loss = 0.20634521543979645, acc = 0.9296875\n",
      "Batch 120: loss = 0.2302285134792328, acc = 0.919921875\n",
      "Batch 121: loss = 0.24609968066215515, acc = 0.91796875\n",
      "Batch 122: loss = 0.24278312921524048, acc = 0.919921875\n",
      "Batch 123: loss = 0.2620430588722229, acc = 0.9111328125\n",
      "Batch 124: loss = 0.25052282214164734, acc = 0.9169921875\n",
      "Batch 125: loss = 0.26762688159942627, acc = 0.916015625\n",
      "Batch 126: loss = 0.25303491950035095, acc = 0.9169921875\n",
      "\n",
      "Epoch 92/100\n",
      "Batch 1: loss = 0.39933308959007263, acc = 0.8857421875\n",
      "Batch 2: loss = 0.2950420379638672, acc = 0.896484375\n",
      "Batch 3: loss = 0.2578398585319519, acc = 0.91796875\n",
      "Batch 4: loss = 0.2952977418899536, acc = 0.9052734375\n",
      "Batch 5: loss = 0.2647151052951813, acc = 0.912109375\n",
      "Batch 6: loss = 0.30726784467697144, acc = 0.89453125\n",
      "Batch 7: loss = 0.24162210524082184, acc = 0.923828125\n",
      "Batch 8: loss = 0.2662087678909302, acc = 0.9130859375\n",
      "Batch 9: loss = 0.2865210175514221, acc = 0.8994140625\n",
      "Batch 10: loss = 0.25711673498153687, acc = 0.91015625\n",
      "Batch 11: loss = 0.2855912446975708, acc = 0.904296875\n",
      "Batch 12: loss = 0.24191464483737946, acc = 0.9169921875\n",
      "Batch 13: loss = 0.2577287554740906, acc = 0.916015625\n",
      "Batch 14: loss = 0.2692931890487671, acc = 0.9228515625\n",
      "Batch 15: loss = 0.21657925844192505, acc = 0.9287109375\n",
      "Batch 16: loss = 0.2478514164686203, acc = 0.9189453125\n",
      "Batch 17: loss = 0.23425546288490295, acc = 0.9248046875\n",
      "Batch 18: loss = 0.2261435091495514, acc = 0.9296875\n",
      "Batch 19: loss = 0.2585691511631012, acc = 0.9189453125\n",
      "Batch 20: loss = 0.22962792217731476, acc = 0.91796875\n",
      "Batch 21: loss = 0.279558390378952, acc = 0.9072265625\n",
      "Batch 22: loss = 0.28360122442245483, acc = 0.9033203125\n",
      "Batch 23: loss = 0.25622987747192383, acc = 0.9208984375\n",
      "Batch 24: loss = 0.2513997554779053, acc = 0.9130859375\n",
      "Batch 25: loss = 0.24997882544994354, acc = 0.921875\n",
      "Batch 26: loss = 0.23408719897270203, acc = 0.908203125\n",
      "Batch 27: loss = 0.25972801446914673, acc = 0.916015625\n",
      "Batch 28: loss = 0.26384639739990234, acc = 0.916015625\n",
      "Batch 29: loss = 0.27585339546203613, acc = 0.9033203125\n",
      "Batch 30: loss = 0.2865360379219055, acc = 0.90234375\n",
      "Batch 31: loss = 0.25072669982910156, acc = 0.9130859375\n",
      "Batch 32: loss = 0.2673957347869873, acc = 0.9091796875\n",
      "Batch 33: loss = 0.2357262670993805, acc = 0.92578125\n",
      "Batch 34: loss = 0.28273695707321167, acc = 0.9072265625\n",
      "Batch 35: loss = 0.26361218094825745, acc = 0.900390625\n",
      "Batch 36: loss = 0.21938985586166382, acc = 0.9267578125\n",
      "Batch 37: loss = 0.24493247270584106, acc = 0.9248046875\n",
      "Batch 38: loss = 0.2285131812095642, acc = 0.921875\n",
      "Batch 39: loss = 0.2351338416337967, acc = 0.9287109375\n",
      "Batch 40: loss = 0.24233540892601013, acc = 0.9267578125\n",
      "Batch 41: loss = 0.2879496216773987, acc = 0.9033203125\n",
      "Batch 42: loss = 0.23032571375370026, acc = 0.9267578125\n",
      "Batch 43: loss = 0.24099141359329224, acc = 0.9150390625\n",
      "Batch 44: loss = 0.24290308356285095, acc = 0.923828125\n",
      "Batch 45: loss = 0.26439791917800903, acc = 0.9130859375\n",
      "Batch 46: loss = 0.2382984161376953, acc = 0.9208984375\n",
      "Batch 47: loss = 0.24210530519485474, acc = 0.916015625\n",
      "Batch 48: loss = 0.24479198455810547, acc = 0.91015625\n",
      "Batch 49: loss = 0.24768517911434174, acc = 0.9228515625\n",
      "Batch 50: loss = 0.21715408563613892, acc = 0.9267578125\n",
      "Batch 51: loss = 0.24178850650787354, acc = 0.9150390625\n",
      "Batch 52: loss = 0.2726619839668274, acc = 0.9130859375\n",
      "Batch 53: loss = 0.2451382279396057, acc = 0.91796875\n",
      "Batch 54: loss = 0.21829532086849213, acc = 0.92578125\n",
      "Batch 55: loss = 0.23435580730438232, acc = 0.9248046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 56: loss = 0.22008883953094482, acc = 0.9248046875\n",
      "Batch 57: loss = 0.2867163419723511, acc = 0.904296875\n",
      "Batch 58: loss = 0.26849281787872314, acc = 0.904296875\n",
      "Batch 59: loss = 0.2383987456560135, acc = 0.9248046875\n",
      "Batch 60: loss = 0.2538965940475464, acc = 0.916015625\n",
      "Batch 61: loss = 0.22926652431488037, acc = 0.9267578125\n",
      "Batch 62: loss = 0.2347041219472885, acc = 0.9150390625\n",
      "Batch 63: loss = 0.24800923466682434, acc = 0.91796875\n",
      "Batch 64: loss = 0.21387751400470734, acc = 0.923828125\n",
      "Batch 65: loss = 0.22606322169303894, acc = 0.9169921875\n",
      "Batch 66: loss = 0.26126739382743835, acc = 0.9189453125\n",
      "Batch 67: loss = 0.2586173415184021, acc = 0.9111328125\n",
      "Batch 68: loss = 0.244848370552063, acc = 0.91796875\n",
      "Batch 69: loss = 0.22988048195838928, acc = 0.9345703125\n",
      "Batch 70: loss = 0.26303809881210327, acc = 0.9111328125\n",
      "Batch 71: loss = 0.23815014958381653, acc = 0.921875\n",
      "Batch 72: loss = 0.2294619083404541, acc = 0.931640625\n",
      "Batch 73: loss = 0.24958282709121704, acc = 0.9111328125\n",
      "Batch 74: loss = 0.2739487290382385, acc = 0.919921875\n",
      "Batch 75: loss = 0.2745244801044464, acc = 0.9072265625\n",
      "Batch 76: loss = 0.28416067361831665, acc = 0.9111328125\n",
      "Batch 77: loss = 0.2425471544265747, acc = 0.916015625\n",
      "Batch 78: loss = 0.24591585993766785, acc = 0.921875\n",
      "Batch 79: loss = 0.24201586842536926, acc = 0.9150390625\n",
      "Batch 80: loss = 0.24511981010437012, acc = 0.9150390625\n",
      "Batch 81: loss = 0.26072704792022705, acc = 0.90625\n",
      "Batch 82: loss = 0.2923434376716614, acc = 0.9111328125\n",
      "Batch 83: loss = 0.2432214468717575, acc = 0.9228515625\n",
      "Batch 84: loss = 0.2560517191886902, acc = 0.91015625\n",
      "Batch 85: loss = 0.25391703844070435, acc = 0.9072265625\n",
      "Batch 86: loss = 0.26611819863319397, acc = 0.912109375\n",
      "Batch 87: loss = 0.24632616341114044, acc = 0.9150390625\n",
      "Batch 88: loss = 0.3127235174179077, acc = 0.900390625\n",
      "Batch 89: loss = 0.2300107777118683, acc = 0.9287109375\n",
      "Batch 90: loss = 0.24004103243350983, acc = 0.9091796875\n",
      "Batch 91: loss = 0.2565494477748871, acc = 0.91015625\n",
      "Batch 92: loss = 0.2712570130825043, acc = 0.9052734375\n",
      "Batch 93: loss = 0.2556312084197998, acc = 0.9189453125\n",
      "Batch 94: loss = 0.27010291814804077, acc = 0.912109375\n",
      "Batch 95: loss = 0.23457393050193787, acc = 0.9228515625\n",
      "Batch 96: loss = 0.261618435382843, acc = 0.9130859375\n",
      "Batch 97: loss = 0.2593746781349182, acc = 0.9140625\n",
      "Batch 98: loss = 0.22298100590705872, acc = 0.9326171875\n",
      "Batch 99: loss = 0.26777705550193787, acc = 0.91015625\n",
      "Batch 100: loss = 0.2683342695236206, acc = 0.9072265625\n",
      "Batch 101: loss = 0.25850725173950195, acc = 0.9140625\n",
      "Batch 102: loss = 0.26047688722610474, acc = 0.912109375\n",
      "Batch 103: loss = 0.2888275384902954, acc = 0.9140625\n",
      "Batch 104: loss = 0.21713899075984955, acc = 0.927734375\n",
      "Batch 105: loss = 0.2354883998632431, acc = 0.9169921875\n",
      "Batch 106: loss = 0.2190173864364624, acc = 0.9267578125\n",
      "Batch 107: loss = 0.23774701356887817, acc = 0.9248046875\n",
      "Batch 108: loss = 0.24440714716911316, acc = 0.9140625\n",
      "Batch 109: loss = 0.24597296118736267, acc = 0.916015625\n",
      "Batch 110: loss = 0.24018195271492004, acc = 0.923828125\n",
      "Batch 111: loss = 0.22511285543441772, acc = 0.9267578125\n",
      "Batch 112: loss = 0.2203485518693924, acc = 0.9228515625\n",
      "Batch 113: loss = 0.24703843891620636, acc = 0.916015625\n",
      "Batch 114: loss = 0.2509724497795105, acc = 0.9189453125\n",
      "Batch 115: loss = 0.25636881589889526, acc = 0.91015625\n",
      "Batch 116: loss = 0.21344530582427979, acc = 0.9345703125\n",
      "Batch 117: loss = 0.26079124212265015, acc = 0.9169921875\n",
      "Batch 118: loss = 0.21271072328090668, acc = 0.9306640625\n",
      "Batch 119: loss = 0.20788583159446716, acc = 0.923828125\n",
      "Batch 120: loss = 0.24100066721439362, acc = 0.916015625\n",
      "Batch 121: loss = 0.26968812942504883, acc = 0.912109375\n",
      "Batch 122: loss = 0.22350765764713287, acc = 0.92578125\n",
      "Batch 123: loss = 0.25185835361480713, acc = 0.9228515625\n",
      "Batch 124: loss = 0.3097597360610962, acc = 0.888671875\n",
      "Batch 125: loss = 0.25014251470565796, acc = 0.916015625\n",
      "Batch 126: loss = 0.2709868848323822, acc = 0.91015625\n",
      "\n",
      "Epoch 93/100\n",
      "Batch 1: loss = 0.37289804220199585, acc = 0.8984375\n",
      "Batch 2: loss = 0.2194545865058899, acc = 0.9296875\n",
      "Batch 3: loss = 0.2802690863609314, acc = 0.90625\n",
      "Batch 4: loss = 0.2659592032432556, acc = 0.9140625\n",
      "Batch 5: loss = 0.2480245679616928, acc = 0.9208984375\n",
      "Batch 6: loss = 0.2591608166694641, acc = 0.919921875\n",
      "Batch 7: loss = 0.23095038533210754, acc = 0.9248046875\n",
      "Batch 8: loss = 0.29740485548973083, acc = 0.9033203125\n",
      "Batch 9: loss = 0.279555082321167, acc = 0.8994140625\n",
      "Batch 10: loss = 0.2281731367111206, acc = 0.919921875\n",
      "Batch 11: loss = 0.26931947469711304, acc = 0.9013671875\n",
      "Batch 12: loss = 0.25948381423950195, acc = 0.9208984375\n",
      "Batch 13: loss = 0.2557644844055176, acc = 0.9130859375\n",
      "Batch 14: loss = 0.24454274773597717, acc = 0.92578125\n",
      "Batch 15: loss = 0.24539446830749512, acc = 0.919921875\n",
      "Batch 16: loss = 0.24190650880336761, acc = 0.9228515625\n",
      "Batch 17: loss = 0.23418191075325012, acc = 0.9228515625\n",
      "Batch 18: loss = 0.24313640594482422, acc = 0.919921875\n",
      "Batch 19: loss = 0.23698782920837402, acc = 0.91796875\n",
      "Batch 20: loss = 0.24194757640361786, acc = 0.9150390625\n",
      "Batch 21: loss = 0.25980281829833984, acc = 0.9091796875\n",
      "Batch 22: loss = 0.2762947976589203, acc = 0.90625\n",
      "Batch 23: loss = 0.2412768006324768, acc = 0.9150390625\n",
      "Batch 24: loss = 0.20259708166122437, acc = 0.9306640625\n",
      "Batch 25: loss = 0.26097041368484497, acc = 0.9130859375\n",
      "Batch 26: loss = 0.22218146920204163, acc = 0.9287109375\n",
      "Batch 27: loss = 0.23582841455936432, acc = 0.927734375\n",
      "Batch 28: loss = 0.2840738594532013, acc = 0.90625\n",
      "Batch 29: loss = 0.27247655391693115, acc = 0.9072265625\n",
      "Batch 30: loss = 0.2615780830383301, acc = 0.9091796875\n",
      "Batch 31: loss = 0.23763875663280487, acc = 0.9111328125\n",
      "Batch 32: loss = 0.2730151116847992, acc = 0.9130859375\n",
      "Batch 33: loss = 0.23699524998664856, acc = 0.923828125\n",
      "Batch 34: loss = 0.27230995893478394, acc = 0.91015625\n",
      "Batch 35: loss = 0.22384224832057953, acc = 0.935546875\n",
      "Batch 36: loss = 0.2447414994239807, acc = 0.919921875\n",
      "Batch 37: loss = 0.21490272879600525, acc = 0.9375\n",
      "Batch 38: loss = 0.22704866528511047, acc = 0.9208984375\n",
      "Batch 39: loss = 0.24885836243629456, acc = 0.9130859375\n",
      "Batch 40: loss = 0.24473856389522552, acc = 0.916015625\n",
      "Batch 41: loss = 0.2748720347881317, acc = 0.91796875\n",
      "Batch 42: loss = 0.2303587943315506, acc = 0.9287109375\n",
      "Batch 43: loss = 0.2602680027484894, acc = 0.9150390625\n",
      "Batch 44: loss = 0.2606586217880249, acc = 0.9140625\n",
      "Batch 45: loss = 0.2189704179763794, acc = 0.935546875\n",
      "Batch 46: loss = 0.2347814440727234, acc = 0.916015625\n",
      "Batch 47: loss = 0.26944348216056824, acc = 0.91015625\n",
      "Batch 48: loss = 0.24010053277015686, acc = 0.9130859375\n",
      "Batch 49: loss = 0.2436089664697647, acc = 0.9169921875\n",
      "Batch 50: loss = 0.234453022480011, acc = 0.912109375\n",
      "Batch 51: loss = 0.2629779279232025, acc = 0.9169921875\n",
      "Batch 52: loss = 0.21194320917129517, acc = 0.927734375\n",
      "Batch 53: loss = 0.2750646471977234, acc = 0.9140625\n",
      "Batch 54: loss = 0.190598264336586, acc = 0.93359375\n",
      "Batch 55: loss = 0.22463038563728333, acc = 0.921875\n",
      "Batch 56: loss = 0.2558731436729431, acc = 0.916015625\n",
      "Batch 57: loss = 0.26795196533203125, acc = 0.916015625\n",
      "Batch 58: loss = 0.2683466076850891, acc = 0.90625\n",
      "Batch 59: loss = 0.22585691511631012, acc = 0.916015625\n",
      "Batch 60: loss = 0.29122620820999146, acc = 0.904296875\n",
      "Batch 61: loss = 0.22095876932144165, acc = 0.9306640625\n",
      "Batch 62: loss = 0.3108542561531067, acc = 0.89453125\n",
      "Batch 63: loss = 0.22896912693977356, acc = 0.9208984375\n",
      "Batch 64: loss = 0.24663585424423218, acc = 0.9189453125\n",
      "Batch 65: loss = 0.23864148557186127, acc = 0.931640625\n",
      "Batch 66: loss = 0.2452806979417801, acc = 0.9208984375\n",
      "Batch 67: loss = 0.2429070621728897, acc = 0.9189453125\n",
      "Batch 68: loss = 0.24337762594223022, acc = 0.908203125\n",
      "Batch 69: loss = 0.2641766667366028, acc = 0.9208984375\n",
      "Batch 70: loss = 0.2846548557281494, acc = 0.904296875\n",
      "Batch 71: loss = 0.2713295817375183, acc = 0.91015625\n",
      "Batch 72: loss = 0.2346082627773285, acc = 0.921875\n",
      "Batch 73: loss = 0.26552098989486694, acc = 0.9072265625\n",
      "Batch 74: loss = 0.2952101528644562, acc = 0.89453125\n",
      "Batch 75: loss = 0.2915799021720886, acc = 0.900390625\n",
      "Batch 76: loss = 0.2728445827960968, acc = 0.90625\n",
      "Batch 77: loss = 0.2743566334247589, acc = 0.919921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 78: loss = 0.26020631194114685, acc = 0.9189453125\n",
      "Batch 79: loss = 0.2321133315563202, acc = 0.923828125\n",
      "Batch 80: loss = 0.2551240921020508, acc = 0.9072265625\n",
      "Batch 81: loss = 0.21642279624938965, acc = 0.92578125\n",
      "Batch 82: loss = 0.2722027003765106, acc = 0.9169921875\n",
      "Batch 83: loss = 0.26440978050231934, acc = 0.91015625\n",
      "Batch 84: loss = 0.2519679069519043, acc = 0.916015625\n",
      "Batch 85: loss = 0.2620565891265869, acc = 0.9111328125\n",
      "Batch 86: loss = 0.26828908920288086, acc = 0.9091796875\n",
      "Batch 87: loss = 0.26789402961730957, acc = 0.91796875\n",
      "Batch 88: loss = 0.28964751958847046, acc = 0.9033203125\n",
      "Batch 89: loss = 0.2527908682823181, acc = 0.91796875\n",
      "Batch 90: loss = 0.2854675352573395, acc = 0.900390625\n",
      "Batch 91: loss = 0.2726772427558899, acc = 0.912109375\n",
      "Batch 92: loss = 0.29453009366989136, acc = 0.9052734375\n",
      "Batch 93: loss = 0.26334983110427856, acc = 0.916015625\n",
      "Batch 94: loss = 0.24055913090705872, acc = 0.916015625\n",
      "Batch 95: loss = 0.23311510682106018, acc = 0.9287109375\n",
      "Batch 96: loss = 0.28578776121139526, acc = 0.9033203125\n",
      "Batch 97: loss = 0.28212830424308777, acc = 0.904296875\n",
      "Batch 98: loss = 0.25282996892929077, acc = 0.921875\n",
      "Batch 99: loss = 0.30525434017181396, acc = 0.892578125\n",
      "Batch 100: loss = 0.23530644178390503, acc = 0.9130859375\n",
      "Batch 101: loss = 0.2363942414522171, acc = 0.919921875\n",
      "Batch 102: loss = 0.2784672975540161, acc = 0.904296875\n",
      "Batch 103: loss = 0.26087620854377747, acc = 0.921875\n",
      "Batch 104: loss = 0.2508012354373932, acc = 0.91796875\n",
      "Batch 105: loss = 0.22975265979766846, acc = 0.92578125\n",
      "Batch 106: loss = 0.2507479786872864, acc = 0.9169921875\n",
      "Batch 107: loss = 0.2460584044456482, acc = 0.91796875\n",
      "Batch 108: loss = 0.24464631080627441, acc = 0.923828125\n",
      "Batch 109: loss = 0.24867582321166992, acc = 0.91796875\n",
      "Batch 110: loss = 0.2638550102710724, acc = 0.919921875\n",
      "Batch 111: loss = 0.2702076733112335, acc = 0.9052734375\n",
      "Batch 112: loss = 0.2584802210330963, acc = 0.9130859375\n",
      "Batch 113: loss = 0.23920448124408722, acc = 0.921875\n",
      "Batch 114: loss = 0.27235740423202515, acc = 0.9052734375\n",
      "Batch 115: loss = 0.27601444721221924, acc = 0.9091796875\n",
      "Batch 116: loss = 0.2570962905883789, acc = 0.912109375\n",
      "Batch 117: loss = 0.25068405270576477, acc = 0.9189453125\n",
      "Batch 118: loss = 0.25041505694389343, acc = 0.9091796875\n",
      "Batch 119: loss = 0.21502083539962769, acc = 0.9248046875\n",
      "Batch 120: loss = 0.19306102395057678, acc = 0.9326171875\n",
      "Batch 121: loss = 0.21397051215171814, acc = 0.9287109375\n",
      "Batch 122: loss = 0.2471769154071808, acc = 0.919921875\n",
      "Batch 123: loss = 0.2487269639968872, acc = 0.916015625\n",
      "Batch 124: loss = 0.26994404196739197, acc = 0.91015625\n",
      "Batch 125: loss = 0.2802123427391052, acc = 0.9111328125\n",
      "Batch 126: loss = 0.2743150293827057, acc = 0.908203125\n",
      "\n",
      "Epoch 94/100\n",
      "Batch 1: loss = 0.3958950638771057, acc = 0.888671875\n",
      "Batch 2: loss = 0.25720393657684326, acc = 0.912109375\n",
      "Batch 3: loss = 0.254101037979126, acc = 0.9150390625\n",
      "Batch 4: loss = 0.24889111518859863, acc = 0.921875\n",
      "Batch 5: loss = 0.25491422414779663, acc = 0.916015625\n",
      "Batch 6: loss = 0.2603817880153656, acc = 0.9189453125\n",
      "Batch 7: loss = 0.2505776286125183, acc = 0.9140625\n",
      "Batch 8: loss = 0.2657942473888397, acc = 0.91796875\n",
      "Batch 9: loss = 0.22443366050720215, acc = 0.92578125\n",
      "Batch 10: loss = 0.23190701007843018, acc = 0.92578125\n",
      "Batch 11: loss = 0.2414739727973938, acc = 0.908203125\n",
      "Batch 12: loss = 0.22055485844612122, acc = 0.9287109375\n",
      "Batch 13: loss = 0.23298683762550354, acc = 0.9248046875\n",
      "Batch 14: loss = 0.254415899515152, acc = 0.9150390625\n",
      "Batch 15: loss = 0.21363788843154907, acc = 0.935546875\n",
      "Batch 16: loss = 0.26271572709083557, acc = 0.9111328125\n",
      "Batch 17: loss = 0.26308777928352356, acc = 0.9140625\n",
      "Batch 18: loss = 0.25348949432373047, acc = 0.9140625\n",
      "Batch 19: loss = 0.25623923540115356, acc = 0.921875\n",
      "Batch 20: loss = 0.2274009734392166, acc = 0.9169921875\n",
      "Batch 21: loss = 0.3079710602760315, acc = 0.900390625\n",
      "Batch 22: loss = 0.2895129919052124, acc = 0.9033203125\n",
      "Batch 23: loss = 0.3128697872161865, acc = 0.888671875\n",
      "Batch 24: loss = 0.2613551616668701, acc = 0.908203125\n",
      "Batch 25: loss = 0.2716210186481476, acc = 0.9150390625\n",
      "Batch 26: loss = 0.23459181189537048, acc = 0.91796875\n",
      "Batch 27: loss = 0.24339431524276733, acc = 0.9169921875\n",
      "Batch 28: loss = 0.2589854598045349, acc = 0.9130859375\n",
      "Batch 29: loss = 0.24562036991119385, acc = 0.9169921875\n",
      "Batch 30: loss = 0.26099857687950134, acc = 0.9111328125\n",
      "Batch 31: loss = 0.2494216412305832, acc = 0.9033203125\n",
      "Batch 32: loss = 0.2703735828399658, acc = 0.9130859375\n",
      "Batch 33: loss = 0.23585806787014008, acc = 0.91796875\n",
      "Batch 34: loss = 0.24077476561069489, acc = 0.923828125\n",
      "Batch 35: loss = 0.23718175292015076, acc = 0.9208984375\n",
      "Batch 36: loss = 0.22295325994491577, acc = 0.931640625\n",
      "Batch 37: loss = 0.21574024856090546, acc = 0.9287109375\n",
      "Batch 38: loss = 0.26363706588745117, acc = 0.9130859375\n",
      "Batch 39: loss = 0.21270005404949188, acc = 0.919921875\n",
      "Batch 40: loss = 0.2314291000366211, acc = 0.92578125\n",
      "Batch 41: loss = 0.26258420944213867, acc = 0.9150390625\n",
      "Batch 42: loss = 0.23656871914863586, acc = 0.921875\n",
      "Batch 43: loss = 0.24376460909843445, acc = 0.9208984375\n",
      "Batch 44: loss = 0.26102524995803833, acc = 0.916015625\n",
      "Batch 45: loss = 0.2698580026626587, acc = 0.9150390625\n",
      "Batch 46: loss = 0.21699158847332, acc = 0.9287109375\n",
      "Batch 47: loss = 0.2381831705570221, acc = 0.92578125\n",
      "Batch 48: loss = 0.26884955167770386, acc = 0.9072265625\n",
      "Batch 49: loss = 0.21601268649101257, acc = 0.9267578125\n",
      "Batch 50: loss = 0.2321256846189499, acc = 0.9169921875\n",
      "Batch 51: loss = 0.22977429628372192, acc = 0.9140625\n",
      "Batch 52: loss = 0.26596152782440186, acc = 0.9052734375\n",
      "Batch 53: loss = 0.2566564083099365, acc = 0.9208984375\n",
      "Batch 54: loss = 0.21136458218097687, acc = 0.9345703125\n",
      "Batch 55: loss = 0.24016469717025757, acc = 0.916015625\n",
      "Batch 56: loss = 0.24382290244102478, acc = 0.923828125\n",
      "Batch 57: loss = 0.2641643285751343, acc = 0.9072265625\n",
      "Batch 58: loss = 0.26735034584999084, acc = 0.91015625\n",
      "Batch 59: loss = 0.23249942064285278, acc = 0.919921875\n",
      "Batch 60: loss = 0.2576373219490051, acc = 0.919921875\n",
      "Batch 61: loss = 0.20734047889709473, acc = 0.927734375\n",
      "Batch 62: loss = 0.2808361053466797, acc = 0.90234375\n",
      "Batch 63: loss = 0.2516002655029297, acc = 0.9169921875\n",
      "Batch 64: loss = 0.23844709992408752, acc = 0.9150390625\n",
      "Batch 65: loss = 0.2415936440229416, acc = 0.9208984375\n",
      "Batch 66: loss = 0.28804266452789307, acc = 0.8955078125\n",
      "Batch 67: loss = 0.272315114736557, acc = 0.9091796875\n",
      "Batch 68: loss = 0.27135300636291504, acc = 0.9033203125\n",
      "Batch 69: loss = 0.2295016050338745, acc = 0.9150390625\n",
      "Batch 70: loss = 0.27004408836364746, acc = 0.90625\n",
      "Batch 71: loss = 0.22783522307872772, acc = 0.91796875\n",
      "Batch 72: loss = 0.2529319226741791, acc = 0.91015625\n",
      "Batch 73: loss = 0.2558667063713074, acc = 0.9150390625\n",
      "Batch 74: loss = 0.31292176246643066, acc = 0.89453125\n",
      "Batch 75: loss = 0.2901251018047333, acc = 0.9013671875\n",
      "Batch 76: loss = 0.2475188672542572, acc = 0.9189453125\n",
      "Batch 77: loss = 0.26029524207115173, acc = 0.916015625\n",
      "Batch 78: loss = 0.3081681728363037, acc = 0.8974609375\n",
      "Batch 79: loss = 0.25435739755630493, acc = 0.9169921875\n",
      "Batch 80: loss = 0.20433105528354645, acc = 0.9228515625\n",
      "Batch 81: loss = 0.2722208797931671, acc = 0.904296875\n",
      "Batch 82: loss = 0.253207802772522, acc = 0.923828125\n",
      "Batch 83: loss = 0.2383740246295929, acc = 0.91796875\n",
      "Batch 84: loss = 0.2341865450143814, acc = 0.9140625\n",
      "Batch 85: loss = 0.2386317402124405, acc = 0.91015625\n",
      "Batch 86: loss = 0.2812310755252838, acc = 0.9052734375\n",
      "Batch 87: loss = 0.24832472205162048, acc = 0.923828125\n",
      "Batch 88: loss = 0.29655563831329346, acc = 0.896484375\n",
      "Batch 89: loss = 0.24915289878845215, acc = 0.91796875\n",
      "Batch 90: loss = 0.22809478640556335, acc = 0.9267578125\n",
      "Batch 91: loss = 0.27874279022216797, acc = 0.912109375\n",
      "Batch 92: loss = 0.27031955122947693, acc = 0.9228515625\n",
      "Batch 93: loss = 0.22314298152923584, acc = 0.9189453125\n",
      "Batch 94: loss = 0.2462696135044098, acc = 0.921875\n",
      "Batch 95: loss = 0.19256167113780975, acc = 0.9404296875\n",
      "Batch 96: loss = 0.27726471424102783, acc = 0.90625\n",
      "Batch 97: loss = 0.24089083075523376, acc = 0.92578125\n",
      "Batch 98: loss = 0.2507229447364807, acc = 0.923828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 99: loss = 0.2685861587524414, acc = 0.9130859375\n",
      "Batch 100: loss = 0.2253618985414505, acc = 0.9189453125\n",
      "Batch 101: loss = 0.25827258825302124, acc = 0.9111328125\n",
      "Batch 102: loss = 0.2787795066833496, acc = 0.908203125\n",
      "Batch 103: loss = 0.26254022121429443, acc = 0.9091796875\n",
      "Batch 104: loss = 0.23488673567771912, acc = 0.9326171875\n",
      "Batch 105: loss = 0.22037865221500397, acc = 0.9228515625\n",
      "Batch 106: loss = 0.2633131742477417, acc = 0.9140625\n",
      "Batch 107: loss = 0.2245001643896103, acc = 0.921875\n",
      "Batch 108: loss = 0.23995311558246613, acc = 0.923828125\n",
      "Batch 109: loss = 0.24439290165901184, acc = 0.9208984375\n",
      "Batch 110: loss = 0.26111912727355957, acc = 0.9130859375\n",
      "Batch 111: loss = 0.2449067085981369, acc = 0.9189453125\n",
      "Batch 112: loss = 0.24629510939121246, acc = 0.9296875\n",
      "Batch 113: loss = 0.2771524488925934, acc = 0.90234375\n",
      "Batch 114: loss = 0.2551920413970947, acc = 0.9228515625\n",
      "Batch 115: loss = 0.2909652590751648, acc = 0.9033203125\n",
      "Batch 116: loss = 0.2532427906990051, acc = 0.9130859375\n",
      "Batch 117: loss = 0.2502792775630951, acc = 0.9072265625\n",
      "Batch 118: loss = 0.2326612025499344, acc = 0.9130859375\n",
      "Batch 119: loss = 0.22442841529846191, acc = 0.923828125\n",
      "Batch 120: loss = 0.2179144322872162, acc = 0.9267578125\n",
      "Batch 121: loss = 0.24342019855976105, acc = 0.912109375\n",
      "Batch 122: loss = 0.2547715902328491, acc = 0.9111328125\n",
      "Batch 123: loss = 0.249599426984787, acc = 0.9111328125\n",
      "Batch 124: loss = 0.24430440366268158, acc = 0.9228515625\n",
      "Batch 125: loss = 0.2790282666683197, acc = 0.900390625\n",
      "Batch 126: loss = 0.28728267550468445, acc = 0.90234375\n",
      "\n",
      "Epoch 95/100\n",
      "Batch 1: loss = 0.3501186668872833, acc = 0.904296875\n",
      "Batch 2: loss = 0.2600988447666168, acc = 0.90625\n",
      "Batch 3: loss = 0.28284192085266113, acc = 0.91015625\n",
      "Batch 4: loss = 0.2511831521987915, acc = 0.9140625\n",
      "Batch 5: loss = 0.23567675054073334, acc = 0.9248046875\n",
      "Batch 6: loss = 0.24069300293922424, acc = 0.916015625\n",
      "Batch 7: loss = 0.2337365448474884, acc = 0.9189453125\n",
      "Batch 8: loss = 0.2876003384590149, acc = 0.90234375\n",
      "Batch 9: loss = 0.29297906160354614, acc = 0.904296875\n",
      "Batch 10: loss = 0.19816628098487854, acc = 0.92578125\n",
      "Batch 11: loss = 0.2343824803829193, acc = 0.9169921875\n",
      "Batch 12: loss = 0.2626939117908478, acc = 0.9091796875\n",
      "Batch 13: loss = 0.23434871435165405, acc = 0.9111328125\n",
      "Batch 14: loss = 0.2620694041252136, acc = 0.9130859375\n",
      "Batch 15: loss = 0.24680699408054352, acc = 0.9111328125\n",
      "Batch 16: loss = 0.25411248207092285, acc = 0.9189453125\n",
      "Batch 17: loss = 0.2457374930381775, acc = 0.91796875\n",
      "Batch 18: loss = 0.2356518805027008, acc = 0.927734375\n",
      "Batch 19: loss = 0.273662805557251, acc = 0.9033203125\n",
      "Batch 20: loss = 0.2476518452167511, acc = 0.9072265625\n",
      "Batch 21: loss = 0.27005571126937866, acc = 0.921875\n",
      "Batch 22: loss = 0.254742294549942, acc = 0.9208984375\n",
      "Batch 23: loss = 0.28311729431152344, acc = 0.8955078125\n",
      "Batch 24: loss = 0.24878495931625366, acc = 0.912109375\n",
      "Batch 25: loss = 0.24742750823497772, acc = 0.9228515625\n",
      "Batch 26: loss = 0.22911006212234497, acc = 0.919921875\n",
      "Batch 27: loss = 0.2620575726032257, acc = 0.91015625\n",
      "Batch 28: loss = 0.2681428790092468, acc = 0.9111328125\n",
      "Batch 29: loss = 0.24260053038597107, acc = 0.9208984375\n",
      "Batch 30: loss = 0.25034043192863464, acc = 0.9140625\n",
      "Batch 31: loss = 0.240749329328537, acc = 0.9130859375\n",
      "Batch 32: loss = 0.2671889662742615, acc = 0.9140625\n",
      "Batch 33: loss = 0.22674262523651123, acc = 0.9296875\n",
      "Batch 34: loss = 0.2490602433681488, acc = 0.9169921875\n",
      "Batch 35: loss = 0.22788092494010925, acc = 0.92578125\n",
      "Batch 36: loss = 0.21766728162765503, acc = 0.9267578125\n",
      "Batch 37: loss = 0.25859910249710083, acc = 0.90625\n",
      "Batch 38: loss = 0.2098255306482315, acc = 0.9306640625\n",
      "Batch 39: loss = 0.22177305817604065, acc = 0.92578125\n",
      "Batch 40: loss = 0.24096156656742096, acc = 0.912109375\n",
      "Batch 41: loss = 0.23840740323066711, acc = 0.9228515625\n",
      "Batch 42: loss = 0.24891287088394165, acc = 0.9072265625\n",
      "Batch 43: loss = 0.26549530029296875, acc = 0.90625\n",
      "Batch 44: loss = 0.25073370337486267, acc = 0.9150390625\n",
      "Batch 45: loss = 0.21956588327884674, acc = 0.92578125\n",
      "Batch 46: loss = 0.23360314965248108, acc = 0.9140625\n",
      "Batch 47: loss = 0.24315710365772247, acc = 0.919921875\n",
      "Batch 48: loss = 0.2378295361995697, acc = 0.9208984375\n",
      "Batch 49: loss = 0.21005703508853912, acc = 0.927734375\n",
      "Batch 50: loss = 0.21433180570602417, acc = 0.923828125\n",
      "Batch 51: loss = 0.22830326855182648, acc = 0.9208984375\n",
      "Batch 52: loss = 0.20849408209323883, acc = 0.9296875\n",
      "Batch 53: loss = 0.2522774934768677, acc = 0.9140625\n",
      "Batch 54: loss = 0.21372219920158386, acc = 0.9375\n",
      "Batch 55: loss = 0.23208224773406982, acc = 0.923828125\n",
      "Batch 56: loss = 0.2641565203666687, acc = 0.91015625\n",
      "Batch 57: loss = 0.2524946928024292, acc = 0.9072265625\n",
      "Batch 58: loss = 0.28207916021347046, acc = 0.9072265625\n",
      "Batch 59: loss = 0.2365017831325531, acc = 0.916015625\n",
      "Batch 60: loss = 0.2226894050836563, acc = 0.919921875\n",
      "Batch 61: loss = 0.25618037581443787, acc = 0.9169921875\n",
      "Batch 62: loss = 0.25258269906044006, acc = 0.9150390625\n",
      "Batch 63: loss = 0.2833713889122009, acc = 0.90234375\n",
      "Batch 64: loss = 0.23502136766910553, acc = 0.9169921875\n",
      "Batch 65: loss = 0.2509338855743408, acc = 0.912109375\n",
      "Batch 66: loss = 0.23117470741271973, acc = 0.9228515625\n",
      "Batch 67: loss = 0.25873127579689026, acc = 0.91796875\n",
      "Batch 68: loss = 0.25601139664649963, acc = 0.9091796875\n",
      "Batch 69: loss = 0.2391814887523651, acc = 0.9169921875\n",
      "Batch 70: loss = 0.27673202753067017, acc = 0.9091796875\n",
      "Batch 71: loss = 0.26155662536621094, acc = 0.9208984375\n",
      "Batch 72: loss = 0.22432826459407806, acc = 0.9208984375\n",
      "Batch 73: loss = 0.25906336307525635, acc = 0.908203125\n",
      "Batch 74: loss = 0.2495182454586029, acc = 0.916015625\n",
      "Batch 75: loss = 0.26686662435531616, acc = 0.91015625\n",
      "Batch 76: loss = 0.27899831533432007, acc = 0.90625\n",
      "Batch 77: loss = 0.24570752680301666, acc = 0.9228515625\n",
      "Batch 78: loss = 0.28002768754959106, acc = 0.916015625\n",
      "Batch 79: loss = 0.2373553216457367, acc = 0.9208984375\n",
      "Batch 80: loss = 0.2211122214794159, acc = 0.92578125\n",
      "Batch 81: loss = 0.22415833175182343, acc = 0.921875\n",
      "Batch 82: loss = 0.2766568660736084, acc = 0.91015625\n",
      "Batch 83: loss = 0.28672346472740173, acc = 0.9052734375\n",
      "Batch 84: loss = 0.2437705397605896, acc = 0.9189453125\n",
      "Batch 85: loss = 0.2725566625595093, acc = 0.908203125\n",
      "Batch 86: loss = 0.23627454042434692, acc = 0.9208984375\n",
      "Batch 87: loss = 0.27321702241897583, acc = 0.9072265625\n",
      "Batch 88: loss = 0.2544029951095581, acc = 0.9228515625\n",
      "Batch 89: loss = 0.25591742992401123, acc = 0.91796875\n",
      "Batch 90: loss = 0.23150521516799927, acc = 0.916015625\n",
      "Batch 91: loss = 0.2592812776565552, acc = 0.9140625\n",
      "Batch 92: loss = 0.2720907926559448, acc = 0.908203125\n",
      "Batch 93: loss = 0.23411664366722107, acc = 0.9267578125\n",
      "Batch 94: loss = 0.23068249225616455, acc = 0.9228515625\n",
      "Batch 95: loss = 0.23739919066429138, acc = 0.921875\n",
      "Batch 96: loss = 0.2554048001766205, acc = 0.9140625\n",
      "Batch 97: loss = 0.25963661074638367, acc = 0.91796875\n",
      "Batch 98: loss = 0.2726755142211914, acc = 0.91015625\n",
      "Batch 99: loss = 0.2737060487270355, acc = 0.90625\n",
      "Batch 100: loss = 0.257379412651062, acc = 0.9140625\n",
      "Batch 101: loss = 0.2521694004535675, acc = 0.912109375\n",
      "Batch 102: loss = 0.2659122943878174, acc = 0.91015625\n",
      "Batch 103: loss = 0.2293339967727661, acc = 0.9140625\n",
      "Batch 104: loss = 0.24284882843494415, acc = 0.9189453125\n",
      "Batch 105: loss = 0.20361176133155823, acc = 0.9267578125\n",
      "Batch 106: loss = 0.2262992262840271, acc = 0.919921875\n",
      "Batch 107: loss = 0.23041866719722748, acc = 0.9130859375\n",
      "Batch 108: loss = 0.25201284885406494, acc = 0.9140625\n",
      "Batch 109: loss = 0.23936162889003754, acc = 0.9248046875\n",
      "Batch 110: loss = 0.22959387302398682, acc = 0.9296875\n",
      "Batch 111: loss = 0.24244976043701172, acc = 0.9228515625\n",
      "Batch 112: loss = 0.25001057982444763, acc = 0.9130859375\n",
      "Batch 113: loss = 0.23628753423690796, acc = 0.91796875\n",
      "Batch 114: loss = 0.2556051015853882, acc = 0.921875\n",
      "Batch 115: loss = 0.25949347019195557, acc = 0.9169921875\n",
      "Batch 116: loss = 0.2895750105381012, acc = 0.908203125\n",
      "Batch 117: loss = 0.23382745683193207, acc = 0.9189453125\n",
      "Batch 118: loss = 0.21380648016929626, acc = 0.92578125\n",
      "Batch 119: loss = 0.1963440328836441, acc = 0.9267578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 120: loss = 0.2224162071943283, acc = 0.9228515625\n",
      "Batch 121: loss = 0.23298120498657227, acc = 0.919921875\n",
      "Batch 122: loss = 0.2622128427028656, acc = 0.9111328125\n",
      "Batch 123: loss = 0.24434016644954681, acc = 0.921875\n",
      "Batch 124: loss = 0.2755190134048462, acc = 0.9169921875\n",
      "Batch 125: loss = 0.23838374018669128, acc = 0.923828125\n",
      "Batch 126: loss = 0.27624982595443726, acc = 0.908203125\n",
      "\n",
      "Epoch 96/100\n",
      "Batch 1: loss = 0.38123390078544617, acc = 0.8984375\n",
      "Batch 2: loss = 0.26122310757637024, acc = 0.9052734375\n",
      "Batch 3: loss = 0.2614079713821411, acc = 0.9091796875\n",
      "Batch 4: loss = 0.2594393789768219, acc = 0.9267578125\n",
      "Batch 5: loss = 0.2369559407234192, acc = 0.9287109375\n",
      "Batch 6: loss = 0.2572171986103058, acc = 0.9130859375\n",
      "Batch 7: loss = 0.247311532497406, acc = 0.908203125\n",
      "Batch 8: loss = 0.23084907233715057, acc = 0.9248046875\n",
      "Batch 9: loss = 0.2413857877254486, acc = 0.9228515625\n",
      "Batch 10: loss = 0.2219163179397583, acc = 0.9248046875\n",
      "Batch 11: loss = 0.24853730201721191, acc = 0.9150390625\n",
      "Batch 12: loss = 0.22178173065185547, acc = 0.9228515625\n",
      "Batch 13: loss = 0.21656033396720886, acc = 0.92578125\n",
      "Batch 14: loss = 0.2615059018135071, acc = 0.9111328125\n",
      "Batch 15: loss = 0.2436015009880066, acc = 0.9169921875\n",
      "Batch 16: loss = 0.26350706815719604, acc = 0.9091796875\n",
      "Batch 17: loss = 0.2721292972564697, acc = 0.9111328125\n",
      "Batch 18: loss = 0.2489466518163681, acc = 0.9150390625\n",
      "Batch 19: loss = 0.2667990028858185, acc = 0.912109375\n",
      "Batch 20: loss = 0.2392757385969162, acc = 0.90625\n",
      "Batch 21: loss = 0.24479004740715027, acc = 0.9130859375\n",
      "Batch 22: loss = 0.24844351410865784, acc = 0.921875\n",
      "Batch 23: loss = 0.24983009696006775, acc = 0.91796875\n",
      "Batch 24: loss = 0.23458023369312286, acc = 0.91796875\n",
      "Batch 25: loss = 0.24781477451324463, acc = 0.9189453125\n",
      "Batch 26: loss = 0.2491563856601715, acc = 0.9189453125\n",
      "Batch 27: loss = 0.24631598591804504, acc = 0.9228515625\n",
      "Batch 28: loss = 0.2530856728553772, acc = 0.9189453125\n",
      "Batch 29: loss = 0.2524572014808655, acc = 0.9248046875\n",
      "Batch 30: loss = 0.26883697509765625, acc = 0.900390625\n",
      "Batch 31: loss = 0.24167148768901825, acc = 0.9111328125\n",
      "Batch 32: loss = 0.2704075276851654, acc = 0.91015625\n",
      "Batch 33: loss = 0.26439329981803894, acc = 0.90625\n",
      "Batch 34: loss = 0.23558089137077332, acc = 0.92578125\n",
      "Batch 35: loss = 0.24270272254943848, acc = 0.9169921875\n",
      "Batch 36: loss = 0.20761166512966156, acc = 0.93359375\n",
      "Batch 37: loss = 0.2317219376564026, acc = 0.92578125\n",
      "Batch 38: loss = 0.235237717628479, acc = 0.92578125\n",
      "Batch 39: loss = 0.23409461975097656, acc = 0.923828125\n",
      "Batch 40: loss = 0.23841547966003418, acc = 0.921875\n",
      "Batch 41: loss = 0.21956518292427063, acc = 0.9345703125\n",
      "Batch 42: loss = 0.2561044991016388, acc = 0.912109375\n",
      "Batch 43: loss = 0.24396300315856934, acc = 0.9189453125\n",
      "Batch 44: loss = 0.2423919439315796, acc = 0.9267578125\n",
      "Batch 45: loss = 0.26353132724761963, acc = 0.9208984375\n",
      "Batch 46: loss = 0.20948997139930725, acc = 0.927734375\n",
      "Batch 47: loss = 0.22467154264450073, acc = 0.9267578125\n",
      "Batch 48: loss = 0.24808178842067719, acc = 0.9130859375\n",
      "Batch 49: loss = 0.2224978506565094, acc = 0.927734375\n",
      "Batch 50: loss = 0.24883729219436646, acc = 0.9111328125\n",
      "Batch 51: loss = 0.26866745948791504, acc = 0.90234375\n",
      "Batch 52: loss = 0.23226286470890045, acc = 0.923828125\n",
      "Batch 53: loss = 0.25723159313201904, acc = 0.91796875\n",
      "Batch 54: loss = 0.20394200086593628, acc = 0.9384765625\n",
      "Batch 55: loss = 0.19795498251914978, acc = 0.9267578125\n",
      "Batch 56: loss = 0.23746570944786072, acc = 0.9306640625\n",
      "Batch 57: loss = 0.24353575706481934, acc = 0.91796875\n",
      "Batch 58: loss = 0.2669057846069336, acc = 0.9189453125\n",
      "Batch 59: loss = 0.2282792031764984, acc = 0.9248046875\n",
      "Batch 60: loss = 0.2301476150751114, acc = 0.916015625\n",
      "Batch 61: loss = 0.23334252834320068, acc = 0.923828125\n",
      "Batch 62: loss = 0.2586621344089508, acc = 0.908203125\n",
      "Batch 63: loss = 0.24162490665912628, acc = 0.9248046875\n",
      "Batch 64: loss = 0.21176151931285858, acc = 0.9296875\n",
      "Batch 65: loss = 0.23471319675445557, acc = 0.9169921875\n",
      "Batch 66: loss = 0.23822236061096191, acc = 0.9150390625\n",
      "Batch 67: loss = 0.22354534268379211, acc = 0.9345703125\n",
      "Batch 68: loss = 0.264984130859375, acc = 0.90625\n",
      "Batch 69: loss = 0.23876221477985382, acc = 0.92578125\n",
      "Batch 70: loss = 0.24646112322807312, acc = 0.9169921875\n",
      "Batch 71: loss = 0.23970767855644226, acc = 0.9228515625\n",
      "Batch 72: loss = 0.2262864112854004, acc = 0.9267578125\n",
      "Batch 73: loss = 0.2508904039859772, acc = 0.9091796875\n",
      "Batch 74: loss = 0.2660185694694519, acc = 0.8984375\n",
      "Batch 75: loss = 0.2681325078010559, acc = 0.904296875\n",
      "Batch 76: loss = 0.2658652663230896, acc = 0.9052734375\n",
      "Batch 77: loss = 0.2354041337966919, acc = 0.9169921875\n",
      "Batch 78: loss = 0.2719632685184479, acc = 0.9150390625\n",
      "Batch 79: loss = 0.2117360234260559, acc = 0.9296875\n",
      "Batch 80: loss = 0.21440064907073975, acc = 0.919921875\n",
      "Batch 81: loss = 0.250335693359375, acc = 0.91015625\n",
      "Batch 82: loss = 0.25068199634552, acc = 0.9189453125\n",
      "Batch 83: loss = 0.26220303773880005, acc = 0.9072265625\n",
      "Batch 84: loss = 0.24681982398033142, acc = 0.9140625\n",
      "Batch 85: loss = 0.2545524835586548, acc = 0.91796875\n",
      "Batch 86: loss = 0.26051855087280273, acc = 0.912109375\n",
      "Batch 87: loss = 0.278899222612381, acc = 0.916015625\n",
      "Batch 88: loss = 0.3098655343055725, acc = 0.888671875\n",
      "Batch 89: loss = 0.22592583298683167, acc = 0.9287109375\n",
      "Batch 90: loss = 0.24519968032836914, acc = 0.9140625\n",
      "Batch 91: loss = 0.2569977045059204, acc = 0.9130859375\n",
      "Batch 92: loss = 0.3206409215927124, acc = 0.8974609375\n",
      "Batch 93: loss = 0.26987969875335693, acc = 0.908203125\n",
      "Batch 94: loss = 0.2537446618080139, acc = 0.916015625\n",
      "Batch 95: loss = 0.21040961146354675, acc = 0.923828125\n",
      "Batch 96: loss = 0.2643449306488037, acc = 0.91015625\n",
      "Batch 97: loss = 0.2342090606689453, acc = 0.9208984375\n",
      "Batch 98: loss = 0.2521468698978424, acc = 0.9248046875\n",
      "Batch 99: loss = 0.221841961145401, acc = 0.923828125\n",
      "Batch 100: loss = 0.27393633127212524, acc = 0.900390625\n",
      "Batch 101: loss = 0.2346520721912384, acc = 0.927734375\n",
      "Batch 102: loss = 0.255618155002594, acc = 0.9111328125\n",
      "Batch 103: loss = 0.2609776556491852, acc = 0.9091796875\n",
      "Batch 104: loss = 0.22293582558631897, acc = 0.9326171875\n",
      "Batch 105: loss = 0.23395287990570068, acc = 0.9267578125\n",
      "Batch 106: loss = 0.21863777935504913, acc = 0.931640625\n",
      "Batch 107: loss = 0.23938153684139252, acc = 0.919921875\n",
      "Batch 108: loss = 0.26118385791778564, acc = 0.9052734375\n",
      "Batch 109: loss = 0.2555939257144928, acc = 0.9130859375\n",
      "Batch 110: loss = 0.23314504325389862, acc = 0.9228515625\n",
      "Batch 111: loss = 0.2733697295188904, acc = 0.908203125\n",
      "Batch 112: loss = 0.2277425229549408, acc = 0.9248046875\n",
      "Batch 113: loss = 0.23416215181350708, acc = 0.931640625\n",
      "Batch 114: loss = 0.2615470290184021, acc = 0.9130859375\n",
      "Batch 115: loss = 0.2767323851585388, acc = 0.8994140625\n",
      "Batch 116: loss = 0.26675111055374146, acc = 0.912109375\n",
      "Batch 117: loss = 0.2877272367477417, acc = 0.8916015625\n",
      "Batch 118: loss = 0.25747036933898926, acc = 0.9111328125\n",
      "Batch 119: loss = 0.2411627471446991, acc = 0.916015625\n",
      "Batch 120: loss = 0.23669888079166412, acc = 0.9296875\n",
      "Batch 121: loss = 0.24173147976398468, acc = 0.9189453125\n",
      "Batch 122: loss = 0.2681593894958496, acc = 0.9169921875\n",
      "Batch 123: loss = 0.24790498614311218, acc = 0.9248046875\n",
      "Batch 124: loss = 0.2782267928123474, acc = 0.912109375\n",
      "Batch 125: loss = 0.2785530984401703, acc = 0.8984375\n",
      "Batch 126: loss = 0.2730717658996582, acc = 0.9091796875\n",
      "\n",
      "Epoch 97/100\n",
      "Batch 1: loss = 0.3881130814552307, acc = 0.9013671875\n",
      "Batch 2: loss = 0.22512730956077576, acc = 0.9208984375\n",
      "Batch 3: loss = 0.27664393186569214, acc = 0.90625\n",
      "Batch 4: loss = 0.26680174469947815, acc = 0.919921875\n",
      "Batch 5: loss = 0.24690671265125275, acc = 0.9169921875\n",
      "Batch 6: loss = 0.26366594433784485, acc = 0.921875\n",
      "Batch 7: loss = 0.23528414964675903, acc = 0.9140625\n",
      "Batch 8: loss = 0.2785026431083679, acc = 0.91015625\n",
      "Batch 9: loss = 0.2891375422477722, acc = 0.8974609375\n",
      "Batch 10: loss = 0.2030830681324005, acc = 0.9248046875\n",
      "Batch 11: loss = 0.28323131799697876, acc = 0.90625\n",
      "Batch 12: loss = 0.2283666431903839, acc = 0.91015625\n",
      "Batch 13: loss = 0.2192225605249405, acc = 0.927734375\n",
      "Batch 14: loss = 0.23514442145824432, acc = 0.9267578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15: loss = 0.22340306639671326, acc = 0.9267578125\n",
      "Batch 16: loss = 0.24185305833816528, acc = 0.9248046875\n",
      "Batch 17: loss = 0.261089950799942, acc = 0.9189453125\n",
      "Batch 18: loss = 0.25549033284187317, acc = 0.919921875\n",
      "Batch 19: loss = 0.25609371066093445, acc = 0.9169921875\n",
      "Batch 20: loss = 0.24109874665737152, acc = 0.9189453125\n",
      "Batch 21: loss = 0.2730081379413605, acc = 0.9072265625\n",
      "Batch 22: loss = 0.27005451917648315, acc = 0.9130859375\n",
      "Batch 23: loss = 0.2431151270866394, acc = 0.91796875\n",
      "Batch 24: loss = 0.23859858512878418, acc = 0.921875\n",
      "Batch 25: loss = 0.2350604236125946, acc = 0.9306640625\n",
      "Batch 26: loss = 0.2399674952030182, acc = 0.9169921875\n",
      "Batch 27: loss = 0.24495850503444672, acc = 0.923828125\n",
      "Batch 28: loss = 0.25520390272140503, acc = 0.91796875\n",
      "Batch 29: loss = 0.26761573553085327, acc = 0.9091796875\n",
      "Batch 30: loss = 0.24140959978103638, acc = 0.919921875\n",
      "Batch 31: loss = 0.2816953659057617, acc = 0.8984375\n",
      "Batch 32: loss = 0.2618041932582855, acc = 0.9111328125\n",
      "Batch 33: loss = 0.20152869820594788, acc = 0.9326171875\n",
      "Batch 34: loss = 0.23287591338157654, acc = 0.923828125\n",
      "Batch 35: loss = 0.24824020266532898, acc = 0.916015625\n",
      "Batch 36: loss = 0.21058806777000427, acc = 0.935546875\n",
      "Batch 37: loss = 0.22179338335990906, acc = 0.93359375\n",
      "Batch 38: loss = 0.23228898644447327, acc = 0.9296875\n",
      "Batch 39: loss = 0.20972199738025665, acc = 0.927734375\n",
      "Batch 40: loss = 0.2576755881309509, acc = 0.912109375\n",
      "Batch 41: loss = 0.24769490957260132, acc = 0.9248046875\n",
      "Batch 42: loss = 0.2344183623790741, acc = 0.919921875\n",
      "Batch 43: loss = 0.24880287051200867, acc = 0.9140625\n",
      "Batch 44: loss = 0.2540186643600464, acc = 0.921875\n",
      "Batch 45: loss = 0.2472730129957199, acc = 0.9189453125\n",
      "Batch 46: loss = 0.22723397612571716, acc = 0.9228515625\n",
      "Batch 47: loss = 0.2542864680290222, acc = 0.912109375\n",
      "Batch 48: loss = 0.23804029822349548, acc = 0.9287109375\n",
      "Batch 49: loss = 0.2555534839630127, acc = 0.921875\n",
      "Batch 50: loss = 0.23457002639770508, acc = 0.923828125\n",
      "Batch 51: loss = 0.270833820104599, acc = 0.90625\n",
      "Batch 52: loss = 0.23283082246780396, acc = 0.9208984375\n",
      "Batch 53: loss = 0.24180766940116882, acc = 0.916015625\n",
      "Batch 54: loss = 0.22751037776470184, acc = 0.92578125\n",
      "Batch 55: loss = 0.213875412940979, acc = 0.931640625\n",
      "Batch 56: loss = 0.23453685641288757, acc = 0.9150390625\n",
      "Batch 57: loss = 0.24800865352153778, acc = 0.91015625\n",
      "Batch 58: loss = 0.2715701162815094, acc = 0.919921875\n",
      "Batch 59: loss = 0.239604189991951, acc = 0.927734375\n",
      "Batch 60: loss = 0.2685224413871765, acc = 0.9072265625\n",
      "Batch 61: loss = 0.26542553305625916, acc = 0.9111328125\n",
      "Batch 62: loss = 0.29485848546028137, acc = 0.9052734375\n",
      "Batch 63: loss = 0.24250712990760803, acc = 0.9169921875\n",
      "Batch 64: loss = 0.2178654670715332, acc = 0.92578125\n",
      "Batch 65: loss = 0.24839818477630615, acc = 0.916015625\n",
      "Batch 66: loss = 0.2442009299993515, acc = 0.9169921875\n",
      "Batch 67: loss = 0.23475027084350586, acc = 0.9208984375\n",
      "Batch 68: loss = 0.23782601952552795, acc = 0.9228515625\n",
      "Batch 69: loss = 0.22003903985023499, acc = 0.9287109375\n",
      "Batch 70: loss = 0.22626632452011108, acc = 0.931640625\n",
      "Batch 71: loss = 0.25243550539016724, acc = 0.9169921875\n",
      "Batch 72: loss = 0.23840057849884033, acc = 0.9140625\n",
      "Batch 73: loss = 0.2525784969329834, acc = 0.9169921875\n",
      "Batch 74: loss = 0.2391422688961029, acc = 0.9189453125\n",
      "Batch 75: loss = 0.28133636713027954, acc = 0.9052734375\n",
      "Batch 76: loss = 0.23498380184173584, acc = 0.923828125\n",
      "Batch 77: loss = 0.2420523464679718, acc = 0.9189453125\n",
      "Batch 78: loss = 0.27148276567459106, acc = 0.9130859375\n",
      "Batch 79: loss = 0.2523104250431061, acc = 0.9130859375\n",
      "Batch 80: loss = 0.19841697812080383, acc = 0.9326171875\n",
      "Batch 81: loss = 0.26782143115997314, acc = 0.9013671875\n",
      "Batch 82: loss = 0.2819724678993225, acc = 0.912109375\n",
      "Batch 83: loss = 0.23541882634162903, acc = 0.92578125\n",
      "Batch 84: loss = 0.2722661793231964, acc = 0.912109375\n",
      "Batch 85: loss = 0.27102965116500854, acc = 0.9111328125\n",
      "Batch 86: loss = 0.23641003668308258, acc = 0.916015625\n",
      "Batch 87: loss = 0.288186639547348, acc = 0.9140625\n",
      "Batch 88: loss = 0.3056115210056305, acc = 0.890625\n",
      "Batch 89: loss = 0.20457608997821808, acc = 0.9384765625\n",
      "Batch 90: loss = 0.25405728816986084, acc = 0.9111328125\n",
      "Batch 91: loss = 0.2373971790075302, acc = 0.9287109375\n",
      "Batch 92: loss = 0.29002198576927185, acc = 0.90625\n",
      "Batch 93: loss = 0.22782652080059052, acc = 0.9248046875\n",
      "Batch 94: loss = 0.2557950019836426, acc = 0.9150390625\n",
      "Batch 95: loss = 0.22635650634765625, acc = 0.9150390625\n",
      "Batch 96: loss = 0.22786495089530945, acc = 0.9248046875\n",
      "Batch 97: loss = 0.24552839994430542, acc = 0.931640625\n",
      "Batch 98: loss = 0.2484590858221054, acc = 0.9091796875\n",
      "Batch 99: loss = 0.2553941607475281, acc = 0.9111328125\n",
      "Batch 100: loss = 0.22307567298412323, acc = 0.9189453125\n",
      "Batch 101: loss = 0.21593427658081055, acc = 0.9306640625\n",
      "Batch 102: loss = 0.25006717443466187, acc = 0.9169921875\n",
      "Batch 103: loss = 0.2761155664920807, acc = 0.904296875\n",
      "Batch 104: loss = 0.24652093648910522, acc = 0.9150390625\n",
      "Batch 105: loss = 0.23637276887893677, acc = 0.9140625\n",
      "Batch 106: loss = 0.23211795091629028, acc = 0.9208984375\n",
      "Batch 107: loss = 0.24891789257526398, acc = 0.9208984375\n",
      "Batch 108: loss = 0.2735213041305542, acc = 0.9033203125\n",
      "Batch 109: loss = 0.24172548949718475, acc = 0.9150390625\n",
      "Batch 110: loss = 0.21753114461898804, acc = 0.9306640625\n",
      "Batch 111: loss = 0.2895907163619995, acc = 0.8994140625\n",
      "Batch 112: loss = 0.2213621884584427, acc = 0.9345703125\n",
      "Batch 113: loss = 0.25344493985176086, acc = 0.9189453125\n",
      "Batch 114: loss = 0.24406415224075317, acc = 0.9228515625\n",
      "Batch 115: loss = 0.2535436451435089, acc = 0.91015625\n",
      "Batch 116: loss = 0.266018807888031, acc = 0.9169921875\n",
      "Batch 117: loss = 0.2774932384490967, acc = 0.90234375\n",
      "Batch 118: loss = 0.22457881271839142, acc = 0.921875\n",
      "Batch 119: loss = 0.21319779753684998, acc = 0.93359375\n",
      "Batch 120: loss = 0.19873081147670746, acc = 0.9345703125\n",
      "Batch 121: loss = 0.24966099858283997, acc = 0.904296875\n",
      "Batch 122: loss = 0.2246314287185669, acc = 0.9169921875\n",
      "Batch 123: loss = 0.24093671143054962, acc = 0.9248046875\n",
      "Batch 124: loss = 0.25354987382888794, acc = 0.9130859375\n",
      "Batch 125: loss = 0.2625369131565094, acc = 0.912109375\n",
      "Batch 126: loss = 0.27080750465393066, acc = 0.9150390625\n",
      "\n",
      "Epoch 98/100\n",
      "Batch 1: loss = 0.36373186111450195, acc = 0.9033203125\n",
      "Batch 2: loss = 0.23760774731636047, acc = 0.916015625\n",
      "Batch 3: loss = 0.26915788650512695, acc = 0.904296875\n",
      "Batch 4: loss = 0.25526905059814453, acc = 0.916015625\n",
      "Batch 5: loss = 0.23040109872817993, acc = 0.927734375\n",
      "Batch 6: loss = 0.261077344417572, acc = 0.9140625\n",
      "Batch 7: loss = 0.26436537504196167, acc = 0.9150390625\n",
      "Batch 8: loss = 0.23960207402706146, acc = 0.9169921875\n",
      "Batch 9: loss = 0.25628942251205444, acc = 0.9091796875\n",
      "Batch 10: loss = 0.20761044323444366, acc = 0.9326171875\n",
      "Batch 11: loss = 0.25455281138420105, acc = 0.919921875\n",
      "Batch 12: loss = 0.23004838824272156, acc = 0.91796875\n",
      "Batch 13: loss = 0.2175906002521515, acc = 0.923828125\n",
      "Batch 14: loss = 0.24712663888931274, acc = 0.923828125\n",
      "Batch 15: loss = 0.23954810202121735, acc = 0.916015625\n",
      "Batch 16: loss = 0.22487536072731018, acc = 0.93359375\n",
      "Batch 17: loss = 0.23619325459003448, acc = 0.927734375\n",
      "Batch 18: loss = 0.2579849362373352, acc = 0.9150390625\n",
      "Batch 19: loss = 0.2504551410675049, acc = 0.921875\n",
      "Batch 20: loss = 0.20228977501392365, acc = 0.9345703125\n",
      "Batch 21: loss = 0.26953038573265076, acc = 0.9072265625\n",
      "Batch 22: loss = 0.2957609295845032, acc = 0.90234375\n",
      "Batch 23: loss = 0.2621961534023285, acc = 0.9130859375\n",
      "Batch 24: loss = 0.23121903836727142, acc = 0.91796875\n",
      "Batch 25: loss = 0.26511693000793457, acc = 0.9150390625\n",
      "Batch 26: loss = 0.22453659772872925, acc = 0.931640625\n",
      "Batch 27: loss = 0.238447904586792, acc = 0.919921875\n",
      "Batch 28: loss = 0.2665232717990875, acc = 0.9130859375\n",
      "Batch 29: loss = 0.2558160424232483, acc = 0.91796875\n",
      "Batch 30: loss = 0.24369919300079346, acc = 0.919921875\n",
      "Batch 31: loss = 0.24603721499443054, acc = 0.919921875\n",
      "Batch 32: loss = 0.24790418148040771, acc = 0.92578125\n",
      "Batch 33: loss = 0.2338194102048874, acc = 0.9208984375\n",
      "Batch 34: loss = 0.260044664144516, acc = 0.9169921875\n",
      "Batch 35: loss = 0.24831731617450714, acc = 0.9140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 36: loss = 0.23070350289344788, acc = 0.921875\n",
      "Batch 37: loss = 0.20216375589370728, acc = 0.931640625\n",
      "Batch 38: loss = 0.24514281749725342, acc = 0.9130859375\n",
      "Batch 39: loss = 0.22283081710338593, acc = 0.9208984375\n",
      "Batch 40: loss = 0.24027958512306213, acc = 0.92578125\n",
      "Batch 41: loss = 0.23684431612491608, acc = 0.9208984375\n",
      "Batch 42: loss = 0.23471775650978088, acc = 0.9150390625\n",
      "Batch 43: loss = 0.2554735839366913, acc = 0.91015625\n",
      "Batch 44: loss = 0.21665480732917786, acc = 0.9306640625\n",
      "Batch 45: loss = 0.23945577442646027, acc = 0.9228515625\n",
      "Batch 46: loss = 0.21094021201133728, acc = 0.927734375\n",
      "Batch 47: loss = 0.2200438380241394, acc = 0.9287109375\n",
      "Batch 48: loss = 0.23325711488723755, acc = 0.921875\n",
      "Batch 49: loss = 0.24020862579345703, acc = 0.9228515625\n",
      "Batch 50: loss = 0.23502182960510254, acc = 0.9228515625\n",
      "Batch 51: loss = 0.24590323865413666, acc = 0.921875\n",
      "Batch 52: loss = 0.23983177542686462, acc = 0.916015625\n",
      "Batch 53: loss = 0.22577901184558868, acc = 0.92578125\n",
      "Batch 54: loss = 0.2058401256799698, acc = 0.9296875\n",
      "Batch 55: loss = 0.2541019022464752, acc = 0.9169921875\n",
      "Batch 56: loss = 0.2739909887313843, acc = 0.9111328125\n",
      "Batch 57: loss = 0.24315093457698822, acc = 0.91796875\n",
      "Batch 58: loss = 0.24727681279182434, acc = 0.92578125\n",
      "Batch 59: loss = 0.22389903664588928, acc = 0.93359375\n",
      "Batch 60: loss = 0.2563413083553314, acc = 0.916015625\n",
      "Batch 61: loss = 0.22026751935482025, acc = 0.9208984375\n",
      "Batch 62: loss = 0.2756401598453522, acc = 0.904296875\n",
      "Batch 63: loss = 0.23839347064495087, acc = 0.923828125\n",
      "Batch 64: loss = 0.1955624371767044, acc = 0.93359375\n",
      "Batch 65: loss = 0.24098621308803558, acc = 0.919921875\n",
      "Batch 66: loss = 0.24574275314807892, acc = 0.9140625\n",
      "Batch 67: loss = 0.2491927444934845, acc = 0.9208984375\n",
      "Batch 68: loss = 0.24843813478946686, acc = 0.912109375\n",
      "Batch 69: loss = 0.23243668675422668, acc = 0.9267578125\n",
      "Batch 70: loss = 0.2592974305152893, acc = 0.91015625\n",
      "Batch 71: loss = 0.2276793122291565, acc = 0.9267578125\n",
      "Batch 72: loss = 0.231186181306839, acc = 0.921875\n",
      "Batch 73: loss = 0.24860334396362305, acc = 0.91796875\n",
      "Batch 74: loss = 0.26081568002700806, acc = 0.908203125\n",
      "Batch 75: loss = 0.2886665463447571, acc = 0.9052734375\n",
      "Batch 76: loss = 0.24525338411331177, acc = 0.91796875\n",
      "Batch 77: loss = 0.25088778138160706, acc = 0.9150390625\n",
      "Batch 78: loss = 0.25689220428466797, acc = 0.9091796875\n",
      "Batch 79: loss = 0.21300163865089417, acc = 0.9208984375\n",
      "Batch 80: loss = 0.22301244735717773, acc = 0.923828125\n",
      "Batch 81: loss = 0.2750985026359558, acc = 0.904296875\n",
      "Batch 82: loss = 0.23789559304714203, acc = 0.91796875\n",
      "Batch 83: loss = 0.2602316737174988, acc = 0.9072265625\n",
      "Batch 84: loss = 0.22312107682228088, acc = 0.935546875\n",
      "Batch 85: loss = 0.2591911554336548, acc = 0.912109375\n",
      "Batch 86: loss = 0.2468641847372055, acc = 0.9208984375\n",
      "Batch 87: loss = 0.2572999596595764, acc = 0.9130859375\n",
      "Batch 88: loss = 0.29233038425445557, acc = 0.904296875\n",
      "Batch 89: loss = 0.20569318532943726, acc = 0.9306640625\n",
      "Batch 90: loss = 0.2435392290353775, acc = 0.9130859375\n",
      "Batch 91: loss = 0.2462797462940216, acc = 0.9228515625\n",
      "Batch 92: loss = 0.2487105131149292, acc = 0.9208984375\n",
      "Batch 93: loss = 0.21908323466777802, acc = 0.9228515625\n",
      "Batch 94: loss = 0.2526400089263916, acc = 0.9248046875\n",
      "Batch 95: loss = 0.22953146696090698, acc = 0.91796875\n",
      "Batch 96: loss = 0.2596333622932434, acc = 0.9140625\n",
      "Batch 97: loss = 0.2688022255897522, acc = 0.908203125\n",
      "Batch 98: loss = 0.25483331084251404, acc = 0.916015625\n",
      "Batch 99: loss = 0.2711349129676819, acc = 0.9091796875\n",
      "Batch 100: loss = 0.2702309489250183, acc = 0.90234375\n",
      "Batch 101: loss = 0.23491185903549194, acc = 0.921875\n",
      "Batch 102: loss = 0.258685439825058, acc = 0.9091796875\n",
      "Batch 103: loss = 0.28826621174812317, acc = 0.9033203125\n",
      "Batch 104: loss = 0.2532113194465637, acc = 0.9169921875\n",
      "Batch 105: loss = 0.2798054814338684, acc = 0.9072265625\n",
      "Batch 106: loss = 0.24489068984985352, acc = 0.9150390625\n",
      "Batch 107: loss = 0.25117141008377075, acc = 0.923828125\n",
      "Batch 108: loss = 0.2381175011396408, acc = 0.9208984375\n",
      "Batch 109: loss = 0.24370749294757843, acc = 0.91796875\n",
      "Batch 110: loss = 0.2317201793193817, acc = 0.927734375\n",
      "Batch 111: loss = 0.261202871799469, acc = 0.9248046875\n",
      "Batch 112: loss = 0.24450623989105225, acc = 0.9208984375\n",
      "Batch 113: loss = 0.24249887466430664, acc = 0.916015625\n",
      "Batch 114: loss = 0.25585484504699707, acc = 0.916015625\n",
      "Batch 115: loss = 0.2647990584373474, acc = 0.916015625\n",
      "Batch 116: loss = 0.26439422369003296, acc = 0.904296875\n",
      "Batch 117: loss = 0.2563144862651825, acc = 0.919921875\n",
      "Batch 118: loss = 0.21626634895801544, acc = 0.9208984375\n",
      "Batch 119: loss = 0.21912039816379547, acc = 0.923828125\n",
      "Batch 120: loss = 0.20381441712379456, acc = 0.9296875\n",
      "Batch 121: loss = 0.23830315470695496, acc = 0.9130859375\n",
      "Batch 122: loss = 0.20906095206737518, acc = 0.9189453125\n",
      "Batch 123: loss = 0.24824005365371704, acc = 0.90625\n",
      "Batch 124: loss = 0.24782347679138184, acc = 0.912109375\n",
      "Batch 125: loss = 0.24653972685337067, acc = 0.9150390625\n",
      "Batch 126: loss = 0.23742267489433289, acc = 0.9228515625\n",
      "\n",
      "Epoch 99/100\n",
      "Batch 1: loss = 0.3344738483428955, acc = 0.8974609375\n",
      "Batch 2: loss = 0.2341778576374054, acc = 0.919921875\n",
      "Batch 3: loss = 0.2335534691810608, acc = 0.9287109375\n",
      "Batch 4: loss = 0.2678573727607727, acc = 0.9130859375\n",
      "Batch 5: loss = 0.23752866685390472, acc = 0.919921875\n",
      "Batch 6: loss = 0.24642688035964966, acc = 0.9248046875\n",
      "Batch 7: loss = 0.2699160575866699, acc = 0.912109375\n",
      "Batch 8: loss = 0.2615613639354706, acc = 0.916015625\n",
      "Batch 9: loss = 0.2659277319908142, acc = 0.9130859375\n",
      "Batch 10: loss = 0.21110647916793823, acc = 0.9248046875\n",
      "Batch 11: loss = 0.246158167719841, acc = 0.91796875\n",
      "Batch 12: loss = 0.23259395360946655, acc = 0.9326171875\n",
      "Batch 13: loss = 0.21598124504089355, acc = 0.931640625\n",
      "Batch 14: loss = 0.2475229799747467, acc = 0.923828125\n",
      "Batch 15: loss = 0.24064496159553528, acc = 0.921875\n",
      "Batch 16: loss = 0.25119879841804504, acc = 0.9208984375\n",
      "Batch 17: loss = 0.23955675959587097, acc = 0.91796875\n",
      "Batch 18: loss = 0.2484503835439682, acc = 0.912109375\n",
      "Batch 19: loss = 0.23713883757591248, acc = 0.9228515625\n",
      "Batch 20: loss = 0.25119221210479736, acc = 0.912109375\n",
      "Batch 21: loss = 0.3019982874393463, acc = 0.9013671875\n",
      "Batch 22: loss = 0.27596884965896606, acc = 0.8994140625\n",
      "Batch 23: loss = 0.2661682963371277, acc = 0.912109375\n",
      "Batch 24: loss = 0.23247195780277252, acc = 0.92578125\n",
      "Batch 25: loss = 0.2739119529724121, acc = 0.912109375\n",
      "Batch 26: loss = 0.23581266403198242, acc = 0.9140625\n",
      "Batch 27: loss = 0.28919166326522827, acc = 0.8876953125\n",
      "Batch 28: loss = 0.24403920769691467, acc = 0.91796875\n",
      "Batch 29: loss = 0.26022961735725403, acc = 0.9140625\n",
      "Batch 30: loss = 0.27078238129615784, acc = 0.9013671875\n",
      "Batch 31: loss = 0.2398862987756729, acc = 0.92578125\n",
      "Batch 32: loss = 0.24468757212162018, acc = 0.9140625\n",
      "Batch 33: loss = 0.2325308918952942, acc = 0.9130859375\n",
      "Batch 34: loss = 0.25289857387542725, acc = 0.9140625\n",
      "Batch 35: loss = 0.22422513365745544, acc = 0.9287109375\n",
      "Batch 36: loss = 0.23742854595184326, acc = 0.9189453125\n",
      "Batch 37: loss = 0.21829256415367126, acc = 0.9248046875\n",
      "Batch 38: loss = 0.2215450555086136, acc = 0.9287109375\n",
      "Batch 39: loss = 0.23105163872241974, acc = 0.921875\n",
      "Batch 40: loss = 0.2175695151090622, acc = 0.93359375\n",
      "Batch 41: loss = 0.22969794273376465, acc = 0.923828125\n",
      "Batch 42: loss = 0.21679559350013733, acc = 0.92578125\n",
      "Batch 43: loss = 0.24199828505516052, acc = 0.9189453125\n",
      "Batch 44: loss = 0.2277499884366989, acc = 0.923828125\n",
      "Batch 45: loss = 0.23621335625648499, acc = 0.93359375\n",
      "Batch 46: loss = 0.19765548408031464, acc = 0.9326171875\n",
      "Batch 47: loss = 0.23913449048995972, acc = 0.9130859375\n",
      "Batch 48: loss = 0.21598902344703674, acc = 0.9296875\n",
      "Batch 49: loss = 0.22323232889175415, acc = 0.931640625\n",
      "Batch 50: loss = 0.23923850059509277, acc = 0.9208984375\n",
      "Batch 51: loss = 0.23756039142608643, acc = 0.919921875\n",
      "Batch 52: loss = 0.2363804429769516, acc = 0.923828125\n",
      "Batch 53: loss = 0.22449736297130585, acc = 0.919921875\n",
      "Batch 54: loss = 0.18766747415065765, acc = 0.939453125\n",
      "Batch 55: loss = 0.2073211967945099, acc = 0.927734375\n",
      "Batch 56: loss = 0.25011688470840454, acc = 0.923828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 57: loss = 0.2251749038696289, acc = 0.923828125\n",
      "Batch 58: loss = 0.27314233779907227, acc = 0.9208984375\n",
      "Batch 59: loss = 0.20726588368415833, acc = 0.9248046875\n",
      "Batch 60: loss = 0.2540775239467621, acc = 0.912109375\n",
      "Batch 61: loss = 0.23604588210582733, acc = 0.9296875\n",
      "Batch 62: loss = 0.25724565982818604, acc = 0.904296875\n",
      "Batch 63: loss = 0.22720924019813538, acc = 0.9248046875\n",
      "Batch 64: loss = 0.23046337068080902, acc = 0.916015625\n",
      "Batch 65: loss = 0.2332845777273178, acc = 0.921875\n",
      "Batch 66: loss = 0.2428068220615387, acc = 0.921875\n",
      "Batch 67: loss = 0.2531864047050476, acc = 0.9189453125\n",
      "Batch 68: loss = 0.25817298889160156, acc = 0.916015625\n",
      "Batch 69: loss = 0.22500073909759521, acc = 0.9248046875\n",
      "Batch 70: loss = 0.27572351694107056, acc = 0.904296875\n",
      "Batch 71: loss = 0.28285253047943115, acc = 0.90234375\n",
      "Batch 72: loss = 0.2524932622909546, acc = 0.912109375\n",
      "Batch 73: loss = 0.27452218532562256, acc = 0.912109375\n",
      "Batch 74: loss = 0.27400368452072144, acc = 0.9033203125\n",
      "Batch 75: loss = 0.267142653465271, acc = 0.91796875\n",
      "Batch 76: loss = 0.2595052719116211, acc = 0.9072265625\n",
      "Batch 77: loss = 0.2444906234741211, acc = 0.9189453125\n",
      "Batch 78: loss = 0.2854786813259125, acc = 0.91015625\n",
      "Batch 79: loss = 0.2257431149482727, acc = 0.921875\n",
      "Batch 80: loss = 0.2356078028678894, acc = 0.91015625\n",
      "Batch 81: loss = 0.2447092980146408, acc = 0.90625\n",
      "Batch 82: loss = 0.28548383712768555, acc = 0.9052734375\n",
      "Batch 83: loss = 0.25593921542167664, acc = 0.9111328125\n",
      "Batch 84: loss = 0.2208537459373474, acc = 0.921875\n",
      "Batch 85: loss = 0.24464207887649536, acc = 0.916015625\n",
      "Batch 86: loss = 0.23127099871635437, acc = 0.923828125\n",
      "Batch 87: loss = 0.24268388748168945, acc = 0.912109375\n",
      "Batch 88: loss = 0.29932868480682373, acc = 0.8984375\n",
      "Batch 89: loss = 0.22795401513576508, acc = 0.921875\n",
      "Batch 90: loss = 0.2627859115600586, acc = 0.9111328125\n",
      "Batch 91: loss = 0.2394583821296692, acc = 0.91796875\n",
      "Batch 92: loss = 0.24795931577682495, acc = 0.9111328125\n",
      "Batch 93: loss = 0.22946515679359436, acc = 0.9189453125\n",
      "Batch 94: loss = 0.22826053202152252, acc = 0.921875\n",
      "Batch 95: loss = 0.1945480853319168, acc = 0.9267578125\n",
      "Batch 96: loss = 0.28385651111602783, acc = 0.9072265625\n",
      "Batch 97: loss = 0.26962465047836304, acc = 0.9052734375\n",
      "Batch 98: loss = 0.2607577443122864, acc = 0.9228515625\n",
      "Batch 99: loss = 0.2690270245075226, acc = 0.90625\n",
      "Batch 100: loss = 0.2731439471244812, acc = 0.8984375\n",
      "Batch 101: loss = 0.2602098286151886, acc = 0.9130859375\n",
      "Batch 102: loss = 0.2845335900783539, acc = 0.9091796875\n",
      "Batch 103: loss = 0.265588641166687, acc = 0.9140625\n",
      "Batch 104: loss = 0.23899543285369873, acc = 0.9130859375\n",
      "Batch 105: loss = 0.21306592226028442, acc = 0.9267578125\n",
      "Batch 106: loss = 0.2675457000732422, acc = 0.9111328125\n",
      "Batch 107: loss = 0.23931924998760223, acc = 0.9228515625\n",
      "Batch 108: loss = 0.2490866482257843, acc = 0.923828125\n",
      "Batch 109: loss = 0.254686564207077, acc = 0.916015625\n",
      "Batch 110: loss = 0.22167091071605682, acc = 0.9228515625\n",
      "Batch 111: loss = 0.269946813583374, acc = 0.9052734375\n",
      "Batch 112: loss = 0.25832927227020264, acc = 0.9189453125\n",
      "Batch 113: loss = 0.24797794222831726, acc = 0.91796875\n",
      "Batch 114: loss = 0.25459200143814087, acc = 0.92578125\n",
      "Batch 115: loss = 0.24032853543758392, acc = 0.9140625\n",
      "Batch 116: loss = 0.2556309103965759, acc = 0.9189453125\n",
      "Batch 117: loss = 0.25627511739730835, acc = 0.9140625\n",
      "Batch 118: loss = 0.2332955151796341, acc = 0.9189453125\n",
      "Batch 119: loss = 0.22244969010353088, acc = 0.92578125\n",
      "Batch 120: loss = 0.23518382012844086, acc = 0.921875\n",
      "Batch 121: loss = 0.2518021762371063, acc = 0.9130859375\n",
      "Batch 122: loss = 0.20627950131893158, acc = 0.92578125\n",
      "Batch 123: loss = 0.24350577592849731, acc = 0.9169921875\n",
      "Batch 124: loss = 0.2421572357416153, acc = 0.9150390625\n",
      "Batch 125: loss = 0.22444140911102295, acc = 0.9189453125\n",
      "Batch 126: loss = 0.23082664608955383, acc = 0.9169921875\n",
      "\n",
      "Epoch 100/100\n",
      "Batch 1: loss = 0.3372318744659424, acc = 0.9111328125\n",
      "Batch 2: loss = 0.23400402069091797, acc = 0.9150390625\n",
      "Batch 3: loss = 0.23639538884162903, acc = 0.927734375\n",
      "Batch 4: loss = 0.27912676334381104, acc = 0.916015625\n",
      "Batch 5: loss = 0.23443979024887085, acc = 0.9208984375\n",
      "Batch 6: loss = 0.26059144735336304, acc = 0.9150390625\n",
      "Batch 7: loss = 0.2526804804801941, acc = 0.927734375\n",
      "Batch 8: loss = 0.24400050938129425, acc = 0.9306640625\n",
      "Batch 9: loss = 0.2987655699253082, acc = 0.9072265625\n",
      "Batch 10: loss = 0.22724537551403046, acc = 0.92578125\n",
      "Batch 11: loss = 0.23972375690937042, acc = 0.9296875\n",
      "Batch 12: loss = 0.23875901103019714, acc = 0.9208984375\n",
      "Batch 13: loss = 0.24671967327594757, acc = 0.919921875\n",
      "Batch 14: loss = 0.25351038575172424, acc = 0.916015625\n",
      "Batch 15: loss = 0.22362928092479706, acc = 0.92578125\n",
      "Batch 16: loss = 0.22495514154434204, acc = 0.9287109375\n",
      "Batch 17: loss = 0.2184009999036789, acc = 0.9326171875\n",
      "Batch 18: loss = 0.239467591047287, acc = 0.923828125\n",
      "Batch 19: loss = 0.2557859420776367, acc = 0.9208984375\n",
      "Batch 20: loss = 0.24746543169021606, acc = 0.912109375\n",
      "Batch 21: loss = 0.24348923563957214, acc = 0.919921875\n",
      "Batch 22: loss = 0.2744397819042206, acc = 0.908203125\n",
      "Batch 23: loss = 0.27191001176834106, acc = 0.9140625\n",
      "Batch 24: loss = 0.21877020597457886, acc = 0.9296875\n",
      "Batch 25: loss = 0.23993222415447235, acc = 0.923828125\n",
      "Batch 26: loss = 0.21523943543434143, acc = 0.9248046875\n",
      "Batch 27: loss = 0.30704325437545776, acc = 0.9013671875\n",
      "Batch 28: loss = 0.24081481993198395, acc = 0.9150390625\n",
      "Batch 29: loss = 0.2685082256793976, acc = 0.90625\n",
      "Batch 30: loss = 0.2469717562198639, acc = 0.91796875\n",
      "Batch 31: loss = 0.26477622985839844, acc = 0.9052734375\n",
      "Batch 32: loss = 0.2701452374458313, acc = 0.9150390625\n",
      "Batch 33: loss = 0.20028963685035706, acc = 0.935546875\n",
      "Batch 34: loss = 0.2506239116191864, acc = 0.9189453125\n",
      "Batch 35: loss = 0.22406363487243652, acc = 0.931640625\n",
      "Batch 36: loss = 0.21003597974777222, acc = 0.92578125\n",
      "Batch 37: loss = 0.20998115837574005, acc = 0.93359375\n",
      "Batch 38: loss = 0.206548273563385, acc = 0.9345703125\n",
      "Batch 39: loss = 0.23460733890533447, acc = 0.9228515625\n",
      "Batch 40: loss = 0.21197426319122314, acc = 0.9287109375\n",
      "Batch 41: loss = 0.24536696076393127, acc = 0.9140625\n",
      "Batch 42: loss = 0.23236289620399475, acc = 0.919921875\n",
      "Batch 43: loss = 0.2908230423927307, acc = 0.904296875\n",
      "Batch 44: loss = 0.23465657234191895, acc = 0.919921875\n",
      "Batch 45: loss = 0.23795583844184875, acc = 0.923828125\n",
      "Batch 46: loss = 0.23011401295661926, acc = 0.921875\n",
      "Batch 47: loss = 0.2193111628293991, acc = 0.9228515625\n",
      "Batch 48: loss = 0.2281612902879715, acc = 0.91796875\n",
      "Batch 49: loss = 0.22925761342048645, acc = 0.9228515625\n",
      "Batch 50: loss = 0.2582213580608368, acc = 0.919921875\n",
      "Batch 51: loss = 0.22970637679100037, acc = 0.9228515625\n",
      "Batch 52: loss = 0.24375391006469727, acc = 0.916015625\n",
      "Batch 53: loss = 0.24563917517662048, acc = 0.9111328125\n",
      "Batch 54: loss = 0.20736807584762573, acc = 0.92578125\n",
      "Batch 55: loss = 0.21361738443374634, acc = 0.9306640625\n",
      "Batch 56: loss = 0.2740311920642853, acc = 0.908203125\n",
      "Batch 57: loss = 0.2661018967628479, acc = 0.9091796875\n",
      "Batch 58: loss = 0.27395373582839966, acc = 0.912109375\n",
      "Batch 59: loss = 0.2077072560787201, acc = 0.9345703125\n",
      "Batch 60: loss = 0.25867384672164917, acc = 0.9111328125\n",
      "Batch 61: loss = 0.19898954033851624, acc = 0.9404296875\n",
      "Batch 62: loss = 0.2520366609096527, acc = 0.921875\n",
      "Batch 63: loss = 0.2367292046546936, acc = 0.919921875\n",
      "Batch 64: loss = 0.21661321818828583, acc = 0.931640625\n",
      "Batch 65: loss = 0.21739083528518677, acc = 0.9228515625\n",
      "Batch 66: loss = 0.22978165745735168, acc = 0.91796875\n",
      "Batch 67: loss = 0.2325734943151474, acc = 0.916015625\n",
      "Batch 68: loss = 0.2626981735229492, acc = 0.908203125\n",
      "Batch 69: loss = 0.2206527143716812, acc = 0.923828125\n",
      "Batch 70: loss = 0.27941322326660156, acc = 0.904296875\n",
      "Batch 71: loss = 0.25634685158729553, acc = 0.9140625\n",
      "Batch 72: loss = 0.20029738545417786, acc = 0.9248046875\n",
      "Batch 73: loss = 0.27083465456962585, acc = 0.9169921875\n",
      "Batch 74: loss = 0.23201388120651245, acc = 0.9248046875\n",
      "Batch 75: loss = 0.28112247586250305, acc = 0.9091796875\n",
      "Batch 76: loss = 0.2501881420612335, acc = 0.9189453125\n",
      "Batch 77: loss = 0.24197885394096375, acc = 0.9150390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 78: loss = 0.26577651500701904, acc = 0.9033203125\n",
      "Batch 79: loss = 0.2408066689968109, acc = 0.9140625\n",
      "Batch 80: loss = 0.2164982408285141, acc = 0.92578125\n",
      "Batch 81: loss = 0.2488577514886856, acc = 0.9130859375\n",
      "Batch 82: loss = 0.2561171054840088, acc = 0.9150390625\n",
      "Batch 83: loss = 0.22665399312973022, acc = 0.9140625\n",
      "Batch 84: loss = 0.283382773399353, acc = 0.9013671875\n",
      "Batch 85: loss = 0.25325891375541687, acc = 0.916015625\n",
      "Batch 86: loss = 0.259896844625473, acc = 0.91015625\n",
      "Batch 87: loss = 0.28303512930870056, acc = 0.90625\n",
      "Batch 88: loss = 0.2790393829345703, acc = 0.9111328125\n",
      "Batch 89: loss = 0.20333845913410187, acc = 0.939453125\n",
      "Batch 90: loss = 0.23817229270935059, acc = 0.9169921875\n",
      "Batch 91: loss = 0.2570294439792633, acc = 0.90625\n",
      "Batch 92: loss = 0.26777133345603943, acc = 0.919921875\n",
      "Batch 93: loss = 0.20220310986042023, acc = 0.9365234375\n",
      "Batch 94: loss = 0.2398848533630371, acc = 0.92578125\n",
      "Batch 95: loss = 0.2026374489068985, acc = 0.9345703125\n",
      "Batch 96: loss = 0.23897188901901245, acc = 0.9140625\n",
      "Batch 97: loss = 0.2425159513950348, acc = 0.927734375\n",
      "Batch 98: loss = 0.23306892812252045, acc = 0.9296875\n",
      "Batch 99: loss = 0.23338884115219116, acc = 0.921875\n",
      "Batch 100: loss = 0.24580711126327515, acc = 0.916015625\n",
      "Batch 101: loss = 0.244742289185524, acc = 0.9072265625\n",
      "Batch 102: loss = 0.2633443772792816, acc = 0.9140625\n",
      "Batch 103: loss = 0.2726009488105774, acc = 0.9130859375\n",
      "Batch 104: loss = 0.2652742266654968, acc = 0.9140625\n",
      "Batch 105: loss = 0.2380402684211731, acc = 0.921875\n",
      "Batch 106: loss = 0.24240460991859436, acc = 0.921875\n",
      "Batch 107: loss = 0.2322845160961151, acc = 0.92578125\n",
      "Batch 108: loss = 0.2396961748600006, acc = 0.9140625\n",
      "Batch 109: loss = 0.2699506878852844, acc = 0.90234375\n",
      "Batch 110: loss = 0.22870761156082153, acc = 0.9326171875\n",
      "Batch 111: loss = 0.23108255863189697, acc = 0.9189453125\n",
      "Batch 112: loss = 0.2767629027366638, acc = 0.908203125\n",
      "Batch 113: loss = 0.24624323844909668, acc = 0.9111328125\n",
      "Batch 114: loss = 0.25375455617904663, acc = 0.9208984375\n",
      "Batch 115: loss = 0.2525169849395752, acc = 0.9130859375\n",
      "Batch 116: loss = 0.25654035806655884, acc = 0.91015625\n",
      "Batch 117: loss = 0.2703104317188263, acc = 0.904296875\n",
      "Batch 118: loss = 0.24654582142829895, acc = 0.923828125\n",
      "Batch 119: loss = 0.21142563223838806, acc = 0.93359375\n",
      "Batch 120: loss = 0.22010758519172668, acc = 0.9287109375\n",
      "Batch 121: loss = 0.25132691860198975, acc = 0.9130859375\n",
      "Batch 122: loss = 0.23504099249839783, acc = 0.9248046875\n",
      "Batch 123: loss = 0.24491484463214874, acc = 0.9111328125\n",
      "Batch 124: loss = 0.26549774408340454, acc = 0.9033203125\n",
      "Batch 125: loss = 0.2683379054069519, acc = 0.916015625\n",
      "Batch 126: loss = 0.2619397044181824, acc = 0.91796875\n",
      "Saved checkpoint to weights.100.h5\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(LOG_DIR):\n",
    "        os.makedirs(LOG_DIR)\n",
    "train(open(os.path.join(DATA_DIR, \"input.txt\")).read(), 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.144330</td>\n",
       "      <td>0.182346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.162593</td>\n",
       "      <td>0.381200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.775683</td>\n",
       "      <td>0.483848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.614309</td>\n",
       "      <td>0.523693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.491862</td>\n",
       "      <td>0.544449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.399065</td>\n",
       "      <td>0.560175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.329014</td>\n",
       "      <td>0.576242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.276682</td>\n",
       "      <td>0.588588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.234373</td>\n",
       "      <td>0.601004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.191572</td>\n",
       "      <td>0.614165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.150929</td>\n",
       "      <td>0.626387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.110102</td>\n",
       "      <td>0.640152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1.074349</td>\n",
       "      <td>0.650925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.044831</td>\n",
       "      <td>0.661311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.012436</td>\n",
       "      <td>0.669844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.983294</td>\n",
       "      <td>0.679137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.955336</td>\n",
       "      <td>0.689492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.930459</td>\n",
       "      <td>0.696731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.906632</td>\n",
       "      <td>0.704024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.877986</td>\n",
       "      <td>0.713487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.856267</td>\n",
       "      <td>0.720006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.833336</td>\n",
       "      <td>0.728113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.812613</td>\n",
       "      <td>0.734173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.787767</td>\n",
       "      <td>0.741784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.766259</td>\n",
       "      <td>0.750015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.755635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.728894</td>\n",
       "      <td>0.761300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.706465</td>\n",
       "      <td>0.768051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.695321</td>\n",
       "      <td>0.773097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.673937</td>\n",
       "      <td>0.778499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>0.307621</td>\n",
       "      <td>0.898174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>0.305948</td>\n",
       "      <td>0.898321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>0.300696</td>\n",
       "      <td>0.899507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>0.300903</td>\n",
       "      <td>0.900026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>0.298919</td>\n",
       "      <td>0.899585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>0.295143</td>\n",
       "      <td>0.901638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>0.288648</td>\n",
       "      <td>0.903685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>0.289749</td>\n",
       "      <td>0.903925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>0.285537</td>\n",
       "      <td>0.904932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>0.284849</td>\n",
       "      <td>0.904948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>0.278817</td>\n",
       "      <td>0.906746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>0.277536</td>\n",
       "      <td>0.907118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83</td>\n",
       "      <td>0.271715</td>\n",
       "      <td>0.909420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>0.272950</td>\n",
       "      <td>0.908257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>0.267949</td>\n",
       "      <td>0.910908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>0.267074</td>\n",
       "      <td>0.910226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>0.264859</td>\n",
       "      <td>0.911730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>0.261970</td>\n",
       "      <td>0.911830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>0.261055</td>\n",
       "      <td>0.912357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>0.258420</td>\n",
       "      <td>0.913931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>0.259029</td>\n",
       "      <td>0.914124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>0.252780</td>\n",
       "      <td>0.916047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>0.254293</td>\n",
       "      <td>0.915706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>94</td>\n",
       "      <td>0.252153</td>\n",
       "      <td>0.915636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>95</td>\n",
       "      <td>0.248214</td>\n",
       "      <td>0.916496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.248230</td>\n",
       "      <td>0.917124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>0.247697</td>\n",
       "      <td>0.917953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>0.244995</td>\n",
       "      <td>0.918364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>0.245516</td>\n",
       "      <td>0.917527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>0.244579</td>\n",
       "      <td>0.918938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch      loss       acc\n",
       "0       1  3.144330  0.182346\n",
       "1       2  2.162593  0.381200\n",
       "2       3  1.775683  0.483848\n",
       "3       4  1.614309  0.523693\n",
       "4       5  1.491862  0.544449\n",
       "5       6  1.399065  0.560175\n",
       "6       7  1.329014  0.576242\n",
       "7       8  1.276682  0.588588\n",
       "8       9  1.234373  0.601004\n",
       "9      10  1.191572  0.614165\n",
       "10     11  1.150929  0.626387\n",
       "11     12  1.110102  0.640152\n",
       "12     13  1.074349  0.650925\n",
       "13     14  1.044831  0.661311\n",
       "14     15  1.012436  0.669844\n",
       "15     16  0.983294  0.679137\n",
       "16     17  0.955336  0.689492\n",
       "17     18  0.930459  0.696731\n",
       "18     19  0.906632  0.704024\n",
       "19     20  0.877986  0.713487\n",
       "20     21  0.856267  0.720006\n",
       "21     22  0.833336  0.728113\n",
       "22     23  0.812613  0.734173\n",
       "23     24  0.787767  0.741784\n",
       "24     25  0.766259  0.750015\n",
       "25     26  0.747368  0.755635\n",
       "26     27  0.728894  0.761300\n",
       "27     28  0.706465  0.768051\n",
       "28     29  0.695321  0.773097\n",
       "29     30  0.673937  0.778499\n",
       "..    ...       ...       ...\n",
       "70     71  0.307621  0.898174\n",
       "71     72  0.305948  0.898321\n",
       "72     73  0.300696  0.899507\n",
       "73     74  0.300903  0.900026\n",
       "74     75  0.298919  0.899585\n",
       "75     76  0.295143  0.901638\n",
       "76     77  0.288648  0.903685\n",
       "77     78  0.289749  0.903925\n",
       "78     79  0.285537  0.904932\n",
       "79     80  0.284849  0.904948\n",
       "80     81  0.278817  0.906746\n",
       "81     82  0.277536  0.907118\n",
       "82     83  0.271715  0.909420\n",
       "83     84  0.272950  0.908257\n",
       "84     85  0.267949  0.910908\n",
       "85     86  0.267074  0.910226\n",
       "86     87  0.264859  0.911730\n",
       "87     88  0.261970  0.911830\n",
       "88     89  0.261055  0.912357\n",
       "89     90  0.258420  0.913931\n",
       "90     91  0.259029  0.914124\n",
       "91     92  0.252780  0.916047\n",
       "92     93  0.254293  0.915706\n",
       "93     94  0.252153  0.915636\n",
       "94     95  0.248214  0.916496\n",
       "95     96  0.248230  0.917124\n",
       "96     97  0.247697  0.917953\n",
       "97     98  0.244995  0.918364\n",
       "98     99  0.245516  0.917527\n",
       "99    100  0.244579  0.918938\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('logs/training_log.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting training loss over epochs\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(df['epoch'], df['loss'])\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting training accuracy over epochs\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(df['epoch'], df['acc'])\n",
    "plt.title('Training Accuracy over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sample_model(vocab_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 512, batch_input_shape=(1, 1)))\n",
    "    for i in range(3):\n",
    "        model.add(LSTM(256, return_sequences=(i != 2), stateful=True))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(epoch, header, num_chars):\n",
    "    with open(os.path.join(DATA_DIR, 'char_to_idx.json')) as f:\n",
    "        char_to_idx = json.load(f)\n",
    "    idx_to_char = { i: ch for (ch, i) in char_to_idx.items() }\n",
    "    vocab_size = len(char_to_idx)\n",
    "\n",
    "    model = build_sample_model(vocab_size)\n",
    "    load_weights(epoch, model)\n",
    "    model.save(os.path.join(MODEL_DIR, 'model.{}.h5'.format(epoch)))\n",
    "\n",
    "    sampled = [char_to_idx[c] for c in header]\n",
    "    print(sampled)\n",
    "    \n",
    "\n",
    "    for i in range(num_chars):\n",
    "        batch = np.zeros((1, 1))\n",
    "        if sampled:\n",
    "            batch[0, 0] = sampled[-1]\n",
    "        else:\n",
    "            batch[0, 0] = np.random.randint(vocab_size)\n",
    "        result = model.predict_on_batch(batch).ravel()\n",
    "        sample = np.random.choice(range(vocab_size), p=result)\n",
    "        sampled.append(sample)\n",
    "\n",
    "    return ''.join(idx_to_char[c] for c in sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\prateeksood\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\prateeksood\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "[]\n",
      "D\"FAA \"G\"BAG|\"D\"F3 \"G\"G3:|\n",
      "\n",
      "\n",
      "X: 173\n",
      "T:Johny The Bous\n",
      "% Nottingham Music Database\n",
      "S:Trad, arr Phil Rowe\n",
      "M:6/8\n",
      "K:D\n",
      "A|\"D\"DFA d2d|\"A\"e2A ABc|\"D\"dcd \"Em\"edc|\"A7\"BcA \"D\"d2A|\n",
      "\"G\"B2G \"D7\"c2A|\"G\"BAG \"C\"E2G|\"A7\"ABc \"D\"def|\"Em\"g2f \"A7\"edc|\n",
      "\"D\"dAF D2D|\"G\"B2A B2c|\"G\"d3 \"A7\"Adc|\"D\"d3 \"A7\"a2g|\n",
      "\"D\"f2d f2a|\"D\"a2f def|\"Em\"g2e \"A7\"Ace|\"D\"fdf agf|\"D\"edA F2A|\n",
      "\"D\"DFA d2A|\"G\"BAB \"D\"def|\"G\"g2f \"Em\"deg|\"D\"fed \"G\"BAB|\n",
      "\"D\"ABA AFA|\"D\"dcd \"G\"BdB|\"D\"A2A \"Bm\"AGF|\"Em\"E2E \"A7\"EFG|\n",
      "\"D\"A3 f2e|\"D\"dcd \"A\"ABA|\"G\"Bcd \"A7\"efg|\"D\"fed d2::\n",
      "f|\"D\"abf\n"
     ]
    }
   ],
   "source": [
    "print(sample(100, '', 512))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
